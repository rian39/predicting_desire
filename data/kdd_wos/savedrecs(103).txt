PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
J	Blockeel, H; Kersting, K; Nijssen, S; Zelezny, F				Blockeel, Hendrik; Kersting, Kristian; Nijssen, Siegfried; Zelezny, Filip			Guest editor's introduction: special issue of the ECML PKDD 2013 journal track	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Blockeel, Hendrik; Nijssen, Siegfried] Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium; [Kersting, Kristian] Univ Bonn, Inst Geodesy & Geoinformat, D-53115 Bonn, Germany; [Kersting, Kristian] Fraunhofer IAIS, Dept Knowledge Discovery, D-53754 St Augustin, Germany; [Nijssen, Siegfried] Leiden Univ, Leiden Inst Adv Comp Sci, NL-2333 CA Leiden, Netherlands; [Zelezny, Filip] Czech Tech Univ, Fac Elect Engn, Prague 16627, Czech Republic	Blockeel, H (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Louvain, Belgium.	hendrik.blockeel@cs.kuleuven.be; kersting@igg.uni-bonn.de; siegfried.nijssen@cs.kuleuven.be; zelezny@fel.cvut.cz						0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		291	293		10.1007/s10618-013-0332-z		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200001	
J	Berlingerio, M; Pinelli, F; Calabrese, F				Berlingerio, Michele; Pinelli, Fabio; Calabrese, Francesco			ABACUS: frequent pAttern mining-BAsed Community discovery in mUltidimensional networkS	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Community discovery; Multidimensional networks; Social network analysis	COMPLEX NETWORKS; SOCIAL NETWORKS; MULTISCALE; CONSTRAINTS	Community discovery in complex networks is the problem of detecting, for each node of the network, its membership to one of more groups of nodes, the communities, that are densely connected, or highly interactive, or, more in general, similar, according to a similarity function. So far, the problem has been widely studied in monodimensional networks, i.e. networks where only one connection between two entities may exist. However, real networks are often multidimensional, i.e., multiple connections between any two nodes may exist, either reflecting different kinds of relationships, or representing different values of the same type of tie. In this context, the problem of community discovery has to be redefined, taking into account multidimensional structure of the graph. We define a new concept of community that groups together nodes sharing memberships to the same monodimensional communities in the different single dimensions. As we show, such communities are meaningful and able to group nodes even if they might not be connected in any of the monodimensional networks. We devise frequent pAttern mining-BAsed Community discoverer in mUltidimensional networkS (ABACUS), an algorithm that is able to extract multidimensional communities based on the extraction of frequent closed itemsets from monodimensional community memberships. Experiments on two different real multidimensional networks confirm the meaningfulness of the introduced concepts, and open the way for a new class of algorithms for community discovery that do not rely on the dense connections among nodes.	[Berlingerio, Michele; Pinelli, Fabio; Calabrese, Francesco] IBM Res, Dublin, Ireland	Berlingerio, M (reprint author), IBM Res, Dublin, Ireland.	michele.berlingerio@gmail.com; fabiopin@ie.ibm.com; fcalabre@ie.ibm.com					Ahn YY, 2010, NATURE, V466, P761, DOI 10.1038/nature09182; Balcan D, 2009, P NATL ACAD SCI USA, V106, P21484, DOI 10.1073/pnas.0906910106; Bastide Y., 2000, Computational Logic - CL 2000. First International Conference. Proceedings (Lecture Notes in Artificial Intelligence Vol.1861); Benevenuto F, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P49; Berlingerio M, 2011, J COMPUTATIONAL SCI, V2, P223; Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008; Bonchi F, 2005, KNOWL INF SYST, V8, P131, DOI 10.1007/s10115-004-0164-7; Bonchi F, 2005, ADV KNOWL DISCOV DAT, V3518, P173; Borgelt C, 2003, IEEE ICDM WORKSH FRE, P90; Bringmann B, 2010, IEEE INTELL SYST, V25, P26, DOI 10.1109/MIS.2010.91; Bringmann B, 2007, IEEE DATA MINING, P63; Cai D, 2005, EUR C MACH LEARN PRI, P445; Cerf L, 2009, LECT NOTES COMPUT SC, V5722, P513; Cerf L, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497580; Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111; Cook DJ, 2010, CYBERNET SYST, V41, P90, DOI 10.1080/01969720903584183; Coscia M, 2012, MULTIDIMENSIONAL NET, P1; Coscia M, 2011, ACM C INF KNOWL MAN, P2181; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; FRANCISCO AP, 2008, STRING PROCESSING IN, V5280, P188; Giannotti F, 2011, ACM INT C KNOWL DISC, P1190; Goyal A, 2008, ACM C INF KNOWL MAN, P499; Gregory S, 2009, STUD COMPUT INTELL, V207, P47; Gunnemann S, 2010, ICDM, P845; Han J, 2002, ICDM, P721; Huang Y, 2010, ACM C INF KNOWL MAN, P1453; Kleinberg J, 2010, ACM INT C WORLD WID, P641; Mongiovi M., 2012, IEEE INFOCOM 2012 - IEEE Conference on Computer Communications, DOI 10.1109/INFCOM.2012.6195503; Monreale A, 2011, INT C ADV SOC NETW A, P485; Mougel Pierre-Nicolas, 2012, Advances in Knowledge Discovery and Data Mining. Proceedings 16th Pacific-Asia Conference (PAKDD 2012), DOI 10.1007/978-3-642-30220-6_16; Mucha PJ, 2010, SCIENCE, V328, P876, DOI 10.1126/science.1184819; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Nijssen S, 2011, WORKSH IEEE INT C DA, P1120; Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607; Papadimitriou S, 2008, LECT NOTES ARTIF INT, V5212, P170, DOI 10.1007/978-3-540-87481-2_12; Pei J, 2001, PROC INT CONF DATA, P433; Pei J, 2000, ACM SIGKDD C, P350; Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106; Rath C, 2011, IEEE INT C SOC COMP; Rossetti G, 2011, WORKSH IEEE INT C DA, P979; Rosvall M, 2008, P NATL ACAD SCI USA, V105, P1118, DOI 10.1073/pnas.0706851105; Sun YZ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P797; Szell M, 2010, P NATL ACAD SCI USA, V107, P13636, DOI 10.1073/pnas.1004008107; Tang L, 2009, ACM C INF KNOWL MAN, P1107; Torgeson C, 2006, ACM INT C SCAL INF S, P1; Zeng Z, 2006, ACM INT C KNOWL DISC, P797; Zhou L, 2006, ICDE 2006 APR, P73	47	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		294	320		10.1007/s10618-013-0331-0		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200002	
J	Bonchi, F; Morales, GD; Gionis, A; Ukkonen, A				Bonchi, Francesco; De Francisci Morales, Gianmarco; Gionis, Aristides; Ukkonen, Antti			Activity preserving graph simplification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Information propagation; Graph sparsification; Submodular minimization	ALGORITHMS; NETWORKS	We study the problem of simplifying a given directed graph by keeping a small subset of its arcs. Our goal is to maintain the connectivity required to explain a set of observed traces of information propagation across the graph. Unlike previous work, we do not make any assumption about an underlying model of information propagation. Instead, we approach the task as a combinatorial problem. We prove that the resulting optimization problem is -hard. We show that a standard greedy algorithm performs very well in practice, even though it does not have theoretical guarantees. Additionally, if the activity traces have a tree structure, we show that the objective function is supermodular, and experimentally verify that the approach for size-constrained submodular minimization recently proposed by Nagano et al. (28th International Conference on Machine Learning, 2011) produces very good results. Moreover, when applied to the task of reconstructing an unobserved graph, our methods perform comparably to a state-of-the-art algorithm devised specifically for this task.	[Bonchi, Francesco; De Francisci Morales, Gianmarco] Yahoo Res Barcelona, Barcelona, Spain; [Ukkonen, Antti] Aalto Univ, HIIT, Espoo, Finland; [Gionis, Aristides] Aalto Univ, Dept Informat & Comp Sci, Espoo, Finland	Ukkonen, A (reprint author), Aalto Univ, HIIT, Espoo, Finland.	bonchi@yahoo-inc.com; gdfm@yahoo-inc.com; aristides.gionis@aalto.fi; antti.ukkonen@aalto.fi	Gionis, Aristides/G-2225-2013	Gionis, Aristides/0000-0002-5211-112X			Aihara K, 2011, P 28 INT C MACH LEAR, P977; Edmonds J, 2003, LECT NOTES COMPUT SC, V2570, P11; Elkin M, 2005, THEOR COMPUT SCI, V337, P249, DOI 10.1016/j.tcs.2004.11.022; Faloutsos C, 2007, P 24 INT C MACH LEAR, P497, DOI http://doi.acm.org/10.1145/1273496.1273559; Fujishige S, 2005, ANN DISCR MATH, V58, P1; Fung WS, 2011, ACM S THEORY COMPUT, P71; Arenas A, 2007, NEW J PHYS, V9, DOI 10.1088/1367-2630/9/6/176; Gomez-Rodriguez M., 2010, P 16 ACM SIGKDD INT, P1019, DOI 10.1145/1835804.1835933; Foti NJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016431; Iwata S, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1230; Jamali M, 2010, 2010 IEEE INT C DAT, P336, DOI 10.1109/ICDMW.2010.97; Kempe D, 2003, P 9 ACM SIGKDD INT C, P137; Krause A, 2010, J MACH LEARN RES, V11, P1141; Leskovec J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P497; Mathioudakis M., 2011, P 17 ACM SIGKDD INT, P529; Misiolek E, 2006, INFORM PROCESS LETT, V97, P197, DOI 10.1016/j.ipl.2005.11.002; NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971; PELEG D, 1989, J GRAPH THEOR, V13, P99, DOI 10.1002/jgt.3190130114; Quirin A, 2008, INFORM PROCESS MANAG, V44, P1611, DOI 10.1016/j.ipm.2007.09.005; Scholkopf B, 2011, P 28 INT C MACH LEAR, P561; Serrano E, 2010, INFORM SCIENCES, V180, P561, DOI 10.1016/j.ins.2009.11.007; Serrano MA, 2009, P NATL ACAD SCI USA, V106, P6483, DOI 10.1073/pnas.0808904106; Srikant R, 2001, P 10 INT WORLD WID W, P430, DOI 10.1145/371920.372097; Svitkina Z, 2011, SIAM J COMPUT, V40, P1715, DOI 10.1137/100783352; WOLFE P, 1976, MATH PROGRAM, V11, P128, DOI 10.1007/BF01580381; Zhou F, 2010, DAT MIN ICDM 2010 IE, P659; Zhou F, 2010, ADV INTELLIGENT DATA, VIX, P220	27	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		321	343		10.1007/s10618-013-0328-8		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200003	
J	Campello, RJGB; Moulavi, D; Zimek, A; Sander, J				Campello, R. J. G. B.; Moulavi, D.; Zimek, A.; Sander, J.			A framework for semi-supervised and unsupervised optimal extraction of clusters from hierarchies	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Hierarchical clustering; Optimal selection of clusters; Should-link and should-not-link constraints; Cluster quality	INSTANCE-LEVEL CONSTRAINTS; GENE-EXPRESSION DATA; TEXT CATEGORIZATION; DENSITY; NUMBER; TREE	We introduce a framework for the optimal extraction of flat clusterings from local cuts through cluster hierarchies. The extraction of a flat clustering from a cluster tree is formulated as an optimization problem and a linear complexity algorithm is presented that provides the globally optimal solution to this problem in semi-supervised as well as in unsupervised scenarios. A collection of experiments is presented involving clustering hierarchies of different natures, a variety of real data sets, and comparisons with specialized methods from the literature.	[Campello, R. J. G. B.; Moulavi, D.; Zimek, A.; Sander, J.] Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada; [Campello, R. J. G. B.] Univ Sao Paulo, Dept Comp Sci, Sao Carlos, SP, Brazil	Campello, RJGB (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada.	rcampell@ualberta.ca; moulavi@ualberta.ca; zimek@ualberta.ca; jsander@ualberta.ca			Fapesp / CNPq (Brazil); NSERC (Canada)	This study was supported by Fapesp / CNPq (Brazil) and NSERC (Canada).	Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; Aone C, 1999, INT C KNOWL DISC DAT; Bade K, 2008, SIAM INT C DAT MIN S; Bade K, 2007, LECT NOTES ARTIF INT, V4701, P518; Basu S, 2009, CH CRC DATA MIN KNOW, P1; Benkhalifa M, 2001, INT J INTELL SYST, V16, P929, DOI 10.1002/int.1042; Bohm C, 2008, INT C EXT DAT TECHN; Boudaillier E, 1997, LECT NOTES ARTIF INT, V1263, P288; Davidson I, 2009, DATA MIN KNOWL DISC, V18, P257, DOI 10.1007/s10618-008-0103-4; Davidson I, 2011, ACM SIGKDD INT C KNO; Davidson I, 2005, EUR C PRINC PRACT KN; De Raedt L, 1998, INT C MACH LEARN, P55; Ester M, 1996, INT C KNOWL DISC DAT; Everitt B.S, 2001, CLUSTER ANAL; Feng B, 2010, IEEE INT C DAT MIN I; Ferraretti D, 2009, INT C IT ASS ART INT; Frank A., 2010, UCI MACHINE LEARNING; Gargouri F, 2012, P 12 IND C DAT MIN, P194; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Gupta G, 2010, IEEE ACM T COMPUT BI, V7, P223, DOI 10.1109/TCBB.2008.32; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hebrail G, 1998, INTELL DATA ANAL, V2, P229, DOI 10.1016/S1088-467X(98)00026-2; Herbin M, 2001, PATTERN RECOGN LETT, V22, P1557, DOI 10.1016/S0167-8655(01)00103-9; Horta D, 2012, PATTERN RECOGN, V45, P4370, DOI 10.1016/j.patcog.2012.05.011; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Keim DA, 1998, INT C KNOWL DISC DAT; Kestler HA, 2007, 5 INT WORKSH MIN LEA, P1; Kettenring JR, 2006, J CLASSIF, V23, P3, DOI 10.1007/s00357-006-0002-6; Klein D, 2002, INT C MACH LEARN ICM; Kriegel HP, 2011, WIRES DATA MIN KNOWL, V1, P231, DOI 10.1002/widm.30; Lee SG, 2002, ACM S APPL COMP SAC; Lelis L, 2009, INT C DAT MIN ICDM; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Miyamoto S, 2010, IEEE INT C FUZZ SYST, P1, DOI 10.1109/FUZZY.2010.5584625; Miyamoto S, 2012, J ADV COMPUT INTELL, V16, P174; Naldi MC, 2011, APPL SOFT COMPUT, V11, P1938, DOI 10.1016/j.asoc.2010.06.010; Nurnberger A, 2006, IEEE WIC ACM INT C W; Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443; Pfeifle M, 2004, SIAM INT C DAT MIN S; Qi Z, 2010, INT C KNOWL DISC DAT; Sander J, 2003, PAC AS C KNOWL DISC; Schwenker F, 2006, IAPR WORKSH ART NEUR; Skarmeta AG, 2000, INT J INTELL SYST, V15, P633, DOI 10.1002/(SICI)1098-111X(200007)15:7<633::AID-INT4>3.3.CO;2-#; Struyf J, 2007, LECT NOTES ARTIF INT, V4701, P359; Stuetzle W, 2003, J CLASSIF, V20, P25, DOI 10.1007/s00357-003-0004-6; Stuetzle W, 2010, J COMPUT GRAPH STAT, V19, P397, DOI 10.1198/jcgs.2009.07049; Tan P-N, 2006, INTRO DATA MINING; Wagstaff KL, 2002, THESIS CORNELL U; Wagstaff KL, 2006, EUR C PRINC PRACT KN; Xiong TK, 2011, LECT NOTES ARTIF INT, V6634, P265; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977; Yeung KY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-5-r34; Zhao Y, 2005, DATA MIN KNOWL DISC, V10, P141, DOI 10.1007/s10618-005-0361-3; Zheng L, 2011, IEEE INT C DAT MIN I	55	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		344	371		10.1007/s10618-013-0311-4		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200004	
J	Letham, B; Rudin, C; Heller, KA				Letham, Benjamin; Rudin, Cynthia; Heller, Katherine A.			Growing a list	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Set completion; Ranking; Internet data mining; Collective intelligence	SET EXPANSION; WEB; EXTRACTION; RANK	It is easy to find expert knowledge on the Internet on almost any topic, but obtaining a complete overview of a given topic is not always easy: information can be scattered across many sources and must be aggregated to be useful. We introduce a method for intelligently growing a list of relevant items, starting from a small seed of examples. Our algorithm takes advantage of the wisdom of the crowd, in the sense that there are many experts who post lists of things on the Internet. We use a collection of simple machine learning components to find these experts and aggregate their lists to produce a single complete and meaningful list. We use experiments with gold standards and open-ended experiments without gold standards to show that our method significantly outperforms the state of the art. Our method uses the ranking algorithm Bayesian Sets even when its underlying independence assumption is violated, and we provide a theoretical generalization bound to motivate its use.	[Letham, Benjamin] MIT, Ctr Operat Res, Cambridge, MA 02139 USA; [Rudin, Cynthia] MIT, MIT Sloan Sch Management, Cambridge, MA 02139 USA; [Heller, Katherine A.] Duke Univ, Ctr Cognit Neurosci, Durham, NC USA	Letham, B (reprint author), MIT, Ctr Operat Res, Cambridge, MA 02139 USA.	bletham@mit.edu; rudin@mit.edu; kheller@gmail.com			MIT Lincoln Laboratory; NSF [IIS-1053407]; NSF; NIH [P30 DA028803]	Cynthia Rudin acknowledges funding from MIT Lincoln Laboratory and from NSF IIS-1053407. Katherine Heller acknowledges funding from a NSF postdoctoral fellowship and NIH P30 DA028803.	Baeza-Yates R, 2011, ADV TOPICS INFORM RE; Beg MMS, 2003, WORLD WIDE WEB, V6, P5, DOI 10.1023/A:1022344031752; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; de Rijke M, 2007, P 16 ACM C INF KNOWL, P959, DOI 10.1145/1321440.1321585; Dwork C., 2001, P 10 INT C WORLD WID, P613, DOI DOI 10.1145/371920.372165; Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001; Hsu DF, 2005, INFORM RETRIEVAL, V8, P449, DOI 10.1007/s10791-005-6994-4; Freitag D., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Ghahramani Z, 2006, P IEEE COMP SOC C CO, P2110; Grossman R, 2003, P 9 ACM SIGKDD INT C, P601; Heller KA, 2005, ADV NEURAL INFORM PR, V18, P435; Hruschka ER, 2010, P 24 C ART INT AAAI; Jindal P., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), DOI 10.1109/ICDM.2011.86; Kikui G, 2011, P 49 ANN M ASS COMP, V2, P726; Kozareva Z., 2008, P ACL 08 HLT, P1048; Kushmerick N, 1997, THESIS U WASHINGTON; Le HQ, 2010, P 2010 INT C AS LANG, P170; LIU B., 2005, P 14 INT C WORLD WID, P76, DOI 10.1145/1060745.1060761; LOCHOVSKY F., 2003, P 12 INT C WORLD WID, P187; Chang CC, 2001, OSA TRENDS OPT PHOTO, V62, P681, DOI 10.1145/371920.372182; Mitchell TM, 2010, P ACM INT C WEB SEAR, P101, DOI 10.1145/1718487.1718501; Pantel P., 2009, P 2009 C EMP METH NA, P938; Pasca M, 2007, P CIKM 07, P683, DOI 10.1145/1321440.1321536; Pasca M, 2007, P 16 WORLD WID WEB C, P101, DOI 10.1145/1242572.1242587; Renda ME, 2003, P 2003 ACM S APPL CO, P841; Sarawagi S, 2009, PVLDB, V2, P289; Soderland S, 1999, MACH LEARN, V34, P233, DOI 10.1023/A:1007562322031; Verma S, 2012, P 2012 EUR C MACH LE, P307; Wang RC, 2007, IEEE DATA MINING, P342; Wang RC, 2008, IEEE DATA MINING, P1091, DOI 10.1109/ICDM.2008.145; Zhang L, 2011, P 22 ACM C HYP HYP H, P281	31	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		372	395		10.1007/s10618-013-0329-7		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200005	
J	Lo, YC; Li, JY; Yeh, MY; Lin, SD; Pei, J				Lo, Yi-Chen; Li, Jhao-Yin; Yeh, Mi-Yen; Lin, Shou-De; Pei, Jian			What distinguish one from its peers in social networks?	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Social query; Node identification; Social networks		Being able to discover the uniqueness of an individual is a meaningful task in social network analysis. This paper proposes two novel problems in social network analysis: how to identify the uniqueness of a given query vertex, and how to identify a group of vertices that can mutually identify each other. We further propose intuitive yet effective methods to identify the uniqueness identification sets and the mutual identification groups of different properties. We further conduct an extensive experiment on both real and synthetic datasets to demonstrate the effectiveness of our model.	[Lo, Yi-Chen; Lin, Shou-De] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan; [Li, Jhao-Yin; Yeh, Mi-Yen] Acad Sinica, Inst Informat Sci, Taipei, Taiwan; [Yeh, Mi-Yen] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 115, Taiwan; [Pei, Jian] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Yeh, MY (reprint author), Acad Sinica, Inst Informat Sci, Taipei, Taiwan.	d00922006@csie.ntu.edu.tw; louisjyli@iis.sinica.edu.tw; miyen@iis.sinica.edu.tw; sdlin@csie.ntu.edu.tw; jpei@cs.sfu.ca			National Science Council of Taiwan, R.O.C. [NSC101-2221-E-001-013]; National Science Council; National Taiwan University; Intel Corporation [NSC100-2911-I-002-001, NSC101-2628-E-002-028-MY2, NTU102R7501]; NSERC; BCFRST NRAS Endowment Research Team Program project	Mi-Yen Yeh's research is supported in part by National Science Council of Taiwan, R.O.C., under Contracts NSC101-2221-E-001-013. Shou-De Lin's research is supported by National Science Council, National Taiwan University and Intel Corporation under Grants NSC100-2911-I-002-001, NSC101-2628-E-002-028-MY2 and NTU102R7501. Jian Pei's research is supported in part by an NSERC Discovery Grant and a BCFRST NRAS Endowment Research Team Program project. All opinions, findings, conclusions and recommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies.	Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47; Chen M-S, 2011, P INT C VER LARG DAT; Erd&0151s P., 1961, B I INT STATIST TOKY, V38, P343; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Gionis A, 2010, P ACM SIGKDD INT C K; Lin S-D, 2009, ASONAM 2009; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; Shan M-K, 2010, IEEE SOCIALCOM; Tang J, 2008, P ACM SIGKDD INT C K; Terzi E, 2009, P ACM SIGKDD INT C K; Watts D, 1998, NATURE, V363, P202; Wen J-R, 2009, P INT WORLD WID WEB; Zhou B, 2008, P IEEE INT C DAT ENG	13	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		396	420		10.1007/s10618-013-0330-1		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200006	
J	Tatti, N				Tatti, Nikolaj			Fast sequence segmentation using log-linear models	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Segmentation; Pruning; Change-point detection; Dynamic program		Sequence segmentation is a well-studied problem, where given a sequence of elements, an integer K, and some measure of homogeneity, the task is to split the sequence into K contiguous segments that are maximally homogeneous. A classic approach to find the optimal solution is by using a dynamic program. Unfortunately, the execution time of this program is quadratic with respect to the length of the input sequence. This makes the algorithm slow for a sequence of non-trivial length. In this paper we study segmentations whose measure of goodness is based on log-linear models, a rich family that contains many of the standard distributions. We present a theoretical result allowing us to prune many suboptimal segmentations. Using this result, we modify the standard dynamic program for 1D log-linear models, and by doing so reduce the computational time. We demonstrate empirically, that this approach can significantly reduce the computational burden of finding the optimal segmentation.	[Tatti, Nikolaj] Univ Antwerp, Dept Math & Comp Sci, B-2020 Antwerp, Belgium; [Tatti, Nikolaj] Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium	Tatti, N (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium.	nikolaj.tatti@gmail.com			Post-Doctoral Fellowship of the Research Foundation-Flanders (FWO)	Nikolaj Tatti was partly supported by a Post-Doctoral Fellowship of the Research Foundation-Flanders (FWO).	Basseville M., 1993, DETECTION ABRUPT CHA; BELLMAN R, 1961, COMMUN ACM, V4, P284, DOI 10.1145/366573.366611; BernaolaGalvan P, 1996, PHYS REV E, V53, P5181, DOI 10.1103/PhysRevE.53.5181; Calders T, 2007, IEEE DATA MINING, P83; Douglas D., 1973, CANADIAN CARTOGRAPHE, V10, P112, DOI DOI 10.3138/FM57-6770-U75U-7727; Dzeroski S, 2010, INDUCTIVE DATABASES AND CONSTRAINT-BASED DATA MINING, P1; Gedikli A, 2010, STOCH ENV RES RISK A, V24, P547, DOI 10.1007/s00477-009-0335-x; Gionis A, 2003, P 7 INT C RES COMP M, P123, DOI 10.1145/640075.640091; Grunwald P. D., 2007, MINIMUM DESCRIPTION; Haiminen N, 2004, ICDM 04, P106; Himberg J, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P203; Keogh EJ, 2004, ICDE, P339; Kifer D, 2004, VLDB, P180; Lavrenko V, 2000, KDD WORKSH TEXT MIN, P37; Lin J, 2005, ICDM, P226; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shatkay H, 1996, ICDE 96, P536; Tsaparas P, 2006, SIAM DATA MINING	18	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		421	441		10.1007/s10618-012-0301-y		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200007	
J	De Bie, T; Flach, PA				De Bie, Tijl; Flach, Peter A.			Guest editors' introduction: special section of selected papers from ECML-PKDD 2012	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[De Bie, Tijl; Flach, Peter A.] Univ Bristol, Intelligent Syst Lab, Bristol, Avon, England	De Bie, T (reprint author), Univ Bristol, Intelligent Syst Lab, Bristol, Avon, England.	tijl.debie@gmail.com					Cristianini Nello, 2012, LECT NOTES COMPUTE 1, V7523; Flach Peter A., 2012, LECT NOTES COMPUTE 2, V7524	2	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		442	443		10.1007/s10618-013-0325-y		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200008	
J	Wang, YY; Ramon, J; Fannes, T				Wang, Yuyi; Ramon, Jan; Fannes, Thomas			An efficiently computable subgraph pattern support measure: counting independent observations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph mining; Frequency counting; Overlap graph; Linear program; Variance on sample estimates	GRAPH; FREQUENT	Graph support measures are functions measuring how frequently a given subgraph pattern occurs in a given database graph. An important class of support measures relies on overlap graphs. A major advantage of overlap-graph based approaches is that they combine anti-monotonicity with counting the occurrences of a subgraph pattern which are independent according to certain criteria. However, existing overlap-graph based support measures are expensive to compute. In this paper, we propose a new support measure which is based on a new notion of independence. We show that our measure is the solution to a sparse linear program, which can be computed efficiently using interior point methods. We study the anti-monotonicity and other properties of this new measure, and relate it to the statistical power of a sample of embeddings in a network. We show experimentally that, in contrast to earlier overlap-graph based proposals, our support measure makes it feasible to mine subgraph patterns in large networks.	[Wang, Yuyi; Ramon, Jan; Fannes, Thomas] Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium	Wang, YY (reprint author), Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium.	yuyi.wang@cs.kuleuven.be; jan.ramon@cs.kuleuven.be; thomas.fannes@cs.kuleuven.be			ERC [240186]	This work was supported by ERC Starting Grant 240186 "MiGraNT: Mining Graphs and Networks: a Theory-based approach".	Agrawal R., 1993, P 1993 ACM SIGMOD IN, V22, P207; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Berlingerio M, 2009, LECT NOTES ARTIF INT, V5781, P115; Borgelt C, 2007, P WORKSH MIN LEARN G; Boyd S., 2004, CONVEX OPTIMIZATION; Bringmann B, 2008, LECT NOTES ARTIF INT, V5012, P858, DOI 10.1007/978-3-540-68125-0_84; Calders T, 2011, DATA MIN KNOWL DISC, V23, P503, DOI 10.1007/s10618-011-0217-y; Chakrabarti D, 2006, ACM COMPUT SURV, V38, P2, DOI DOI 10.1145/1132952.1132954; Chan THH, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1- 4, P2808, DOI 10.1109/ISIT.2009.5205779; Diestel R., 2010, GRAPH THEORY; Dreweke A, 2007, CGO 2007: INTERNATIONAL SYMPOSIUM ON CODE GENERATION AND OPTIMIZATION, P259; FAGIN R, 1976, J SYMBOLIC LOGIC, V41, P50, DOI 10.2307/2272945; Garey M. R., 1979, COMPUTERS INTRACTIBI; Iyengar G, 2011, SIAM J OPTIMIZ, V21, P231, DOI 10.1137/090762671; Kibriya AM, 2012, P ECML PKDD 2012 BRI, P426; Klein P., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237980; Knuth D. E., 1994, ELECTRON J COMB, V1, P1; Kuramochi M, 2005, DATA MIN KNOWL DISC, V11, P243, DOI 10.1007/s10618-005-0003-9; LOVASZ L, 1979, IEEE T INFORM THEORY, V25, P1, DOI 10.1109/TIT.1979.1055985; Luigi P, 2004, IEEE T PATTERN ANAL, V26, P1367; Markopoulou A, 2010, P IEEE INFOCOM 2010, P1; SCHRIJVER A, 1979, IEEE T INFORM THEORY, V25, P425, DOI 10.1109/TIT.1979.1056072; Szegedy M, 1991, APPROXIMATING CLIQUE, P2; Vanetik N., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183988; Vanetik N, 2006, DATA MIN KNOWL DISC, V13, P243, DOI 10.1007/s10618-006-0044-8; Wang Y, 2012, P ECML PKDD 2012 BRI, P362	26	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		444	477		10.1007/s10618-013-0318-x		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200009	
J	Kibriya, AM; Ramon, J				Kibriya, Ashraf M.; Ramon, Jan			Nearly exact mining of frequent trees in large networks	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph mining; Pattern mining; Pattern matching; Isomorphism; Subgraph isomorphism; Homomorphism	GRAPH DATA; ALGORITHM; ISOMORPHISM	Mining frequent patterns in a single network (graph) poses a number of challenges. Already only to match one path pattern to a network under subgraph isomorphism is NP-complete. Classical matching algorithms become intractable even for reasonably small patterns, on networks which are large or have a high average degree. Based on recent advances in parameterized complexity theory, we propose a novel miner for rooted trees in networks. The miner, for a fixed parameter (maximal pattern size), can mine all rooted trees with delay linear in the size of the network and only mildly exponential in the fixed parameter . This allows us to mine tractably, rooted trees, in large networks such as the WWW or social networks. We establish the practical applicability of our miner, by presenting an experimental evaluation on both synthetic and real-world data.	[Kibriya, Ashraf M.; Ramon, Jan] Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium	Kibriya, AM (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium.	ashraf.kibriya@cs.kuleuven.be; jan.ramon@cs.kuleuven.be			ERC [240186]	This research is supported by ERC Starting Grant 240186 "MiGraNT: Mining Graphs and Networks, a Theory-Based Approach". We thank Anton Dries and Constantin Commendant for the valuable suggestions.	Berlingerio M, 2009, LECT NOTES ARTIF INT, V5781, P115; BLUM M, 1995, J ASSOC COMPUT MACH, V42, P269, DOI 10.1145/200836.200880; Bogdanov P., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), DOI 10.1109/ICDM.2011.101; Borgelt C, 2005, P 1 INT WORKSH OP SO, P6, DOI 10.1145/1133905.1133908; Borgelt C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183885; Calders T, 2011, DATA MIN KNOWL DISC, V23, P503, DOI 10.1007/s10618-011-0217-y; Chehreghani M, 2011, 2011 IEEE 11 INT C D, P111; Chen J, 2001, J ALGORITHM, V41, P280, DOI 10.1006/jagm.2001.1186; Chi Y, 2005, IEEE T KNOWL DATA EN, V17, P190; Chi Y, 2004, P 16 INT C SCI STAT, P11, DOI DOI 10.1109/SSDBM.2004.41; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Cook DJ, 2000, IEEE INTELL SYST APP, V15, P32, DOI 10.1109/5254.850825; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; De Wolf R, 1997, LECT NOTES COMPUTER, V1228; Diestel R., 2010, GRAPH THEORY; Dries A, 2012, P 12 SIAM INT C DAT, P260; Fierens D, 2005, LECT NOTES ARTIF INT, V3625, P121; Frasconi P, 2007, P ACL WORKSH GRAMM B, P1, DOI 10.3115/1626333.1626335; Gallagher B, 2008, P 14 ACM SIGKDD INT, P256, DOI 10.1145/1401890.1401925; Getoor L, 2007, INTRO STAT RELATIONA; Gjoka M, 2010, P IEEE INFOCOM 10; Hasan MA, 2009, PVLDB, V2, P730; Horvath T, 2010, KNOWL DISCOV DATA MI, V21, P472; Horvath T, 2010, THEOR COMPUT SCI, V411, P2784, DOI 10.1016/j.tcs.2010.03.030; Huan J, 2003, P 3 IEEE INT C DAT M, P549; Huan J, 2004, P 10 ACM SIGKDD INT, P581, DOI 10.1145/1014052.1014123; Inokuchi A, 2000, LECT NOTES COMPUT<D>, V1910, P13; Jiang X, 2009, DATA KNOWL ENG, V68, P1034, DOI 10.1016/j.datak.2009.04.008; Karlapalem K, 2010, ACM T KNOWL DISCOV D, V4, P10; Kibriya AM, 2012, P ECML PKDD 2012 BRI, P426; Koutis I, 2008, LECT NOTES COMPUT SC, V5125, P575, DOI 10.1007/978-3-540-70575-8_47; Koutis I, 2009, LECT NOTES COMPUT SC, V5555, P653, DOI 10.1007/978-3-642-02927-1_54; Kuramochi M, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P313; Kuramochi M, 2005, DATA MIN KNOWL DISC, V11, P243, DOI 10.1007/s10618-005-0003-9; Li L, 2011, P 17 ACM SIGKDD INT, P663; Motwani R., 1995, RANDOMIZED ALGORITHM; Nijssen S, 2005, ELECT NOTES THEORETI, V127, P77, DOI 10.1016/j.entcs.2004.12.039; Nijssen S, 2005, P INT WORKSH GRAPH B; Nijssen S, 2004, P 10 ACM SIGKDD INT, P647, DOI 10.1145/1014052.1014134; Nijssen S, COMMUNICATION; ROBSON JM, 1986, J ALGORITHM, V7, P425, DOI 10.1016/0196-6774(86)90032-5; Rossi RA, 2012, J ARTIF INTELL RES, V45, P363; Sansone C, 2001, 3 IAPR TC15 WORKSH G, P149; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; Wang Y, 2012, LECT NOTES COMPUTER, V7523, P362; WORLEIN M, 2005, P 9 EUR C PRINC PRAC, V3721, P392; Yan X., 2002, P 2002 IEEE INT C DA, P721; YAN X, 2003, P 9 ACM SIGKDD INT C, P286	48	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2013	27	3			SI		478	504		10.1007/s10618-013-0321-2		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	191ZR	WOS:000322454200010	
J	Dhurandhar, A				Dhurandhar, Amit			Using coarse information for real valued prediction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Regression; Hierarchical; Coarse-to-fine	REGRESSION	In domains such as consumer products and manufacturing amongst others, we have problems that warrant the prediction of a continuous target. Besides the usual set of explanatory attributes, we may also have exact (or approximate) estimates of aggregated targets, which are the sums of disjoint sets of individual targets that we are trying to predict. The question now becomes can we use these aggregated targets, which are a coarser piece of information, to improve the quality of predictions of the individual targets? In this paper, we provide a simple yet provable way of accomplishing this. In particular, given predictions from any regression model of the target on the test data, we elucidate a provable method for improving these predictions in terms of mean squared error, given exact (or accurate enough) information of the aggregated targets. These estimates of the aggregated targets may be readily available or obtained-through multilevel regression-at different levels of granularity. Based on the proof of our method we suggest a criterion for choosing the appropriate level. Moreover, in addition to estimates of the aggregated targets, if we have exact (or approximate) estimates of the mean and variance of the target distribution, then based on our general strategy we provide an optimal way of incorporating this information so as to further improve the quality of predictions of the individual targets. We then validate the results and our claims by conducting experiments on synthetic and real industrial data obtained from diverse domains.	IBM TJ Watson, Yorktown Hts, NY 10598 USA	Dhurandhar, A (reprint author), IBM TJ Watson, Yorktown Hts, NY 10598 USA.	adhuran@us.ibm.com					Arnold A, 2007, KNOWLEDGE DISCOVERY; Dhurandhar A, 2010, LARG SCAL AN COMPL I; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; Hastie T, 2009, ELEMENTS STAT LEARNI; Jackson C, 2008, J ROY STAT SOC A STA, V171, P159; Liu Y, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225; Munoz D., 2010, ECCV; Park MY, 2007, BIOSTATISTICS, V8, P212, DOI 10.1093/biostatistics/kxl002; Raudenbush S., 2002, HIERARCHICAL LINEAR; Sapp B, 2010, ECCV; Singer JD, 2003, APPL LONGITUDINAL DA; Slav P, 2009, THESIS UC BERKELEY; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Weiss D, 2010, P AISTATS	15	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2013	27	2					167	192		10.1007/s10618-012-0287-5		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	167WG	WOS:000320665500001	
J	Hossain, MS; Ramakrishnan, N; Davidson, I; Watson, LT				Hossain, M. Shahriar; Ramakrishnan, Naren; Davidson, Ian; Watson, Layne T.			How to "alternatize" a clustering algorithm	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Clustering; Alternative clustering	CONTINGENCY TABLE; CONSTRAINTS; CONSENSUS; NETWORKS; MODEL	Given a clustering algorithm, how can we adapt it to find multiple, nonredundant, high-quality clusterings? We focus on algorithms based on vector quantization and describe a framework for automatic 'alternatization' of such algorithms. Our framework works in both simultaneous and sequential learning formulations and can mine an arbitrary number of alternative clusterings. We demonstrate its applicability to various clustering algorithms-k-means, spectral clustering, constrained clustering, and co-clustering-and effectiveness in mining a variety of datasets.	[Hossain, M. Shahriar] Virginia State Univ, Dept Math & Comp Sci, Petersburg, VA 23806 USA; [Ramakrishnan, Naren; Watson, Layne T.] Virginia Polytech Inst & State Univ, Dept Comp Sci, Blacksburg, VA 24061 USA; [Watson, Layne T.] Virginia Polytech Inst & State Univ, Dept Math, Blacksburg, VA 24061 USA; [Davidson, Ian] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA	Hossain, MS (reprint author), Virginia State Univ, Dept Math & Comp Sci, 1 Hayden Dr, Petersburg, VA 23806 USA.	mshossain@vsu.edu			Institute for Critical Technology and Applied Science-Virginia Tech; US National Science Foundation [CCF-0937133]; AFRL [FA8650-09-2-3938]; AFOSR [FA9550-09-1-0153]	This work is supported in part by the Institute for Critical Technology and Applied Science-Virginia Tech, the US National Science Foundation through grants CCF-0937133, AFRL through grant FA8650-09-2-3938, and AFOSR through grant FA9550-09-1-0153.	Agrawal R., 1998, SIGMOD Record, V27; Bae E, 2006, IEEE DATA MINING, P53; Banerjee A, 2007, SDM 07, P225; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Brohee S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-488; Caruana R, 2006, IEEE DATA MINING, P107; Chakrabarti D., 2004, KDD, P79; Cheng C, 1999, KNOWLEDGE DISCOVERY, P84; Conn AR, 1992, LANCELOT FORTRAN PAC, V17; Cui Y, 2007, IEEE DATA MINING, P133; Dang X, 2010, SDM, P118; Dang X, 2010, KDD 10, P573; Davidson I, 2007, TKDD, P1; Davidson I, 2008, IEEE DATA MINING, P773, DOI 10.1109/ICDM.2008.141; Dhillon I. S., 2003, KDD, P89; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Dunn J. C., 1974, Journal of Cybernetics, V4; Friedman N, 2001, UNCERTAINTY ARTIFICI, P152; Gondek D, 2007, KNOWL INF SYST, V12, P1, DOI 10.1007/s10115-006-0009-7; Gondek D, 2005, SIAM PROC S, P126; Gondek D, 2005, KDD 05, P70; Govaert G, 2003, PATTERN RECOGN, V36, P463; GREENACRE MJ, 1988, J CLASSIF, V5, P39, DOI 10.1007/BF01901670; Hossain MS, 2010, KDD 10, P593; Jain P, 2008, SDM 08, P858; Kaski S, 2005, IEEE ACM T COMPUT BI, V2, P203, DOI 10.1109/TCBB.2005.32; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kullback S, 1978, INFORM CONTINGENCY T; Li T, 2007, IEEE DATA MINING, P577; Malakooti B, 2004, IEEE T SYST MAN CY B, V34, P40, DOI 10.1109/TSMCB.2003.811114; Miettinen K, 1999, EUR J OPER RES, V119, P50, DOI 10.1016/S0377-2217(98)00352-X; Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487; Nadif M, 2005, LECT NOTES COMPUT SC, V3646, P249; Niu D, 2010, ICML 10, P831; Qi ZJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P717; Ross DA, 2006, J MACH LEARN RES, V7, P2369; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Sinkkonen J, 2002, LECT NOTES ARTIF INT, V2430, P418; Sinkkonen J, 2002, NEURAL COMPUT, V14, P217, DOI 10.1162/089976602753284509; Sinkkonen J, 2004, LECT NOTES COMPUT SC, V3201, P396; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Tadepalli S, 2009, THESIS VIRGINIA TECH; Tan P.N, 2005, INTRO DATA MINING; Vinh NX, 2010, ICDM 10, P521; Wang X, 2010, KDD 10, P563; Zeng YJ, 2002, CSB2002: IEEE COMPUTER SOCIETY BIOINFORMATICS CONFERENCE, P276; Zhang W, 2009, ICML 09, P1241	47	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2013	27	2					193	224		10.1007/s10618-012-0288-4		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	167WG	WOS:000320665500002	
J	Chen, ZZ; Hendrix, W; Guan, H; Tetteh, IK; Choudhary, A; Semazzi, F; Samatova, NF				Chen, Zhengzhang; Hendrix, William; Guan, Hang; Tetteh, Isaac K.; Choudhary, Alok; Semazzi, Fredrick; Samatova, Nagiza F.			Discovery of extreme events-related communities in contrasting groups of physical system networks	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Spatio-temporal data mining; Complex network analysis; Community detection; Comparative analysis; Networkmotif detection; Extreme event prediction	TROPICAL CYCLONE ACTIVITY; ABSOLUTE DEVIATION REGRESSION; ATLANTIC HURRICANE SEASON; BIOLOGICAL NETWORKS; CLIMATE VARIABILITY; OUTLIER DETECTION; COMPLEX NETWORKS; EL-NINO; PREDICTION; TEMPERATURE	The latent behavior of a physical system that can exhibit extreme events such as hurricanes or rainfalls, is complex. Recently, a very promising means for studying complex systems has emerged through the concept of complex networks. Networks representing relationships between individual objects usually exhibit community dynamics. Conventional community detection methods mainly focus on either mining frequent subgraphs in a network or detecting stable communities in time-varying networks. In this paper, we formulate a novel problem-detection of predictive and phase-biased communities in contrasting groups of networks, and propose an efficient and effective machine learning solution for finding such anomalous communities. We build different groups of networks corresponding to different system's phases, such as higher or low hurricane activity, discover phase-related system components as seeds to help bound the search space of community generation in each network, and use the proposed contrast-based technique to identify the changing communities across different groups. The detected anomalous communities are hypothesized (1) to play an important role in defining the target system's state(s) and (2) to improve the predictive skill of the system's states when used collectively in the ensemble of predictive models. When tested on the two important extreme event problems-identification of tropical cyclone-related and of African Sahel rainfall-related climate indices-our algorithm demonstrated the superior performance in terms of various skill and robustness metrics, including 8-16 % accuracy increase, as well as physical interpretability of detected communities. The experimental results also show the efficiency of our algorithm on synthetic datasets.	[Chen, Zhengzhang; Hendrix, William; Tetteh, Isaac K.; Semazzi, Fredrick; Samatova, Nagiza F.] N Carolina State Univ, Raleigh, NC 27695 USA; [Chen, Zhengzhang; Samatova, Nagiza F.] Oak Ridge Natl Lab, Oak Ridge, TN 37831 USA; [Guan, Hang] Zhejiang Univ, Hangzhou 31000, Zhejiang, Peoples R China; [Choudhary, Alok] Northwestern Univ, Evanston, IL 60201 USA	Samatova, NF (reprint author), Oak Ridge Natl Lab, Oak Ridge, TN 37831 USA.	samatova@csc.ncsu.edu			U.S. Department of Energy, Office of Science; Office of Advanced Scientific Computing Research (ASCR); Office of Biological and Environmental Research (BER); U.S. National Science Foundation; LLC U.S. D.O.E. [DEAC05-00OR22725]	The authors would like to thank the editor and the anonymous reviewers for their valuable comments and suggestions to improve the paper. This work was supported in part by the U.S. Department of Energy, Office of Science, the Office of Advanced Scientific Computing Research (ASCR) and the Office of Biological and Environmental Research (BER) and the U.S. National Science Foundation (Expeditions in Computing). Oak Ridge National Laboratory is managed by UT-Battelle for the LLC U.S. D.O.E. under contract no. DEAC05-00OR22725.	Balasundaram B, 2011, OPER RES, V59, P133, DOI 10.1287/opre.1100.0851; Borgelt C, 2002, IEEE INT C DAT MIN I, P51; Breiman L, 1984, CLASSIFICATION REGRE; Camargo S, 2010, J CLIMATOL, V23, P3057; Chakrabarti D, 2004, SIAM INT C DAT MIN; Chakrabarti D, 2004, LECT NOTES ARTIF INT, V3202, P112; Chan PK, 2005, ICDM, P90; Chen Zhi-min, 2011, Journal of Gun Launch & Control; Cheng H, 2008, IEEE INT C DAT MIN W, P349; Chu PS, 2007, TERR ATMOS OCEAN SCI, V18, P805, DOI 10.3319/TAO.2007.18.4.805(A); Clark JD, 2002, J METEOROL SOC JPN, V80, P403, DOI 10.2151/jmsj.80.403; Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111; Donges JF, 2009, EUR PHYS J-SPEC TOP, V174, P157, DOI 10.1140/epjst/e2009-01098-2; Eberle W, 2007, ICDM VORKSH, P393; Elsner J, 2001, AMS, V84, P353; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; Ganguly AR, 2009, P NATL ACAD SCI USA, V106, P15555, DOI 10.1073/pnas.0904495106; Gill R, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-95; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Goldenberg SB, 1996, J CLIMATE, V9, P1169, DOI 10.1175/1520-0442(1996)009<1169:PMFTAO>2.0.CO;2; Gozolchiani A, 2008, EPL-EUROPHYS LETT, V83, DOI 10.1209/0295-5075/83/28005; Hey T., 2009, 4 PARADIGM DATA INTE; Jensen LJ, 2009, NUCLEIC ACIDS RES, V37, pD412, DOI 10.1093/nar/gkn760; Jolliffe I. T., 2003, FORECAST VERIFICATIO; Kalaev M, 2008, LECT N BIOINFORMAT, V4955, P246; Kawale J, 2011, CIDU, P189; Kim HM, 2010, GEOPHYS RES LETT, V37, DOI 10.1029/2010GL044792; Kim HS, 2010, INT J CLIMATOL, V30, P210, DOI 10.1002/joc.1878; Magill T, 2008, NWD, V32, P1; Moonesinghe HDK, 2006, PROC INT C TOOLS ART, P532; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Pei J., 2005, Proceedings. 21st International Conference on Data Engineering; Pei J, 2005, P 11 ACM SIGKDD INT, P228, DOI 10.1145/1081870.1081898; Peng JY, 2008, BMEI 2008: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS, VOL 1, P677, DOI 10.1109/BMEI.2008.187; Saunders MA, 1997, GEOPHYS RES LETT, V24, P1255, DOI 10.1029/97GL01164; SEIDMAN SB, 1978, J MATH SOCIOL, V6, P139; Sharan R, 2005, J COMPUT BIOL, V12, P835, DOI 10.1089/cmb.2005.12.835; Steinhaeuser K, 2009, SENSORKDD 09, P23; Steinhaeuser Karsten, 2011, Statistical Analysis and Data Mining, V4, DOI 10.1002/sam.10100; Sun J, 2006, KDD 06, P374; Sun JM, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P687; Sutton RT, 2000, J CLIMATE, V13, P3261, DOI 10.1175/1520-0442(2000)013<3261:TEOCVI>2.0.CO;2; Tan Aik Choon, 2003, Appl Bioinformatics, V2, pS75; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088; Tsonis AA, 2011, CLIM DYNAM, V37, P933, DOI 10.1007/s00382-010-0874-3; Tsonis AA, 2007, GEOPHYS RES LETT, V34, DOI 10.1029/2007GL030288; Tsonis AA, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.228502; Tsonis AA, 2006, B AM METEOROL SOC, V87, P585, DOI 10.1175/BAMS-87-5-585; Tsonis AA, 2008, J CLIMATE, V21, P2990, DOI 10.1175/2007JCLI1907.1; Tsonis AA, 2004, PHYSICA A, V333, P497, DOI 10.1016/j.physa.2003.10.045; Wakita K, 2007, ABSCS0702048 CORR; Xie L, 2005, GEOPHYS RES LETT, V32, DOI 10.1029/2004GL021702; Yeshanew A, 2007, THEOR APPL CLIMATOL, V89, P51, DOI 10.1007/s00704-006-0262-4; Zeng Z, 2006, P 12 ACM SIGKDD INT, P797, DOI [10.1145/1150402.1150506, DOI 10.1145/1150402.1150506]; Zeng Z, 2007, ACM T DATABASE SYST, V32, DOI 10.1145/1242524.1242530; Zhang B, 2009, BIOINFORMATICS, V25, P526, DOI 10.1093/bioinformatics/btn660	56	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2013	27	2					225	258		10.1007/s10618-012-0289-3		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	167WG	WOS:000320665500003	
J	Naldi, MC; Carvalho, ACPLF; Campello, RJGB				Naldi, M. C.; Carvalho, A. C. P. L. F.; Campello, R. J. G. B.			Cluster ensemble selection based on relative validity indexes	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Cluster ensemble selection; Combination; Relative validity indexes; Evaluation; Diversity	VALIDATION; PARTITIONS; EFFICIENCY; ALGORITHM; NUMBER	Cluster ensemble aims at producing high quality data partitions by combining a set of different partitions produced from the same data. Diversity and quality are claimed to be critical for the selection of the partitions to be combined. To enhance these characteristics, methods can be applied to evaluate and select a subset of the partitions that provide ensemble results similar or better than those based on the full set of partitions. Previous studies have shown that this selection can significantly improve the quality of the final partitions. For such, an appropriate evaluation of the candidate partitions to be combined must be performed. In this work, several methods to evaluate and select partitions are investigated, most of them based on relative clustering validity indexes. These indexes select the partitions with the highest quality to participate in the ensemble. However, each relative index can be more suitable for particular data conformations. Thus, distinct relative indexes are combined to create a final evaluation that tends to be robust to changes in the application scenario, as the majority of the combined indexes may compensate the poor performance of some individual indexes. We also investigate the impact of the diversity among partitions used for the ensemble. A comparative evaluation of results obtained from an extensive collection of experiments involving state-of-the-art methods and statistical tests is presented. Based on the obtained results, a practical design approach is proposed to support cluster ensemble selection. This approach was successfully applied to real public domain data sets.	[Naldi, M. C.] Fed Univ Vicosa UFV, BR-38810000 Rio Paranaiba, MG, Brazil; [Carvalho, A. C. P. L. F.; Campello, R. J. G. B.] Univ Sao Paulo, BR-13560970 Sao Carlos, SP, Brazil	Naldi, MC (reprint author), Fed Univ Vicosa UFV, Post Box 22, BR-38810000 Rio Paranaiba, MG, Brazil.	murilocn@ufv.br; andre@icmc.usp.br; campello@icmc.usp.br			CNPq; FAPESP	The authors acknowledge the Brazilian Research Agencies CNPq and FAPESP for financial support.	Aeberhard S, 1992, 02 J COOK U N QUEENS; Alcock R, 1999, 7 HELL C INF IOANN G, P27; ASUNCION A., 2007, UCI MACHINE LEARNING; Ayad HG, 2008, IEEE T PATTERN ANAL, V30, P160, DOI 10.1109/TPAMI.2007.1138; Azimi J, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P992; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Bollacker KD, 1998, INT C MACH LEARN, P64; Calinski RB, 1974, COMMUNICATIONS STAT, V3, P1; Caruana R, 2006, IEEE DATA MINING, P828; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dimitriadou E, 2003, THESIS TU WIEN WIEN; Dimitriadou E, 1999, FUZZY NEURO SYSTEMS, P63; Dudoit S, 2003, BIOINFORMATICS, V19, P1090, DOI 10.1093/bioinformatics/btg038; Dunn J. C., 1974, Journal of Cybernetics, V4; DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330; Fern X., 2008, J STAT ANAL DATA MIN, V1; Fern X.Z., 2004, P 21 INT C MACH LEAR, P36; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Greene D, 2004, CBMS 04, P576, DOI DOI 10.1109/CBMS.2004.40; Hadjitodorov ST, 2007, LECT NOTES COMPUT SC, V4472, P200; Hadjitodorov ST, 2006, INFORM FUSION, V7, P264, DOI 10.1016/j.inffus.2005.01.008; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Handl J, 2007, IEEE T EVOLUT COMPUT, V11, P56, DOI 10.1109/TEVC.2006.877146; Hochberg Y., 1987, MULTIPLE COMP PROCED; Hollander M, 1999, NONPARAMETRIC STAT M; Hruschka ER, 2004, LECT NOTES ARTIF INT, V3315, P861; Hruschka ER, 2004, P 4 IEEE INT C DAT M, P403; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jaccard P., 1908, B SOCIETE VAUDOISE S, V44, P223; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997; Kasturi J, 2004, SAC 04, P116, DOI [10.1145/967900.967926, DOI 10.1145/967900.967926]; Kaufman L., 1990, WILEY SERIES PROBABI; Kuncheva L, 2006, INT C INF FUS, P1, DOI 10.1109/ICIF.2006.301614; Kuncheva LI, 2004, IEEE SYS MAN CYBERN, P1214; Kuncheva LI, 2004, COMBINING PATTERN CL; Mangasarian O. L., 1990, SIAM NEWS, V23; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487; Naldi MC, 2011, APPL SOFT COMPUT, V11, P1938, DOI 10.1016/j.asoc.2010.06.010; Ng AY, 2002, ADV NEUR IN, V14, P849; Pakhira MK, 2004, PATTERN RECOGN, V37, P487, DOI 10.1016/j.patcog.2003.06.005; Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Topchy A, 2004, P SIAM INT C DAT MIN, P331; Tumer K, 2008, PATTERN RECOGN LETT, V29, P1947, DOI 10.1016/j.patrec.2008.06.011; Vendramin L., 2009, SIAM INT C DAT MIN S, P733; Walpole RE, 2006, PROBABILITY STAT ENG; Weingessel A, 2003, DISTR STAT COMP DSC, P1; Yeung KY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-5-r34	54	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2013	27	2					259	289		10.1007/s10618-012-0290-x		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	167WG	WOS:000320665500004	
J	Lou, TC; Tang, J; Hopcroft, J; Fang, ZP; Ding, XW				Lou, Tiancheng; Tang, Jie; Hopcroft, John; Fang, Zhanpeng; Ding, Xiaowen			Learning to Predict Reciprocity and Triadic Closure in Social Networks	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Social network; reciprocal relationship; social influence; predictive model; link prediction; Twitter	LINK-PREDICTION; TIES	We study how links are formed in social networks. In particular, we focus on investigating how a reciprocal (two-way) link, the basic relationship in social networks, is developed from a parasocial (one-way) relationship and how the relationships further develop into triadic closure, one of the fundamental processes of link formation. We first investigate how geographic distance and interactions between users influence the formation of link structure among users. Then we study how social theories including homophily, social balance, and social status are satisfied over networks with parasocial and reciprocal relationships. The study unveils several interesting phenomena. For example, "friend's friend is a friend" indeed exists in the reciprocal relationship network, but does not hold in the parasocial relationship network. We propose a learning framework to formulate the problems of predicting reciprocity and triadic closure into a graphical model. We demonstrate that it is possible to accurately infer 90% of reciprocal relationships in a Twitter network. The proposed model also achieves better performance (+20-30% in terms of F1-measure) than several alternative methods for predicting the triadic closure formation.	[Lou, Tiancheng; Ding, Xiaowen] Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing, Peoples R China; [Tang, Jie; Fang, Zhanpeng] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China; [Hopcroft, John] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Lou, TC (reprint author), Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing, Peoples R China.	tiancheng.lou@gmail.com			National Basic Research Program of China [2011CBA00300, 2011CBA00301, 2011CB302302]; National Natural Science Foundation of China [61033001, 61061130540, 61073174]; Natural Science Foundation of China [61073073, 612222212]; Chinese National Key Foundation Research [60933013, 61035004]; U.S. Air Force Office of Scientific Research [FA9550-09-1-0675]	T. Lou and X. Ding are supported in part by the National Basic Research Program of China grant 2011CBA00300, 2011CBA00301, the National Natural Science Foundation of China grant 61033001, 61061130540, 61073174. J. Tang is supported by the Natural Science Foundation of China (no. 61073073, no. 612222212), National Basic Research Program of China (no. 2011CB302302), and Chinese National Key Foundation Research (no. 60933013, no. 61035004). J. Hopcroft was partially supported by the U.S. Air Force Office of Scientific Research under grant FA9550-09-1-0675.	Backstrom L., 2008, P INT C WEB SEARCH W, P117, DOI 10.1145/1341531.1341549; Backstrom L, 2011, P 4 ACM INT C WEB SE, P635, DOI 10.1145/1935826.1935914; CHA M., 2010, P AAAI INT C WEBL SO; Crandall DJ, 2010, P NATL ACAD SCI USA, V107, P22436, DOI 10.1073/pnas.1006155107; Diehl C. P., 2007, P 22 NAT C ART INT, V1, P546; EAGLE N., 2009, PNAS, V106, P36; Easley D., 2010, NETWORKS CROWDS MARK; HAMMERSLEY J. M., 1971, MARKOV FIELD FINITE; HE J., 2011, P 8 INT C ALG MOD WE; Hopcroft J. E., 2011, P 20 ACM INT C INF K, P1137; HORTON D, 1956, PSYCHIATR, V19, P215; HUBERMAN B., 2009, 1 MONDAY, V14, P118; JAVA A., 2007, P 9 INT WORKSH KNOWL, P118; KATZ L, 1953, PSYCHOMETRIKA, V18, P39; Kwak H, 2010, P 19 INT C WORLD WID, P591, DOI DOI 10.1145/1772690.1772751; Lafferty J, 2001, P 18 INT C MACH LEAR, P282; LAZARSFELD P. F., 1954, FREEDOM CONTROL MODE, P8; Leskovec J., 2010, P 19 INT C WORLD WID, P641, DOI 10.1145/1772690.1772756; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; LICHTENWALTER R., 2010, P 16 ACM SIGKDD INT, P243, DOI 10.1145/1835804.1835837; MATHIOUDAKIS M., 2010, P 2010 INT C MAN DAT, P1155, DOI DOI 10.1145/1807167.180730; Murphy K P, 1999, P UNC AI, P467; Newman MEJ, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.025102; PAGE L., 1999, SIDLWP19990120 STANF; ROMERO D. M., 2010, P AAAI INT C WEBL SO; Sakaki T., 2010, P 19 INT C WORLD WID, P851, DOI DOI 10.1145/1772690.1772777; Tan C., 2010, P 16 ACM SIGKDD INT, P1049, DOI 10.1145/1835804.1835936; Tang J., 2012, P 18 ACM SIGKDD INT; Tang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P807; TANG J., 2012, P 5 ACM INT C WEB SE, P743; TANG J., 2011, P 17 ACM SIGKDD INT, P1397; Tang WB, 2011, LECT NOTES ARTIF INT, V6913, P381; Wang C, 2007, IEEE DATA MINING, P322; Wang CM, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING 2010, VOL 3, P203, DOI 10.1145/1835804.1835833; WEBER M., 1991, NATURE SOCIAL ACTION; Weng J, 2010, P 3 ACM INT C WEB SE, P261, DOI DOI 10.1145/1718487.1718520; Wu S, 2011, P 20 INT C WORLD WID, P705, DOI 10.1145/1963405.1963504; XING E. P, 2003, P 19 ANN C UNC ART I, P583; YANG Z, 2010, P 19 ACM INT C INF K, P1633, DOI 10.1145/1871437.1871691; Zhuang HL, 2012, DATA MIN KNOWL DISC, V25, P270, DOI 10.1007/s10618-012-0274-x	40	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2013	7	2								10.1145/2499907.2499908		25	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	192JB	WOS:000322479200001	
J	Peng, J; Seetharaman, G; Fan, W; Varde, A				Peng, Jing; Seetharaman, Guna; Fan, Wei; Varde, Aparna			Exploiting Fisher and Fukunaga-Koontz Transforms in Chernoff Dimensionality Reduction	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Feature evaluation and selection; Chernoff distance; dimensionality reduction; FKT; LDA	SINGULAR-VALUE DECOMPOSITION; SAMPLE-SIZE PROBLEM; LINEAR DISCRIMINANT-ANALYSIS; LDA; CRITERION; DISTANCE; RECOGNITION; SELECTION	Knowledge discovery from big data demands effective representation of data. However, big data are often characterized by high dimensionality, which makes knowledge discovery more difficult. Many techniques for dimensionality reudction have been proposed, including well-known Fisher's Linear Discriminant Analysis (LDA). However, the Fisher criterion is incapable of dealing with heteroscedasticity in the data. A technique based on the Chernoff criterion for linear dimensionality reduction has been proposed that is capable of exploiting heteroscedastic information in the data. While the Chernoff criterion has been shown to outperform the Fisher's, a clear understanding of its exact behavior is lacking. In this article, we show precisely what can be expected from the Chernoff criterion. In particular, we show that the Chernoff criterion exploits the Fisher and Fukunaga-Koontz transforms in computing its linear discriminants. Furthermore, we show that a recently proposed decomposition of the data space into four subspaces is incomplete. We provide arguments on how to best enrich the decomposition of the data space in order to account for heteroscedasticity in the data. Finally, we provide experimental results validating our theoretical analysis.	[Peng, Jing; Varde, Aparna] Montclair State Univ, Dept Comp Sci, Montclair, NJ 07043 USA; [Fan, Wei] Huawei Noah Ark Lab, Hong Kong, Hong Kong, Peoples R China	Peng, J (reprint author), Montclair State Univ, Dept Comp Sci, Montclair, NJ 07043 USA.	pengj@mail.montclair.edu			Visiting Faculty Research Program from the Information Directorate of the Air Force Research Laboratory	The research reported in this work was partially and indirectly supported by the Visiting Faculty Research Program from the Information Directorate of the Air Force Research Laboratory. The support is duly acknowledged. Any opinions, findings and conclusions and recommendations expressed in this material are those of the authors, and do not necessarily reflect the views of the AFRL. Cleared for public dissemination, with a case number 88ABW-2011-4332.	BELHUMEUR V.I., 1997, IEEE T PATTERN ANAL, V19, P711; BELLMAN R. E., 1961, ADAPTIVE CONTROL PRE; Bian W, 2011, IEEE T PATTERN ANAL, V33, P1037, DOI 10.1109/TPAMI.2010.189; Breiman L, 1984, CLASSIFICATION REGRE; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; CHUNG JK, 1989, J MATH ANAL APPL, V138, P280, DOI 10.1016/0022-247X(89)90335-1; COOTES T.F., 1992, P BRIT MACH VIS C, P9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dai G, 2006, LECT NOTES COMPUT SC, V3954, P308; Decell H. P.  Jr., 1977, Computers & Mathematics with Applications, V3, DOI 10.1016/0898-1221(77)90116-X; DEVIJVER P.A., 1982, RECOGNITION STAT APP; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; ETEMAD K., 1996, P INT C AC SPEECH SI, P2148; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; FUKUNAGA F, 1970, IEEE T COMPUT, V. 19, P311; Fukunaga K., 1990, INTRO STAT PATTERN R; GU Q., 2011, P EUR C MACH LEARN; Hamsici OC, 2008, IEEE T PATTERN ANAL, V30, P647, DOI 10.1109/TPAMI.2007.70717; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; Huang R, 2002, INT C PATT RECOG, P29; Huo X., 2003, P SPIE C; JUO D., 2011, P 25 NAT C ART INT A, P417; Kira K., 1992, P 9 INT C MACH LEARN, P249; KUMAR N., 1996, P JOINT M AM STAT AS; Kyperountas M, 2007, IEEE T NEURAL NETWOR, V18, P506, DOI 10.1109/TNN.2006.885038; Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; NAYAR S. K., 1994, P IEEE C COMP VIS PA, P471; PAIGE CC, 1981, SIAM J NUMER ANAL, V18, P398, DOI 10.1137/0718026; Pentland A., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), DOI 10.1109/CVPR.1994.323814; Rueda L, 2008, PATTERN RECOGN, V41, P3138, DOI 10.1016/j.patcog.2008.01.016; SUN Y., 2008, P SIAM INT C DAT MIN; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VANLOAN CF, 1976, SIAM J NUMER ANAL, V13, P76, DOI 10.1137/0713009; Ye JP, 2005, J MACH LEARN RES, V6, P483; Ye JP, 2005, IEEE T PATTERN ANAL, V27, P929; Zhang S, 2007, IEEE T PATTERN ANAL, V29, P1732, DOI 10.1109/TPAMI.2007.1089; Zhang W, 2007, P ICML, P1135, DOI 10.1145/1273496.1273639	41	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2013	7	2								10.1145/2499907.2499911		25	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	192JB	WOS:000322479200004	
J	Yang, HQ; Lyu, MR; King, I				Yang, Haiqin; Lyu, Michael R.; King, Irwin			Efficient Online Learning for Multitask Feature Selection	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Supervised learning; online learning; multitask learning; feature selection; dual averaging method	MULTIPLE TASKS; ALGORITHMS; REGULARIZATION; OPTIMIZATION	Learning explanatory features across multiple related tasks, or MultiTask Feature Selection (MTFS), is an important problem in the applications of data mining, machine learning, and bioinformatics. Previous MTFS methods fulfill this task by batch-mode training. This makes them inefficient when data come sequentially or when the number of training data is so large that they cannot be loaded into the memory simultaneously. In order to tackle these problems, we propose a novel online learning framework to solve the MTFS problem. A main advantage of the online algorithm is its efficiency in both time complexity and memory cost. The weights of the MTFS models at each iteration can be updated by closed-form solutions based on the average of previous subgradients. This yields the worst-case bounds of the time complexity and memory cost at each iteration, both in the order of O(d x Q), where d is the number of feature dimensions and Q is the number of tasks. Moreover, we provide theoretical analysis for the average regret of the online learning algorithms, which also guarantees the convergence rate of the algorithms. Finally, we conduct detailed experiments to show the characteristics and merits of the online learning algorithms in solving several MTFS problems.	[Yang, Haiqin; Lyu, Michael R.; King, Irwin] Chinese Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China	Yang, HQ (reprint author), Chinese Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.	hqyang@cse.cuhk.edu.hk			National Basic Research Program of China (973 Project) [2011CB302603]; Basic Research Program of Shenzhen [JCYJ20120619152419087]; Research Grants Council of the Hong Kong SAR, China [CUHK413210, CUHK415311]	This work was supported by the National Basic Research Program of China (973 Project no. 2011CB302603), the Basic Research Program of Shenzhen (Project no. JCYJ20120619152419087), and two grants from the Research Grants Council of the Hong Kong SAR, China (Project nos. CUHK413210 and CUHK415311).	AAKER D. A., 2006, MARKETING RES; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; ARGYRIOU A., 2006, ADV NEURAL INFORM PR, V19, P41; BAI J., 2009, P 18 ACM C INF KNOWL, P1549, DOI 10.1145/1645953.1646169; BAKKER B., 2003, J MACH LEARN RES, V4, P83, DOI DOI 10.1162/153244304322765658; Balakrishnan S, 2008, J MACH LEARN RES, V9, P313; Ben-David S, 2008, MACH LEARN, V73, P273, DOI 10.1007/s10994-007-5043-5; Ben-David S, 2003, LECT NOTES ARTIF INT, V2777, P567, DOI 10.1007/978-3-540-45167-9_41; Boyd S., 2004, CONVEX OPTIMIZATION; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; CHEN J., 2012, ACM T KNOWL DISCOV D, V5, P4; CHEN J., 2010, P 16 ACM SIGKDD INT, P1179, DOI 10.1145/1835804.1835952; CHEN J, 2009, P 26 ANN INT C MACH, P18; Chen XT, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON ADVANCED FIBERS AND POLYMER MATERIALS, VOLS 1 AND 2, P746; DEKEL O, 2006, P 19 ANN C LEARN THE, P453; Dhillon PS, 2011, J MACH LEARN RES, V12, P525; Dhillon PS, 2009, LECT NOTES ARTIF INT, V5781, P276; Duchi J., 2009, J MACHINE LEARNING R, V10, P2873; EVGENIOU T., 2004, P 10 ACM SIGKDD INT, P109, DOI 10.1145/1014052.1014067; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; FRIEDMAN J., 2010, NOTE GROUP LASSO SPA; Han J, 2006, DATA MINING CONCEPTS; HAN Y., 2010, P 24 AAAI C ART INT; Hazan E, 2007, MACH LEARN, V69, P169, DOI 10.1007/s10994-007-5016-8; Jebara T, 2011, J MACH LEARN RES, V12, P75; JEBARA T., 2004, P 21 INT C MACH LEAR; KWOK J, 2009, ADV NEURAL INFORM PR, VAdv. Neural Inf. Process. Syst, p[22, 781]; Langford J, 2009, J MACH LEARN RES, V10, P777; Lenk PJ, 1996, MARKET SCI, V15, P173, DOI 10.1287/mksc.15.2.173; LING G., 2012, P IEEE WORLD C COMP, P1; LIU H., 2009, P 26 ANN INT C MACH, P649; Liu J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P547; Liu J., 2009, SLEP SPARSE LEARNING; LIU J., 2009, P 25 C UNC ART INT U; Nesterov Y, 2009, MATH PROGRAM, V120, P221, DOI 10.1007/s10107-007-0149-x; OBOZINSKI G., 2009, STAT COMPUT, V20, P231; Pong TK, 2010, SIAM J OPTIMIZ, V20, P3465, DOI 10.1137/090763184; QUATTONI A., 2009, P 26 INT C MACH LEAR, P857; Shalev-Shwartz S, 2007, MACH LEARN, V69, P115, DOI 10.1007/s10994-007-5014-x; Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807, DOI DOI 10.1145/1273496.1273598; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vapnik V., 1999, NATURE STAT LEARNING; Xiao L, 2010, J MACH LEARN RES, V11, P2543; XU Z., 2010, P 27 INT C MACH LEAR, P1175; YANG H., 2010, P 27 INT C MACH LEAR, P1191; YANG H., 2011, SPARSE LEARNING REGU; YANG H., 2010, P IEEE INT INT TECHN, P1, DOI 10.1109/NLPKE.2010.5587840; YANG H., 2010, P 19 ACM C INF KNOWL, P1693, DOI 10.1145/1871437.1871706; Yang HQ, 2011, IEEE T NEURAL NETWOR, V22, P433, DOI 10.1109/TNN.2010.2103571; ZHANG Y., 2010, P 24 AAAI C ART INT; ZHANG Y., 2010, ADV NEURAL INF PROCE, V23, P2559; ZHAO P, 2011, P 28 INT C MACH LEAR, P233; Zhao PL, 2011, J MACH LEARN RES, V12, P1587; ZHOU Y, 2010, P 14 INT C ART INT S; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	56	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2013	7	2								10.1145/2499907.2499909		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	192JB	WOS:000322479200002	
J	Zhang, Y; Yeung, DY				Zhang, Yu; Yeung, Dit-Yan			Multilabel Relationship Learning	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Multilabel learning; label relationship	LABEL CLASSIFICATION; TEXT CATEGORIZATION	Multilabel learning problems are commonly found in many applications. A characteristic shared by many multilabel learning problems is that some labels have significant correlations between them. In this article, we propose a novel multilabel learning method, called MultiLabel Relationship Learning (MLRL), which extends the conventional support vector machine by explicitly learning and utilizing the relationships between labels. Specifically, we model the label relationships using a label covariance matrix and use it to define a new regularization term for the optimization problem. MLRL learns the model parameters and the label covariance matrix simultaneously based on a unified convex formulation. To solve the convex optimization problem, we use an alternating method in which each subproblem can be solved efficiently. The relationship between MLRL and two widely used maximum margin methods for multilabel learning is investigated. Moreover, we also propose a semisupervised extension of MLRL, called SSMLRL, to demonstrate how to make use of unlabeled data to help learn the label covariance matrix. Through experiments conducted on some multilabel applications, we find that MLRL not only gives higher classification accuracy but also has better interpretability as revealed by the label covariance matrix.	[Zhang, Yu] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; [Yeung, Dit-Yan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Zhang, Y (reprint author), Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	yuzhang@comp.hkbu.edu.hk			Research Grants Council of Hong Kong [621310]	D.-Y. Yeung has been supported by General Research Fund 621310 from the Research Grants Council of Hong Kong.	Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Argyriou A., 2008, ADV NEURAL INFORM PR, V20, P25; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Boyd S., 2004, CONVEX OPTIMIZATION; BUCAK S. S., 2009, P 12 IEEE INT C COMP; CESA-BIANCHI N., 2006, P 23 INT C MACH LEAR, P177, DOI 10.1145/1143844.1143867; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chapelle O, 2006, SEMISUPERVISED LEARN; CHEN G., 2008, P SIAM INT C DAT MIN, P410; Clare A, 2001, P 5 EUR C PRINC DAT, P42; DINUZZO F, 2011, P 28 INT C MACH LEAR, P49; DINUZZO F., 2011, P 3 AS C MACH LEARN, P181; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Furnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8; Gupta A. K., 2000, MATRIX VARIATE DISTR; HARIHARAN B., 2010, P 27 INT C MACH LEAR, P423; Ji SW, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1754428.1754431; JOACHIMS T., 1998, ADV KERNEL METHODS S, P169; Kwok JTY, 1999, IEEE T NEURAL NETWOR, V10, P1018, DOI 10.1109/72.788642; LIU Y., 2006, P 21 NAT C ART INT; Read J, 2009, LECT NOTES ARTIF INT, V5782, P254; Rousu J, 2006, J MACH LEARN RES, V7, P1601; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SEBER G. A. F., 2007, MATRIX HDB STAT; SREBRO N., 2004, ADV NEURAL INF PROCE, V17, P1329; Tsoumakas G, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P667, DOI 10.1007/978-0-387-09823-4_34; Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101; Vens C, 2008, MACH LEARN, V73, P185, DOI 10.1007/s10994-008-5077-3; Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009; Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang Y, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 6, P733; ZHOU D., 2003, ADV NEURAL INFORM PR, V16, P321; Zhu X., 2003, P 20 INT C MACH LEAR, V20, P912	35	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2013	7	2								10.1145/2499907.2499910		30	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	192JB	WOS:000322479200003	
J	Hammer, B; Keim, D; Lawrence, N; Lebanon, G				Hammer, Barbara; Keim, Daniel; Lawrence, Neil; Lebanon, Guy			Preface: Intelligent interactive data visualization	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Hammer, Barbara] Univ Bielefeld, CITEC Ctr Excellence, D-33615 Bielefeld, Germany; [Keim, Daniel] Univ Konstanz, Dept Comp & Informat Sci, Constance, Germany; [Lawrence, Neil] Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England; [Lebanon, Guy] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Hammer, B (reprint author), Univ Bielefeld, CITEC Ctr Excellence, D-33615 Bielefeld, Germany.	bhammer@techfak.uni-bielefeld.de; Daniel.Keim@uni-konstanz.de; N.Lawrence@dcs.sheffield.ac.uk; lebanon@cc.gatech.edu						0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2013	27	1			SI		1	3		10.1007/s10618-013-0309-y		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	131GB	WOS:000317979600001	
J	Lafon, S; Bouali, F; Guinot, C; Venturini, G				Lafon, Sebastien; Bouali, Fatma; Guinot, Christiane; Venturini, Gilles			On studying a 3D user interface for OLAP	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						OLAP; 3D interfaces; Visual data mining; User study; Virtual reality		In this paper, a new visual and interactive user interface for OLAP is presented, and its strengths and weaknesses examined. A survey on 3D interfaces for OLAP is detailed, which shows that only one interface that uses Virtual Reality has been proposed. Then we present our approach: it consists of a 3D representation of OLAP cubes where many OLAP operators have been integrated and where several measures can be visualized. A 3D stereoscopic screen can be used in conjunction with a 3D mouse. Finally a user study is reported that compares standard dynamic cross-tables with our interface on different tasks. We conclude that 3D with stereoscopy is not as promising as expected even with recent 3D devices.	[Lafon, Sebastien; Venturini, Gilles] Univ Tours, Comp Sci Lab, F-37200 Tours, France; [Bouali, Fatma] Univ Lille 2, IUT, F-59100 Roubaix, France; [Guinot, Christiane] CERIES, F-92521 Neuilly Sur Seine, France	Venturini, G (reprint author), Univ Tours, Comp Sci Lab, 64 Ave Jean Portalis, F-37200 Tours, France.	sebastien.lafon@live.fr; fatma.bouali@univ-lille2.fr; christiane.guinot@ceries-lab.com; venturini@univ-tours.fr					Ammoura A, 2001, DAT WAR KNOWL DISC 3, V2114, P174, DOI 10.1007/3-540-44801-2_18; Bulusu P, 2003, THESIS U FLORIDA GAI; Chaudhuri Q., 1997, ACM SIGMOD REC, V26, P65; Codd E., 1993, TECHNICAL REPORT; CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892; Cuzzocrea A., 2009, ENCY DATA WAREHOUSIN, P1439; Eick SG, 2000, IEEE T VIS COMPUT GR, V6, P44, DOI 10.1109/2945.841120; Han J, 1997, CASCON 97, P249; O'Donnell P, 2004, P 2004 IFIP INT C DE; Scotch M, 2007, J USABILITY STUDIES, V2, P76; Shneiderman B, 2003, IEEE COMPUT GRAPH, V23, P6; Siegel S, 1988, NONPARAMETRIC STAT B; Sifer M, 2006, IEEE S VIS ANAL, P175; Stolte C, 2008, COMMUN ACM, V51, P75, DOI 10.1145/1400214.1400234; Verbeke G., 1997, LINEAR MIXED MODELS; Wattenberg M., 2006, P SIGCHI C HUM FACT, P811, DOI 10.1145/1124772.1124891; Wegman EJ, 2002, J COMPUT GRAPH STAT, V11, P163, DOI 10.1198/106186002317375668	17	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2013	27	1			SI		4	21		10.1007/s10618-012-0279-5		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	131GB	WOS:000317979600002	
J	Vellido, A; Garcia, DL; Nebot, A				Vellido, Alfredo; Garcia, David L.; Nebot, Angela			Cartogram visualization for nonlinear manifold learning models	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Cartogram; Data visualization; Generative topographic mapping; Manifold learning; Nonlinear mapping distortion; Magnification factor	CORTICAL MAGNIFICATION FACTOR; SELF-ORGANIZING MAPS; KNOWLEDGE DISCOVERY; NEURAL GAS; GTM; PROJECTION; MULTICENTER; EXPLORATION; ALGORITHM; DATABASE	Real-world applications of multivariate data analysis often stumble upon the barrier of interpretability. Simple data analysis methods are usually easy to interpret, but they risk providing poor data models. More involved methods may instead yield faithful data models, but limited interpretability. This is the case of linear and nonlinear methods for multivariate data visualization through dimensionality reduction. Even though the latter have provided some of the most exciting visualization developments, their practicality is hindered by the difficulty of explaining them in an intuitive manner. The interpretability, and therefore the practical applicability, of data visualization through nonlinear dimensionality reduction (NLDR) methods would improve if, first, we could accurately calculate the distortion introduced by these methods in the visual representation and, second, if we could faithfully reintroduce this distortion into such representation. In this paper, we describe a technique for the reintroduction of the distortion into the visualization space of NLDR models. It is based on the concept of density-equalizing maps, or cartograms, recently developed for the representation of geographic information. We illustrate it using Generative Topographic Mapping (GTM), a nonlinear manifold learning method that can provide both multivariate data visualization and a measure of the local distortion that the model generates. Although illustrated here with GTM, it could easily be extended to other NLDR visualization methods, provided a local distortion measure could be calculated. It could also serve as a guiding tool for interactive data visualization.	[Vellido, Alfredo; Garcia, David L.; Nebot, Angela] Univ Politecn Cataluna, Dept Llenguatges & Sistemes Informat, ES-08034 Barcelona, Spain	Vellido, A (reprint author), Univ Politecn Cataluna, Dept Llenguatges & Sistemes Informat, C Jordi Girona 1-3, ES-08034 Barcelona, Spain.	avellido@lsi.upc.edu; david@lsi.upc.edu; angela@lsi.upc.edu			Spanish R+D projects [TIN2009-13895-C02-01, TIN2012-31377]	Authors gratefully acknowledge former INTERPRET European project partners for the availability of the neuro oncology data. Data providers: Dr. C. Majos (IDI), Dr. A Moreno-Torres (CDP), Dr. F. A. Howe and Prof. J. Griffiths (SGUL), Prof. A. Heerschap (RU), Prof. L. Stefanczyk and Dr. J. Fortuniak (MUL), and Dr. J. Calvar (FLENI); data curators: Drs. Julia-Sape, Candiota and Olier, Ms. Delgado, Ms. Martin and Mr. Perez (GABRMN-UAB). Prof. C. Arus, GABRMN coordinator. This research was partially funded by Spanish R+D TIN2009-13895-C02-01 and TIN2012-31377 projects.	Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732; Aupetit M, 2007, NEUROCOMPUTING, V70, P1304, DOI 10.1016/j.neucom.2006.11.018; Bishop CM, 1998, NATO ADV SCI I D-BEH, V89, P371; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Bishop CM, 1997, IEE CONF PUBL, P64, DOI 10.1049/cp:19970703; Bishop CM, 1997, WSOM 97 WKSHP SELF O, P333; Bishop CM, 1998, IEEE T PATTERN ANAL, V20, P281, DOI 10.1109/34.667885; Cruz-Barbosa R, 2011, INT J NEURAL SYST, V21, P17, DOI 10.1142/S0129065711002626; Cruz-Barbosa R, 2010, PATTERN RECOGN LETT, V31, P202, DOI 10.1016/j.patrec.2009.09.029; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dey T. K., 1999, ADV DISCRETE COMPUTA, V223, P109; Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836; Fayyad U, 1996, AI MAG, V17, P37; Furukawa T, 2009, NEURAL NETWORKS, V22, P463, DOI 10.1016/j.neunet.2009.01.012; Gastner MT, 2004, P NATL ACAD SCI USA, V101, P7499, DOI 10.1073/pnas.0400280101; Gisbrecht A, 2011, NEUROCOMPUTING, V74, P1359, DOI 10.1016/j.neucom.2010.12.011; Govindaraju V, 2000, NMR BIOMED, V13, P129, DOI 10.1002/1099-1492(200005)13:3<129::AID-NBM619>3.3.CO;2-M; Guyon I, 2006, STUDIES FUZZINESS SO; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hammer B, 2003, EUR S ART NEUR NETW, P59; Hammer B, 2007, NEUROCOMPUTING, V70, P1225, DOI 10.1016/j.neucom.2006.10.147; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jeanny H, 2010, VISION IMAGES SIGNAL; Jolliffe I. T., 2002, SPRINGER SERIES STAT; Julia-Sape M, 2006, MAGN RESON MATER PHY, V19, P22, DOI 10.1007/s10334-005-0023-x; Kim M, 2005, PATTERN RECOGN LETT, V26, P2353, DOI 10.1016/j.patrec.2005.04.007; Kohonen T, 2000, INFORM SCI SERIES; Leban G, 2006, DATA MIN KNOWL DISC, V13, P119, DOI 10.1007/s10618-005-0031-5; Lee JA, 2007, INFORM SCI STAT, P1; Likert R., 1932, ARCH PSYCHOL, V140, P1; Lisboa PJG, 2010, IEEE COMPUT INTELL M, V5, P14, DOI 10.1109/MCI.2009.935311; McLachlan G, 2000, SERIES PROBABILITY S; Meyers LS, 2005, APPL MULTIVARIATE RE; Miikkulainen R., 2005, COMPUTATIONAL MAPS V; Okabe A., 2000, SPATIAL TESSELLATION; Paulovich FV, 2011, COMPUT GRAPH FORUM, V30, P1091, DOI 10.1111/j.1467-8659.2011.01958.x; Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081; POINTER JS, 1986, BIOL REV, V61, P97, DOI 10.1111/j.1469-185X.1986.tb00463.x; Rauber A, 2002, IEEE T NEURAL NETWOR, V13, P1331, DOI 10.1109/TNN.2002.804221; Rong GD, 2011, IEEE T VIS COMPUT GR, V17, P345, DOI 10.1109/TVCG.2010.53; Rossi F, 2006, ESANN 2006, P251; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Shearer C, 2000, J DATA WAREHOUSING, V5, P13; Svensen M, 1998, THESIS ASTON U BIRMI; Tino P, 2002, IEEE T PATTERN ANAL, V24, P639, DOI 10.1109/34.1000238; Tobler W, 2004, ANN ASSOC AM GEOGR, V94, P58, DOI 10.1111/j.1467-8306.2004.09401004.x; Tosi A, 2012, ESANN 2012 BRUG BELG, P203; Ultsch A, 1992, GFK1 1992 DORTM GERM; Ultsch A, 2005, 46 PHIL U MARB CS DE; Vellido A, 2006, NEURAL NETWORKS, V19, P1624, DOI 10.1016/j.neunet.2005.11.003; Vellido A, 2011, ESANN 2011, P219; Vellido A, 2012, ESANN 2012, P163; Vellido A, 2009, NEUROCOMPUTING, V72, P3085, DOI 10.1016/j.neucom.2009.03.010; Venna J, 2007, THESIS HELSINKI U TE; Villmann T, 2006, NEURAL COMPUT, V18, P446, DOI 10.1162/089976606775093918; WASSLE H, 1990, VISION RES, V30, P1897, DOI 10.1016/0042-6989(90)90166-I; Ziemkiewicz C, 2009, COMPUT GRAPH FORUM, V28, P911	59	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2013	27	1			SI		22	54		10.1007/s10618-012-0294-6		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	131GB	WOS:000317979600003	
J	Andrienko, N; Andrienko, G				Andrienko, Natalia; Andrienko, Gennady			A visual analytics framework for spatio-temporal analysis and modelling	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Spatio-temporal data; Interactive visual techniques; Clustering; Time series analysis; Visual analytics	TIME-SERIES FRAMEWORK; ATMOSPHERIC-POLLUTION; MOVEMENT DATA; TRAFFIC FLOW; MULTIVARIATE; MAPS	To support analysis and modelling of large amounts of spatio-temporal data having the form of spatially referenced time series (TS) of numeric values, we combine interactive visual techniques with computational methods from machine learning and statistics. Clustering methods and interactive techniques are used to group TS by similarity. Statistical methods for TS modelling are then applied to representative TS derived from the groups of similar TS. The framework includes interactive visual interfaces to a library of modelling methods supporting the selection of a suitable method, adjustment of model parameters, and evaluation of the models obtained. The models can be externally stored, communicated, and used for prediction and in further computational analyses. From the visual analytics perspective, the framework suggests a way to externalize spatio-temporal patterns emerging in the mind of the analyst as a result of interactive visual analysis: the patterns are represented in the form of computer-processable and reusable models. From the statistical analysis perspective, the framework demonstrates how TS analysis and modelling can be supported by interactive visual interfaces, particularly, in a case of numerous TS that are hard to analyse individually. From the application perspective, the framework suggests a way to analyse large numbers of spatial TS with the use of well-established statistical methods for TS analysis.	[Andrienko, Natalia; Andrienko, Gennady] Fraunhofer Inst IAIS Intelligent Anal & Informat, St Augustin, Germany	Andrienko, G (reprint author), Fraunhofer Inst IAIS Intelligent Anal & Informat, St Augustin, Germany.	gennady.andrienko@iais.fraunhofer.de			European Commission [FPT-ICT-270833]; DFG-Deutsche Forschungsgemeinschaft (German Research Foundation) [SPP 1335]	This work was supported by the European Commission within the international cooperation project DataSim-DATA science for Simulating the era of electric vehicles (contract FPT-ICT-270833) and by DFG-Deutsche Forschungsgemeinschaft (German Research Foundation) within the Priority Research Programme "Scalable Visual Analytics" (SPP 1335). We are thankful to our colleagues who discussed with us our work and gave us helpful comments.	Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, DOI 10.1109/VAST.2009.5332584; Andrienko G, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P799, DOI 10.1109/IV.2005.135; Andrienko Gennady, 2010, Journal of Location Based Services, V4, DOI 10.1080/17489725.2010.532816; Andrienko G, 2010, COMPUT GRAPH FORUM, V29, P913, DOI 10.1111/j.1467-8659.2009.01664.x; Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44; Crossno Patricia J, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, DOI 10.1109/VAST.2009.5333428; Demsar U, 2008, INFORM VISUAL, V7, P181, DOI 10.1057/palgrave.ivs.9500187; Garg S, 2010, P IEEE S VIS AN SCI, P67; Garg S, 2008, IEEE S VIS ANAL, P19; Guo DS, 2009, CH CRC DATA MIN KNOW, P325; Guo Z, 2009, P IEEE S VAST 2009, P75; Hao MC, 2011, COMPUT GRAPH FORUM, V30, P691, DOI 10.1111/j.1467-8659.2011.01918.x; Kamarianakis Y, 2005, COMPUT GEOSCI-UK, V31, P119, DOI 10.1016/j.cageo.2004.05.012; Kamarianakis Y, 2006, WORKING PAPERS U CRE; Kamarianakis Y, 2003, TRANSPORT RES REC, P74; Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5; Kohonen T, 2001, SELF ORGANIZING MAPS; Kyriakidis PC, 2001, ATMOS ENVIRON, V35, P2331, DOI 10.1016/S1352-2310(00)00541-0; Kyriakidis PC, 2001, ATMOS ENVIRON, V35, P2339, DOI 10.1016/S1352-2310(00)00541-0; Maciejewski R, 2011, J VISUAL LANG COMPUT, V22, P268, DOI 10.1016/j.jvlc.2011.04.002; Maciejewski R, 2010, IEEE T VIS COMPUT GR, V16, P205, DOI 10.1109/TVCG.2009.100; Matkovic K, 2011, P EUROVA BERG NORW, P45; Matkovic K, 2010, IEEE T VIS COMPUT GR, V16, P1449, DOI 10.1109/TVCG.2010.171; Migut M, 2010, P IEEE S VIS AN SCI, P11; Rinzivillo S, 2008, INFORM VISUAL, V7, P225, DOI 10.1057/palgrave.ivs.9500183; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Schreck T, 2009, INFORM VISUAL, V8, P14, DOI 10.1057/ivs.2008.29; Slingsby A, 2010, P ACC 2010 C LEIC UK; Theron R, 2006, LECT NOTES COMPUT SC, V4224, P191; Xiao L, 2006, IEEE S VIS ANAL, P107; Ziegler H, 2010, P IEEE S VIS AN SCI, P83	31	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2013	27	1			SI		55	83		10.1007/s10618-012-0285-7		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	131GB	WOS:000317979600004	
J	Xu, KS; Kliger, M; Hero, AO				Xu, Kevin S.; Kliger, Mark; Hero, Alfred O., III			A regularized graph layout framework for dynamic network visualization	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph layout; Dynamic network; Visualization; Mental map; Regularization; Multidimensional scaling; Spectral layout; Graph Laplacian	DIMENSIONALITY REDUCTION; SOCIAL NETWORKS; ALGORITHM; REGRESSION; PLACEMENT	Many real-world networks, including social and information networks, are dynamic structures that evolve over time. Such dynamic networks are typically visualized using a sequence of static graph layouts. In addition to providing a visual representation of the network structure at each time step, the sequence should preserve the mental map between layouts of consecutive time steps to allow a human to interpret the temporal evolution of the network. In this paper, we propose a framework for dynamic network visualization in the on-line setting where only present and past graph snapshots are available to create the present layout. The proposed framework creates regularized graph layouts by augmenting the cost function of a static graph layout algorithm with a grouping penalty, which discourages nodes from deviating too far from other nodes belonging to the same group, and a temporal penalty, which discourages large node movements between consecutive time steps. The penalties increase the stability of the layout sequence, thus preserving the mental map. We introduce two dynamic layout algorithms within the proposed framework, namely dynamic multidimensional scaling and dynamic graph Laplacian layout. We apply these algorithms on several data sets to illustrate the importance of both grouping and temporal regularization for producing interpretable visualizations of dynamic networks.	[Xu, Kevin S.; Hero, Alfred O., III] Univ Michigan, Dept EECS, Ann Arbor, MI 48109 USA; [Kliger, Mark] Omek Interact Ltd, Bet Shemesh, Israel	Xu, KS (reprint author), Univ Michigan, Dept EECS, 1301 Beal Ave, Ann Arbor, MI 48109 USA.	xukevin@umich.edu; mark.kliger@gmail.com; hero@umich.edu			Natural Sciences and Engineering Research Council of Canada; Office of Naval Research [N00014-08-1-1065]; National Science Foundation [CCF 0830490]; Army Research Office [W911NF-09-1-0310]	Kevin Xu was partially supported by an award from the Natural Sciences and Engineering Research Council of Canada. This work was partially supported by the Office of Naval Research grant N00014-08-1-1065, the National Science Foundation grant CCF 0830490, and the Army Research Office grant W911NF-09-1-0310.	Baur M., 2008, DYNAMIC GRAPH DRAWIN; Bazaraa M. S., 2006, NONLINEAR PROGRAMMIN; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bender-deMoll S, 2012, SONIA SOCIAL NETWORK; Bender-Demoll S., 2006, J SOCIAL STRUCTURE, V7, P1; Borg I., 2005, MODERN MULTIDIMENSIO; Brandes U., 2003, Information Visualization, V2, DOI 10.1057/palgrave.ivs.9500037; Brandes U, 2012, SOC NETWORKS, V34, P291, DOI 10.1016/j.socnet.2011.06.002; Brandes U., 1997, LNCS, V1353, P236; Brandes U, 2011, P 19 INT S GRAPH DRA, P99; Brandes U, 2007, J GRAPH ALGORITHMS A, V11, P325; Brandes U, 2004, MATH VISUAL, P321; Branke J., 2001, LNCS, V2025, P228; Byrd RH, 1999, SIAM J OPTIMIZ, V9, P877, DOI 10.1137/S1052623497325107; Chi Y, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1631162.1631165; Costa JA, 2005, INT CONF ACOUST SPEE, P1077; de Leeuw J, 1980, P 5 INT S MULT AN, P501; Eades P, 1999, GRAPH DRAWING ALGORI; Eades P., 2000, GRAPH ALGORITHMS APP, V4, P157; Eagle N, 2009, P NATL ACAD SCI USA, V106, P15274, DOI 10.1073/pnas.0900282106; Erten C, 2004, P SOC PHOTO-OPT INS, V5295, P45, DOI 10.1117/12.539245; Frishman Y, 2008, IEEE T VIS COMPUT GR, V14, P727, DOI 10.1109/TVCG.2008.11; FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102; Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239; HALL KM, 1970, MANAGE SCI, V17, P219, DOI 10.1287/mnsc.17.3.219; Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; HOLLAND PW, 1983, SOC NETWORKS, V5, P109, DOI 10.1016/0378-8733(83)90021-7; KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6; Koren Y, 2005, COMPUT MATH APPL, V49, P1867, DOI 10.1016/j.camwa.2004.08.015; Kossinets G, 2006, SCIENCE, V311, P88, DOI 10.1126/science.1116869; Lee JA, 2007, INFORM SCI STAT, P1; Leskovec J, 2007, ACM T WEB, V1, DOI 10.1145/1232722.1232727; Leydesdorff L, 2008, J AM SOC INF SCI TEC, V59, P1810, DOI 10.1002/asi.20891; Lutkepohl H, 1997, HDB MATRICES; MISUE K, 1995, J VISUAL LANG COMPUT, V6, P183, DOI 10.1006/jvlc.1995.1010; MIT-WWW, 2005, MIT AC CAL 2004 2005; Moody J, 2005, AM J SOCIOL, V110, P1206, DOI 10.1086/421509; Mucha PJ, 2010, SCIENCE, V328, P876, DOI 10.1126/science.1184819; Newcomb T.M., 1961, ACQUAINTANCE PROCESS; Ng A., 2001, NEURAL INFORM PROCES, V14, P849; Nordlie P.H., 1958, THESIS U MICHIGAN; Sun JM, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P366; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tong Hanghang, 2008, P C KNOWL DISC DAT M, P686, DOI 10.1145/1401890.1401973; Trefethen L.N., 1997, NUMERICAL LINEAR ALG; Wang X, 1995, P 2 INT S GRAPH DRAW, P504; Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008; Witten DM, 2011, COMPUT STAT DATA AN, V55, P789, DOI 10.1016/j.csda.2010.07.001; Xu KS, 2011, ARXIV11041990; Xu KS, 2011, P 9 WORKSH MIN LEARN; Xu KS, 2012, REGULARIZED GRAPH LA	52	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2013	27	1			SI		84	116		10.1007/s10618-012-0286-6		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	131GB	WOS:000317979600005	
J	Labitzke, B; Bayraktar, S; Kolb, A				Labitzke, Bjoern; Bayraktar, Serkan; Kolb, Andreas			Generic visual analysis for multi- and hyperspectral image data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Multi-/hyperspectral data; Feature extraction; Interactive visual analysis	INTERACTIVE VISUALIZATION; ENDMEMBER EXTRACTION	Multi- and hyperspectral imaging and data analysis has been investigated in the last decades in the context of various fields of application like remote sensing or microscopic spectroscopy. However, recent developments in sensor technology and a growing number of application areas require a more generic view on data analysis, that clearly expands the current, domain-specific approaches. In this context, we address the problem of interactive exploration of multi- and hyperspectral data, consisting of (semi-)automatic data analysis and scientific visualization in a comprehensive fashion. In this paper, we propose an approach that enables a generic interactive exploration and easy segmentation of multi- and hyperspectral data, based on characterizing spectra of an individual dataset, the so-called endmembers. Using the concepts of existing endmember extraction algorithms, we derive a visual analysis system, where the characteristic spectra initially identified serve as input to interactively tailor a problem-specific visual analysis by means of visual exploration. An optional outlier detection improves the robustness of the endmember detection and analysis. An adequate system feedback of the costly unmixing procedure for the spectral data with respect to the current set of endmembers is ensured by a novel technique for progressive unmixing and view update which is applied at user modification. The progressive unmixing is based on an efficient prediction scheme applied to previous unmixing results. We present a detailed evaluation of our system in terms of confocal Raman microscopy, common multispectral imaging and remote sensing.	[Labitzke, Bjoern; Bayraktar, Serkan; Kolb, Andreas] Univ Siegen, Comp Graph Grp, Inst Vis & Graph, Fac Sci & Technol 4, D-57068 Siegen, Germany	Labitzke, B (reprint author), Univ Siegen, Comp Graph Grp, Inst Vis & Graph, Fac Sci & Technol 4, D-57068 Siegen, Germany.	bjoern.labitzke@uni-siegen.de; serkan.bayraktar@uni-siegen.de; andreas.kolb@uni-siegen.de			German Research Foundation (DFG)	Activities leading to this work have been funded by the German Research Foundation (DFG) in the context of the Research Training Group 1564 Imaging New Modalities. Furthermore, the Raman datasets are kindly provided by the Research Group for High Frequency and Quantum Electronics at the University of Siegen.	Biehl L, 2002, COMPUT GEOSCI-UK, V28, P1153, DOI 10.1016/S0098-3004(02)00033-X; Boardman JW, 1995, 5 ANN JPL AIRB GEOSC; Broersen A, 2005, EUR IEEE VGTC S VIS, P117, DOI 10.2312/VisSym/EuroVis05/117-123; Chang CI, 2004, IEEE T GEOSCI REMOTE, V42, P608, DOI 10.1109/TGRS.2003.819189; Chang CI, 2005, IEEE T GEOSCI REMOTE, V43, P502, DOI 10.1109/TGRS.2004.839543; Colantoni P, 2006, ANAL MULTISPECTRAL I; Cui M, 2009, IEEE T GEOSCI REMOTE, V47, P1673, DOI 10.1109/TGRS.2008.2010129; Dieing T, 2010, SPRINGER SERIES OPTI, V158, DOI [10.1007/978-3-642-12522-5, DOI 10.1007/978-3-642-12522-5]; Egan WJ, 1998, ANAL CHEM, V70, P2372, DOI 10.1021/ac970763d; Gray RM, 1984, IEEE ASSP MAG, V4, P4; HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007; Inselberg A., 1990, VIS 90, P361, DOI DOI 10.1109/VISUAL.1990.146402; ITT, 2011, VIS INF SOL ENVI; Jacobson NP, 2005, IEEE T GEOSCI REMOTE, V43, P2684, DOI 10.1109/TGRS.2005.857623; Jordan J, 2010, VMV 2010 VISION MODE, V1, P259; Joye W. A., 2003, ASP C SERIES, V295, P489; Kastner M, 2011, 3 WORKSH HYP IM SIGN, P1, DOI [10.1109/WHISPERS.2011.6080854, DOI 10.1109/WHISPERS.2011.6080854]; Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5; Keshava N., 2003, Lincoln Laboratory Journal, V14; Kim SJ, 2010, IEEE T VIS COMPUT GR, V16, P1441, DOI 10.1109/TVCG.2010.172; KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N; Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718; Li HW, 2008, IEEE T VIS COMPUT GR, V14, P1555, DOI 10.1109/TVCG.2008.182; Mignotte M, 2010, IEEE T GEOSCI REMOTE, V48, P4236, DOI 10.1109/TGRS.2010.2051553; Nascimento JMP, 2004, IEEE T GEOSCI REMOTE, V43, P898; Plaza A, 2002, IEEE T GEOSCI REMOTE, V40, P2025, DOI 10.1109/TGRS.2002.802494; Plaza A, 2009, P 1 WORKSH HYP IM SI, P1, DOI 10.1109/WHISPERS.2009. 5289024; Plaza A, 2010, ADV SIGNAL PROCESSIN, V3, P300; Polder G, 2001, P SPIE, V4553; Roberto V, 2008, P WORK C ADV VIS INT, P462, DOI [10.1145/1385569.1385659, DOI 10.1145/1385569.1385659]; Robila S.A., 2005, IEEE, V1, P163, DOI DOI 10.1109/ISSCS.2005.1509878; Sanchez S, 2010, INT GEOSCI REMOTE SE, P955, DOI 10.1109/IGARSS.2010.5650231; Sanchez S., 2010, P IEEE INT C CLUST C, V1, P1; Sanchez S, 2010, PROC SPIE, V7810, DOI 10.1117/12.860775; Setoain J, 2007, IEEE GEOSCI REMOTE S, V4, P441, DOI 10.1109/LGRS.2007.897398; Setoain J, 2008, INT J HIGH PERFORM C, V22, P424, DOI 10.1177/1094342007088379; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Veganzones MA, 2008, LECT NOTES COMPUTER, P400, DOI [10.1007/978-3-540-85567-5_50, DOI 10.1007/978-3-540-85567-5_]; Winter ME, 1999, STORAGE RETRIEVAL IM, DOI [10.1117/12.366289, DOI 10.1117/12.366289]	39	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2013	27	1			SI		117	145		10.1007/s10618-012-0283-9		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	131GB	WOS:000317979600006	
J	Lehrmann, A; Huber, M; Polatkan, AC; Pritzkau, A; Nieselt, K				Lehrmann, Andreas; Huber, Michael; Polatkan, Aydin C.; Pritzkau, Albert; Nieselt, Kay			Visualizing dimensionality reduction of systems biology data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Dimension reduction; Principal component analysis; Independent component analysis; Local linear embedding; Systems biology	INDEPENDENT COMPONENT ANALYSIS; STREPTOMYCES-COELICOLOR; EXPRESSION DATA; POINT; MICROARRAY; ANALYTICS; MANIFOLDS; ALGORITHM; CRITERION; SELECTION	One of the challenges in analyzing high-dimensional expression data is the detection of important biological signals. A common approach is to apply a dimension reduction method, such as principal component analysis. Typically, after application of such a method the data is projected and visualized in the new coordinate system, using scatter plots or profile plots. These methods provide good results if the data have certain properties which become visible in the new coordinate system but which were hard to detect in the original coordinate system. Often however, the application of only one method does not suffice to capture all important signals. Therefore several methods addressing different aspects of the data need to be applied. We have developed a framework for linear and non-linear dimension reduction methods within our visual analytics pipeline SpRay. This includes measures that assist the interpretation of the factorization result. Different visualizations of these measures can be combined with functional annotations that support the interpretation of the results. We show an application to high-resolution time series microarray data in the antibiotic-producing organism Streptomyces coelicolor as well as to microarray data measuring expression of cells with normal karyotype and cells with trisomies of human chromosomes 13 and 21.	[Lehrmann, Andreas; Polatkan, Aydin C.; Nieselt, Kay] Univ Tubingen, Ctr Bioinformat Tubingen, D-72076 Tubingen, Germany; [Huber, Michael] Univ Tubingen, Wilhelm Schickard Inst Comp Sci, D-72076 Tubingen, Germany; [Pritzkau, Albert] Univ Leipzig, D-04009 Leipzig, Germany	Nieselt, K (reprint author), Univ Tubingen, Ctr Bioinformat Tubingen, Sand 14, D-72076 Tubingen, Germany.	lehrmann@informatik.uni-tuebingen.de; michael.huber@uni-tuebingen.de; polatkan@informatik.uni-tuebingen.de; albert.pritzkau@medizin.uni-leipzig.de; kay.nieselt@uni-tuebingen.de			Deutsche Forschungsgemeinschaft (DFG) [Hu954/4, Hu954/5]; DFG	We wish to thank Peter Wills for critically reading an earlier version of the manuscript. We also thank the anonymous referees for their thorough reviews and valuable comments that helped improving the presentation of the paper. M. Huber was supported by the Deutsche Forschungsgemeinschaft (DFG) via a Heisenberg grant (Hu954/4) and a Heinz Maier-Leibnitz Prize grant (Hu954/5). A. C. Polatkan and A. Pritzkau were supported by the DFG Priority Program 1335 "Scalable Visual Analytics".	Abdi H, 2010, WILEY INTERDISCIPLIN, V2, P433, DOI DOI 10.1002/WICS.101; Agilent Technologies, 2007, GENESPRING GX MAN; Altug-Teber O, 2008, CYTOGENIC GENOME RES, V119, P171; Battke F, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-121; Battke F, 2011, ADV EXP MED BIOL, V696, P3, DOI 10.1007/978-1-4419-7046-6_1; Dietzsch J, 2009, IEEE S VIS AN SCI TE; Fontes M, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-307; Golub G. H., 1983, MATRIX COMPUTATIONS; Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042; Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888; Hyvaerinen A, 1997, ADV NEURAL INFORM PR, V10, P273; Hyvaerinen A, 2001, ADAPTIVE LEARNING SY; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; Inselberg A., 2009, PARALLEL COORDINATES; Inselberg Alfred, 1985, VISUAL COMPUT, V1, P69, DOI DOI 10.1007/BF01898350; Jeong DH, 2009, COMPUT GRAPH FORUM, V28, P767; Joliffe I, 2002, SPRINGER SERIES STAT; KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233; Karbauskaite R, 2007, INF TECHNOL CONTROL, V36, P359; Kouropteva O, 2002, P 1 INT C FUZZ SYST, P359; Lockhart DJ, 1996, NAT BIOTECHNOL, V14, P1675, DOI 10.1038/nbt1296-1675; Mannfolk P, 2010, MAGN RESON MATER PHY, V23, P327, DOI 10.1007/s10334-010-0204-0; Nieselt K, 2010, BMC GENOMICS, V11, DOI 10.1186/1471-2164-11-10; Pearson K, 1901, PHILOS MAG, V2, P559; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saeed AI, 2006, METHOD ENZYMOL, V411, P134, DOI 10.1016/S0076-6879(06)11009-5; Saul L. K., 2003, J MACHINE LEARNING R, V4, P119; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Shendure J, 2008, NAT BIOTECHNOL, V26, P1135, DOI 10.1038/nbt1486; Tarjan R., 1972, SIAM Journal on Computing, V1, DOI 10.1137/0201010; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Valencia-Aguirre J, 2009, LECT NOTES COMPUT SC, V5856, P77, DOI 10.1007/978-3-642-10268-4_9; Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154	35	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2013	27	1			SI		146	165		10.1007/s10618-012-0268-8		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	131GB	WOS:000317979600007	
J	Liu, HW; Li, XL; Zheng, XY				Liu, Hongwei; Li, Xiangli; Zheng, Xiuyun			Solving non-negative matrix factorization by alternating least squares with a modified strategy	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Non-negative matrix factorization; Alternating non-negative least squares	IMAGE CLASSIFICATION; OBJECT RECOGNITION; ALGORITHMS; DISCOVERY	Non-negative matrix factorization (NMF) is a method to obtain a representation of data using non-negativity constraints. A popular approach is alternating non-negative least squares (ANLS). As is well known, if the sequence generated by ANLS has at least one limit point, then the limit point is a stationary point of NMF. However, no evdience has shown that the sequence generated by ANLS has at least one limit point. In order to overcome this shortcoming, we propose a modified strategy for ANLS in this paper. The modified strategy can ensure the sequence generated by ANLS has at least one limit point, and this limit point is a stationary point of NMF. The results of numerical experiments are reported to show the effectiveness of the proposed algorithm.	[Liu, Hongwei; Li, Xiangli; Zheng, Xiuyun] Xidian Univ, Dept Math, Xian 710071, Peoples R China; [Li, Xiangli] Guilin Univ Elect Technol, Coll Math & Comp Sci, Guilin 541004, Peoples R China	Li, XL (reprint author), Xidian Univ, Dept Math, Xian 710071, Peoples R China.	lixiangli213@gmail.com			National Natural Science Foundation of China [61072144, 61179040]	The project was supported by National Natural Science Foundation of China (Grant No. 61072144, 61179040).	Ahn J.-H., 2004, ACCV; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Cho YC, 2005, PATTERN RECOGN LETT, V26, P1327, DOI 10.1016/j.patrec.2004.11.026; Chu M., 2004, SIAM J MATRIX ANAL A, P4; Gao Y, 2005, BIOINFORMATICS, V21, P3970, DOI 10.1093/bioinformatics/bti653; Gonzalez E., 2005, TECHNICAL REPORT; Guillamet D, 2003, PATTERN RECOGN LETT, V24, P2447, DOI 10.1016/S0167-8655(03)00089-8; Guillamet D, 2002, INT C PATT RECOG, P116; Guillamet D, 2002, P 5 CAT C ART INT; Kim D., 2007, P SIAM C DAT MIN; Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134; Kim H, 2008, SIAM J MATRIX ANAL A, V30, P713, DOI 10.1137/07069239X; Kim PM, 2003, GENOME RES, V13, P1706, DOI 10.1101/gr.903503; Lee DD, 2001, ADV NEUR IN, V13, P556; Lee DD, 1999, NATURE, V401, P788; Lee J.S., 2002, 3 INT C IND COMP AN, P556; Li H, 2005, MACHINE LEARNING SIG, P253; Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756; Lin CJ, 2007, IEEE T NEURAL NETWOR, V18, P1589, DOI 10.1109/TNN.2007.895831; Liu WX, 2004, PATTERN RECOGN LETT, V25, P893, DOI 10.1016/j.patrec.2004.02.002; Okun Oleg, 2006, EURASIP J APPL SIG P, V2009, P62; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Paatero P, 1999, J COMPUT GRAPH STAT, V8, P1; Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60; Pauca V.P., 2004, P 4 SIAM INT C DAT M; Rao N., 2004, COMP SYST BIOINF C; RICHARDS.WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; Spratling MW, 2006, J MACH LEARN RES, V7, P793; Wang Y, 2005, INT J PATTERN RECOGN, V19, P495, DOI 10.1142/S0218001405004198; Zdunek R, 2008, COMPUTATIONAL INTELL; Zdunek R, 2006, LECT NOTES COMPUT SC, V4029, P870	31	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2013	26	3					435	451		10.1007/s10618-012-0265-y		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	076NK	WOS:000313963000001	
J	Gullo, F; Domeniconi, C; Tagarelli, A				Gullo, Francesco; Domeniconi, Carlotta; Tagarelli, Andrea			Projective clustering ensembles	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Clustering; Clustering ensembles; Projective clustering; Multi-objective optimization	HIGH-DIMENSIONAL DATA; ALGORITHM; CONSENSUS; HIERARCHIES; MODEL	A considerable amount of work has been done in data clustering research during the last four decades, and a myriad of methods has been proposed focusing on different data types, proximity functions, cluster representation models, and cluster presentation. However, clustering remains a challenging problem due to its ill-posed nature: it is well known that off-the-shelf clustering methods may discover different patterns in a given set of data, mainly because every clustering algorithm has its own bias resulting from the optimization of different criteria. This bias becomes even more important as in almost all real-world applications, data is inherently high-dimensional and multiple clustering solutions might be available for the same data collection. In this respect, the problems of projective clustering and clustering ensembles have been recently defined to deal with the high dimensionality and multiple clusterings issues, respectively. Nevertheless, despite such two issues can often be encountered together, existing approaches to the two problems have been developed independently of each other. In our earlier work Gullo et al. (Proceedings of the international conference on data mining (ICDM), 2009a) we introduced a novel clustering problem, called projective clustering ensembles (PCE): given a set (ensemble) of projective clustering solutions, the goal is to derive a projective consensus clustering, i.e., a projective clustering that complies with the information on object-to-cluster and the feature-to-cluster assignments given in the ensemble. In this paper, we enhance our previous study and provide theoretical and experimental insights into the PCE problem. PCE is formalized as an optimization problem and is designed to satisfy desirable requirements on independence from the specific clustering ensemble algorithm, ability to handle hard as well as soft data clustering, and different feature weightings. Two PCE formulations are defined: a two-objective optimization problem, in which the two objective functions respectively account for the object- and feature-based representations of the solutions in the ensemble, and a single-objective optimization problem, in which the object- and feature-based representations are embedded into a single function to measure the distance error between the projective consensus clustering and the projective ensemble. The significance of the proposed methods for solving the PCE problem has been shown through an extensive experimental evaluation based on several datasets and comparatively with projective clustering and clustering ensemble baselines.	[Gullo, Francesco] Yahoo Res, Barcelona 08018, Spain; [Tagarelli, Andrea] Univ Calabria, DEIS Dept, I-87036 Arcavacata Di Rende, CS, Italy; [Domeniconi, Carlotta] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Gullo, F (reprint author), Yahoo Res, Barcelona 08018, Spain.	gullo@yahoo-inc.com; carlotta@cs.gmu.edu; tagarelli@deis.unical.it					Achtert E, 2006, LECT NOTES ARTIF INT, V4213, P446; Achtert E, 2007, LECT NOTES COMPUT SC, V4443, P152; Aggarwal C. C., 1999, SIGMOD Record, V28; Agrawal R., 1998, SIGMOD Record, V27; Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; Assent I, 2008, P 17 ACM C INF KNOWL, P1093, DOI 10.1145/1458082.1458227; Asuncion A., 2010, UCI MACHINE LEARNING; Ayad H, 2003, LECT NOTES COMPUT SC, V2709, P166; BARTHELEMY JP, 1995, DIMACS SERIES DISCRE, V19, P3; Bellman R., 1961, ADAPTIVE CONTROL PRO; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Bohm C, 2004, P IEEE INT C DAT MIN, P27; Boulis C, 2004, LECT NOTES ARTIF INT, V3202, P63; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Caruana R, 2006, IEEE DATA MINING, P107; Chen LF, 2008, IEEE DATA MINING, P755, DOI 10.1109/ICDM.2008.15; Deb K., 2001, MULTIOBJECTIVE OPTIM; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dimitriadou E, 2001, LECT NOTES COMPUT SC, V2130, P217; Domeniconi C, 2009, ACM T KNOWL DISC DAT, V2; Domeniconi C, 2007, DATA MIN KNOWL DISC, V14, P63, DOI 10.1007/s10618-006-0060-8; Dudoit S, 2003, BIOINFORMATICS, V19, P1090, DOI 10.1093/bioinformatics/btg038; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Fern XZ, 2008, P 8 SIAM INT C DAT M, P787; Fern XZ, 2004, P 21 INT C MACH LEAR, P281; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P1411, DOI 10.1109/TPAMI.2003.1240115; Fred A. L. N., 2001, P 2 INT WORKSH MULT, V2096, P309; Fred ALN, 2002, INT C PATT RECOG, P276; Gan G, 2007, ASA SIAM SER STAT AP, V20, P1, DOI 10.1137/1.9780898718348; Ghaemi R, 2011, ARTIF INTELL REV, V35, P287, DOI 10.1007/s10462-010-9195-5; Ghosh J, 2011, WIRES DATA MIN KNOWL, V1, P305, DOI 10.1002/widm.32; Gionis A, 2007, ACM T KNOWL DISC DAT, V1; Gullo F., 2009, P SDM2009, P437; Gullo F, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.138; Gullo F, 2009, IEEE DATA MINING, P794, DOI 10.1109/ICDM.2009.131; Gullo F, 2011, P ACM SIGMOD INT C M, P733; Gunnemann S, 2011, P ACM C INF KNOWL MA, P1363; Gunnemann S., 2011, P EUR C MACH LEARN K, P565; Hinneburg A., 2000, P 26 INT C VER LARG, P506; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Karypis G, 1997, DES AUT CON, P526; Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997; Keogh E, 2003, UCR TIME SERIES CLAS; Kriegel H-P, 2005, P IEEE ICDM INT C DA, P250; Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578; KRIVANEK M, 1986, ACTA INFORM, V23, P311, DOI 10.1007/BF00289116; Kuhn H., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109; Kuncheva LI, 2006, P 19 INT C INF FUS I, P1; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Li T, 2008, P SIAM INT C DAT MIN, P798; Li T, 2007, IEEE DATA MINING, P577; Meil M., 2005, P 22 INT C MACH LEAR, P577, DOI 10.1145/1102351.1102424; Moise G, 2008, KNOWL INF SYST, V14, P273, DOI 10.1007/s10115-007-0090-6; Moise G, 2009, KNOWL INF SYST, V21, P299, DOI 10.1007/s10115-009-0226-y; Muller Emmanuel, 2009, Proceedings of the 2009 Ninth IEEE International Conference on Data Mining (ICDM 2009), DOI 10.1109/ICDM.2009.10; Muller E, 2011, P ACM C INF KNOWL MA, P1077; Muller E, 2009, EVALUATING CLUSTERIN; Muller E., 2009, PVLDB, V2, P1270; Ng A., 2001, NEURAL INFORM PROCES, V14, P849; Ng EKK, 2005, IEEE T KNOWL DATA EN, V17, P369, DOI 10.1109/TKDE.2005.47; Nguyen N, 2007, IEEE DATA MINING, P607; Parsons L, 2004, ACM SIGKDD EXPLORATI, V6, P90, DOI 10.1145/1007730.1007731; Patrikainen A, 2006, IEEE T KNOWL DATA EN, V18, P902, DOI 10.1109/TKDE.2006.106; Procopiuc CM, 2002, P ACM SIGMOD INT C M, P418; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Sequeira K., 2004, P 4 IEEE INT C DAT M, P186; Srinivas N., 1994, Evolutionary Computation, V2, P221, DOI 10.1162/evco.1994.2.3.221; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Strehl A., 2000, P AAAI WORKSH AI WEB, P58; Tomasev N, 2011, LECT NOTES ARTIF INT, V6634, P183, DOI 10.1007/978-3-642-20841-6_16; Topchy A, 2004, SIAM PROC S, P379; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Wang H, 2011, STAT ANAL DATA MIN, V4, P54, DOI 10.1002/sam.10098; Wang H, 2009, P SIAM INT C DAT MIN, P209; Wang P, 2011, P SIAM INT C DAT MIN, P331; Wang P, 2010, P EUR C MACH LEARN K, P435; Woo KG, 2004, INFORM SOFTWARE TECH, V46, P255, DOI 10.1016/j.infsof.2003.07.003; Yang Y, 2006, PATTERN RECOGN, V39, P1278, DOI 10.1016/j.patcog.2006.02.012; Yip KY, 2004, IEEE T KNOWL DATA EN, V16, P1387, DOI 10.1109/TKDE.2004.74; Yip KY, 2005, PROC INT CONF DATA, P329; Yiu ML, 2005, IEEE T KNOWL DATA EN, V17, P176; Zeng Y, 2002, P IEEE COMP SOC BIOI, P330	85	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2013	26	3					452	511		10.1007/s10618-012-0266-x		60	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	076NK	WOS:000313963000002	
J	Lee, K; Gray, A; Kim, H				Lee, Kichun; Gray, Alexander; Kim, Heeyoung			Dependence maps, a dimensionality reduction with dependence distance for high-dimensional data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Dependence maps; Dimensionality reduction; Dependence; Markov chain	REGULARIZATION; EIGENMAPS	We introduce the dependence distance, a new notion of the intrinsic distance between points, derived as a pointwise extension of statistical dependence measures between variables. We then introduce a dimension reduction procedure for preserving this distance, which we call the dependence map. We explore its theoretical justification, connection to other methods, and empirical behavior on real data sets.	[Lee, Kichun] Hanyang Univ, Seoul 133791, South Korea; [Gray, Alexander] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Lee, K (reprint author), Hanyang Univ, Seoul 133791, South Korea.	skylee@hanyang.ac.kr; agray@cc.gatech.edu; hykim@gatech.edu					Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bottou L, 1994, P 12 IAPR INT C PA B, V2; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1784, DOI 10.1109/TPAMI.2006.223; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Haykin S., 2008, NEURAL NETWORKS COMP; Lee K, 2009, ADV APPL STAT SCI, V1, P327; Mahadevan S, 2006, ADV NEURAL INFORM PR, V18, P843; Mari D. D., 2001, CORRELATION DEPENDEN, P518; Nelsen R.B., 2006, INTRO COPULAS; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Smola AJ, 2003, LECT NOTES ARTIF INT, V2777, P144, DOI 10.1007/978-3-540-45167-9_12; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Zhou DY, 2005, LECT NOTES COMPUT SC, V3663, P361	14	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2013	26	3					512	532		10.1007/s10618-012-0267-9		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	076NK	WOS:000313963000003	
J	De Smet, W; Moens, MF				De Smet, Wim; Moens, Marie-Francine			Representations for multi-document event clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Text mining; Probabilistic content models; Clustering	TRACKING	We study several techniques for representing, fusing and comparing content representations of news documents. As underlying models we consider the vector space model (both in a term setting and in a latent semantic analysis setting) and probabilistic topic models based on latent Dirichlet allocation. Content terms can be classified as topical terms or named entities, yielding several models for content fusion and comparison. All used methods are completely unsupervised. We find that simple methods can still outperform the current state-of-the-art techniques.	[De Smet, Wim; Moens, Marie-Francine] Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium	De Smet, W (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium.	wim.desmet@cs.kuleuven.be; marie-francine.moens@cs.kuleuven.be					Allan J, 2002, KLUW S INF, V12, P197; Allan J, 2003, SIGIR 2003, P314; Bagga A., 1998, 1 INT C LANG RES EV, P563; Barzilay R, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P16; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Buntine W, 2006, SUBSPACE LATENT STRU, P237; CUTTING DR, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P318; de Marneffe MC, 2008, ACL 08 HLT ASS COMP, P1039; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Deschacht K, 2012, COMPUT SPEECH LANG, V26, P384, DOI 10.1016/j.csl.2012.04.001; Gong Y, 2001, SIGIR 01, P19; Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211; Hatzivassiloglou V, 1998, THESIS NEW YORK; Hershkop S, 2005, KDD 05 P 11 ACM SIGK, P98; Hofmann T, 1999, P UNC ART INT STOCKH; Kumaran G, 2004, SIGIR 04, P297; Lee MD, 2005, COGSCI2005, P1254; Li W., 2006, ICML 06, P577; Li ZY, 2005, INT INTEG REL WRKSP, P106; Makkonen U, 2002, P INT C NAT LANG PRO, P175; McCallum A, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P786; McKeown K., 1995, SIGIR Forum; Nallapati R, 2004, CIKM 2004, P446; Pearl J, 1991, PROBABILISTIC REASON; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Salton G., 1989, AUTOMATIC TEXT PROCE; Shafer G, 1976, MATH THEORY EVIDENCE; Snoek CGM, 2005, ACM MULT C, P399; Steinberger J, 2009, DOCENG'09: PROCEEDINGS OF THE 2009 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P205; Steinberger J, 2007, INFORM PROCESS MANAG, V43, P1663, DOI 10.1016/j.ipm.2007.01.010; Steinberger J., 2010, P ACL 2010 C, P382; Stone B, 2011, TOP COGN SCI, V3, P92, DOI 10.1111/j.1756-8765.2010.01108.x; Tsatsaronis G, 2010, J ARTIF INTELL RES, V37, P1; Voorhees EM, 1986, TECHNICAL REPORT; Wang KS, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P467; WANG ZW, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P152; Yang YM, 1999, IEEE INTELL SYST APP, V14, P32, DOI 10.1109/5254.784083; Zhang K, 2007, SIGIR 07, P215	38	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2013	26	3					533	558		10.1007/s10618-012-0270-1		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	076NK	WOS:000313963000004	
J	Iwata, T; Sawada, H				Iwata, Tomoharu; Sawada, Hiroshi			Topic model for analyzing purchase data with price information	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Purchase log; Probabilistic topic modeling; Gibbs sampling; Clustering	PROMOTIONS	We propose a new topic model for analyzing purchase data with price information. Price is an important factor in consumer purchase behavior. The proposed model assumes that a topic has its own price distributions for each item as well as an item distribution. The topic proportions, which represent a user's purchase tendency, are influenced by the user's purchased items and their prices. By estimating the mean and the variance of the price for each topic, the proposed model can cluster related items taking their price ranges into consideration. We present its efficient inference procedure based on collapsed Gibbs sampling. Experiments on real purchase data demonstrate the effectiveness of the proposed model.	[Iwata, Tomoharu; Sawada, Hiroshi] NTT Commun Sci Labs, Seika, Kyoto 6190237, Japan	Iwata, T (reprint author), NTT Commun Sci Labs, 2-4 Hikaridai, Seika, Kyoto 6190237, Japan.	iwata.tomoharu@lab.ntt.co.jp					Blei D, 2006, P INT C MACH LEARN, V1, P113; Blei D. M., 2003, J MACHINE LEARNING R, V3, P3, DOI DOI 10.1162/JMLR.2003.3.4-5.993; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Das A., 2007, WWW 07, P271; Fu W, 2009, ICML 09, P329; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Hamuro Y, 1998, DATA MIN KNOWL DISC, V2, P391, DOI 10.1023/A:1009748731133; Hoffman M, 2010, NIPS 10; Hofmann T, 2003, SIGIR 03, P259; Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289; Iwata T., 2010, KDD 10, P663; Iwata T, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1427; Iwata T, 2006, KDD 06, P574; Jin X, 2004, KDD 04, P197; Li M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1215; Mimno D, 2009, EMNLP 2009, P880; Minka T, 2002, UNCERTAINTY ARTIFICI, P352; Minka T., 2000, TECHNICAL REPORT; Newman D, 2007, NIPS 07, P1081; Nijs VR, 2001, MARKET SCI, V20, P1, DOI 10.1287/mksc.20.1.1.10197; RAJU JS, 1992, MARKET SCI, V11, P207, DOI 10.1287/mksc.11.3.207; Rosen-Zvi M., 2004, UAI 04, P487; Sato I, 2010, NIPS 10; Shani G, 2005, J MACH LEARN RES, V6, P1265; Teh YW, 2006, NIPS 06, P1378; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Thomas S., 2000, High Performance Computing - HiPC 2000. 7th International Conference. Proceedings (Lecture Notes in Computer Science Vol.1970); Wallach H. M., 2006, ICML 06, P977; Wang X., 2006, KDD 06, P424, DOI DOI 10.1145/1150402.1150450; Williamson S, 2010, ICML 10, P1151	30	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2013	26	3					559	573		10.1007/s10618-012-0281-y		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	076NK	WOS:000313963000005	
J	Cerf, L; Besson, J; Nguyen, KNT; Boulicaut, JF				Cerf, Loic; Besson, Jeremy; Nguyen, Kim-Ngan T.; Boulicaut, Jean-Francois			Closed and noise-tolerant patterns in n-ary relations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Boolean tensor; Multi-way set; Fault-tolerance; Cross-graph quasi-clique	ASSOCIATION RULES; FREQUENT; DATABASES; ALGORITHM; CLIQUES	Binary relation mining has been extensively studied. Nevertheless, many interesting 0/1 data naturally appear as n-ary relations with n a parts per thousand yen 3. A timely challenge is to extend local pattern extraction, eg, closed pattern mining, to such contexts. When considering higher arities, faint noise affects more and more the quality of the extracted patterns. We study a declarative specification of error-tolerant patterns by means of new primitive constraints and the design of an efficient algorithm to extract every solution pattern. It exploits the enumeration principles of the state-of-the-art Data-Peeler algorithm for n-ary relation mining. Efficiently enforcing error-tolerance crucially depends on innovative strategies to incrementally compute partial information on the data. Our prototype is tested on both synthetic and real datasets. It returns relevant collections of patterns even in the case of noisy ternary or 4-ary relations, eg, in the context of pattern discovery from dynamic networks.	[Cerf, Loic] Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil; [Besson, Jeremy] Vilnius State Univ, Vilnius, Lithuania; [Nguyen, Kim-Ngan T.; Boulicaut, Jean-Francois] Univ Lyon, CNRS, INSA, LIRIS,UMR5205, F-69621 Lyon, France	Cerf, L (reprint author), Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil.	lcerf@dcc.ufmg.br; contact.jeremy.besson@gmail.com; tknnguyen@insa-lyon.fr; jean-francois.boulicaut@insa-lyon.fr			project ANR MDCO Bingo2; FAPEMIG	This research has been partially funded by project ANR MDCO Bingo2(2007-2011) and by the FAPEMIG.	Avis D, 1996, DISCRETE APPL MATH, V65, P21, DOI 10.1016/0166-218X(95)00026-N; Bayardo RJ, 2004, FIMI 04, V126; Besson J, 2006, LECT NOTES ARTIF INT, V4068, P144; Besson J, 2005, INTELL DATA ANAL, V9, P59; Bonchi F, 2005, LECT NOTES ARTIF INT, V3518, P114; Bonchi F, 2004, ICDM, P35; Boulicaut JF, 2000, LECT NOTES ARTIF INT, V1805, P62; Calders T., 2006, LNCS, V3848, P64; Cerf L, 2009, CIKM 09, P1753; Cerf L, 2010, INDUCTIVE DATABASES AND CONSTRAINT-BASED DATA MINING, P199; Cerf L, 2009, LECT NOTES COMPUT SC, V5722, P513; Cerf L, 2009, ACM T KNOWL DISCOV D, V3, P1; Gallo A, 2009, 123936 U BRIST; Gallo A, 2007, LECT NOTES ARTIF INT, V4702, P438; Ganter B, 2005, LECT NOTES COMPUTER; Ganti V, 1999, KNOWLEDGE DISCOVERY, P73; Garriga GC, 2008, J MACH LEARN RES, V9, P559; Georgii E, 2009, DMMT 09, P32; Georgii E, 2011, MACH LEARN, V82, P123, DOI 10.1007/s10994-010-5210-y; Goethals B, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P321, DOI 10.1007/978-0-387-09823-4_16; Gupta R, 2008, KDD, P301; Jaschke R., 2006, ICDM 2006, P907, DOI DOI 10.1109/ICDM.2006.162; Ji L., 2006, VLDB, P811; Jiang D., 2009, ACM T KNOWL DISCOV D, V2, P1; Koh JL, 2005, LECT NOTES COMPUT SC, V3453, P568; Liu J, 2006, SDM, P405; Pan F, 2003, KDD, P637; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; Pei J, 2001, DMKD 01; Poernomo AK, 2009, SDM 09, P1014; Poernorno AK, 2007, IEEE DATA MINING, P272; Poernomo AK, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P697; Seppanen JK, 2004, KDD, P683; Sim K, 2011, INFORM SCIENCES, V181, P201, DOI 10.1016/j.ins.2010.08.035; Uno T, 2007, LECT NOTES COMPUT SC, V4835, P402; Yang C, 2000, 200020 MICR RES MICR; Zaki MJ, 2007, DATA KNOWL ENG, V60, P51, DOI 10.1016/j.datak.2006.01.005; Zaki MJ, 2004, DATA MIN KNOWL DISC, V9, P223, DOI 10.1023/B:DAMI.0000040429.96086.c7; Zeng Z, 2007, ACM T DATABASE SYST, V32, DOI 10.1145/1242524.1242530	39	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2013	26	3					574	619		10.1007/s10618-012-0284-8		46	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	076NK	WOS:000313963000006	
J	Angiulli, F; Fassetti, F				Angiulli, Fabrizio; Fassetti, Fabio			Nearest Neighbor-Based Classification of Uncertain Data	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Classification; uncertain data; nearest neighbor rule; probability density functions; nearest neighbor	METRIC-SPACES; SEARCH; TREES	This work deals with the problem of classifying uncertain data. With this aim we introduce the Uncertain Nearest Neighbor (UNN) rule, which represents the generalization of the deterministic nearest neighbor rule to the case in which uncertain objects are available. The UNN rule relies on the concept of nearest neighbor class, rather than on that of nearest neighbor object. The nearest neighbor class of a test object is the class that maximizes the probability of providing its nearest neighbor. The evidence is that the former concept is much more powerful than the latter in the presence of uncertainty, in that it correctly models the right semantics of the nearest neighbor decision rule when applied to the uncertain scenario. An effective and efficient algorithm to perform uncertain nearest neighbor classification of a generic (un)certain test object is designed, based on properties that greatly reduce the temporal cost associated with nearest neighbor class probability computation. Experimental results are presented, showing that the UNN rule is effective and efficient in classifying uncertain data.	[Angiulli, Fabrizio; Fassetti, Fabio] Univ Calabria, DIMES, I-87030 Commenda Di Rende, Italy	Angiulli, F (reprint author), Univ Calabria, DIMES, I-87030 Commenda Di Rende, Italy.	f.angiulli@dimes.unical.it; f.fassett@dimes.unical.it					Achtert E., 2005, P 5 INT C DAT MIN IC, P10; Agarwal PK, 2009, PODS'09: PROCEEDINGS OF THE TWENTY-EIGHTH ACM SIGMOD-SIGACT-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P137, DOI 10.1145/1559795.1559816; Aggarwal C., 2007, PROCEEDINGS OF ICDE; Aggarwal CC, 2009, ADV DATABASE SYST, V35, P1, DOI 10.1007/978-0-387-09690-2; Aggarwal CC, 2009, IEEE T KNOWL DATA EN, V21, P609, DOI 10.1109/TKDE.2008.190; Aggarwal CC, 2008, P SIAM INT C DAT MIN, P483; Angiulli F, 2012, IEEE T KNOWL DATA EN, V24, P1640, DOI 10.1109/TKDE.2011.93; ASUNCION A., 2007, UCI MACHINE LEARNING; Bai F., 2006, WIRELESS AD HOC AND; Beckmann N., 1990, ACM SIGMOD RECORD, V19, P322, DOI 10.1145/93605.98741; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Bettstetter C, 2004, WIREL NETW, V10, P555, DOI 10.1023/B:WINE.0000036458.88990.e5; Bi J., 2004, ADV NEURAL INFORM PR, V17, P161; Broch J., 1998, P 4 ANN ACM IEEE INT, P85, DOI 10.1145/288235.288256; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; Cheng R., 2004, P 30 INT C VER LARG, P876, DOI 10.1016/B978-012088469-8/50077-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L, 1996, PROBABILISTIC THEORY; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Green TJ, 2006, IEEE DATA ENG B, V29, P17; Kriegel H.-P., 2005, P 11 ACM SIGKDD INT, P672, DOI 10.1145/1081870.1081955; Lepage G., 1978, J COMPUT PHYS, V27; Lindley DV, 2006, UNDERSTANDING UNCERT; Lukaszyk S, 2004, COMPUT MECH, V33, P299, DOI 10.1007/s00466-003-0532-2; Mico L., 1994, PATTERN RECOGN, V15, P9; Mitchell T. M, 1997, MACHINE LEARNING; Mohri M, 2003, LECT NOTES ARTIF INT, V2777, P656, DOI 10.1007/978-3-540-45167-9_48; Moore A. W., 1994, P 11 INT C MACH LEAR, P190; Ngai WK, 2006, IEEE DATA MINING, P436; Rifkin R, 2004, J MACH LEARN RES, V5, P101; RUSHDI AM, 1994, MICROELECTRON RELIAB, V34, P1489, DOI 10.1016/0026-2714(94)90457-X; Singh S, 2007, P 23 INT C DAT ENG I, P616; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Tan P.N, 2005, INTRO DATA MINING; Tao YF, 2007, ACM T DATABASE SYST, V32, DOI 10.1145/1272743.1272745; Tsang S, 2009, PROC INT CONF DATA, P441; WESOLOWSKI K, 2002, MOBILE COMMUNICATION; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Zezula P., 2006, ADVANCES IN DATABASE, V32	42	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2013	7	1							1	10.1145/2435209.2435210		35	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	110BA	WOS:000316415700001	
J	Bayati, M; Gleich, DF; Saberi, A; Wang, Y				Bayati, Mohsen; Gleich, David F.; Saberi, Amin; Wang, Ying			Message-Passing Algorithms for Sparse Network Alignment	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Network alignment; graph matching; belief propagation; message-passing	PROTEIN-INTERACTION NETWORKS; QUADRATIC ASSIGNMENT PROBLEM; GLOBAL ALIGNMENT; SIMILARITY; GRAPHS	Network alignment generalizes and unifies several approaches for forming a matching or alignment between the vertices of two graphs. We study a mathematical programming framework for network alignment problem and a sparse variation of it where only a small number of matches between the vertices of the two graphs are possible. We propose a new message passing algorithm that allows us to compute, very efficiently, approximate solutions to the sparse network alignment problems with graph sizes as large as hundreds of thousands of vertices. We also provide extensive simulations comparing our algorithms with two of the best solvers for network alignment problems on two synthetic matching problems, two bioinformatics problems, and three large ontology alignment problems including a multilingual problem with a known labeled alignment.	[Bayati, Mohsen] Stanford Univ, Grad Sch Business, Stanford, CA 94305 USA; [Gleich, David F.] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA; [Saberi, Amin] Stanford Univ, Management Sci & Engn Dept, Stanford, CA 94305 USA; [Wang, Ying] Google, Mountain View, CA USA	Bayati, M (reprint author), Stanford Univ, Grad Sch Business, 450 Serra Mall, Stanford, CA 94305 USA.	bayati_mohsen@gsb.stanford.edu; dgleich@purdue.edu; saberi@stanford.edu; yingmwang@google.com			NSF [DBI-0850203, HRD-0833093, DMS-0915110]; DHS [2009-ST-062-00016, 2010-ST-062-000039]; Library of Congress	This work was partially supported by NSF grants DBI-0850203, HRD-0833093, and DMS-0915110, and DHS grants 2009-ST-062-00016 and 2010-ST-062-000039. The Library of Congress also funded this work.	Adams W. P., 1994, DIMACS SERIES DISCRE, V16, P43; Bayati M, 2009, IEEE DATA MINING, P705, DOI 10.1109/ICDM.2009.135; Bayati M., 2005, P IEEE INT S INF THE, P1763, DOI DOI 10.1109/ISIT.2005.1523648; Bayati M, 2007, LECT NOTES COMPUT SC, V4627, P326; Bayati M., 2007, ARXIVORGABS07091190; Berg J, 2006, P NATL ACAD SCI USA, V103, P10967, DOI 10.1073/pnas.0602294103; Blondel VD, 2004, SIAM REV, V46, P647, DOI 10.1137/S0036144502415960; Bradde S, 2010, EPL-EUROPHYS LETT, V89, DOI 10.1209/0295-5075/89/37009; Braunstein A., 2006, PHYS REV LETT; Burkard R., 2012, ASSIGNMENT PROBLEMS; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Cohen W. W., 2003, P KDD WORKSH DAT CLE; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Donoho DL, 2009, P NATL ACAD SCI USA, V106, P18914, DOI 10.1073/pnas.0909892106; Ehrig M, 2004, LECT NOTES COMPUT SC, V3298, P683; El-Kebir M, 2011, LECT N BIOINFORMAT, V7036, P225, DOI 10.1007/978-3-642-24855-9_20; Flannick J, 2008, LECT N BIOINFORMAT, V4955, P214; Flannick J, 2006, GENOME RES, V16, P1169, DOI 10.1101/gr.5235706; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; FRIEZE AM, 1983, DISCRETE APPL MATH, V5, P89, DOI 10.1016/0166-218X(83)90018-5; Gallager RG, 1963, LOW DENSITY PARITY C; Hatcher E., 2004, LUCENE ACTION; Hu W., 2005, P K CAP WORKSH INT O, P41; Hu W, 2008, DATA KNOWL ENG, V67, P140, DOI 10.1016/j.datak.2008.06.003; Huang B., 2007, P ART INT STAT AISTA; Klau GW, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-S1-S59; Koyuturk M, 2006, J COMPUT BIOL, V13, P182, DOI 10.1089/cmb.2006.13.182; Kuchaiev O., 2009, 08103280 ARXIV; Kuchaiev O, 2010, J R SOC INTERFACE, V7, P1341, DOI 10.1098/rsif.2010.0063; Lacoste-Julien S., 2006, P HUM LANG TECHN C N, P112, DOI 10.3115/1220835.1220850; LAWLER EL, 1963, MANAGE SCI, V9, P586, DOI 10.1287/mnsc.9.4.586; Liang Z, 2006, BIOINFORMATICS, V22, P2175, DOI 10.1093/bioinformatics/btl287; Melnik S, 2002, PROC INT CONF DATA, P117, DOI 10.1109/ICDE.2002.994702; Mezard M., 2002, PHYS REV E, V66; Mezard M, 2009, INFORM PHYS COMPUTAT; Murphy K., 1999, P UNC ART INT UAI; Pearl J., 1988, PROBABILISTIC REASON; Sanghavi S., 2011, IEEE T INFORM THEORY, V57, P4; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171; Sharan R, 2005, J COMPUT BIOL, V12, P835, DOI 10.1089/cmb.2005.12.835; Singh R, 2007, LECT NOTES COMPUT SC, V4453, P16; Singh R, 2008, P NATL ACAD SCI USA, V105, P12763, DOI 10.1073/pnas.0806627105; Svab O., 2007, LNCS, V4825, P950; Tappen M., 2003, P ICCV; Wikipedia, 2007, WIK XML DAT DUMP APR; Yanover C., 2002, ADV NEURAL PROCESSIN	46	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2013	7	1							3	10.1145/2435209.2435212		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	110BA	WOS:000316415700003	
J	Li, B; Hoi, SCH; Zhao, PL; Gopalkrishnan, V				Li, Bin; Hoi, Steven C. H.; Zhao, Peilin; Gopalkrishnan, Vivekanand			Confidence Weighted Mean Reversion Strategy for Online Portfolio Selection	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Design; Algorithms; Economics; Experimentation; Portfolio selection; mean reversion; confidence weighted learning; online learning	UNIVERSAL PORTFOLIOS; STOCK; ALGORITHMS; INFORMATION; PERCEPTRON; PRICES; MODEL; RISK	Online portfolio selection has been attracting increasing attention from the data mining and machine learning communities. All existing online portfolio selection strategies focus on the first order information of a portfolio vector, though the second order information may also be beneficial to a strategy. Moreover, empirical evidence shows that relative stock prices may follow the mean reversion property, which has not been fully exploited by existing strategies. This article proposes a novel online portfolio selection strategy named Confidence Weighted Mean Reversion (CWMR). Inspired by the mean reversion principle in finance and confidence weighted online learning technique in machine learning, CWMR models the portfolio vector as a Gaussian distribution, and sequentially updates the distribution by following the mean reversion trading principle. CWMR's closed-form updates clearly reflect the mean reversion trading idea. We also present several variants of CWMR algorithms, including a CWMR mixture algorithm that is theoretical universal. Empirically, CWMR strategy is able to effectively exploit the power of mean reversion for online portfolio selection. Extensive experiments on various real markets show that the proposed strategy is superior to the state-of-the-art techniques. The experimental testbed including source codes and data sets is available online.(1)	[Li, Bin; Hoi, Steven C. H.; Zhao, Peilin] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Gopalkrishnan, Vivekanand] Deloitte Analyt Inst Asia, Singapore, Singapore	Li, B (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	s080061@ntu.edu.sg; chhoi@ntu.edu.sg; zhao0106@ntu.edu.sg; vivek@deloitte.com			Singapore MOE tier 1 project [RG33/11]	This work was supported by Singapore MOE tier 1 project (RG33/11).	Agarwal A., 2005, NEW ALGORITHMS REPEA; Agarwal A., 2006, P 23 INT C MACH LEAR, P9, DOI 10.1145/1143844.1143846; Akcoglu K., 2005, SIAM J COMPUT, V34, P1; Aldridge I., 2010, HIGH FREQUENCY TRADI; Belentepe C. Y., 2005, THESIS U PENNSYLVANI; Bernoulli D, 1954, ECONOMETRICA, V22, P23, DOI 10.2307/1909829; Blum A, 1999, MACH LEARN, V35, P193, DOI 10.1023/A:1007530728748; Bondt W. F. M. D., 1985, J FINANC, V40, P793, DOI 10.2307/2327804; Bondt W. F. M. D., 1987, J FINANC, V42, P557, DOI 10.2307/2328371; Borodin A, 2000, LECT NOTES COMPUT SC, V1776, P173, DOI 10.1007/10719839_19; Borodin A, 2004, J ARTIF INTELL RES, V21, P579; Boyd S., 2004, CONVEX OPTIMIZATION; Breiman L., 1961, P 4 BERK S MATH STAT, P65; Cao LJ, 2003, IEEE T NEURAL NETWOR, V14, P1506, DOI 10.1109/TNN.2003.820556; Cesa-Bianchi N, 2004, IEEE T INFORM THEORY, V50, P2050, DOI 10.1109/TIT.2004.833339; Chaudhuri K., 2003, MANAGE FINANC, V29, P22, DOI 10.1108/03074350310768490; Chopra V.K., 1993, J PORTF MANAGE, V4, P6, DOI DOI 10.3905/JPM.1993.409440; Cover T., 1998, P ANN IEEE INT S INF; Cover T. M., 1991, ELEMENTS INFORM THEO; Cover T. M., 1991, MATH FINANC, V1, P1, DOI 10.1111/j.1467-9965.1991.tb00002.x; COVER TM, 1986, ADV APPL MATH, V7, P170, DOI 10.1016/0196-8858(86)90029-1; Cover TM, 1996, IEEE T INFORM THEORY, V42, P348, DOI 10.1109/18.485708; Crammer K., 2008, ADV NEURAL INFORM PR; Crammer K, 2006, J MACH LEARN RES, V7, P551; Crammer K, 2003, J MACH LEARN RES, V3, P951, DOI 10.1162/jmlr.2003.3.4-5.951; Crammer K., 2009, P C EMP METH NAT LAN, P496; Cross JE, 2003, MATH FINANC, V13, P245, DOI 10.1111/1467-9965.00016; Das P., 2011, P 17 ACM SIGKDD INT, P1163; DREDZE M, 2008, ICML ACM INT P SERIE, V307, P264; Duchi J., 2008, P 25 INT C MACH LEAR, P272, DOI DOI 10.1145/1390156.1390191; Elton E. J., 1995, MODERN PORTFOLIO THE; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Gaivoronski AA, 2003, J ECON DYN CONTROL, V27, P1013, DOI 10.1016/S0165-1889(02)00053-2; Gaivoronski AA, 2000, ANN OPER RES, V100, P165, DOI 10.1023/A:1019271201970; Gentile C., 2001, J MACHINE LEARNING R, V2, P213; Golub G.H., 1996, MATRIX COMPUTATIONS; GRINOLD R. C, 1999, ACTIVE PORTFOLIO MAN; Gyorfi L., 2008, STAT DECISIONS, V26, P145, DOI 10.1524/stnd.2008.0917; Gyorfi L., 2012, MACHINE LEARNING FIN; GYORFI L, 2008, P 19 INT C ALG LEARN, V5254, P108; Gyorfi L., 2003, P ADV LEARN THEOR ME; GYORFI L., 2007, INT J THEOR APPL FIN, V10, P505, DOI 10.1142/S0219024907004251; Gyorfi L, 2006, MATH FINANC, V16, P337, DOI 10.1111/j.1467-9965.2006.00274.x; Hazan E., 2009, P 26 ANN INT C MACH, P393; Hazan E., 2009, P ADV NEUR INF PROC; Helmbold DP, 1997, MACH LEARN, V27, P97, DOI 10.1023/A:1007301011561; Helmbold DP, 1998, MATH FINANC, V8, P325, DOI 10.1111/1467-9965.00058; JEGADEESH N, 1990, J FINANC, V45, P881, DOI 10.2307/2328797; JEGADEESH N, 1991, J FINANC, V46, P1427, DOI 10.2307/2328865; Kalai A., 2002, J MACH LEARN RES, V3, P423; KELLY JL, 1956, AT&T TECH J, V35, P917; Kimoto T., 1993, NEURAL NETWORKS FINA, P343; Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LATANE HA, 1959, J POLIT ECON, V67, P144, DOI 10.1086/258157; Levina T, 2008, INT J UNCERTAIN FUZZ, V16, P437, DOI 10.1142/S0218488508005364; Li B., 2011, J MACH LEARN RES P T, V15, P434; Li B, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961193; Li B., 2012, P 29 ANN INT C MACH; Li B, 2012, MACH LEARN, V87, P221, DOI 10.1007/s10994-012-5281-z; Li Y., 1999, P ADV NEUR INF PROC; LO AW, 1990, REV FINANC STUD, V3, P175, DOI 10.1093/rfs/3.2.175; Lu CJ, 2009, DECIS SUPPORT SYST, V47, P115, DOI 10.1016/j.dss.2009.02.001; MAGDONISMAIL M, 2004, RISK, V17, P99; Markowitz H, 1952, J FINANC, V7, P77, DOI 10.2307/2975974; Ordentlich E., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238161; Ottucsak G., 2007, STAT DECISIONS, V25, P63, DOI 10.1524/stnd.2007.25.1.63; POTERBA JM, 1988, J FINANC ECON, V22, P27, DOI 10.1016/0304-405X(88)90021-9; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; SHARPE WF, 1994, J PORTFOLIO MANAGE, V21, P49, DOI 10.3905/jpm.1994.409501; SHARPE WF, 1964, J FINANC, V19, P425, DOI 10.2307/2977928; SHARPE WF, 1963, MANAGE SCI, V9, P277, DOI 10.1287/mnsc.9.2.277; Singer Y., 1997, INT J NEURAL SYST, V8, P488; Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3; Thorp E. O., 1971, P BUS EC SECT AM STA; Tsang E, 2004, DECIS SUPPORT SYST, V37, P559, DOI 10.1016/S0167-9236(03)00087-3; Vovk V., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279947; Vovk V. G., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; Wang J., 2012, P 29 ANN INT C MACH; Zhao PL, 2011, J MACH LEARN RES, V12, P1587	80	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2013	7	1							4	10.1145/2435209.2435213		38	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	110BA	WOS:000316415700004	
J	Wang, DD; Zhu, SH; Li, T; Gong, YH				Wang, Dingding; Zhu, Shenghuo; Li, Tao; Gong, Yihong			Comparative Document Summarization via Discriminative Sentence Selection	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Experimentation; Performance; Comparative document summarization; discriminative sentence selection		Given a collection of document groups, a natural question is to identify the differences among these groups. Although traditional document summarization techniques can summarize the content of the document groups one by one, there exists a great necessity to generate a summary of the differences among the document groups. In this article, we study a novel problem of summarizing the differences between document groups. A discriminative sentence selection method is proposed to extract the most discriminative sentences that represent the specific characteristics of each document group. Experiments and case studies on real-world data sets demonstrate the effectiveness of our proposed method.	[Wang, Dingding; Li, Tao] Florida Int Univ, Dept Comp Sci, Miami, FL 33199 USA; [Zhu, Shenghuo; Gong, Yihong] NEC Labs Amer Inc, Cupertino, CA 95014 USA	Wang, DD (reprint author), Florida Int Univ, Dept Comp Sci, 11200 SW 8th St, Miami, FL 33199 USA.	dwang003@cs.fiu.edu; zsh@sv.nec-labs.com; taoli@cs.fiu.edu; ygong@sv.nec-labs.com			NSF [DBI-0850203, HRD-0833093, DMS-0915110]; DHS [2009-ST-062-000016, 2010-ST-062-000039]	The work was partially supported by NSF grants DBI-0850203, HRD-0833093, and DMS-0915110, and DHS grants 2009-ST-062-000016 and 2010-ST-062-000039.	Allan J., 1998, P DARPA BROADC NEWS, P194; Allan J., 2001, P 24 ANN INT ACM SIG, P10, DOI 10.1145/383952.383954; Baeza-Yates R. A., 1999, MODERN INFORM RETRIE; Barzilay R., 1999, P ACL; BAXENDALE PB, 1958, IBM J RES DEV, V2, P354; Brants T, 2003, P 26 ANN INT ACM SIG, P330; Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.291025; Chi Y., 2007, P SIGKDD; Conroy J.M., 2001, P 24 ANN INT ACM SIG, P406, DOI 10.1145/383952.384042; Ding C., 2005, P SIAM DAT MIN; EDMUNDSO.HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519; Erkan S., 2004, P EMNLP; FUNG GPC, 2007, P KDD, P300, DOI 10.1145/1281192.1281227; Goldstein J., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312665; Gong Y., 2001, P 21 ANN INT ACM SIG; Hu M., 2004, P SIGKDD; Jing H., 2000, P NAACL 00; Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9; Kumaran G., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009044; Lerman K., 2009, P HUM LANG TECHN 200, P113, DOI 10.3115/1620853.1620886; Li T, 2006, IEEE DATA MINING, P362; Li T., 2008, P SIAM INT C DAT MIN; Li X., 2006, P CIKM 06, P238, DOI 10.1145/1183614.1183652; Lin C., 2003, P NLT NAACL; Makkonen J, 2004, INFORM RETRIEVAL, V7, P347, DOI 10.1023/B:INRT.0000011210.12953.86; Mani I., 1999, Information Retrieval, V1, DOI 10.1023/A:1009930203452; Mani I., 1997, P 15 NAT C ART INT A, P622; Mani I., 2001, AUTOMATIC SUMMARIZAT; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; Mihalcea R., 2005, P IJCNLP; Morinaga S., 2004, P 10 ACM SIGKDD INT, P811, DOI 10.1145/1014052.1016919; NEICKOVA A., 2007, T SPEECH LANG PROCES, V4, P2; Ning H., 2007, P SIAM DAT MIN C; Ou S., 2007, P INT C REC ADV NAT, P442; Paul M. J., 2010, P C EMP METH NAT LAN, P66; Petersen K. B., 2006, MATRIX COOKBOOK VERS; Radev DR, 2004, INFORM PROCESS MANAG, V40, P919, DOI 10.1016/j.ipm.2003.10.006; Shen C., 2010, P 23 INT C COMP LING, P984; Shen D., 2007, P 20 INT JOINT C ART, P2862; Wan X., 2008, P 31 ANN INT SIGIR C; Wang D., 2008, P 31 ANN INT ACM SIG, P307, DOI 10.1145/1390334.1390387; Wang D., 2009, P 18 ACM C INF KNOWL, P1963, DOI 10.1145/1645953.1646276; Wang Dengting, 2009, Proceedings of the 5th International Conference on Asian and Pacific Coasts. APAC 2009, DOI 10.3115/1667583.1667675; Wang DD, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P809; Yang Y, 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953; Yu K., 2006, P ICML; Zhai C., 2004, P SIGKDD; Zhang K., 2007, P SIGIR 2007, P215, DOI 10.1145/1277741.1277780; Zhang Y, 2002, P 25 ANN INT ACM SIG, P81; Zhao Q., 2007, P 22 NAT C ART INT, V2, P1501; Zhu SH, 2010, IEEE ACM T COMPUT BI, V7, P25, DOI 10.1109/TCBB.2008.35	51	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2013	7	1							2	10.1145/2435209.2435211		18	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	110BA	WOS:000316415700002	
J	Ienco, D; Robardet, C; Pensa, RG; Meo, R				Ienco, Dino; Robardet, Celine; Pensa, Ruggero G.; Meo, Rosa			Parameter-less co-clustering for star-structured heterogeneous data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Co-clustering; Star-structured data; Multi-view data	NONNEGATIVE MATRIX FACTORIZATION; LOCAL SEARCH; ALGORITHMS	The availability of data represented with multiple features coming from heterogeneous domains is getting more and more common in real world applications. Such data represent objects of a certain type, connected to other types of data, the features, so that the overall data schema forms a star structure of inter-relationships. Co-clustering these data involves the specification of many parameters, such as the number of clusters for the object dimension and for all the features domains. In this paper we present a novel co-clustering algorithm for heterogeneous star-structured data that is parameter-less. This means that it does not require either the number of row clusters or the number of column clusters for the given feature spaces. Our approach optimizes the Goodman-Kruskal's tau, a measure for cross-association in contingency tables that evaluates the strength of the relationship between two categorical variables. We extend tau to evaluate co-clustering solutions and in particular we apply it in a higher dimensional setting. We propose the algorithm CoStar which optimizes tau by a local search approach. We assess the performance of CoStar on publicly available datasets from the textual and image domains using objective external criteria. The results show that our approach outperforms state-of-the-art methods for the co-clustering of heterogeneous data, while it remains computationally efficient.	[Ienco, Dino; Pensa, Ruggero G.; Meo, Rosa] Univ Turin, Dept Comp Sci, I-10139 Turin, Italy; [Robardet, Celine] Univ Lyon, CNRS, INSA Lyon, LIRIS UMR5205, F-69621 Villeurbanne, France; [Ienco, Dino] IRSTEA Montpellier, UMR TETIS, F-34093 Montpellier, France	Ienco, D (reprint author), IRSTEA Montpellier, UMR TETIS, F-34093 Montpellier, France.	dino.ienco@teledetection.fr; celine.robardet@insa-lyon.fr; pensa@di.unito.it; meo@di.unito.it	Pensa, Ruggero/B-5994-2011	Pensa, Ruggero/0000-0001-5145-3438	French Research Agency (ANR) through the FOSTER project [ANR-2010-COSI-012-02]	Celine Robardet is partially funded by the French Research Agency (ANR) through the FOSTER project (ANR-2010-COSI-012-02).	Anagnostopoulos A, 2008, P 27 ACM SIGMOD SIGA, P201, DOI 10.1145/1376916.1376945; Banerjee A, 2007, J MACH LEARN RES, V8, P1919; Bekkerman R, 2007, COMPUTER VISION PATT, P1; Bickel S, 2004, ICDM 04, P19; Chakrabarti D., 2004, KDD, P79; Chen YH, 2009, LECT NOTES ARTIF INT, V5781, P211; Chen YH, 2010, IEEE T KNOWL DATA EN, V22, P1459, DOI 10.1109/TKDE.2009.169; Cho H, 2004, P SIAM SDM 2004; Cleuziou G, 2009, IEEE DATA MINING, P752, DOI 10.1109/ICDM.2009.138; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Gao B, 2006, IEEE DATA MINING, P880; GOODMAN LA, 1954, J AM STAT ASSOC, V49, P732, DOI 10.2307/2281536; Greco G, 2009, IEEE T KNOWL DATA EN, V22, P1649; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Ienco D, 2009, LECT NOTES ARTIF INT, V5781, P580; Jaszkiewicz A, 2002, EUR J OPER RES, V137, P50, DOI 10.1016/S0377-2217(01)00104-7; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Knowles J, 2006, 214 TIK ETH ZUR; Lee DD, 2001, ADV NEUR IN, V13, P556; Liefooghe A, 2012, J HEURISTICS, V18, P317, DOI 10.1007/s10732-011-9181-3; Long B, 2006, ICML, P585; Long B, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P470; Paquete L, 2006, STOCHASTIC LOCAL SEA, V295; Paquete L, 2006, EUR J OPER RES, V169, P943, DOI 10.1016/j.ejor.2004.08.024; Pensa R. G., 2008, P SIAM SDM, P25; Ramage Daniel, 2009, WSDM 09, P54; Robardet C, 2001, LECT NOTES ARTIF INT, V2168, P399; Robardet C, 2001, LNCS, V2226, P323; Sheskin D.J., 2007, HDB PARAMETRIC NONPA; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Zar J.H., 1998, BIOSTATISTICAL ANAL	33	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2013	26	2					217	254		10.1007/s10618-012-0248-z		38	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	069PI	WOS:000313448400001	
J	Zhen, Y; Yeung, DY				Zhen, Yi; Yeung, Dit-Yan			Active hashing and its application to image and text retrieval	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Active hashing; Semi-supervised hashing; Hashing; Hash function learning	APPROXIMATE NEAREST-NEIGHBOR; DIMENSIONS	In recent years, hashing-based methods for large-scale similarity search have sparked considerable research interests in the data mining and machine learning communities. While unsupervised hashing-based methods have achieved promising successes for metric similarity, they cannot handle semantic similarity which is usually given in the form of labeled point pairs. To overcome this limitation, some attempts have recently been made on semi-supervised hashing which aims at learning hash functions from both metric and semantic similarity simultaneously. Existing semi-supervised hashing methods can be regarded as passive hashing since they assume that the labeled pairs are provided in advance. In this paper, we propose a novel framework, called active hashing, which can actively select the most informative labeled pairs for hash function learning. Specifically, it identifies the most informative points to label and constructs labeled pairs accordingly. Under this framework, we use data uncertainty as a measure of informativeness and develop a batch mode algorithm to speed up active selection. We empirically compare our method with a state-of-the-art passive hashing method on two benchmark data sets, showing that the proposed method can reduce labeling cost as well as overcome the limitations of passive hashing.	[Zhen, Yi; Yeung, Dit-Yan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China	Zhen, Y (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Clearwater Bay Rd, Kowloon, Hong Kong, Peoples R China.	yzhen@cse.ust.hk; dyyeung@cse.ust.hk			Research Grants Council of the Hong Kong Special Administrative Region, China [622209]	This research has been supported by General Research Fund 622209 from the Research Grants Council of the Hong Kong Special Administrative Region, China.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Atkinson A., 1992, OPTIMUM EXPT DESIGNS; Boyd S., 2004, CONVEX OPTIMIZATION; Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Eshghi K, 2008, P 14 ACM SIGKDD INT, P221, DOI 10.1145/1401890.1401921; Freund Y., 2003, J MACHINE LEARNING R, V4, P933, DOI 10.1162/jmlr.2003.4.6.933; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Guo Y., 2007, ADV NEURAL INFORM PR, V20, P593; Guo YH, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P823; He J., 2010, P 16 ACM SIGKDD INT, P1129, DOI 10.1145/1835804.1835946; He X, 2007, P 30 ANN INT ACM SIG, P119, DOI 10.1145/1277741.1277764; Hoi S. C. H., 2006, P 23 INT C MACH LEAR, P417, DOI 10.1145/1143844.1143897; Hoi S. C. H., 2006, P 15 INT C WORLD WID, P633, DOI 10.1145/1135777.1135870; Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI 10.1145/1401890.1401944; Kulis B., 2009, ADV NEURAL INFORM PR, V20, P1042; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Lewis D.D., 1994, P ANN SIGIR C RES DE, V15, P3; Lin RS, 2010, PROC CVPR IEEE, P848, DOI 10.1109/CVPR.2010.5540129; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; McCallum A, 2001, P 18 INT C MACH LEAR, P441; McCallum A., 1998, P 15 INT C MACH LEAR, P350; Mu Y, 2010, P 24 AAAI C ART INT, P539; Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024; Nguyen H. T., 2004, P 21 INT C MACH LEAR, P79; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Seung H., 1992, P ACM WORKSH COMP LE, V452, P287; Shakhnarovich G., 2005, THESIS MIT; Shakhnarovich G., 2006, NEAREST NEIGHBOR MET; Tong S, 2002, J MACH LEARN RES, V2, P45; Torre A., 2008, P IEEE C COMP VIS PA, P1; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Wang J., 2010, P 27 INT C MACH LEAR, P1127; Weiss Y., 2008, ADV NEURAL INFORM PR, V21, P1753; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Yu K., 2006, P 23 INT C MACH LEAR, V1, P1081, DOI 10.1145/1143844.1143980; Yu K., 2008, P 31 ANN INT ACM SIG, P635, DOI 10.1145/1390334.1390442; Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18; Zhen Y, 2010, P 33 ANN INT ACM SIG, P299, DOI 10.1145/1835449.1835501; Zhu X., 2003, ICML WORKSH CONT LAB	44	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2013	26	2					255	274		10.1007/s10618-012-0249-y		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	069PI	WOS:000313448400002	
J	Wang, XY; Mueen, A; Ding, H; Trajcevski, G; Scheuermann, P; Keogh, E				Wang, Xiaoyue; Mueen, Abdullah; Ding, Hui; Trajcevski, Goce; Scheuermann, Peter; Keogh, Eamonn			Experimental comparison of representation methods and distance measures for time series data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Time series; Representation; Distance measure; Experimental comparison		The previous decade has brought a remarkable increase of the interest in applications that deal with querying and mining of time series data. Many of the research efforts in this context have focused on introducing new representation methods for dimensionality reduction or novel similarity measures for the underlying data. In the vast majority of cases, each individual work introducing a particular method has made specific claims and, aside from the occasional theoretical justifications, provided quantitative experimental observations. However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive validation, we conducted an extensive experimental study re-implementing eight different time series representations and nine similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In this article, we give an overview of these different techniques and present our comparative experimental findings regarding their effectiveness. In addition to providing a unified validation of some of the existing achievements, our experiments also indicate that, in some cases, certain claims in the literature may be unduly optimistic.	[Wang, Xiaoyue; Mueen, Abdullah; Keogh, Eamonn] Univ Calif Riverside, Riverside, CA 92521 USA; [Ding, Hui; Trajcevski, Goce; Scheuermann, Peter] Northwestern Univ, Evanston, IL USA	Wang, XY (reprint author), Univ Calif Riverside, Riverside, CA 92521 USA.	xwang@cs.ucr.edu; mueen@cs.ucr.edu; hdi117@eecs.northwestern.edu; goce@eecs.northwestern.edu; peters@eecs.northwestern.edu; eamonn@cs.ucr.edu	Trajcevski, Goce/B-7277-2009; Scheuermann, Peter/B-7269-2009		NSF [0803410, 0808770]; NSF-CNS [0910952]	Research supported by NSF awards 0803410 and 0808770, NSF-CNS grant 0910952.	Alon J, 2005, ICDAR 05, P839; Andre-Jonsson H, 1997, PKDD; Assfalg J, 2006, EDBT; Assfalg J, 2008, MMM 08, P123; Bennett B, 2004, ARTIF INTELL, V153, P13, DOI 10.1016/j.artint.2003.02.001; Berndt D.J., 1994, KDD WORKSH, P359; Cai Y., 2004, SIGMOD C; Cardle M, 2004, TECHNICAL REPORT; Chan K.-P., 1999, ICDE; Chen L, 2005, SSDBM; Chen L., 2005, SIGMOD C; Chen L., 2004, VLDB; Chen Q., 2007, VLDB; Duda R., 1973, PATTERN CLASSIFICATI; Faloutsos C, 1994, SIGMOD C; Flato E, 2000, THESIS TEL AVIV U; Frentzos E, 2007, ICDE; Geurts P, 2002, THESIS U LIEGE BELGI; Geurts P, 2001, PKDD; Jia S, 2004, INT C PATT RECOG, P634; Jiawei H, 2005, DATA MINING CONCEPTS; Karamitopoulos L, 2009, CSIE, P490; Karydis I, 2005, IJBIDM, V1; Kawagoe K, 2002, TIME; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; Keogh E, 2001, SIGMOD RECORD, V30, P151; Keogh E, 2009, VLDB J, V18, P611, DOI 10.1007/s00778-008-0111-4; Keogh E., 2006, UCR TIME SERIES DATA; Keogh E., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011669; Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9; Keogh Eamonn, 2002, VLDB; Keogh EJ, 2006, VLDB; Kim S-W, 2001, ICDE; Kohavi R., 1995, IJCAI; Korn F., 1997, SIGMOD C; Kumar A, 2007, LECT NOTES COMPUT SC, V4843, P586; Lemire D, 2009, PATTERN RECOGN, V42, P2169, DOI 10.1016/j.patcog.2008.11.030; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Lin Y, 2006, GRAPHITE 06 P 4 INT, P31; Morse MD, 2007, SIGMOD C; Ng RT, 2006, NOTE CAUTION; Olofsson P, 2005, PROBABILITY STAT STO; Papadopoulos AN, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1089; Park S, 2006, PREFIX QUERYING 11 D; Patel J.M., 2007, ICDE; Popivanov I, 2002, ICDE; Ratanamahatana CA, 2005, SDM; Sakurai Y., 2005, PODS, P326, DOI 10.1145/1065167.1065210; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Seidl T., 2009, PVLDB, V2, P826; Steinbach M, 2003, KDD; Tan P.N, 2005, INTRO DATA MINING; Tansel A., 1993, TEMPORAL DATABASES T; Vlachos M, 2006, VLDB J, V15, P1, DOI 10.1007/s00778-004-0144-2; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; Wu Y-L, 2000, CIKM; Xi X, 2006, ICML; Yi B-K, 1998, ICDE; Yi B-K, 2000, VLDB; Zhang G HB, 2009, COMPUT METHODS BIOME; Zhou M, 2007, ICDE, P1307; Zhu Y, 2003, SIGMOD C; [Anonymous], 2007, WORKSH CHALL TIM SER	63	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2013	26	2					275	309		10.1007/s10618-012-0250-5		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	069PI	WOS:000313448400003	
J	Gorecki, T; Luczak, M				Gorecki, Tomasz; Luczak, Maciej			Using derivatives in time series classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Dynamic Time Warping; Derivative Dynamic Time Warping; Data mining; Time series		Over recent years the popularity of time series has soared. Given the widespread use of modern information technology, a large number of time series may be collected during business, medical or biological operations, for example. As a consequence there has been a dramatic increase in the amount of interest in querying and mining such data, which in turn has resulted in a large number of works introducing new methodologies for indexing, classification, clustering and approximation of time series. In particular, many new distance measures between time series have been introduced. In this paper, we propose a new distance function based on a derivative. In contrast to well-known measures from the literature, our approach considers the general shape of a time series rather than point-to-point function comparison. The new distance is used in classification with the nearest neighbor rule. In order to provide a comprehensive comparison, we conducted a set of experiments, testing effectiveness on 20 time series datasets from a wide variety of application domains. Our experiments show that our method provides a higher quality of classification on most of the examined datasets.	[Gorecki, Tomasz] Adam Mickiewicz Univ, Fac Math & Comp Sci, PL-61614 Poznan, Poland; [Luczak, Maciej] Koszalin Univ Technol, Dept Civil & Environm Engn, PL-75453 Koszalin, Poland	Gorecki, T (reprint author), Adam Mickiewicz Univ, Fac Math & Comp Sci, Umultowska 87, PL-61614 Poznan, Poland.	tomasz.gorecki@amu.edu.pl; mluczak@wbiis.tu.koszalin.pl					Batista G, 2011, 11 SIAM INT C DAT MI; Benedikt L, 2008, BMVC, V2, P235; Benedikt L, 2010, IEEE T SYST MAN CY A, V40, P449, DOI 10.1109/TSMCA.2010.2041656; Berndt D., 1994, AAAI 94 WORKSH KNOWL, P229; Box GEP, 2008, TIME SERIES ANAL FOR; Demsar J, 2006, J MACH LEARN RES, V7, P1; Ding H., 2008, P VLDB ENDOWMENT, V1, P1542, DOI DOI 10.1145/1454159.1454226; DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330; Eads D, 2002, P SOC PHOTO-OPT INS, V4787, P74, DOI 10.1117/12.453526; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Gullo F, 2009, PATTERN RECOGN, V42, P2998, DOI 10.1016/j.patcog.2009.03.030; Hollander M., 1973, NONPARAMETRIC STAT M; IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; Keogh E., 2002, KNOWL INF SYST, V7, P406; Keogh E, 2001, P SIAM INT C DAT MIN; Keogh E. J., 2006, UCR TIME SERIES CLAS; Kulbacki M, 2002, P INT INF SYST 2002; Looney S.W., 1998, PATTERN RECOGN LETT, V8, P5; Luan F, 2010, INT J MODEL IDENTIF, V10, P81; Mokhtar N, 2010, SCI RES ESSAYS, V5, P2947; Nemenyi PB, 1963, THESIS PRINCETON U; Pavlovic V, 1999, COMPUT VIS PATTERN R, V2, P2609; Penny WD, 1999, COMPUT BIOMED RES, V32, P483, DOI 10.1006/cbmr.1999.1511; Kehagias A, 1997, NEURAL NETWORKS, V10, P31, DOI 10.1016/S0893-6080(96)00040-8	25	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2013	26	2					310	331		10.1007/s10618-012-0251-4		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	069PI	WOS:000313448400004	
J	Sim, K; Gopalkrishnan, V; Zimek, A; Cong, G				Sim, Kelvin; Gopalkrishnan, Vivekanand; Zimek, Arthur; Cong, Gao			A survey on enhanced subspace clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Subspace Clustering; High-Dimensional Clustering; Projected Clustering; Survey	HIGH-DIMENSIONAL DATA; FINANCIAL RATIOS; CLOSED PATTERNS; QUASI-BICLIQUES; INFORMATION; ALGORITHM; HIERARCHIES; FRAMEWORK	Subspace clustering finds sets of objects that are homogeneous in subspaces of high-dimensional datasets, and has been successfully applied in many domains. In recent years, a new breed of subspace clustering algorithms, which we denote as enhanced subspace clustering algorithms, have been proposed to (1) handle the increasing abundance and complexity of data and to (2) improve the clustering results. In this survey, we present these enhanced approaches to subspace clustering by discussing the problems they are solving, their cluster definitions and algorithms. Besides enhanced subspace clustering, we also present the basic subspace clustering and the related works in high-dimensional clustering.	[Sim, Kelvin] ASTAR, Inst Infocomm Res, Data Min Dept, Singapore, Singapore; [Gopalkrishnan, Vivekanand] IBM Res Corp, Singapore, Singapore; [Zimek, Arthur] Univ Munich, Inst Informat, D-80539 Munich, Germany; [Cong, Gao] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Sim, K (reprint author), ASTAR, Inst Infocomm Res, Data Min Dept, Singapore, Singapore.	shsim@i2r.a-star.edu.sg; vivek@sg.ibm.com; zimek@dbs.ifi.lmu.de; gaocong@ntu.edu.sg					Achtert E., 2006, P 12 ACM SIGKDD INT, P4, DOI 10.1145/1150402.1150408; Achtert E, 2006, LECT NOTES ARTIF INT, V4213, P446; Achtert E, 2007, LECT NOTES COMPUT SC, V4443, P152; AGGARWAL CC, 2004, P 30 INT C VER LARG, P852, DOI 10.1016/B978-012088469-8/50075-9; Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Aggarwal C. C., 1999, SIGMOD Record, V28; Agrawal R., 1998, SIGMOD Record, V27; Agrawal R., 1994, P 20 INT C VER LARG, P487; Assent I, 2008, P 17 ACM C INF KNOWL, P1093, DOI 10.1145/1458082.1458227; Assent I, 2008, IEEE DATA MINING, P719, DOI 10.1109/ICDM.2008.46; Assent I, 2007, IEEE DATA MINING, P409; Avis D, 1996, DISCRETE APPL MATH, V65, P21, DOI 10.1016/0166-218X(95)00026-N; Bennett KP, 1999, P 5 INT C KNOWL DISC, P233, DOI 10.1145/312129.312236; Berkhin P., 2006, GROUPING MULTIDIMENS, V10, P25; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Bohm C., 2004, P 2004 ACM SIGMOD IN, P455, DOI 10.1145/1007568.1007620; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Cerf L., 2008, P 8 SIAM INT C DAT M, P37; Cerf L, 2009, ACM T KNOWL DISCOV D, V3, P1; Chan EY, 2004, PATTERN RECOGN, V37, P943, DOI 10.1016/j.patcog.2003.11.003; Cheng C. H., 1999, P 5 ACM SIGKDD INT C, P84, DOI 10.1145/312129.312199; Cheng Y, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P93; Chiaravalloti AD, 2006, LECT NOTES COMPUT SC, V4081, P248; Dai W., 2008, P 25 INT C MACH LEAR, P200, DOI 10.1145/1390156.1390182; Dash M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P115, DOI 10.1109/ICDM.2002.1183893; Dhillon I. S, 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; Ding C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183897; Domeniconi C, 2004, SIAM PROC S, P517; Duda R.O., 2001, PATTERN CLASSIFICATI; Faloutsos C, 2007, DATA MIN KNOWL DISC, V15, P3, DOI 10.1007/s10618-006-0057-3; Farber I, 2010, P 1 INT WORKSH DISC; Francois D, 2007, IEEE T KNOWL DATA EN, V19, P873, DOI 10.1109/TKDE.2007.1037; Fromont E., 2009, P SIAM INT C DAT MIN, P26; Fu QA, 2009, IEEE DATA MINING, P776, DOI 10.1109/ICDM.2009.132; Gao B, 2006, IEEE DATA MINING, P880; Georgii E, 2010, MACH LEARN, V82, P123; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; GUNNEMANN S, 2009, P 18 ACM C INF KNOWL, P1317, DOI 10.1145/1645953.1646120; Gunnemann S., 2010, P SIAM INT C DAT MIN, P385; Gunnemann Stephan, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.95; Gunnemann S, 2010, P 1 INT WORKSH DISC; Hinneburg A., 2000, P 26 INT C VER LARG, P506; Houle ME, 2010, P 22 INT C SCI STAT; Hsu CM, 2004, LECT NOTES ARTIF INT, V3056, P31; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jaschke R., 2006, P 6 IEEE INT C DAT M, P907; Ji L., 2006, P 32 INT C VER LARG, P811; Jiang D., 2004, P 10 ACM SIGKDD INT, P430, DOI 10.1145/1014052.1014101; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; Jing L, 2007, IEEE T KNOWL DATA EN, V19, P1026, DOI 10.1109/TKDE.2007.1048; Kailing K, 2003, LECT NOTES ARTIF INT, V2838, P241; Kailing K, 2004, SIAM PROC S, P246; Ke Y, 2006, P 12 ACM SIGKDD INT, P227, DOI 10.1145/1150402.1150430; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Kleinberg J, 1998, DATA MIN KNOWL DISC, V2, P311, DOI 10.1023/A:1009726428407; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kontaki M, 2008, INFORM SYST, V33, P240, DOI 10.1016/j.is.2007.09.001; Kriegel H-P, 2005, P IEEE ICDM INT C DA, P250; Kriegel HP, 2007, DATA MIN KNOWL DISC, V15, P87, DOI 10.1007/s10618-007-0067-9; Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578; Kriegel HP, 2010, P 1 INT WORKSH DISC; Kriegel HP, 2011, P 23 INT C SCI STAT, P387; Li J., 2008, P SIAM INT C DAT MIN, P72; Li JY, 2005, LECT NOTES ARTIF INT, V3721, P146; Li T., 2004, P 27 ANN INT ACM SIG, P218, DOI 10.1145/1008992.1009031; Liu G, 2009, STAT ANAL DATA MIN, V2, P427; Liu GM, 2006, LECT NOTES COMPUT SC, V4081, P437; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; Mishra N, 2004, MACH LEARN, V56, P115, DOI 10.1023/B:MACH.0000033117.77257.41; Moise G., 2008, P 14 ACM SIGKDD INT, P533, DOI 10.1145/1401890.1401956; Moise G, 2009, KNOWL INF SYST, V21, P299, DOI 10.1007/s10115-009-0226-y; Muller E, 2008, P 14 ACM INT C KNOWL, P1089, DOI 10.1145/1401890.1402026; Muller E, 2009, P 9 SIAM INT C DAT M, P173; Muller E, 2009, IEEE DATA MINING, P377, DOI 10.1109/ICDM.2009.10; Muller E., 2009, PVLDB, V2, P1270; Muller E, 2009, P 21 INT C SCI STAT, P497; Nagesh H, 2001, P 1 SIAM INT C DAT M; Nocedal J., 2006, NUMERICAL OPTIMIZATI, P497; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Parsons L, 2004, ACM SIGKDD EXPLORATI, V6, P90, DOI 10.1145/1007730.1007731; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; Patrikainen A, 2006, IEEE T KNOWL DATA EN, V18, P902, DOI 10.1109/TKDE.2006.106; Pensa R. G., 2008, P SIAM SDM, P25; Rege M, 2006, IEEE DATA MINING, P532; RYMON R, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P539; Sequeira K., 2004, P 4 IEEE INT C DAT M, P186; [Anonymous], 1986, CHAPMAN HALL CRC MON; Sim Kelvin, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.19; Sim K, 2011, INFORM SCIENCES, V181, P201, DOI 10.1016/j.ins.2010.08.035; Sim K, 2009, LECT NOTES ARTIF INT, V5782, P398, DOI 10.1007/978-3-642-04174-7_26; Sim K, 2006, IEEE DATA MINING, P1059; Sim K., 2010, P 10 SIAM INT C DAT, P442; Sim K, 2009, STAT ANAL DATA MININ, V2, P255; Snedecor GW, 1989, STAT METHODS; Srikant R., 1996, SIGMOD Record, V25; Sun JM, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P687; TANAY A, 2004, HDB COMPUTATIONAL MO; Tomita E., 2004, P 10 INT COMP COMB C, P161; Uno T, 2004, P 2 INT WORKSH FREQ; Vreeken J, 2011, P 2 INT WORKSH DISC, P7; Wagstaff K., 2001, P 18 INT C MACH LEAR, P577; Wang H., 2002, P 2002 ACM SIGMOD IN, P394; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; Xu X, 2009, PROC INT CONF DATA, P445; Yan CH, 2005, MOL PHYLOGENET EVOL, V35, P528, DOI 10.1016/j.ympev.2005.02.008; YANG J, 2002, PROC INT CONF DATA, P517; Zaki MJ, 2005, P 11 ACM INT C KNOWL, P736, DOI 10.1145/1081870.1081965; Zhang Q, 2007, P 7 IEEE INT C DAT M, P727; Zhang X, 2007, P 19 INT C SCI STAT, P32; Zhao L., 2005, P ACM SIGMOD INT C M, P694, DOI DOI 10.1145/1066157.1066236	111	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2013	26	2					332	397		10.1007/s10618-012-0258-x		66	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	069PI	WOS:000313448400005	
J	McGovern, A; Troutman, N; Brown, RA; Williams, JK; Abernethy, J				McGovern, Amy; Troutman, Nathaniel; Brown, Rodger A.; Williams, John K.; Abernethy, Jennifer			Enhanced spatiotemporal relational probability trees and forests	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Spatiotemporal relational learning; Statistical relational learning; Hazardous weather	PREDICTION SYSTEM ARPS; NONHYDROSTATIC ATMOSPHERIC SIMULATION; DOPPLER RADAR OBSERVATIONS; UPPER-LEVEL TURBULENCE; SUPERCELL THUNDERSTORM; CLASSIFICATION; REPRESENTATION; ALGORITHMS; TORNADOES; NETWORKS	Many real world domains are inherently spatiotemporal in nature. In this work, we introduce significant enhancements to two spatiotemporal relational learning methods, the spatiotemporal relational probability tree and the spatiotemporal relational random forest, that increase their ability to learn using spatiotemporal data. We enabled the models to formulate questions on both objects and the scalar and vector fields within and around objects, allowing the models to differentiate based on the gradient, divergence, and curl and to recognize the shape of point clouds defined by fields. This enables the model to ask questions about the change of a shape over time or about its orientation. These additions are validated on several real-world hazardous weather datasets. We demonstrate that these additions enable the models to learn robust classifiers that outperform the versions without these new additions. In addition, analysis of the learned models shows that the findings are consistent with current meteorological theories.	[McGovern, Amy; Troutman, Nathaniel] Univ Oklahoma, Sch Comp Sci, Norman, OK 73019 USA; [Brown, Rodger A.] NOAA, Natl Severe Storms Lab, Norman, OK 73072 USA; [Williams, John K.; Abernethy, Jennifer] Natl Ctr Atmospher Res, Res Applicat Lab, Boulder, CO 80307 USA	McGovern, A (reprint author), Univ Oklahoma, Sch Comp Sci, 100 W Boyd St, Norman, OK 73019 USA.	amcgovern@ou.edu; nathanieltroutman@gmail.com; Rodger.Brown@noaa.gov; jkwillia@ucar.edu; jabernet75@gmail.com			National Science Foundation [NSF/IIS/0746816]; NASA [NNX08AL89G]	The authors thank Jason Craig, David J. Gagne II, Nathan Hiers, Gregory Meymaris, Timothy Supinie, and Derek Rosendahl for their work in generating some of the data used in this research. This research was supported by the National Science Foundation under Grant No. NSF/IIS/0746816 and by NASA under Grant No. NNX08AL89G. Much of the computing for this project was performed at the OU Supercomputing Center for Education & Research (OSCER) at the University of Oklahoma (OU).	Allcroft DJ, 2001, SCRI ANN REPORT 2001, P192; ALLEN JF, 1991, INT J INTELL SYST, V6, P341, DOI 10.1002/int.4550060403; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Bedka K, 2010, J APPL METEOROL CLIM, V49, P181, DOI 10.1175/2009JAMC2286.1; Bluestein HB, 2007, MON WEATHER REV, V135, P475, DOI 10.1175/MWR3295.1; Bodenhamer M, 2009, P 2009 IEEE INT C DA; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Cornman L, 2004, 11 C AV RANG AER MET, pP43; CORNMAN LB, 1995, J AIRCRAFT, V32, P171, DOI 10.2514/3.46697; Cova TJ, 2002, INT J GEOGR INF SCI, V16, P509, DOI 10.1080/13658810210137040; Davies-Jones R, 2008, J ATMOS SCI, V65, P2469, DOI 10.1175/2007JAS2516.1; DUTTON JA, 1970, SCIENCE, V167, P937, DOI 10.1126/science.167.3920.937; Egan JP, 1984, SERIES COGNITION PER; Eldardiry H, 2011, P 25 C ART INT AAAI; Fast A, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P941; Fern A, 2006, SRL2006 OPEN PROBLEM; Friedman HF, 1996, P 13 NAT C ART INT, P717; Friedman N., 1999, P 16 INT JOINT C ART, P1300; Gagne II DJ, 2010, 8 C ART INT APPL ENV; GANDIN LS, 1992, MON WEATHER REV, V120, P361, DOI 10.1175/1520-0493(1992)120<0361:ESSFCF>2.0.CO;2; GERRITY JP, 1992, MON WEATHER REV, V120, P2709, DOI 10.1175/1520-0493(1992)120<2709:ANOGAM>2.0.CO;2; Getoor L., 2001, P 18 INT C MACH LEAR, P170; Getoor L., 2002, J MACHINE LEARNING R, V3, P679; Glasbey C, 2007, 39 FRENCH STAT ASS S; Goodchild MF, 2007, INT J GEOGR INF SCI, V21, P239, DOI 10.1080/13658810600965271; Jensen D., 2002, P 19 INT C MACH LEAR, P259; Jensen D, 2003, IJCAI 2003 WORKSH LE; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; Jolliffe I. T., 2003, FORECAST VERIFICATIO; KLEMP JB, 1983, J ATMOS SCI, V40, P359, DOI 10.1175/1520-0469(1983)040<0359:ASOTTR>2.0.CO;2; Kononenko I., 1984, EXPT AUTOMATIC LEARN; Liu WZ, 1997, LECT NOTES COMPUT SC, V1280, P527; Longley P.A., 2005, GEOGRAPHIC INFORM SY; Markowski PM, 2009, ATMOS RES, V93, P3, DOI 10.1016/j.atmosres.2008.09.015; Markowski PM, 2003, J ATMOS SCI, V60, P295; Marzban C, 1998, WEATHER FORECAST, V13, P753, DOI 10.1175/1520-0434(1998)013<0753:SMOPIR>2.0.CO;2; McGovern A, 2011, DATA MIN KNOWL DISC, V22, P232, DOI 10.1007/s10618-010-0193-7; McGovern A., 2008, P 2008 IEEE INT C DA, P935; McGovern A, 2010, P 2010 NASA C INT DA, P213; McGovern Amy, 2011, Statistical Analysis and Data Mining, V4, DOI 10.1002/sam.10128; Miller HJ, 2009, CH CRC DATA MIN KNOW, P1; NEVILLE J., 2005, P 11 ACM SIGKDD INT, P449, DOI DOI 10.1145/1081870.1081922; Neville J, 2007, J MACH LEARN RES, V8, P653; Neville J, 2005, P 5 IEEE INT C DAT M, P322; Neville J., 2003, P 9 ACM SIGKDD INT C, P625; O'Rourke J, 1985, INT J COMPUT INF SCI, V14, P17; O'Sullivan D, 2002, GEOGRAPHIC INFORM AN; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F, 2000, 0004IS CDER NYU U WA; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1; Rosendahl DH, 2008, THESIS U OKLAHOMA; Russell S, 2009, ARTIFICIAL INTELLIGE; Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x; Sharan U, 2008, P IEEE INT C DAT MIN; Sharan U, 2007, P 1 SNA KDD WORKSH 1; Sharman R, 2006, WEATHER FORECAST, V21, P268, DOI 10.1175/WAF924.1; Snook N, 2008, GEOPHYS RES LETT, V35, DOI 10.1029/2008GL035866; Srinivasan A, 1999, PRGTR1600 OXF U COMP; Storm Prediction Center, 2012, ANN FAT TORN SUMM; Supinie TA, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS (ICDMW 2009), P630, DOI 10.1109/ICDMW.2009.89; Trapp RJ, 2005, WEATHER FORECAST, V20, P680, DOI 10.1175/WAF864.1; Trier SB, 2009, MON WEATHER REV, V137, P1972, DOI 10.1175/2008MWR2770.1; Troutman N, 2010, THESIS U OKLAHOMA; Valdes-Sosa PA, 2004, NEUROINFORMATICS, V2, P239, DOI 10.1385/NI:2:2:239; WEBER RO, 1993, MON WEATHER REV, V121, P2611, DOI 10.1175/1520-0493(1993)121<2611:SROSCF>2.0.CO;2; White AP, 1987, PROBABILISTIC INDUCT, P34; WICKER LJ, 1995, J ATMOS SCI, V52, P2675, DOI 10.1175/1520-0469(1995)052<2675:SAAOTD>2.0.CO;2; Williams JK, 2008, P SPIE REMOTE SENSIN, V7088; Wolff JK, 2008, J APPL METEOROL CLIM, V47, P2198, DOI 10.1175/2008JAMC1799.1; Wurman J, 1996, SCIENCE, V272, P1774, DOI 10.1126/science.272.5269.1774; Xue M, 2003, METEOROL ATMOS PHYS, V82, P139, DOI 10.1007/s00703-001-0595-6; Xue M, 2000, METEOROL ATMOS PHYS, V75, P161, DOI 10.1007/s007030070003; Xue M, 2001, METEOROL ATMOS PHYS, V76, P143, DOI 10.1007/s007030170027	76	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2013	26	2					398	433		10.1007/s10618-012-0261-2		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	069PI	WOS:000313448400006	
J	Forestiero, A; Pizzuti, C; Spezzano, G				Forestiero, Agostino; Pizzuti, Clara; Spezzano, Giandomenico			A single pass algorithm for clustering evolving data streams based on swarm intelligence	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Data streams; Density-based clustering; Bio-inspired flocking model		Existing density-based data stream clustering algorithms use a two-phase scheme approach consisting of an online phase, in which raw data is processed to gather summary statistics, and an offline phase that generates the clusters by using the summary data. In this article we propose a data stream clustering method based on a multi-agent system that uses a decentralized bottom-up self-organizing strategy to group similar data points. Data points are associated with agents and deployed onto a 2D space, to work simultaneously by applying a heuristic strategy based on a bio-inspired model, known as flocking model. Agents move onto the space for a fixed time and, when they encounter other agents into a predefined visibility range, they can decide to form a flock if they are similar. Flocks can join to form swarms of similar groups. This strategy allows to merge the two phases of density-based approaches and thus to avoid the computing demanding offline cluster computation, since a swarm represents a cluster. Experimental results show that the bio-inspired approach can obtain very good results on real and synthetic data sets.	[Forestiero, Agostino; Pizzuti, Clara; Spezzano, Giandomenico] Natl Res Council Italy CNR, I-87036 Arcavacata Di Rende, CS, Italy	Pizzuti, C (reprint author), Natl Res Council Italy CNR, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.	forestiero@icar.cnr.it; pizzuti@icar.cnr.it; spezzano@icar.cnr.it					Aggarwal C., 2007, DATA STREAMS MODELS; Aggarwal C. C., 2003, P 29 INT C VER LARG, V29, P81; Aggarwal CC, 2006, DATA STREAMS MODELS, P11; Azzag H, 2003, LECT NOTES ARTIF INT, V2801, P564; Babock B, 2003, P 22 ACM S PRINC DAT, P234; Barbara D, 2002, SIGKDD EXPLORATIONS, V3, P23; Beringer J, 2006, DATA KNOWL ENG, V58, P180, DOI 10.1016/j.datak.2005.05.009; CAO F, 2006, P SIAM C DAT MIN, P326; Charikar M., 2003, P 35 ANN ACM S THEOR, P30, DOI DOI 10.1145/780542.780548; Chen Y, 2009, ACM T KNOWL DISCOV D, V3, P12; Chen YX, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P133; Cui X, 2006, P ACIS INT C SOFTW E, P97; Dai BR, 2006, IEEE T KNOWL DATA EN, V18, P1166; Eberhart R., 2001, MORGAN KAUFMANN SERI; Ester M, 1996, P 2 ACM SIGKDD INT C, P373; Folino G, 2009, INFORM SCIENCES, V179, P3059, DOI 10.1016/j.ins.2009.05.017; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; Guha S, 2000, ANN IEEE SYMP FOUND, P359; Hamdi A, 2008, LECT NOTES COMPUT SC, V5217, P411, DOI 10.1007/978-3-540-87527-7_50; Handl J., 2007, SWARM INTELLIGENCE, V1, P95, DOI 10.1007/s11721-007-0008-7; Li W, 2009, ACM T KNOWL DISCOV D, V3, P14; Liu S, 2004, 3 INT C MACH LEARN C, P1491; Nasraoui O, 2006, P SIAM C DAT MIN, P618; Nasraoui O, 2003, P ICDM, P235; O'Callaghan L, 2002, PROC INT CONF DATA, P685, DOI 10.1109/ICDE.2002.994785; Reynolds C., 1987, SIGGRAPH 87 C P, V21, P25, DOI DOI 10.1145/37402.37406; Sanghamitra B, 2006, INFORM SCI, V176, P1952; Tan P-N, 2006, INTRO DATA MINING; Wang Z, 2004, LECT NOTES COMPUT SC, V3007, P416; Zhou A, 2007, KNOWL INF SYST, V15, P181	30	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2013	26	1					1	26		10.1007/s10618-011-0242-x		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	064ZT	WOS:000313116400001	
J	Wu, G; Xu, W; Zhang, Y; Wei, YM				Wu, Gang; Xu, Wei; Zhang, Ying; Wei, Yimin			A preconditioned conjugate gradient algorithm for GeneRank with application to microarray data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Gene network; Microarray; GeneRank; Preconditioned conjugate gradient method (PCG); Krylov subspace method	GENES	The problem of identifying key genes is of fundamental importance in biology and medicine. The GeneRank model explores connectivity data to produce a prioritization of the genes in a microarray experiment that is less susceptible to variation caused by experimental noise than the one based on expression levels alone. The GeneRank algorithm amounts to solving an unsymmetric linear system. However, when the matrix in question is very large, the GeneRank algorithm is inefficient and even can be infeasible. On the other hand, the adjacency matrix is symmetric in the GeneRank model, while the original GeneRank algorithm fails to exploit the symmetric structure of the problem in question. In this paper, we discover that the GeneRank problem can be rewritten as a symmetric positive definite linear system, and propose a preconditioned conjugate gradient algorithm to solve it. Numerical experiments support our theoretical results, and show superiority of the novel algorithm.	[Wu, Gang] Xuzhou Normal Univ, Sch Math Sci, Xuzhou 221116, Jiangsu, Peoples R China; [Xu, Wei] Tongji Univ, Dept Math, Shanghai 200092, Peoples R China; [Zhang, Ying] Xuzhou Med Coll, Xuzhou 221000, Jiangsu, Peoples R China; [Wei, Yimin] Fudan Univ, Sch Math Sci, Shanghai Key Lab Contemporary Appl Math, Shanghai 200433, Peoples R China	Xu, W (reprint author), Tongji Univ, Dept Math, Shanghai 200092, Peoples R China.	gangwu76@yahoo.com.cn; wdxu@tongji.edu.cn; drzhangying@yahoo.com.cn; ymwei@fudan.edu.cn			National Science Foundation of China [11171289, 10901132, 11101310]; Qing-Lan Project of Jiangsu Province; 333 Project of Jiangsu Province; National Natural Science Foundation of China [10871051]; 973 Program Project [2010CB327900]; Ministry of Education [20090071110003]; Shanghai Education Committee [08SG01]; Shanghai Science and Technology Committee [09DZ2272900]	We would like to express our sincere thanks to the reviewers for their invaluable suggestions that make us greatly improve the representation of this paper. Meanwhile, we are grateful to J. Morrison, R. Breitling, D. Higham, D. Gilbert and Jun-feng Yin, for providing us with the GeneRank data files utilized in the numerical experiments. We also appreciate A. Taylor and D. Higham for providing us with the MATLAB file of the RENGA model. Gang Wu is supported by the National Science Foundation of China under grants 10901132 and 11171289, the Qing-Lan Project of Jiangsu Province, and the 333 Project of Jiangsu Province. The work of Wei Xu is partially supported by the National Science Foundation of China under grants 10901132 and 11101310. The work of Ying Zhang is partially supported by the National Science Foundation of China under grant 10901132. Yimin Wei is supported by the National Natural Science Foundation of China under grant 10871051, 973 Program Project (no. 2010CB327900), Doctoral Program of the Ministry of Education under grant 20090071110003, Shanghai Education Committee (Dawn Project 08SG01) and Shanghai Science and Technology Committee under grant 09DZ2272900.	Aerts S, 2006, NAT BIOTECHNOL, V24, P537, DOI 10.1038/nbt1203; Agarwal S, 2009, P LSS COMPUT SYST BI, V8, P37; Bai Z., 2000, TEMPLATES SOLUTION A; Benzi M, 2002, J COMPUT PHYS, V182, P418, DOI 10.1006/jcph.2002.7176; Cipra B., 2000, SIAM NEWS, V33; Demmel J., 1997, APPL NUMERICAL LINEA; Franke L, 2006, AM J HUM GENET, V78, P1011, DOI 10.1086/504300; Freschi V, 2007, IEEE INT C BIOINF BI, P42; Golub G.H., 1996, MATRIX COMPUTATIONS; Hai D, 2008, IEEE INT C NETW SENS, V6-8, P1496; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; Jia ZX, 1997, LINEAR ALGEBRA APPL, V259, P1, DOI 10.1016/S0024-3795(96)00238-8; Ma XT, 2007, BIOINFORMATICS, V23, P215, DOI 10.1093/bioinformatics/btl569; Morrison JL, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-233; Page L., 1998, TECHNICAL REPORT; Saad Y., 2003, ITERATIVE METHODS SP; Sharan R., 2007, MOL SYSTEMS BIOL, V3, P1; Taylor A, 2008, ACM T MATH SOFTWARE, V35; The MathWorks Inc, 2004, MATLAB 7; Wu G, 2010, J COMPUT BIOL, V17, P631, DOI 10.1089/cmb.2009.0004; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Yue B, 2007, IEEE 1 INT C BIOINF, V6-8, P248	22	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2013	26	1					27	56		10.1007/s10618-011-0245-7		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	064ZT	WOS:000313116400002	
J	Gupta, SK; Phung, D; Adams, B; Venkatesh, S				Gupta, Sunil Kumar; Dinh Phung; Adams, Brett; Venkatesh, Svetha			Regularized nonnegative shared subspace learning	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Nonnegative shared subspace learning; Transfer learning; Auxiliary sources; Multi-task clustering	MATRIX FACTORIZATION; ALGORITHMS; INITIALIZATION; RETRIEVAL; FRAMEWORK	Joint modeling of related data sources has the potential to improve various data mining tasks such as transfer learning, multitask clustering, information retrieval etc. However, diversity among various data sources might outweigh the advantages of the joint modeling, and thus may result in performance degradations. To this end, we propose a regularized shared subspace learning framework, which can exploit the mutual strengths of related data sources while being immune to the effects of the variabilities of each source. This is achieved by further imposing a mutual orthogonality constraint on the constituent subspaces which segregates the common patterns from the source specific patterns, and thus, avoids performance degradations. Our approach is rooted in nonnegative matrix factorization and extends it further to enable joint analysis of related data sources. Experiments performed using three real world data sets for both retrieval and clustering applications demonstrate the benefits of regularization and validate the effectiveness of the model. Our proposed solution provides a formal framework appropriate for jointly analyzing related data sources and therefore, it is applicable to a wider context in data mining.	[Gupta, Sunil Kumar; Dinh Phung; Adams, Brett; Venkatesh, Svetha] Curtin Univ Technol, Dept Comp, Perth, WA 6102, Australia	Gupta, SK (reprint author), Curtin Univ Technol, Dept Comp, Perth, WA 6102, Australia.	sunil.gupta@postgrad.curtin.edu.au					Agarwal A, 2010, ADV NEURAL INFORM PR, V23, P46; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Bae E, 2006, IEEE DATA MINING, P53; Baeza-Yates R. A., 1999, MODERN INFORM RETRIE; Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Ben-David S, 2003, LECT NOTES ARTIF INT, V2777, P567, DOI 10.1007/978-3-540-45167-9_41; Berry M. W., 2005, Computational & Mathematical Organization Theory, V11, DOI 10.1007/s10588-005-5380-5; Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006; Bickel S., 2004, P 4 IEEE INT C DAT M, P19, DOI [10.1109/icdm.2004.10095, DOI 10.1109/ICDM.2004.10095]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boutsidis C, 2008, PATTERN RECOGN, V41, P1350, DOI 10.1016/j.patcog.2007.09.010; Bucak S, 2007, ICIP, V2, P113; Cai D., 2007, IEEE 11 INT C COMP V, V14, P1; Cai D, 2008, IEEE DATA MINING, P63, DOI 10.1109/ICDM.2008.57; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chaudhuri K., 2009, P 26 ANN INT C MACH, P129; Choi S, 2008, IEEE IJCNN, P1828; Cui Y, 2007, IEEE DATA MINING, P133; DaiW, 2009, ICML, P193; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Ding CH, 2006, P 12 ACM SIGKDD INT, P126, DOI 10.1145/1150402.1150420; Duda R., 2001, PATTERN CLASSIFICATI, V2; Gu QQ, 2009, IEEE DATA MINING, P159, DOI 10.1109/ICDM.2009.32; Gu QQ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1046; Gupta S., 2010, P 16 ACM SIGKDD KDD, P1169, DOI 10.1145/1835804.1835951; Gupta SK, 2011, LECT NOTES ARTIF INT, V6634, P136, DOI 10.1007/978-3-642-20841-6_12; Gupta SK, 2011, P TEXT MIN WORKSH CO; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Ji Shuiwang, 2008, P 14 ACM SIGKDD INT, P381, DOI 10.1145/1401890.1401939; Jolliffe I. T., 2002, PRINCIPLE COMPONENT; Kailing K, 2004, LECT NOTES ARTIF INT, V3056, P394; Kim H, 2008, SIAM J MATRIX ANAL A, V30, P713, DOI 10.1137/07069239X; Langville A., 2006, P 12 ACM SIGKDD INT; Lee DD, 2001, ADV NEUR IN, V13, P556; Li T., 2004, P 27 ANN INT ACM SIG, P218, DOI 10.1145/1008992.1009031; Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756; Lin YR, 2009, IEEE INT CON MULTI, P1456; Lovasz L., 1986, MATCHING THEORY; Manning CD, 2008, INTRO INFORM RETRIEV; Mardia K., 1979, MULTIVARIATE ANAL; NIU D, 2010, P 27 INT C MACH LEAR, P831; Pan S. J., 2008, HKUSTCS0808 DEP COMP; Qi Z, 2009, P 15 ACM SIGKDD INT, P717, DOI 10.1145/1557019.1557099; Rui Y, 2000, PROC CVPR IEEE, P236, DOI 10.1109/CVPR.2000.855825; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Si S., 2009, IEEE T KNOWL DATA EN, V22, P929; Thrun S, 1996, ADV NEUR IN, V8, P640; Wild S, 2004, PATTERN RECOGN, V37, P2217, DOI 10.1016/j.patcog.2004.02.013; Wiswedel B, 2010, DATA MIN KNOWL DISC, V21, P130, DOI 10.1007/s10618-010-0170-1; Xu W, 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Yan R, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P834; Yang T, 2010, P 16 ACM SIGKDD INT, P1159, DOI 10.1145/1835804.1835950; Yu K, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P211, DOI 10.1145/1571941.1571979; Zhang JW, 2011, NEUROCOMPUTING, V74, P1720, DOI 10.1016/j.neucom.2011.02.004; Zhou D., 2004, ADV NEURAL INFORM PR, V16, P595; Zhuang F. Z, 2010, CIKM, P359	57	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2013	26	1					57	97		10.1007/s10618-011-0244-8		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	064ZT	WOS:000313116400003	
J	Zhang, ML; Zhou, ZH				Zhang, Min-Ling; Zhou, Zhi-Hua			Exploiting unlabeled data to enhance ensemble diversity	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Machine learning; Ensemble learning; Unlabeled data; Diversity	CLASSIFICATION; CLASSIFIERS	Ensemble learning learns from the training data by generating an ensemble of multiple base learners. It is well-known that to construct a good ensemble with strong generalization ability, the base learners are deemed to be accurate as well as diverse. In this paper, unlabeled data is exploited to facilitate ensemble learning by helping augment the diversity among the base learners. Specifically, a semi-supervised ensemble method named udeed, i.e. Unlabeled Data to Enhance Ensemble Diversity, is proposed. In contrast to existing semi-supervised ensemble methods which utilize unlabeled data by estimating error-prone pseudo-labels on them to enlarge the labeled data to improve base learners' accuracies, udeed works by maximizing accuracies of base learners on labeled data while maximizing diversity among them on unlabeled data. Extensive experiments on 20 regular-scale and five large-scale data sets are conducted under the setting of either few or abundant labeled data. Experimental results show that udeed can effectively utilize unlabeled data for ensemble learning via diversity augmentation, and is highly competitive to well-established semi-supervised ensemble methods.	[Zhang, Min-Ling] Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China; [Zhang, Min-Ling; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.	zhangml@seu.edu.cn; zhouzh@lamda.nju.edu.cn			National Science Foundation of China [61073097, 60805022, 61175049]; National Fundamental Research Program of China [2010CB327903]; Ph.D. Programs Foundation of Ministry of Education of China for Young Faculties [200802941009]; Cultivation Program for Young Faculties of Southeast University	We want to thank the action editor and the anonymous reviewers for their helpful comments and suggestions. This research was supported by the National Science Foundation of China (61073097, 60805022, 61175049), the National Fundamental Research Program of China (2010CB327903), Ph.D. Programs Foundation of Ministry of Education of China for Young Faculties (200802941009), and the Cultivation Program for Young Faculties of Southeast University.	Bennett K. P., 2002, P 8 ACM SIGKDD INT C, P289; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brown G, 2003, P 20 INT C MACH LEAR, P67; Chapelle O, 2006, SEMISUPERVISED LEARN; Chen HH, 2009, IEEE T NEURAL NETWOR, V20, P1962, DOI 10.1109/TNN.2009.2034144; Chen K, 2008, ADV NEURAL INFORM PR, V20, P281; Chen K, 2011, IEEE T PATTERN ANAL, V33, P129, DOI 10.1109/TPAMI.2010.92; Cunningham P, 2000, TCDCS200002 TRIN COL; d'Alche Buc F, 2002, ADV NEURAL INFORMATI, V14, P553; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Efron B., 1993, INTRO BOOSTRAP; Frank A, 2010, TECHNICAL REPORT; Freund Y., 1995, LNCS, V904, P23, DOI DOI 10.1007/3-540-59119-2_166; Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2; Hettich S, 1998, TECHNICAL REPORT; Krogh A., 1995, ADV NEURAL INFORMATI, V7, P231; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Li M, 2005, LECT NOTES ARTIF INT, V3518, P611; Li M, 2007, IEEE T SYST MAN CY A, V37, P1088, DOI 10.1109/TSMCA.2007.904745; Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; Liu Y, 1999, IEEE T SYST MAN CY B, V29, P716, DOI 10.1109/3477.809027; Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847; Mallapragada PK, 2009, IEEE T PATTERN ANAL, V31, P2000, DOI 10.1109/TPAMI.2008.235; Mason L, 2000, ADV NEUR IN, P221; McKay R, 2001, P 2001 C ART NEUR NE, P22; Melville P., 2003, P IJCAI, VI, P505; Melville P, 2005, THESIS U TEXAS AUSTI; Opitz D. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Opitz D. W., 1996, Connection Science, V8, DOI 10.1080/095400996116802; Partridge D, 1997, INFORM SOFTWARE TECH, V39, P707, DOI 10.1016/S0950-5849(97)00023-2; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; Saffari A, 2009, PROC CVPR IEEE, P967; Saffari A, 2008, LECT NOTES COMPUT SC, V5304, P588, DOI 10.1007/978-3-540-88690-7_44; Skalak D, 1996, AAAI 96 WORKSH INT M; Valizadegan H, 2008, LECT NOTES ARTIF INT, V5212, P522, DOI 10.1007/978-3-540-87481-2_34; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zhang ML, IEEE T SY B IN PRESS; Zhang ML, 2010, P 10 IEEE INT C DAT, P619; Zhou Z, 2007, P 22 AAAI C ART INT, P675; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529; Zhou ZH, 2010, KNOWL INF SYST, V24, P415, DOI 10.1007/s10115-009-0209-z; Zhou ZH, 2004, IEEE T KNOWL DATA EN, V16, P770; Zhou Z.H., 2009, ENCY BIOMETRICS; Zhou ZH, 2009, LECT NOTES COMPUT SC, V5519, P529; Zhu X., 2006, 1530 U WISC MAD DEP	48	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2013	26	1					98	129		10.1007/s10618-011-0243-9		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	064ZT	WOS:000313116400004	
J	Mampaey, M; Vreeken, J				Mampaey, Michael; Vreeken, Jilles			Summarizing categorical data by clustering attributes	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Attribute clustering; MDL; Summarization; Categorical data	CLASSIFICATION; SELECTION; PATTERNS; RULES	For a book, its title and abstract provide a good first impression of what to expect from it. For a database, obtaining a good first impression is typically not so straightforward. While low-order statistics only provide very limited insight, downright mining the data rapidly provides too much detail for such a quick glance. In this paper we propose a middle ground, and introduce a parameter-free method for constructing high-quality descriptive summaries of binary and categorical data. Our approach builds a summary by clustering attributes that strongly correlate, and uses the Minimum Description Length principle to identify the best clustering-without requiring a distance measure between attributes. Besides providing a practical overview of which attributes interact most strongly, these summaries can also be used as surrogates for the data, and can easily be queried. Extensive experimentation shows that our method discovers high-quality results: correlated attributes are correctly grouped, which is verified both objectively and subjectively. Our models can also be employed as surrogates for the data; as an example of this we show that we can quickly and accurately query the estimated supports of frequent generalized itemsets.	[Mampaey, Michael; Vreeken, Jilles] Univ Antwerp, Dept Math & Comp Sci, Adv Database Res & Modelling, B-2020 Antwerp, Belgium	Mampaey, M (reprint author), Univ Antwerp, Dept Math & Comp Sci, Adv Database Res & Modelling, B-2020 Antwerp, Belgium.	michael.mampaey@ua.ac.be; jilles.vreeken@ua.ac.be			Ph.D. grant of the Agency for Innovation through Science and Technology in Flanders (IWT); Research Foundation-Flanders (FWO)	The authors thank i-ICT of Antwerp University Hospital (UZA) for providing the MCADD data and expertise. Furthermore, the authors wish to thank the anonymous reviewers for their detailed and highly constructive comments. Michael Mampaey is supported by a Ph.D. grant of the Agency for Innovation through Science and Technology in Flanders (IWT). Jilles Vreeken is supported by a Post-Doctoral Fellowship of the Research Foundation-Flanders (FWO).	Au WH, 2005, IEEE ACM T COMPUT BI, V2, P83; Baumgartner C, 2005, J BIOMED INFORM, V38, P89, DOI 10.1016/j.jbi.2004.08.009; Bringmann B, 2007, IEEE DATA MINING, P63; Calders T, 2007, DATA MIN KNOWL DISC, V14, P171, DOI 10.1007/s10618-006-0054-6; Chakrabarti D, 2004, P 10 ACM SIGKDD INT, P79, DOI 10.1145/1014052.1014064; Chandola V, 2005, P 5 IEEE INT C DAT M, P98; Coenen F., 2003, LUCS KDD DISCRETISED; Cover T.M., 2006, ELEMENTS INFORM THEO; De Bie T, 2011, DATA MIN KNOWL DISC, V23, P407, DOI 10.1007/s10618-010-0209-3; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Frank A., 2010, UCI MACHINE LEARNING; Garriga GC, 2011, KNOWL INF SYST, V28, P197, DOI 10.1007/s10115-010-0319-7; Gionis A, 2007, ACM T KNOWL DISCOV D, V1, P1556; Goethals B., 2003, FREQUENT ITEMSET MIN; Grunwald P. D., 2007, MINIMUM DESCRIPTION; Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1; Hanhijarvi S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P379; Heikinheimo H., 2009, P SIAM INT C DAT MIN, V5776, P569; Heikinheimo H, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P350; Kirkpatrick S, 1984, STAT PHYS, V34, P975; Knobbe AJ, 2006, P 13 ACM SIGKDD INT, P237, DOI 10.1145/1150402.1150431; Kontonasios KN, 2010, P 10 SIAM INT C DAT, P153; Li M., 1993, INTRO KOLMOGOROV COM; Mampaey M., 2011, P 17 ACM INT C KNOWL, P573; Mampaey M, 2010, P EUR C MACH LEARN P, P321; Mannila H, 1997, P ACM SIGKDD INT C K, P23; Mitchell-Jones A.J., 1999, ATLAS EUROPEAN MAMMA; Myllykangas S, 2006, ONCOGENE, V25, P7324, DOI 10.1038/sj.onc.1209717; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; Pensa R, 2005, P 9 EUR C PRINC PRAC, P643; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rissanen J, 2007, INFORM COMPLEXITY ST; SHANNON CE, 1948, AT&T TECH J, V27, P379; Siebes A., 2006, P 6 SIAM INT C DAT M, V4165, P393; Van den Bulcke T, 2011, J BIOMED INFORM, V44, P319, DOI 10.1016/j.jbi.2010.12.001; Vereshchagin NK, 2004, IEEE T INFORM THEORY, V50, P3265, DOI 10.1109/TIT.2004.838346; Vreeken J, 2007, IEEE DATA MINING, P685, DOI 10.1109/ICDM.2007.25; Vreeken J, 2011, DATA MIN KNOWL DISC, V23, P169, DOI 10.1007/s10618-010-0202-x; Wallace CS, 2005, STAT INDUCTIVE INFER; Wang C, 2006, P 12 ACM SIGKDD INT, P730, DOI 10.1145/1150402.1150495; Wang J., 2004, P IEEE INT C DAT MIN, V3275, P241; Yan X., 2005, P 11 ACM SIGKDD INT, P314, DOI 10.1145/1081870.1081907	42	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2013	26	1					130	173		10.1007/s10618-011-0246-6		44	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	064ZT	WOS:000313116400005	
J	Acid, S; de Campos, LM; Fernandez, M				Acid, Silvia; de Campos, Luis M.; Fernandez, Moises			Score-based methods for learning Markov boundaries by searching in constrained spaces	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Feature subset selection; Markov boundary; Bayesian networks; Local learning; Score plus search	BAYESIAN NETWORK CLASSIFIERS; FEATURE SUBSET-SELECTION; GENE-EXPRESSION; PROBABILISTIC NETWORKS; MUTUAL INFORMATION; BLANKET DISCOVERY; PREDICTION; ALGORITHM; CANCER; CLASSIFICATION	Within probabilistic classification problems, learning the Markov boundary of the class variable consists in the optimal approach for feature subset selection. In this paper we propose two algorithms that learn the Markov boundary of a selected variable. These algorithms are based on the score+search paradigm for learning Bayesian networks. Both algorithms use standard scoring functions but they perform the search in constrained spaces of class-focused directed acyclic graphs, going through the space by means of operators adapted for the problem. The algorithms have been validated experimentally by using a wide spectrum of databases, and their results show a performance competitive with the state-of-the-art.	[Acid, Silvia; de Campos, Luis M.; Fernandez, Moises] Univ Granada, CITIC UGR, ETSI Informat & Telecomunicac, Dept Ciencias Comp & Inteligencia Artificial, E-18071 Granada, Spain	de Campos, LM (reprint author), Univ Granada, CITIC UGR, ETSI Informat & Telecomunicac, Dept Ciencias Comp & Inteligencia Artificial, E-18071 Granada, Spain.	acid@decsai.ugr.es; lci@decsai.ugr.es; moises@decsai.ugr.es	de Campos, Luis/B-7436-2012	de Campos, Luis/0000-0001-9125-1195	Spanish research programme Consolider Ingenio [MIPRCV:CSD2007-00018]; Consejeria de Innovacion, Ciencia y Empresa de la Junta de Andalucia [P09-TIC-4526]	This work has been supported by the Spanish research programme Consolider Ingenio 2010 and the Consejeria de Innovacion, Ciencia y Empresa de la Junta de Andalucia under projects MIPRCV:CSD2007-00018 and P09-TIC-4526, respectively. We are also grateful to J.M. Pena for providing his implementation of the PCMB, KIAMB and IAMB algorithms.	Abramson B, 1996, INT J FORECASTING, V12, P57, DOI 10.1016/0169-2070(95)00664-8; Acid S, 2003, J ARTIF INTELL RES, V18, P445; Acid S, 2005, MACH LEARN, V59, P213; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Aliferis C. F., 2003, P 2003 AM MED INF AS, P21; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Beinlich IA, 1989, P 2 EUR C ART INT ME, P247; Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Buntine W, 1991, P 7 C UNC ART INT, V91, P52; Chickering D., 1995, 5 INT WORKSH ART INT, P112; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; de Campos LM, 2006, J MACH LEARN RES, V7, P2149; de Campos LM, 2007, INT J APPROX REASON, V45, P233, DOI 10.1016/j.ijar.2006.06.009; de Campos LM, 2000, INT J APPROX REASON, V24, P11, DOI 10.1016/S0888-613X(99)00042-0; Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fu S, 2008, LECT NOTES ARTIF INT, V5032, P96; Fu S, 2007, LECT NOTES COMPUT SC, V4830, P68; Fu SK, 2008, LECT NOTES ARTIF INT, V5012, P562, DOI 10.1007/978-3-540-68125-0_51; Gamez JA, 2007, LECT NOTES ARTIF INT, V4724, P585; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Heckerman D, 1997, P 13 C UNC AI SAN FR, P223; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Heckerman D., 1997, MSRTR9706; Inza I, 2001, ARTIF INTELL MED, V23, P187, DOI 10.1016/S0933-3657(01)00085-9; Jensen CS, 1997, THESIS AALBORG U; John G, 1994, P 11 INT C MACH LEAR, V129, P121; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 2009, PROBABILISTIC GRAPHI; Koller D, 1996, INT C MACH LEARN, P284; Kristensen K, 2002, COMPUT ELECTRON AGR, V33, P197, DOI 10.1016/S0168-1699(02)00007-8; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P, 1992, P AAAI 1992, V7, P223; Li H, 2010, EXPERT SYST APPL, V37, P4811, DOI 10.1016/j.eswa.2009.12.034; Mamitsuka H., 2003, Proceedings Third IEEE Symposium on BioInformatics and BioEngineering. BIBE 2003; Margaritis D, 2000, ADV NEUR IN, V12, P505; Moral S., 2004, P IMPU 04, V2, P1307; Neapolitan R, 2003, LEARNING BAYESIAN NE; Pearl J, 1990, P 6 C UNC ART INT, P220; Pearl J., 1988, PROBABILISTIC REASON; Pellet JP, 2008, J MACH LEARN RES, V9, P1295; Pena JM, 2007, INT J APPROX REASON, V45, P211, DOI 10.1016/j.ijar.2006.06.008; Pena JM, 2005, BIOINFORMATICS, V21, P224, DOI 10.1093/bioinformatics/bti1137; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramsey J, 2006, CMUPHIL177; Rasmussen LK, 1995, THESIS RES CTR FOULU; Rodrigues de Morais S, 2008, P 4 EUR WORKSH PROB, P81; Rodriguesde Morais S, 2008, LECT NOTES COMPUT SC, V5212, P298; Roos T, 2005, MACH LEARN, V59, P267; Scheines R., 1993, CAUSATION PREDICTION; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Sierra B, 1998, ARTIF INTELL MED, V14, P215, DOI 10.1016/S0933-3657(98)00024-4; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Singh M, 1996, P 13 INT C MACH LEAR, V13, P453; Song XP, 2010, EXPERT SYST, V27, P299, DOI 10.1111/j.1468-0394.2010.00546.x; Tsamardinos I, 2003, P 9 ACM SIGKDD INT C, P673, DOI DOI 10.1145/956750.956838; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; Tsamardinos I, 2003, P 16 INT FLOR ART IN, P376; Yang Y, 1997, P 14 INT C MACH LEAR, P412; Yaramakala S, 2005, P 5 IEEE INT C DAT M, P809; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Yishi Z, 2009, P AS PAC C INF PROC, V2, P379; Zheng HW, 2008, ADV SPACE RES, V41, P1960, DOI 10.1016/j.asr.2007.08.033	74	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2013	26	1					174	212		10.1007/s10618-011-0247-5		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	064ZT	WOS:000313116400006	
J	Takada, T				Takada, Teruko			Mining local and tail dependence structures based on pointwise mutual information (vol 24, pg 78, 2012)	DATA MINING AND KNOWLEDGE DISCOVERY			English	Correction									Osaka City Univ, Grad Sch Business, Osaka 558, Japan	Takada, T (reprint author), Osaka City Univ, Grad Sch Business, Osaka 558, Japan.	takada@osaka-cu.ac.jp					Takada T, 2012, DATA MIN KNOWL DISC, V24, P78, DOI 10.1007/s10618-011-0220-3	1	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2013	26	1					213	215		10.1007/s10618-011-0241-y		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	064ZT	WOS:000313116400007	
J	Chattopadhyay, R; Sun, Q; Fan, W; Davidson, I; Panchanathan, S; Ye, JP				Chattopadhyay, Rita; Sun, Qian; Fan, Wei; Davidson, Ian; Panchanathan, Sethuraman; Ye, Jieping			Multisource Domain Adaptation and Its Application to Early Detection of Fatigue	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Multisource domain adaption; transfer learning; surface electromyogram; subject-based variability	CUMULATIVE TRAUMA DISORDERS; PERFORMING REPETITIVE TASKS; COVARIATE SHIFT; CONTRACTIONS; FREQUENCY	We consider the characterization of muscle fatigue through a noninvasive sensing mechanism such as Surface ElectroMyoGraphy (SEMG). While changes in the properties of SEMG signals with respect to muscle fatigue have been reported in the literature, the large variation in these signals across different individuals makes the task of modeling and classification of SEMG signals challenging. Indeed, the variation in SEMG parameters from subject to subject creates differences in the data distribution. In this article, we propose two transfer learning frameworks based on the multisource domain adaptation methodology for detecting different stages of fatigue using SEMG signals, that addresses the distribution differences. In the proposed frameworks, the SEMG data of a subject represent a domain; data from multiple subjects in the training set form the Multiple source domains and the test subject data form the target domain. SEMG signals are predominantly different in conditional probability distribution across subjects. The key feature of the first framework is a novel weighting scheme that addresses the conditional probability distribution differences across multiple domains (subjects) and the key feature of the second framework is a two-stage domain adaptation methodology which combines weighted data from multiple sources based on marginal probability differences (first stage) as well as conditional probability differences (second stage), with the target domain data. The weights for minimizing the marginal probability differences are estimated independently, while the weights for minimizing conditional Probability differences are computed simultaneously by exploiting the potential interaction among multiple sources. We also provide a theoretical analysis on the generalization performance of the proposed multisource domain adaptation formulation using the weighted Rademacher complexity measure. We have validated the proposed frameworks on Surface ElectroMyoGram signals collected from 8 people during a fatigue-causing repetitive gripping activity. Comprehensive experiments on the SEMG dataset demonstrate that the proposed method improves the classification accuracy by 20% to 30% over the cases without any domain adaptation method and by 13% to 30% over existing state-of-the-art domain adaptation methods.	[Chattopadhyay, Rita; Sun, Qian; Panchanathan, Sethuraman; Ye, Jieping] Arizona State Univ, Tempe, AZ 85281 USA; [Fan, Wei] IBM TJ Watson Res, Yorktown Hts, NY USA; [Davidson, Ian] Univ Calif Davis, Davis, CA 95616 USA	Chattopadhyay, R (reprint author), Arizona State Univ, 1151 S Forest Ave, Tempe, AZ 85281 USA.				NSF [IIS-0953662]; ONR [N00014-11-1-0108];  [CCF-1025177]	This research is sponsored in part by NSF IIS-0953662, CCF-1025177, and ONR N00014-11-1-0108.	BARTLETT P., 2002, J MACHINE LEARNING R, V3, P463; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Bickel S, 2009, J MACH LEARN RES, V10, P2137; BLITZER J., 2007, P ANN M ASS COMP LIN; Borgwardt K.M., 2006, BIOINFORMATICS, V22, P49; Contessa P, 2009, J APPL PHYSIOL, V107, P235, DOI 10.1152/japplphysiol.00035.2009; Daume H., 2007, P ANN M ASS COMP LIN; Duan L., 2009, P 26 INT C MACH LEAR, P289; DUAN L., 2009, P IEEE C COMP VIS PA; Gao J., 2008, P 14 ACM SIGKDD INT, P283, DOI 10.1145/1401890.1401928; GAURAV P., 2009, P WOM MACH LEARN ADV; Georgakis A, 2003, IEEE T BIO-MED ENG, V50, P262, DOI [10.1109/TBME.2002.807641, 10.1109/TBMe.2002.807641]; Gerdle B, 2000, J ELECTROMYOGR KINES, V10, P225, DOI 10.1016/S1050-6411(00)00011-0; HIGGS P, 1992, PLAST RECONSTR SURG, V90, P614, DOI 10.1097/00006534-199210000-00010; Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26; Knaflitz M, 1999, J ELECTROMYOGR KINES, V9, P337, DOI 10.1016/S1050-6411(99)00009-7; Koltchinskii V, 2001, IEEE T INFORM THEORY, V47, P1902, DOI 10.1109/18.930926; Leon E, 2007, ENG APPL ARTIF INTEL, V20, P337, DOI 10.1016/j.engappai.2006.06.001; MANSOUR Y., 2009, P C ADV NEUR INF PRO; Massart P., 2000, ANN FAC SCI TOULOUSE, V9, P245; MCDIARMID C., 1989, METHOD BOUNDED DIFFE, V5; PAN S. J., 2008, P AAAI C ART INT; REN J, 2009, P ACM SIGKDD INT C K; ROSTAMIZADEH A., 2009, DOMAIN ADAPTATION LE; Schlkopf B., 2002, LEARNING KERNELS SUP; SCHOLKOPF B., 2007, P C ADV NEUR INF PRO; SETHURAMAN P., 2010, P INT INSTR MEAS TEC; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; SILVERSTEIN BA, 1986, BRIT J IND MED, V43, P779; Steinwart I., 2001, J MACHINE LEARNING R, V2, P67, DOI 10.1162/153244302760185252; SUGIYAMA M., 2008, P INT C ADV NEUR INF; TEWARI A., 2008, LECT NOTES CMSC; TSANG I. W, 2009, P INT JOINT C ART IN; VERSCHEURE O, 2009, P ACM SIGKDD INT C K; YANG Q., 2009, IEEE T KNOWL DATA EN, V22, P10; YOUNG VL, 1995, AM J IND MED, V27, P419, DOI 10.1002/ajim.4700270310; ZHUANG F., 2008, P CM INT C INF KNOWL	38	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2012	6	4			SI				18	10.1145/2382577.2382582		26	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	062MU	WOS:000312924700005	
J	Chu, SM; Cheng, J				Chu, Shumo; Cheng, James			Triangle Listing in Massive Networks	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Triangle listing; triangle counting; clustering coefficients; large graphs; massive networks	COMPLEX NETWORKS; GRAPHS; WORLD	Triangle listing is one of the fundamental algorithmic problems whose solution has numerous applications especially in the analysis of complex networks, such as the computation of clustering coefficients, transitivity, triangular connectivity, trusses, etc. Existing algorithms for triangle listing are mainly in-memory algorithms, whose performance cannot scale with the massive volume of today's fast growing networks. When the input graph cannot fit in main memory, triangle listing requires random disk accesses that can incur prohibitively huge I/O cost. Some streaming, semistreaming, and sampling algorithms have been proposed but these are approximation algorithms. We propose an I/O-efficient algorithm for triangle listing. Our algorithm is exact and avoids random disk access. Our results show that our algorithm is scalable and outperforms the state-of-the-art in-memory and local triangle estimation algorithms.	[Chu, Shumo; Cheng, James] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Chu, SM (reprint author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.						AGGARWAL A, 1988, COMMUN ACM, V31, P1116, DOI 10.1145/48529.48535; Alon N, 1999, J COMPUT SYST SCI, V58, P137, DOI 10.1006/jcss.1997.1545; ANDREEV K., 2004, P 16 ANN ACM S PAR A, P120, DOI 10.1145/1007912.1007931; Bar-Yossef Z, 2002, SIAM PROC S, P623; Batagelj V, 2001, SOC NETWORKS, V23, P237, DOI 10.1016/S0378-8733(01)00035-1; Batagelj V, 2007, DISCRETE MATH, V307, P310, DOI 10.1016/j.disc.2005.09.051; Becchetti L., 2008, P 14 ACM SIGKDD INT, P16, DOI 10.1145/1401890.1401898; CHELLAPILLA K., 2008, P INT C WEB SEARCH W, P95, DOI 10.1145/1341531.1341547; CHENG J., 2011, P ACM SIGKDD INT C K, P672; Cheng J, 2011, ACM T DATABASE SYST, V36, DOI 10.1145/2043652.2043654; Cheng J, 2011, PROC INT CONF DATA, P51, DOI 10.1109/ICDE.2011.5767911; Cohen J, 2009, COMPUT SCI ENG, V11, P29, DOI 10.1109/MCSE.2009.120; Eckmann JP, 2002, P NATL ACAD SCI USA, V99, P5825, DOI 10.1073/pnas.032093399; Eppstein D, 2009, LECT NOTES COMPUT SC, V5664, P278, DOI 10.1007/978-3-642-03367-4_25; Faloutsos M, 1999, COMP COMM R, V29, P251; Feige U., 2000, Proceedings 41st Annual Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2000.892070; FIDUCCIA C. M., 1982, P IEEE DES AUT C; FRITZKE B., 1993, SELF ORG NETWORK UNS; GIONIS A., 2010, ACM T KNOWL DISCOV D, V4, P3; GRANOVET.MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469; ITAI A, 1978, SIAM J COMPUT, V7, P413, DOI 10.1137/0207033; Itai A., 1977, P 9 ANN ACM S THEOR, P1, DOI 10.1145/800105.803390; Karypis G, 1999, SIAM REV, V41, P278, DOI 10.1137/S0036144598334138; KARYPIS G, 2006, P IEEE INT PAR DISTR; KE Y., 2010, P SIGMOD INT C MAN D, P447, DOI 10.1145/1807167.1807217; Kernighan B. W., 1970, Bell System Technical Journal, V49; Feige U., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335370; KUMAR R., 2004, P 15 ANN ACM SIAM S, P151; Latapy M, 2008, THEOR COMPUT SCI, V407, P458, DOI 10.1016/j.tcs.2008.07.017; Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824; Newman MEJ, 2002, P NATL ACAD SCI USA, V99, P2566, DOI 10.1073/pnas.012582999; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Schank T., 2007, THESIS U KARLSRUHE; Schank T, 2005, LECT NOTES COMPUT SC, V3503, P606; SOHLER C., 2006, PODS 06, P253, DOI 10.1145/1142351.1142388; Suri S., 2011, P 20 INT C WORLD WID, P607; Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365; Tsourakakis CE, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P837; WANG N., 2010, P VLDB, V4, P58; Wasserman S, 1994, SOCIAL NETWORK ANAL; WATTS D. J., 1998, NATURE, V393, P440; YUSTER R, 1997, ALGORITHMICA, V<IT>17</IT>, P354	42	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2012	6	4			SI				17	10.1145/2382577.2382581		32	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	062MU	WOS:000312924700004	
J	Ghosh, J; Smyth, P; Tomkins, A; Caruana, R				Ghosh, Joydeep; Smyth, Padhraic; Tomkins, Andrew; Caruana, Rich			Special Issue on Best of SIGKDD 2011	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Editorial Material																	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2012	6	4			SI				14	10.1145/2382577.2382578		2	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	062MU	WOS:000312924700001	
J	Kaufman, S; Rosset, S; Perlich, C; Stitelman, O				Kaufman, Shachar; Rosset, Saharon; Perlich, Claudia; Stitelman, Ori			Leakage in Data Mining: Formulation, Detection, and Avoidance	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Data mining; leakage; predictive modeling		Deemed "one of the top ten data mining mistakes", leakage is the introduction of information about the data mining target that should not be legitimately available to mine from. In addition to our own industry experience with real-life projects, controversies around several major public data mining competitions held recently such as the INFORMS 2010 Data Mining Challenge and the IJCNN 2011 Social Network Challenge are evidence that this issue is as relevant today as it has ever been. While acknowledging the importance and prevalence of leakage in both synthetic competitions and real-life data mining projects, existing literature has largely left this idea unexplored. What little has been said turns out not to be broad enough to cover more complex cases of leakage, such as those where the classical independently and identically distributed (i.i.d.) assumption is violated, that have been recently documented. In our new approach, these cases and others are explained by explicitly defining modeling goals and analyzing the broader framework of the data mining problem. The resulting definition enables us to derive general methodology for dealing with the issue. We show that it is possible to avoid leakage with a simple specific approach to data management followed by what we call a learn-predict separation, and present several ways of detecting leakage when the modeler has no control over how the data have been collected. We also offer an alternative point of view on leakage that is based on causal graph modeling concepts.	[Kaufman, Shachar; Rosset, Saharon] Tel Aviv Univ, IL-69978 Tel Aviv, Israel; [Perlich, Claudia; Stitelman, Ori] m6d, New York, NY USA	Kaufman, S (reprint author), Tel Aviv Univ, POB 39040, IL-69978 Tel Aviv, Israel.				Israeli Science Foundation [1227/09]; Edmond J. Safra Center for Bioinformatics at Tel-Aviv University	S. Kaufman and S. Rosset were partially supported by grant 1227/09 from the Israeli Science Foundation, and S. Kaufman was supported by a fellowship from the Edmond J. Safra Center for Bioinformatics at Tel-Aviv University.	Buneman P, 2001, LECT NOTES COMPUT SC, V1973, P316; COGGESHALL S., 2010, STASTIST ANAL DATA M, V<IT>3</IT>, P253; ENGLE RF, 1987, ECONOMETRICA, V55, P251, DOI 10.2307/1913236; Hastie T, 2009, ELEMENTS STAT LEARNI; KOHAVI R., 2004, MACH LEARN, V<IT>1</IT>, P2; KOHAVI R., 2000, ACM SIGKDD EXPLOR NE, V<IT>2</IT>; LIU Y., 2007, ACM SIGKDD EXPLOR NE, V<IT>2</IT>; MACKINLAY A., 1990, REV FINAN STUD, V<IT>1</IT>, P431; MELVILLE P., 2010, DATA MIN KNOWL DISC, V<IT>3</IT>, P439; NARAYANAN A., 2011, P INT JOINT C NEUR N; Nisbet R., 2009, HDB STAT ANAL DATA M; PAREKH R., 2003, P 5 WEBKDD WORKSH; Pearl J., 2009, CAUSALITY MODELS REA; Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.1093/biomet/82.4.669; PERLICH C., 2008, ACM SIGKDD EXPLOR NE, V<IT>2</IT>, P39; PYLE D., 2003, BUSINESS MODELING DA; Pyle D, 1999, DATA PREPARATION DAT; PYLE D., 2009, DATA MINING KNOW IT; Robins J.M., 1997, LECT NOTES STAT, P69; Smith A, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P657; Tukey J.W., 1977, EXPLORATORY DATA ANA; WIDMER G., 1996, MACH LEARN, V<IT>1</IT>; XIANG L., 2011, HYBRID RECOMMENDATIO	23	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2012	6	4			SI				15	10.1145/2382577.2382579		21	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	062MU	WOS:000312924700002	
J	Mampaey, M; Vreeken, J; Tatti, N				Mampaey, Michael; Vreeken, Jilles; Tatti, Nikolaj			Summarizing Data Succinctly with the Most Informative ltemsets	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Frequent itemsets; pattern sets; summarization; maximum entropy; minimum description length principle; MDL; BIC; inclusion-exclusion	ITEMSETS; CLASSIFICATION; PATTERNS; RULES	Knowledge discovery from data is an inherently iterative process. That is, what we know about the data greatly determines our expectations, and therefore, what results we would find interesting and/or surprising. Given new knowledge about the data, our expectations will change. Hence, in order to avoid redundant results, knowledge discovery algorithms ideally should follow such an iterative updating procedure. With this in mind, we introduce a well-founded approach for succinctly summarizing data with the most informative itemsets; using a probabilistic maximum entropy model, we iteratively find the itemset that provides us the most novel information-that is, for which the frequency in the data surprises us the most-and in turn we update our model accordingly. As we use the maximum entropy principle to obtain unbiased probabilistic models, and only include those itemsets that are most informative with regard to the current model, the summaries we construct are guaranteed to be both descriptive and nonredundant. The algorithm that we present, called MTV, can either discover the top-k most informative itemsets, or we can employ either the Bayesian Information Criterion (BIC) or the Minimum Description Length (MDL) principle to automatically identify the set of itemsets that together summarize the data well. In other words, our method will "tell you what you need to know" about the data. Importantly, it is a one-phase algorithm: rather than picking itemsets from a user-provided candidate set, itemsets and their supports are mined on-the-fly. To further its applicability, we provide an efficient method to compute the maximum entropy distribution using Quick Inclusion-Exclusion. Experiments on our method, using synthetic, benchmark, and real data, show that the discovered summaries are succinct, and correctly identify the key patterns in the data. The models they form attain high likelihoods, and inspection shows that they summarize the data well with increasingly specific, yet nonredundant itemsets.	[Mampaey, Michael; Vreeken, Jilles; Tatti, Nikolaj] Univ Antwerp, Dept Math & Comp Sci, ADReM Res Grp, B-2020 Antwerp, Belgium	Mampaey, M (reprint author), Univ Antwerp, Dept Math & Comp Sci, ADReM Res Grp, Middelheimlaan 1, B-2020 Antwerp, Belgium.				Agency for Innovation by Science and Technology in Flanders (IWT); Research Foundation - Flanders (FWO)	M. Mampaey is supported by a Ph.D. grant of the Agency for Innovation by Science and Technology in Flanders (IWT). J. Vreeken is supported by a Post-Doctoral Fellowship of the Research Foundation - Flanders (FWO). N. Tatti is supported by a Post-Doctoral Fellowship of the Research Foundation - Flanders (FWO).	Aggarwal C. C., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275490; Baumgartner C, 2005, J BIOMED INFORM, V38, P89, DOI 10.1016/j.jbi.2004.08.009; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Brijs T, 1999, P 5 INT C KNOWL DISC, P254, DOI 10.1145/312129.312241; Brin S., 1997, P ACM SIGMOD INT C M, V26, P265; Calders T, 2007, DATA MIN KNOWL DISC, V14, P171, DOI 10.1007/s10618-006-0054-6; CALDERS T, 2006, P ECML PKDD WORKSH K, V3933, P86; Cover T.M., 2006, ELEMENTS INFORM THEO; Cowell R., 1999, STAT ENG INFORM SCI; CSISZAR I, 1975, ANN PROBAB, V3, P146, DOI 10.1214/aop/1176996454; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; De Bie T, 2011, P 17 ACM SIGKDD INT, P564; De Bie T, 2011, DATA MIN KNOWL DISC, V23, P407, DOI 10.1007/s10618-010-0209-3; Frank A., 2010, UCI MACHINE LEARNING; Gallo A, 2007, LECT NOTES ARTIF INT, V4702, P438; Garriga GC, 2011, KNOWL INF SYST, V28, P197, DOI 10.1007/s10115-010-0319-7; Geerts F, 2004, LECT NOTES COMPUT SC, V3245, P278; Gelman A., 2004, BAYESIAN DATA ANAL; Geng LQ, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132960.1132963; GEURTS K., 2003, P 82 ANN TRANSP RES, P1; GIONIS A., 2007, ACM T KNOWL DISCOV D, V1, P167; GOETHALS B., 2004, FREQUENT ITEMSET MIN; Grunwald P. D., 2005, ADV MINIMUM DESCRIPT; Grunwald P. D., 2007, MINIMUM DESCRIPTION; Hanhijarvi S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P379; Heikinheimo H, 2007, J BIOGEOGR, V34, P1053, DOI 10.1111/j.1365-2699.2006.01664.x; Jaroszewicz S., 2004, P 10 ACM SIGKDD INT, P178, DOI 10.1145/1014052.1014074; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; Kontonasios KN, 2010, P 10 SIAM INT C DAT, P153; Li M., 1993, INTRO KOLMOGOROV COM; Mampaey M., 2011, P 17 ACM INT C KNOWL, P573; Mampaey M, 2010, P EUR C MACH LEARN P, P321; Mitchell-Jones A.J., 1999, ATLAS EUROPEAN MAMMA; Myllykangas S, 2006, ONCOGENE, V25, P7324, DOI 10.1038/sj.onc.1209717; Nijssen S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P647; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHAFFER JP, 1995, ANNU REV PSYCHOL, V46, P561, DOI 10.1146/annurev.psych.46.1.561; SIEBES A., 2011, P 11 SIAM INT C DAT, P558; Siebes A., 2006, P 6 SIAM INT C DAT M, V4165, P393; Tan P., 2002, P 8 ACM SIGKDD INT C, P32, DOI DOI 10.1145/775047.775053; Tatti N, 2006, INFORM PROCESS LETT, V98, P183, DOI 10.1016/j.ipl.2006.02.003; TATTI N, 2008, P EUR C MACH LEARN P, V5212, P472; Tatti N, 2008, KNOWL INF SYST, V17, P57, DOI 10.1007/s10115-008-0128-4; Tatti N, 2010, DATA MIN KNOWL DISC, V21, P293, DOI 10.1007/s10618-010-0188-4; Tatti N., 2010, P 16 ACM INT C KNOWL, P293, DOI 10.1145/1835804.1835843; Van den Bulcke T, 2011, J BIOMED INFORM, V44, P319, DOI 10.1016/j.jbi.2010.12.001; Vreeken J, 2007, IEEE DATA MINING, P685, DOI 10.1109/ICDM.2007.25; VREEKEN J., 2012, P 12 SIAM INT C DAT, P236; Vreeken J, 2011, DATA MIN KNOWL DISC, V23, P169, DOI 10.1007/s10618-010-0202-x; Wallace CS, 2005, STAT INDUCTIVE INFER; WALLACE CS, 1993, MACH LEARN, V11, P7, DOI 10.1023/A:1022646101185; Wang C, 2006, P 12 ACM SIGKDD INT, P730, DOI 10.1145/1150402.1150495; Webb GI, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644876; Webb GI, 2007, MACH LEARN, V68, P1, DOI 10.1007/s10994-007-5006-x; Zaki M.J., 2005, P 11 ACM SIGKDD INT, P364, DOI DOI 10.1145/1081870.1081912	57	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2012	6	4			SI				16	10.1145/2382577.2382580		42	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	062MU	WOS:000312924700003	
J	Wilkinson, L; Anand, A; Dang, TN				Wilkinson, Leland; Anand, Anushka; Tuan Nhon Dang			Substantial Improvements in the Set-Covering Projection Classifier CHIRP (Composite Hypercubes on Iterated Random Projections)	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Supervised classification; random projections	PURSUIT; CHOICE	In Wilkinson et al. [2011] we introduced a new set-covering random projection classifier that achieved average error lower than that of other classifiers in the Weka platform. This classifier was based on an L-infinity norm distance function and exploited an iterative sequence of three stages (projecting, binning, and covering) to deal with the curse of dimensionality, computational complexity, and nonlinear separability. We now present substantial changes that improve robustness and reduce training and testing time by almost an order of magnitude without jeopardizing CHIRP's outstanding error performance.	[Wilkinson, Leland; Anand, Anushka; Tuan Nhon Dang] Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA	Wilkinson, L (reprint author), Univ Illinois, Dept Comp Sci, 700 S Halsted St 2029, Chicago, IL 60607 USA.				NSF/DHS grant [DMS-FODAVA-0808860]	This work is supported by NSF/DHS grant DMS-FODAVA-0808860.	Achlioptas D., 2001, P ACM S PRINC DAT SY, P274, DOI 10.1145/375551.375608; Agrawal R, 1998, P ACM SIGMOD INT C M, V27, P94; Aguilar J, 1998, LECT NOTES ARTIF INT, V1484, P326; Alpern B., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), DOI 10.1109/VISUAL.1991.175790; Anand A, 2009, IEEE DATA MINING, P687, DOI 10.1109/ICDM.2009.119; ASUNCION A., 2007, UCI MACHINE LEARNING; BARANIUK R., 2007, P C ADV NEUR INF PRO; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Breiman L, 1984, CLASSIFICATION REGRE; CUNNINGHAM S. J., 1999, P ICONIP ANZIIS ANNE, P192; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; FLICK TE, 1990, PATTERN RECOGN, V23, P1367, DOI 10.1016/0031-3203(90)90083-W; GAO B., 2002, THESIS S FRASER U; Gao BJ, 2006, IEEE DATA MINING, P200; Guo Y., 2005, BIOSTATISTICS, V1, P1; Hanczar B, 2010, BIOINFORMATICS, V26, P822, DOI 10.1093/bioinformatics/btq037; HAND D., 2010, MACH LEARN, V<IT>77</IT>, P103; Hastie T., 2001, ELEMENTS STAT LEARNI; HOSKING JRM, 1990, J ROY STAT SOC B MET, V52, P105; JIMENEZ L. O., 1995, P GEOSC REM SENS S I, V1, P148; Johnson W., 1984, CONT MATH, V26, P189; KING R., 1995, APPL ARTIF INTELL, V9; Lazarsfeld PF, 1968, LATENT STRUCTURE ANA; Lee EK, 2005, J COMPUT GRAPH STAT, V14, P831, DOI 10.1198/106186005X77702; Li P., 2006, P 12 ACM SIGKDD INT, P287, DOI 10.1145/1150402.1150436; Li P., 2010, P IEEE UAI; Marchand M., 2002, J MACHINE LEARNING R, V3, P723; MOSTELLER F, 1948, ANN MATH STAT, V19, P58, DOI 10.1214/aoms/1177730290; NG R. T., 2005, P VLDB 2005, P433; Pu KQ, 2005, ACM T DATABASE SYST, V30, P211, DOI 10.1145/1061318.1061324; Quinlan J. R., 1993, MORGAN KAUFMANN SERI; Rivest R.L., 1987, MACH LEARN, V2, P229; SCOTT DW, 1979, BIOMETRIKA, V66, P605, DOI 10.1093/biomet/66.3.605; Silverman B. W., 1986, DENSITY ESTIMATION S; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; SOKOLOVA M., 2003, ADV NEURAL INFORM PR, V15, P921; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Sturges HA, 1926, J AM STAT ASSOC, V21, P65; Tibshirani R., 1995, J ROYAL STAT SOC B, V57, P267; TOH K.-A., 2006, P S IND EL APPL; TUKEY J., 1959, TECHNOMETRICS, P31; Uney F, 2006, EUR J OPER RES, V173, P910, DOI 10.1016/j.ejor.2005.04.049; WAINER H, 1976, PSYCHOL BULL, V83, P213, DOI 10.1037/0033-2909.83.2.213; Wand MP, 1997, AM STAT, V51, P59, DOI 10.2307/2684697; WILKINSON L., 2011, P ACM C KNOWL DISC D	45	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2012	6	4			SI				19	10.1145/2382577.2382583		18	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	062MU	WOS:000312924700006	
J	Wang, F; Tong, HH; Yu, P; Aggarwal, C				Wang, Fei; Tong, Hanghang; Yu, Phillip; Aggarwal, Charu			Guest editorial: special issue on data mining technologies for computational social science	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material							INTERNET; NETWORKS		[Wang, Fei; Tong, Hanghang; Aggarwal, Charu] IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA; [Yu, Phillip] Univ Illinois, Dept Comp Sci, Chicago, IL USA	Wang, F (reprint author), IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA.	feiwang03@gmail.com; htong@us.ibm.com; psyu@cs.uic.edu; charu@us.ibm.com					Albert R, 1999, NATURE, V401, P130; Almasi G, 1989, HIGHLY PARALLEL COMP; Backstrom L., 2006, KDD, P44; Cowell R. G., 1999, PROBABILISTIC NETWOR; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cui P., 2011, P 34 INT ACM SIGIR C, P185; Faloutsos M, 1999, COMP COMM R, V29, P251; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Gonzalez MC, 2008, NATURE, V453, P779, DOI 10.1038/nature06958; Kang U, 2011, TKDD, V5, P8; Kang U, 2010, ICDM, P875; Kempe D., 2003, KDD; Kumar R., 2010, KDD, P553; Kumar R., 2006, KDD 06, P611; Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742; Leskovec J, 2007, ACM T WEB, V1, DOI 10.1145/1232722.1232727; Leskovec J., 2008, KDD 08, P462; Leskovec J., 2005, KDD, P177; Li T, 2011, DATA MIN KNOWL DISC, V22, P337, DOI 10.1007/s10618-011-0214-1; Liben-Nowell D., 2003, CIKM 03, P556; McGlohon M., 2008, KDD, P524; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Page L, 1998, SIDLWP19990120; Tong HH, 2006, IEEE DATA MINING, P613; Tsourakakis CE, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P837; Wang D., 2011, KDD, P1100; Xin D., 2005, VLDB, P709	27	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		415	419		10.1007/s10618-012-0271-0		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500001	
J	Comar, PM; Tan, PN; Jain, AK				Comar, Prakash Mandayam; Tan, Pang-Ning; Jain, Anil K.			Simultaneous classification and community detection on heterogeneous network data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Multi-task learning; Community detection; Classification; Link mining	NONNEGATIVE MATRIX FACTORIZATION; ALGORITHMS	Previous studies on network mining have focused primarily on learning a single task (such as classification or community detection) on a given network. This paper considers the problem of multi-task learning on heterogeneous network data. Specifically, we present a novel framework that enables one to perform classification on one network and community detection in another related network. Multi-task learning is accomplished by introducing a joint objective function that must be optimized to ensure the classes in one network are consistent with the link structure, nodal attributes, as well as the communities detected in another network. We provide both theoretical and empirical analysis of the framework. We also show that the framework can be extended to incorporate prior information about the correspondences between the clusters and classes in different networks. Experiments performed on both real-world and synthetic data sets demonstrate the effectiveness of the joint framework compared to applying classification and community detection algorithms on each network separately.	[Comar, Prakash Mandayam; Tan, Pang-Ning; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Comar, PM (reprint author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	mandayam@cse.msu.edu; ptan@cse.msu.edu; jain@cse.msu.edu			ONR [N00014-09-1-0663]; ARO [W911NF-09-I-0566]	This material is based upon work supported in part by ONR grant number N00014-09-1-0663 and ARO grant number W911NF-09-I-0566.	Banerjee S., 2007, SIGIR, P787; Bollobas B, 1998, GRADUATE TEXT MATH; Cai D, 2005, P 9 EUR C PRINC PRAC; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen F, 2009, CIKM; Comar PM, 2012, NEUROCOMPUTING, V76, P93, DOI 10.1016/j.neucom.2011.04.035; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; Ding CH, 2006, P 12 ACM SIGKDD INT, P126, DOI 10.1145/1150402.1150420; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Flake G., 2000, 6 ACM SIGKDD INT C K, P150; Flake GW, 2002, COMPUTER, V35, P66, DOI 10.1109/2.989932; Ford L.R., 1956, CAN J MATH, V8, P399, DOI 10.4153/CJM-1956-045-5; Getoor L., 2005, SIGKDD EXPLORATIONS, V7, P3; Grineva M, 2008, P INT WORKSH KNOWL A; Ho N-D, 2008, THESIS CATHOLIC U LO; Hu X, 2009, P INT C KONWL DISC D; Kato T, 2009, IEEE T NEURAL NETWOR, V20, P35, DOI 10.1109/TNN.2008.2003354; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Lee DD, 2001, ADV NEUR IN, V13, P556; Lin CJ, 2007, IEEE T NEURAL NETWOR, V18, P1589, DOI 10.1109/TNN.2007.895831; LIN YR, 2009, P 15 ACM SIGKDD INT, P527, DOI 10.1145/1557019.1557080; Long B., 2005, P 11 ACM SIGKDD INT, P635, DOI 10.1145/1081870.1081949; Long B, 2007, P 13 ACM SIGKDD INT, P470, DOI DOI 10.1145/1281192.1281244; Long B, 2008, P 2008 SIAM INT C DA; Mandayam Comar P, 2010, P 2010 IEEE WIC ACM, V01, P476; Mandayam Comar P, 2010, P 19 ACM INT C INF K, P1737, DOI 10.1145/1871437.1871717; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103; Senator TE, 2005, SIGKDD EXPLORATIONS, V7, P76, DOI DOI 10.1145/1117454.1117465; Shi J., 1997, P CVPR; Tang L, 2009, IEEE INT C DAT MIN I; Tang W, 2009, IEEE DATA MINING, P1016, DOI 10.1109/ICDM.2009.125; Wang P, 2008, P 14 ACM SIGKDD INT; Wang P, 2008, P 8 IEEE INT C DAT M, P1085; Wei Y-C, 1989, INT C COMP AID DES, P298, DOI [10.1109/ICCAD.1989.76957, DOI 10.1109/ICCAD.1989.76957]; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yang TB, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P927; Zhou D, 2008, WWW 08, P141; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu X., 2002, LEARNING LABELED UNL	40	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		420	449		10.1007/s10618-012-0260-3		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500002	
J	Cheng, H; Zhou, Y; Huang, X; Yu, JX				Cheng, Hong; Zhou, Yang; Huang, Xin; Yu, Jeffrey Xu			Clustering large attributed information networks: an efficient incremental computing approach	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph clustering; Incremental computation; Parallel computing	RANDOM-WALK; RESTART	In recent years, many information networks have become available for analysis, including social networks, road networks, sensor networks, biological networks, etc. Graph clustering has shown its effectiveness in analyzing and visualizing large networks. The goal of graph clustering is to partition vertices in a large graph into clusters based on various criteria such as vertex connectivity or neighborhood similarity. Many existing graph clustering methods mainly focus on the topological structures, but largely ignore the vertex properties which are often heterogeneous. Recently, a new graph clustering algorithm, SA-cluster, has been proposed which combines structural and attribute similarities through a unified distance measure. SA-Cluster performs matrix multiplication to calculate the random walk distances between graph vertices. As part of the clustering refinement, the graph edge weights are iteratively adjusted to balance the relative importance between structural and attribute similarities. As a consequence, matrix multiplication is repeated in each iteration of the clustering process to recalculate the random walk distances which are affected by the edge weight update. In order to improve the efficiency and scalability of SA-cluster, in this paper, we propose an efficient algorithm In-Cluster to incrementally update the random walk distances given the edge weight increments. Complexity analysis is provided to estimate how much runtime cost Inc-Cluster can save. We further design parallel matrix computation techniques on a multicore architecture. Experimental results demonstrate that Inc-Cluster achieves significant speedup over SA-Cluster on large graphs, while achieving exactly the same clustering quality in terms of intra-cluster structural cohesiveness and attribute value homogeneity.	[Cheng, Hong; Huang, Xin; Yu, Jeffrey Xu] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China; [Zhou, Yang] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Cheng, H (reprint author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.	hcheng@se.cuhk.edu.hk; yzhou@gatech.edu; xhuang@se.cuhk.edu.hk; yu@se.cuhk.edu.hk	Yu, Jeffrey/F-6005-2011; Cheng, Hong/F-7228-2011	Yu, Jeffrey/0000-0002-9738-827X; 	Research Grants Council of the Hong Kong Special Administrative Region, China [CUHK 419008, 411310, 411211]	The work described in this paper was supported by grants from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project no.: CUHK 419008, 411310 and 411211).	Cai D., 2005, P 3 INT WORKSH LINK, P58, DOI 10.1145/1134271.1134280; Cohn H, 2005, S FDN COMP SCI FOCS; Desikan P, 2005, 14 INT WORLD WID WEB, P1094; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50; Jeh G, 2002, P 8 ACM SIGKDD INT C, P538, DOI 10.1145/775047.775126; Long B., 2006, P 23 INT C MACH LEAR, P585, DOI DOI 10.1145/1143844.1143918; Navlakha S., 2008, P 2008 ACM SIGMOD IN, P419, DOI 10.1145/1376616.1376661; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Pons P., 2006, J GRAPH ALGORITHMS A, V10, P191; Satuluri V, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P737; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; STRASSEN V, 1969, NUMER MATH, V13, P354, DOI 10.1007/BF02165411; Sun JM, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P687; Sun Y, 2009, P 12 INT C EXT DAT T, P565, DOI 10.1145/1516360.1516426; TIAN Y, 2008, P ACM SIGMOD INT C M, P567, DOI 10.1145/1376616.1376675; Tong HH, 2006, IEEE DATA MINING, P613; Tong HH, 2008, KNOWL INF SYST, V14, P327, DOI 10.1007/s10115-007-0094-2; Tsai CY, 2008, COMPUT STAT DATA AN, V52, P4658, DOI 10.1016/j.csda.2008.03.002; Wang F, 2011, DATA MIN KNOWL DISC, V22, P493, DOI 10.1007/s10618-010-0181-y; Wu Y, 2009, PROC INT CONF DATA, P54; Xu X, 2007, P 13 ACM SIGKDD INT, P824, DOI DOI 10.1145/1281192.1281280; Zhou Y., 2010, ICDM, P689; ZHOU Y, 2009, P INT C VER LARG DAT, P718	23	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		450	477		10.1007/s10618-012-0263-0		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500003	
J	Jiang, S; Ferreira, J; Gonzalez, MC				Jiang, Shan; Ferreira, Joseph; Gonzalez, Marta C.			Clustering daily patterns of human activities in the city	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Human activity; Eigen decomposition; Daily activity clustering; Metropolitan area; Statistical learning	K-MEANS ALGORITHM; HUMAN MOBILITY; TIME; MODEL; VALIDATION; GENDER; SYSTEM; SPACE	Data mining and statistical learning techniques are powerful analysis tools yet to be incorporated in the domain of urban studies and transportation research. In this work, we analyze an activity-based travel survey conducted in the Chicago metropolitan area over a demographic representative sample of its population. Detailed data on activities by time of day were collected from more than 30,000 individuals (and 10,552 households) who participated in a 1-day or 2-day survey implemented from January 2007 to February 2008. We examine this large-scale data in order to explore three critical issues: (1) the inherent daily activity structure of individuals in a metropolitan area, (2) the variation of individual daily activities-how they grow and fade over time, and (3) clusters of individual behaviors and the revelation of their related socio-demographic information. We find that the population can be clustered into 8 and 7 representative groups according to their activities during weekdays and weekends, respectively. Our results enrich the traditional divisions consisting of only three groups (workers, students and non-workers) and provide clusters based on activities of different time of day. The generated clusters combined with social demographic information provide a new perspective for urban and transportation planning as well as for emergency response and spreading dynamics, by addressing when, where, and how individuals interact with places in metropolitan areas.	[Gonzalez, Marta C.] MIT, Dept Civil & Environm Engn, Cambridge, MA 02139 USA; [Gonzalez, Marta C.] MIT, Engn Syst Div, Cambridge, MA 02139 USA; [Jiang, Shan] MIT, Dept Urban Studies & Planning, Cambridge, MA 02142 USA; [Ferreira, Joseph] MIT, Dept Urban Studies & Planning, Cambridge, MA 02139 USA	Gonzalez, MC (reprint author), MIT, Dept Civil & Environm Engn, 77 Massachusetts Ave,Room 1-153, Cambridge, MA 02139 USA.	shanjang@mit.edu; jf@mit.edu; martag@mit.edu	Gonzalez, Marta/E-9456-2011		MIT Urban Studies and Planning Department; US Department of Transportation Region One University Transportation Center; Singapore National Research Foundation (NRF) through the Singapore-MIT Alliance for Research and Technology (SMART) Center for Future Mobility (FM)	This research was funded in part by the MIT Urban Studies and Planning Department, by the US Department of Transportation Region One University Transportation Center, and by the Singapore National Research Foundation (NRF) through the Singapore-MIT Alliance for Research and Technology (SMART) Center for Future Mobility (FM). The authors acknowledge the comments and feedback from our colleagues and participants in the SC/OM seminar at MIT, at the 2011 CUPUM conference, Canada, and by Dr. Donald G. Janelle at the University of California, Santa Barbara. We are especially grateful for the comments by the anonymous reviewers and to Dr. Dietmar Bauer from Austrian Institute of Technology.	Axhausen KW, 2002, TRANSPORTATION, V29, P95, DOI 10.1023/A:1014247822322; Balcan D, 2009, P NATL ACAD SCI USA, V106, P21484, DOI 10.1073/pnas.0906910106; Balmer M, 1985, AGENT BASED DEMAND M, V1985; Batty M., 2005, CITIES COMPLEXITY UN; Becker G. S., 1991, TREATISE FAMILY; Becker G. S., 1977, EC APPROACH HUMAN BE; BECKER GS, 1965, ECON J, V75, P493, DOI 10.2307/2228949; Bekhor S, 2011, TRANSP RES BOARD 90; Ben-Akiva M, 1998, URBAN STUD, V35, P1131, DOI 10.1080/0042098984529; Bhat CR, 1999, TRANSPORTATION, V26, P119, DOI 10.1023/A:1005196331393; Bishop C, 2009, PATTERN RECOGNITION; Bowman JL, 2001, TRANSPORT RES A-POL, V35, P1, DOI 10.1016/S0965-8564(99)00043-9; Brun M, 2007, PATTERN RECOGN, V40, P807, DOI 10.1016/j.patcog.2006.06.026; Calabrese F, 2010, EIGENPLACES SEGMENTI, V9; Candia J, 2008, J PHYS A-MATH THEOR, V41, DOI DOI 10.1088/1751-8113/41/22/224015; Chapin F. S., 1974, HUMAN ACTIVITY PATTE; Crane R, 2008, P NATL ACAD SCI USA, V105, P15649, DOI 10.1073/pnas.0803685105; Ding C., 2004, P 21 INT C MACH LEAR; Duda R.O., 2001, PATTERN CLASSIFICATI; Dunn J. C., 1973, Journal of Cybernetics, V3; Durrett R., 2005, PROBABILITY THEORY E; Eagle N, 2009, BEHAV ECOL SOCIOBIOL, V63, P1057, DOI 10.1007/s00265-009-0739-0; Eagle N, 2009, P NATL ACAD SCI USA, V106, P15274, DOI 10.1073/pnas.0900282106; Freud S, 1953, COMPLETE PSYCHOLOGIC, VIV, P1; Freud S, 1953, COLLECT PAPERS, Vv, P1; Geerken M, 1983, HOME WORK FAMILYS AL; Foth M, 2011, FROM SOCIAL BUTTERFLY TO ENGAGED CITIZEN: URBAN INFORMATICS, SOCIAL MEDIA, UBIQUITOUS COMPUTING, AND MOBILE TECHNOLOGY TO SUPPORT CITIZEN ENGAGEMENT, P1; Gonzalez MC, 2008, NATURE, V453, P779, DOI 10.1038/nature06958; GOODCHILD MF, 1984, ENVIRON PLANN A, V16, P807, DOI 10.1068/a160807; Greaves S, 2004, HENSHER DA HDB TRANS; Gupta S, 1999, DATA WAREHOUS KNOWL, V1676, P797, DOI [10.1007/3-540-48298-9_22, DOI 10.1007/3-540-48298-9_22]; HAGERSTRAND T, 1989, PAP REG SCI ASSOC, V66, P1, DOI 10.1007/BF01954291; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Hanson S, 2008, TRANSPORT CRITICAL E; HANSON S, 1980, GEOGR REV, V70, P291, DOI 10.2307/214257; Harvey AS, 2000, TRANSPORTATION, V27, P53, DOI 10.1023/A:1005207320044; Hastie T, 2009, ELEMENTS STAT LEARNI; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kargupta H, 2009, CH CRC DATA MIN KNOW, P117; Kim M, 2006, IEEE INFOCOM 06 BARC, DOI citeulike-article-id:903652; Kwan MP, 1999, PROF GEOGR, V51, P210; Li L, 2011, P 28 INT C MACH LEAR; Maslow A., 1987, MOTIVATION PERSONALI; Nature Editorial, 2008, NATURE, V453, P698; Ordonez C, 2003, P 8 ACM SIGMOD WORKS; Portugali J., 2012, COMPLEXITY THEORIES; RALAMBONDRAINY H, 1995, PATTERN RECOGN LETT, V16, P1147, DOI 10.1016/0167-8655(95)00075-R; Reggiani A, 2009, ADV SPAT SCI, P1, DOI 10.1007/978-3-642-01554-0; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Sang SH, 2011, URBAN STUD, V48, P891, DOI 10.1177/0042098010368576; Shen Q, 1998, ENVIRON PLANN B, V25, P345, DOI 10.1068/b250345; Song CM, 2010, SCIENCE, V327, P1018, DOI 10.1126/science.1177170; TAYLOR PJ, 1975, ENVIRON PLANN A, V7, P671, DOI 10.1068/a070671; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Waddell P, 2002, J AM PLANN ASSOC, V68, P297, DOI 10.1080/01944360208976274; Wang D, 2011, 17 ACM SIGKDD C KNOW; Wang D, 2011, P 20 INT C WORLD WID; Wang P, 2009, SCIENCE, V324, P1071, DOI 10.1126/science.1167053; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Xu R, 2008, CLUSTERING, P63, DOI [10.1002/9780470382776.ch4, DOI 10.1002/9780470382776.CH4]; Yang J., 2011, P 4 ACM INT C WEB SE; Yu H, 2008, INT J GEOGR INF SCI, V22, P409, DOI 10.1080/13658810701427569; Zha H., 2001, ADV NEURAL INFORM PR, V14, P1057; [Anonymous], 2008, CHICAGO TRAVEL TRACK	65	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		478	510		10.1007/s10618-012-0264-z		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500004	
J	Liu, L; Tang, J; Han, JW; Yang, SQ				Liu, Lu; Tang, Jie; Han, Jiawei; Yang, Shiqiang			Learning influence from heterogeneous social networks	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Social influence analysis; Social network analysis; Influence propagation; Topic modeling	IDENTIFICATION; CENTRALITY	Influence is a complex and subtle force that governs social dynamics and user behaviors. Understanding how users influence each other can benefit various applications, e.g., viral marketing, recommendation, information retrieval and etc. While prior work has mainly focused on qualitative aspect, in this article, we present our research in quantitatively learning influence between users in heterogeneous networks. We propose a generative graphical model which leverages both heterogeneous link information and textual content associated with each user in the network to mine topic-level influence strength. Based on the learned direct influence, we further study the influence propagation and aggregation mechanisms: conservative and non-conservative propagations to derive the indirect influence. We apply the discovered influence to user behavior prediction in four different genres of social networks: Twitter, Digg, Renren, and Citation. Qualitatively, our approach can discover some interesting influence patterns from these heterogeneous networks. Quantitatively, the learned influence strength greatly improves the accuracy of user behavior prediction.	[Liu, Lu] Capital Med Univ, Beijing, Peoples R China; [Tang, Jie; Yang, Shiqiang] Tsinghua Univ, Beijing 100084, Peoples R China; [Han, Jiawei] Univ Illinois, Urbana, IL 61801 USA	Liu, L (reprint author), Capital Med Univ, Beijing, Peoples R China.	lu-liu@mails.tsinghua.edu.cn			National Natural Science Foundation of China [61103065, 61073073, 61035004, 61003097, 60933013]; U.S. National Science Foundation [IIS-09-05215]; U.S. Army Research Laboratory [W911NF-09-2-0053]	The work was supported in part by the National Natural Science Foundation of China under grants 61103065, 61073073, 61035004, 61003097 and 60933013, and by the U.S. National Science Foundation under grant IIS-09-05215 and the U.S. Army Research Laboratory under Cooperative Agreement Number W911NF-09-2-0053 (NS-CTA).	Anagnostopoulos A., 2008, KDD 08, P7; BONACICH P, 1972, J MATH SOCIOL, V2, P113; Bonacich P, 2001, SOC NETWORKS, V23, P191, DOI 10.1016/S0378-8733(01)00038-7; BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631; Chang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P169; Chen W, 2010, KDD 10; Crandall D., 2008, KDD 08, P160; Cui P, 2011, SIGIR 11; Dietz L, 2007, ICML 07, P233; Domingos P., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Doucet A., 2000, UNCERTAINTY ARTIFICI, P176; Dourisboure Y., 2007, WWW 07, P461; Fowler JH, 2008, BRIT MED J, V337, DOI 10.1136/bmj.a2338; Gerrish S, 2010, ICML 10, P375; Goyal A, 2010, WSDM 10, P207; GRANOVET.MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469; Gruhl D., 2004, WWW, P491; Guha R., 2004, WWW 04, P403; Haveliwala TH, 2002, WWW 02, P517; Hopcroft J. E., 2011, CIKM 11; Iribarren JL, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.038702; Jeh G, 2002, WWW 02, P271; KATZ L, 1953, PSYCHOMETRIKA, V18, P39; Kelman HC, 1958, J CONFLICT RESOLUT, V2, P51, DOI DOI 10.1177/002200275800200106; Kempe D., 2003, KDD 03, P137; KING J, 1987, J INFORM SCI, V13, P261, DOI 10.1177/016555158701300501; Kiss C, 2008, DECIS SUPPORT SYST, V46, P233, DOI 10.1016/j.dss.2008.06.007; Kossinets G., 2008, KDD, P435; Krackhardt David, 1992, NETWORKS ORG; La Fond T, 2010, WWW 10, P601; Liben-Nowell D, 2008, P NATL ACAD SCI USA, V105, P4633, DOI 10.1073/pnas.0708471105; Liu L., 2010, CIKM 10, P199; Macskassy S, 2003, WORKSH MULT DAT MIN; Nallapati R., 2008, KDD, P542; PAGE L., 1999, SIDLWP19990120 STANF; Richardson M., 2002, KDD 02, P61; Rodriguez MG, 2010, KDD 10; Scripps J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P747; Singla P., 2008, WWW 08, P655; Sun Y, 2009, EDBT 09; Sun YZ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P797; Tan C., 2010, KDD, P1049; Tang J, 2012, WSDM 12; Tang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P807; Tang L, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P817; Whitfield J, 2008, NATURE, DOI [10.1038/news.2008.918, DOI 10.1038/NEWS.2008.918]; Xiang R., 2010, WWW 10, P981; Yang TB, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P927; Ye J., 2008, KDD, P1025; Zheleva E, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1007	50	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		511	544		10.1007/s10618-012-0252-3		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500005	
J	Wang, C; Chen, W; Wang, YJ				Wang, Chi; Chen, Wei; Wang, Yajun			Scalable influence maximization for independent cascade model in large-scale social networks	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Influence maximization; Social networks; Independent cascade model; Viral marketing		Influence maximization, defined by Kempe et al. (SIGKDD 2003), is the problem of finding a small set of seed nodes in a social network that maximizes the spread of influence under certain influence cascade models. The scalability of influence maximization is a key factor for enabling prevalent viral marketing in large-scale online social networks. Prior solutions, such as the greedy algorithm of Kempe et al. (SIGKDD 2003) and its improvements are slow and not scalable, while other heuristic algorithms do not provide consistently good performance on influence spreads. In this article, we design a new heuristic algorithm that is easily scalable to millions of nodes and edges in our experiments. Our algorithm has a simple tunable parameter for users to control the balance between the running time and the influence spread of the algorithm. Our results from extensive simulations on several real-world and synthetic networks demonstrate that our algorithm is currently the best scalable solution to the influence maximization problem: (a) our algorithm scales beyond million-sized graphs where the greedy algorithm becomes infeasible, and (b) in all size ranges, our algorithm performs consistently well in influence spread-it is always among the best algorithms, and in most cases it significantly outperforms all other scalable heuristics to as much as 100-260% increase in influence spread.	[Wang, Chi] Univ Illinois, Urbana, IL 61801 USA; [Chen, Wei; Wang, Yajun] Microsoft Res Asia, Beijing, Peoples R China	Wang, C (reprint author), Univ Illinois, Urbana, IL 61801 USA.	chiwang1@illinois.edu; weic@microsoft.com; yajunw@microsoft.com					Bakshy E., 2009, EC 09; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Cha M, 2009, WWW 09; Chen W, 2011, SDM 11; Chen W, 2010, KDD 10; Chen W, 2009, KDD 09; Chen W, 2010, ICDM 10; Chung F., 2000, STOC 00; Cui P, 2011, SIGIR 11; Domingos P, 2001, KDD 01; Feige U, 1998, J ACM, V45, P634, DOI 10.1145/285055.285059; FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7; Goyal A, 2010, WSDM 10; Gruhl D., 2004, WWW 04; Kempe D., 2003, KDD 03; Kimura M, 2006, PKDD 06; Leskovec J, 2007, KDD 07; Misner I. R., 1999, WORLDS BEST KNOWN MA; Nail J., 2004, CONSUMER ADVERTISING; NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971; Richardson M, 2002, KDD 02; Rodriguez MG, 2010, KDD 10; Streeter M, 2007, CMUCS07171; Tang J, 2009, KDD 09; VALIANT LG, 1979, SIAM J COMPUT, V8, P410, DOI 10.1137/0208032; Vazirani V., 2004, APPROXIMATION ALGORI	26	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		545	576		10.1007/s10618-012-0262-1		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500006	
J	Li, ZM; Xiong, H; Liu, YC				Li, Zhongmou; Xiong, Hui; Liu, Yanchi			Mining blackhole and volcano patterns in directed graphs: a general approach	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Blackhole pattern; Volcano pattern; Financial fraud detection; Graph mining; Network structure analysis	OUTLIER DETECTION; COMMUNITY STRUCTURE; NETWORKS	Given a directed graph, the problem of blackhole mining is to identify groups of nodes, called blackhole patterns, in a way such that the average in-weight of this group is significantly larger than the average out-weight of the same group. The problem of finding volcano patterns is a dual problem of mining blackhole patterns. Therefore, we focus on discovering the blackhole patterns. Indeed, in this article, we develop a generalized blackhole mining framework. Specifically, we first design two pruning schemes for reducing the computational cost by reducing both the number of candidate patterns and the average computation cost for each candidate pattern. The first pruning scheme is to exploit the concept of combination dominance to reduce the exponential growth search space. Based on this pruning approach, we develop the gBlackhole algorithm. Instead, the second pruning scheme is an approximate approach, named approxBlackhole, which can strike a balance between the efficiency and the completeness of blackhole mining. Finally, experimental results on real-world data show that the performance of approxBlackhole can be several orders of magnitude faster than gBlackhole, and both of them have huge computational advantages over the brute-force approach. Also, we show that the blackhole mining algorithm can be used to capture some suspicious financial fraud patterns.	[Li, Zhongmou; Xiong, Hui] Rutgers State Univ, Dept Management Sci & Informat Syst, Newark, NJ 07102 USA; [Liu, Yanchi] Univ Sci & Technol Beijing, Beijing 100083, Peoples R China	Xiong, H (reprint author), Rutgers State Univ, Dept Management Sci & Informat Syst, Newark, NJ 07102 USA.	mosesli@pegasus.rutgers.edu; hxiong@rutgers.edu; liuyanchi@manage.ustb.edu.cn			National Science Foundation [CCF-1018151]; National Natural Science Foundation of China (NSFC) [70890082, 71028002]	This research was supported in part by National Science Foundation (CCF-1018151) and National Natural Science Foundation of China (NSFC) via project numbers 70890082 and 71028002. The authors would also like to thank the editors and the anonymous reviewers for their valuable and constructive comments on this article.	Adamic L, 2010, TRADING NETWORKS; Akoglu L, 2010, LECT NOTES ARTIF INT, V6119, P410; Barnett V., 1994, OUTLIERS STAT DATA; Breunig MM, 2000, SIGMOD REC, V29, P93; Chakrabarti D, 2004, LECT NOTES ARTIF INT, V3202, P112; Chaudhary A, 2002, P ACM SIGMOD WORKSH; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Cormen T. H., 2009, INTRO ALGORITHMS; DIESTEL R, 2006, GRADUATE TEXTS MATH; Gehrke J., 2003, ACM SIGKDD EXPLORATI, V5, P149, DOI 10.1145/980972.980992; Ghosh R, 2008, 2 SNA KDD WORKSH SOC; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Hawkins D. M., 1980, IDENTIFICATION OUTLI; Hopcroft J, 2003, P 9 ACM SIGKDD INT C; Huan J., 2003, P 3 IEEE INT C DAT M; Jiang X, 2009, DATA KNOWL ENG, V68, P1034, DOI 10.1016/j.datak.2009.04.008; Johnson R. A., 1998, APPL MULTIVARIATE ST; Knuth D.E., 2011, ART COMPUTER PROGR A, V4A; Kuramochi M, 2005, DATA MIN KNOWL DISC, V11, P243, DOI 10.1007/s10618-005-0003-9; Lazarevic A., 2005, P 11 ACM SIGKDD INT, P157, DOI 10.1145/1081870.1081891; Leskovec J., 2008, ARXIVORG08101355; Leskovec J, 2010, P 19 INT WORLD WID W; Leskovec J., 2010, P 28 ACM C HUM FACT; Leskovec J, 2005, P 11 ACM SIGKDD INT; Leskovec J., 2006, P 12 ACM SIGKDD INT, P631, DOI 10.1145/1150402.1150479; Li Z, 2010, P 10 IEEE INT C DAT, P294; Moonesinghe HDK, 2008, INT J ARTIF INTELL T, V17, P19, DOI 10.1142/S0218213008003753; Naher S., 1999, LEDA PLATFORM COMBIN; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; Noble C. C., 2003, P 9 ACM SIGKDD INT C, P631; Papadimitriou S, 2003, PROC INT CONF DATA, P315, DOI 10.1109/ICDE.2003.1260802; Pathak N, 2008, 2 SNA KDD WORKSH SOC; Steyvers M, 2004, P 10 ACM SIGKDD INT; Sun J., 2005, P 5 IEEE INT C DAT M, P418; Tan P.N, 2005, INTRO DATA MINING; Wang C, 2004, P 10 ACM SIGKDD INT; Wang J., 2006, P 22 INT C DAT ENG I, P74; Yan X, 2002, P 2 IEEE INT C DAT M; Zhou D, 2006, P 15 INT WORLD WID W	40	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		577	602		10.1007/s10618-012-0255-0		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500007	
J	Boldrini, E; Balahur, A; Martinez-Barco, P; Montoyo, A				Boldrini, Ester; Balahur, Alexandra; Martinez-Barco, Patricio; Montoyo, Andres			Using EmotiBlog to annotate and analyse subjectivity in the new textual genres	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Sentiment analysis; Annotation model; Feature selection; Opinion Mining; New textual genres	AGREEMENT	Thanks to the increasing amount of subjective data on the Web 2.0, tools to manage and exploit such data become essential. Our research is focused on the creation of EmotiBlog, a fine-grained annotation scheme for labelling subjectivity in non-traditional textual genres. We also present the EmotiBlog corpus; a collection of blog posts composed by 270,000 tokens about 3 topics and in 3 languages: Spanish, English and Italian. Additionally, we carry out a series of experiments focused on checking the robustness of the model and its applicability to Natural Language Processing tasks with regards to the 3 languages. The experiments for the inter-annotator agreement, as well as for feature selection, provided satisfactory results, which have given an impetus to continue working with the model and extend the annotated corpus. In order to check its applicability, we tested different Machine Learning models created using the annotation in EmotiBlog on other corpora in order to see if the obtained annotation is domain and genre independent, obtaining positive results. Finally, we also applied EmotiBlog to Opinion Mining, proving that our resource allows an improvement the performance of systems built for this task.	[Boldrini, Ester; Balahur, Alexandra; Martinez-Barco, Patricio; Montoyo, Andres] Univ Alicante, GPLSI, E-03080 Alicante, Spain	Boldrini, E (reprint author), Univ Alicante, GPLSI, Apartado Correos 99, E-03080 Alicante, Spain.	eboldrini@dlsi.ua.es	Martinez Barco, Patricio/A-4161-2011		Spanish Government [TIN2009-13391-C04-04, PROMETEO/2009/199]; Valencian Government [TIN2009-13391-C04-04, PROMETEO/2009/199]; Generalitat Valenciana [ACOMP/2011/001]	This work has been partially funded by the Spanish and Valencian Government through the projects "TEXTMESS 2.0: Las tecnologias del Lenguaje Humano ante los nuevos retos de la comunicacion digital" (TIN2009-13391-C04-04), "Desarrollo de tecnicas inteligentes e interactivas de mineria de textos" (PROMETEO/2009/199) and the Generalitat Valenciana (ACOMP/2011/001) respectively.	Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2; Balahur A, 2009, P WORKSH NAT LANG CO; Balahur A, 2009, P RANLP 2009; Balahur A, 2010, P NTCIR 8 MOAT C TOK; Balahur A, 2010, P ECAI C; Balahur A, 2010, P COLING C; Balahur A, 2010, OPAL APPL OPINION MI; Balahur A, 2009, P ACL SING; Balahur A, 2009, P INT C APPL NAT LAN; Balahur A., 2010, P 7 INT C LANG RES E, P2216; Balahur A, 2008, PROCESAMIENTO LENGUA, V40; Boldrini E, 2009, P 5 INT C DAT MIN LA; Boldrini E, 2009, P WOMSA 2009 SEV SPA; Boldrini E, 2010, P 4 LING ANN WORKSH; Carletta J, 1996, ASSESSING AGREEMENT; Cerini S, 2007, MICROWNOP GOLD STAND; Chaovalit P., 2005, P HICSS 05 38 HAW IN; Choi Y, 2005, P HLT EMNL; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Craggs R, 2005, COMPUT LINGUIST, V31, P289, DOI 10.1162/089120105774321109; Cui H, 2006, P 21 NAT C ART INT A; Dave K., 2003, P WWW 03; Esuli A., 2006, P 6 INT C LANG RES E; Gamon M, 2005, LECT NOTES COMPUTER; Gamon M., 2004, P 20 INT C COMP LING, P841, DOI 10.3115/1220355.1220476; Goldberg AB, 2006, HLT NAACL 2006 WORKS; Hatzivassiloglou V, 2000, P COLING 2000; Hu M., 2004, P 19 NAT C ART INT A; Kim S., 2004, P COLING 2004; Lesk M, 1986, P SIGDOC C 1986; Lewis D, 1994, P 17 ANN INT ACM SIG; Liu Bing, 2007, WEB DATA MINING EXPL; Mathieu J, 2005, ANNOTATION EMOTIONS; Mullen T, 2004, P EMNLP; Ng V, 2006, P 40 ANN M ASS COMP; Pang B., 2003, P 43 ANN M ACL, P115; Paquet S, 2003, PERSONAL KNOWLEDGE P; Riloff E, 2003, P 2003 C EMP METH NA; RUSSELL JA, 1983, J PERS SOC PSYCHOL, V45, P1281, DOI 10.1037/0022-3514.45.6.1281; Salton G, 1971, COMPUTER EVALUATION, P143; Scherer K., 1997, ISEAR QUESTIONNAIRE; Scherer K, 2005, SOC SCI INF, V3; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Somasundaran S, 2008, 22 INT C COMP LING C; Somasundaran S, 2007, P INT C WEBL SOC MED; Stoyanov V, 2006, P COLINGACL 2006 WOR; Stoyanov V, 2005, P HUM LANG TECHN C C; Strapparava C., 2004, P 4 INT C LANG RES E, P1083; Strapparava C., 2007, SEMEVAL 2007 TASK 14; TURNEY P., 2002, P 40 ANN M ASS COMP; Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013; Vapnik V.N., 1995, NATURE STAT LEARNING; Wiebe J, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P1065; Wiebe J, 2006, P 6 INT C COMP LING; Wiebe J, 2005, P ACL WORKSH FRONT C; Wiebe J, 2005, LANG RESOUR EVAL, V1, P2165; Wilson T, 2004, P AAAI; Wilson T., 2005, P HLT EMNLP 2005; Wilson T, 2004, P AAAI 2004; Yang Y., 1997, P ICML 97 14 INT C M	60	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		603	634		10.1007/s10618-012-0259-9		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500008	
J	Davidson, I; Gilpin, S; Walker, PB				Davidson, Ian; Gilpin, Sean; Walker, Peter B.			Behavioral event data and their analysis	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Social data; Event data		Social science is broadly defined as the analysis of human behavior whether it be at an individual or a group level. In this work, we explore the analysis of human behavior encoded as a trail of their events over time and space, which we refer to as behavioral event data. We show that such data offers challenges to data mining algorithm designers as the data to analyze is naturally multi-way, involves complex patterns that form/reform over time, and has complex interactions between groups in the population. Though the data naturally lends itself to be represented as graphs and tensors we show how existing techniques are limited in their usefulness and outline our own algorithms to overcome these challenges. In this paper, using the adversarial event behavior of blue and red forces, we show three core problems and solutions in event behavior analysis: (1) Decomposing behavior to identify areas of intense activity, (2) Predicting what groups of events are likely to occur, and (3) Analysis to identify interacting behavior given a known template.	[Davidson, Ian; Gilpin, Sean] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA; [Walker, Peter B.] USN, Sch Aviat Safety, Pensacola, FL USA	Davidson, I (reprint author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.	davidson@cs.ucdavis.edu; sagilpin@ucdavis.edu; peter.b.walker@navy.mil			ONR [N00014-09-1-0712, N00014-11-1-0108]	We gratefully acknowledge support of this research via ONR grants N00014-09-1-0712 Automated Discovery and Explanation of Event Behavior and N00014-11-1-0108 Guided Learning in Dynamic Environments.	Aggrawal CC, 2007, DATA STREAMS MODELS; Allison P. D., 1984, EVENT HIST ANAL REGR; Blum A., 1998, P 11 ANN C COMP LEAR; Box-Steffensmeier J. M., 2004, EVENT HIST MODELING; Davidson I, 2005, 5 SIAM DAT MIN C; Garey M, 1982, IEEE T INFORM THEORY, V28, P2; Haas VJ, 1999, J BIOL PHYS, V25, P309, DOI 10.1023/A:1005115117228; Li S, 2006, P ECCV; Pew R. W., 1998, MODELING HUMAN ORG B; Schafer TJ, 1978, COMPLEXITY SATISFIAB; Taskar B., 2005, P 22 INT C MACH LEAR; Wagstaff K, 2000, 17 INT C MACH LEARN, P1103; Wang X, 2010, FLEXIBLE PRINCIPLED	13	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2012	25	3			SI		635	653		10.1007/s10618-012-0269-7		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	992GL	WOS:000307763500009	
J	Chan, J; Bailey, J; Leckie, C; Houle, M				Chan, Jeffrey; Bailey, James; Leckie, Christopher; Houle, Michael			ciForager: Incrementally Discovering Regions of Correlated Change in Evolving Graphs	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Dynamic graph mining; correlated change; shortest path distance; connected components; fault detection		Data mining techniques for understanding how graphs evolve over time have become increasingly important. Evolving graphs arise naturally in diverse applications such as computer network topologies, multiplayer games and medical imaging. A natural and interesting problem in evolving graph analysis is the discovery of compact subgraphs that change in a similar manner. Such subgraphs are known as regions of correlated change and they can both summarise change patterns in graphs and help identify the underlying events causing these changes. However, previous techniques for discovering regions of correlated change suffer from limited scalability, making them unsuitable for analysing the evolution of very large graphs. In this paper, we introduce a new algorithm called ciForager, that addresses this scalability challenge and offers considerable improvements. The efficiency of ciForager is based on the use of new incremental techniques for detecting change, as well as the use of Voronoi representations for efficiently determining distance. We experimentally show that ciForager can achieve speedups of up to 1000 times over previous approaches. As a result, it becomes feasible for the first time to discover regions of correlated change in extremely large graphs, such as the entire BGP routing topology of the Internet.	[Chan, Jeffrey; Bailey, James; Leckie, Christopher] Univ Melbourne, Dept Comp & Informat Syst, Melbourne, Vic 3010, Australia; [Houle, Michael] Natl Inst Informat, Tokyo, Japan	Chan, J (reprint author), Univ Melbourne, Dept Comp & Informat Syst, Melbourne, Vic 3010, Australia.	jeffrey.chan@unimelb.edu.au			NICTA; National Institute of Informatics	This research was funded by NICTA and the National Institute of Informatics.	Aggarwal C. C., 2003, P 29 INT C VER LARG, V29, P81; AND JIN T., 1999, HPL9935R1; Au M. H., 2005, P 17 INT C SCI STAT, P163; Bae E, 2010, DATA MIN KNOWL DISC, V21, P427, DOI 10.1007/s10618-009-0164-z; Bogdanov P., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), DOI 10.1109/ICDM.2011.101; Borgwardt KM, 2006, IEEE DATA MINING, P818; Celik M, 2006, IEEE DATA MINING, P119; Chakrabarti D., 2006, P 12 ACM SIGKDD INT, P554, DOI 10.1145/1150402.1150467; Chan J, 2008, KNOWL INF SYST, V16, P53, DOI 10.1007/s10115-007-0117-z; Chan J, 2009, INTELL DATA ANAL, V13, P755, DOI 10.3233/IDA-2009-0392; Chi Y, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P153; CLARE S., 1997, THESIS U NOTTINGHAM; Cormen T. H., 2001, INTRO ALGORITHMS; de Berg M., 2008, COMPUTATIONAL GEOMET; Du N, 2010, LECT NOTES ARTIF INT, V6321, P393; Elnekave S, 2007, I C DATA ENGIN WORKS, P585, DOI 10.1109/ICDEW.2007.4401044; Erwig M, 2000, NETWORKS, V36, P156, DOI 10.1002/1097-0037(200010)36:3<156::AID-NET2>3.0.CO;2-L; Gibson D., 2005, P 31 INT C VER LARG, P721; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Honiden S, 2009, 2009 6TH INTERNATIONAL SYMPOSIUM ON VORONOI DIAGRAMS (ISVD 2009), P183, DOI 10.1109/ISVD.2009.26; Jain AK, 1998, ALGORITHMS CLUSTERIN; KUMAR R., 2006, P 12 ACM SIGKDD C KN; Kumar R., 2003, P 12 INT C WORLD WID, P568; Lahiri M, 2010, KNOWL INF SYST, V24, P467, DOI 10.1007/s10115-009-0253-8; Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI 10.1145/1081870.1081893; Luenberger DG., 2003, LINEAR NONLINEAR PRO; Meila M, 2003, LECT NOTES ARTIF INT, V2777, P173, DOI 10.1007/978-3-540-45167-9_14; Steinder M, 2004, SCI COMPUT PROGRAM, V53, P165, DOI 10.1016/j.scico.2004.01.010; Shoubridge P, 2002, J INTERCONNECTION NE, V3, P85, DOI 10.1142/S0219265902000562; Sun J, 2006, P 12 ACM SIGKDD INT, P374, DOI 10.1145/1150402.1150445; Sun JM, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P687; TAN T.-T., 2005, WORKSH LINK AN COUT; THON I., 2008, P 19 EUR C MACH LEAR, P506; Yang H., 2005, P 11 ACM SIGKDD INT, P716, DOI 10.1145/1081870.1081962; ZHOU A., 2007, KNOWL INF SYST, P181; Zhou D., 2005, P 22 INT C MACH LEAR, P1028, DOI 10.1145/1102351.1102481	36	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2012	6	3							11	10.1145/2362383.2362385		50	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	030HB	WOS:000310560600002	
J	de Melo, POSV; Almeida, VAF; Loureiro, AAF; Faloutsos, C				Vaz de Melo, Pedro O. S.; Almeida, Virgilio A. F.; Loureiro, Antonio A. F.; Faloutsos, Christos			Forecasting in the NBA and Other Team Sports: Network Effects in Action	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Complex networks; social networks; sports analytics	PREDICTION MARKETS; ACCURACY	The multi-million sports-betting market is based on the fact that the task of predicting the outcome of a sports event is very hard. Even with the aid of an uncountable number of descriptive statistics and background information, only a few can correctly guess the outcome of a game or a league. In this work, our approach is to move away from the traditional way of predicting sports events, and instead to model sports leagues as networks of players and teams where the only information available is the work relationships among them. We propose two network-based models to predict the behavior of teams in sports leagues. These models are parameter-free, that is, they do not have a single parameter, and moreover are sport-agnostic: they can be applied directly to any team sports league. First, we view a sports league as a network in evolution, and we infer the implicit feedback behind network changes and properties over the years. Then, we use this knowledge to construct the network-based prediction models, which can, with a significantly high probability, indicate how well a team will perform over a season. We compare our proposed models with other prediction models in two of the most popular sports leagues: the National Basketball Association (NBA) and the Major League Baseball (MLB). Our model shows consistently good results in comparison with the other models and, relying upon the network properties of the teams, we achieved a approximate to 14% rank prediction accuracy improvement over our best competitor.	[Vaz de Melo, Pedro O. S.; Almeida, Virgilio A. F.; Loureiro, Antonio A. F.] Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil; [Faloutsos, Christos] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	de Melo, POSV (reprint author), Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil.	pedro.olmo@gmail.com	InWeb, Inct/J-9839-2013				ABBOT H., 2007, TRUE HOOP; BARZILAI A., 2008, ADJUSTED PLUS MINUS; BEN_NAIM E., 2007, J QUANT ANAL SPORTS, V2, P1; BRADLEY R., 2009, LABOR PAINS NOTHING; COWAN C., 2006, BUSINESS WEEK; DA COSTA J P, 2004, AUSTR NZ J STAT, V<IT>47</IT>, P515; DILGER A., 2002, SSRN ELIBRARY; EASTERBROOK G., 2006, ESPN; FAST A., 2006, P AAAI FALL S CAPT U; FESSLER JA, 1994, IEEE T SIGNAL PROCES, V42, P2664, DOI 10.1109/78.324732; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; HAMBACH W., 2006, GAMING LAW REV, V10, P6; ILARDI S., 2007, ADJUSTED PLUS MINUS; Kelly D., 2003, SIGIR Forum, V37; Kendall M., 1990, RANK CORRELATION MET; LAHMAN S., 2008, LAHMAN BASEBALL DATA; LEWIS M., 2009, NY TIMES; LIGHTMAN A., 2010, OPEN PREDICTION SPOR; LOONEY D. S., 1976, SPORTS ILLUSTRATED; Luckner S, 2008, LECT NOTES BUS INF, V2, P227; NEVILLE J., 2005, P 11 ACM SIGKDD INT, P449, DOI DOI 10.1145/1081870.1081922; NEWMAN M., 2010, ACM T EMBED COMPUT S, V<IT>9</IT>, P4; Nichols D., 1998, P 5 DELOS WORKSH FIL, P31; Onody RN, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.037103; PAGE G., 2007, J QUANT ANAL SPORTS, V<IT>3</IT>, P1; Pandit S., 2007, P 16 INT C WORLD WID, P201, DOI 10.1145/1242572.1242600; PARK J., 2005, J STAT MECH-THEORY E, V<IT>10</IT>; PAULSEN J., 2006, EFFICIENCY PER MINUT; REHEUSER R, 2010, NBA ENCY; ROSENBAUM D. T., 2004, MEASURING NBA PLAYER; Shetty J., 2005, P 3 INT WORKSH LINK, P74, DOI 10.1145/1134271.1134282; Spann M, 2009, J FORECASTING, V28, P55, DOI 10.1002/for.1091; Stekler HO, 2010, INT J FORECASTING, V26, P606, DOI 10.1016/j.ijforecast.2010.01.003; Vaz de Melo P. O., 2008, P ACM INT C KNOWL DI, P695; WEINBERG A, 2003, CASE LEGAL SPORTS GA	35	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2012	6	3							13	10.1145/2362383.2362387		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	030HB	WOS:000310560600004	
J	Wang, DD; Zhu, SH; Li, T; Gong, YH				Wang, Dingding; Zhu, Shenghuo; Li, Tao; Gong, Yihong			Comparative Document Summarization via Discriminative Sentence Selection	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Comparative document summarization; discriminative sentence selection		Given a collection of document groups, a natural question is to identify the differences among them. Although traditional document summarization techniques can summarize the content of the document groups one by one, there exists a great necessity to generate a summary of the differences among the document groups. In this article, we study a novel problem, that of summarizing the differences between document groups. A discriminative sentence selection method is proposed to extract the most discriminative sentences which represent the specific characteristics of each document group. Experiments and case studies on real-world data sets demonstrate the effectiveness of our proposed method.	[Wang, Dingding; Li, Tao] Florida Int Univ, Dept Comp Sci, Miami, FL 33199 USA; [Zhu, Shenghuo; Gong, Yihong] NEC Labs Amer Inc, Cupertino, CA 95014 USA	Wang, DD (reprint author), Florida Int Univ, Dept Comp Sci, 11200 SW 8th ST, Miami, FL 33199 USA.	dwang003@cs.fiu.edu; zsh@sv.nec-labs.com; taoli@cs.fiu.edu; ygong@sv.nec-labs.com			NSF [DBI-0850203, HRD-0833093, DMS-0915110]; DHS [2009-ST-062-000016, 2010-ST-062-000039]	This work was partially supported by NSF grants DBI-0850203, HRD-0833093, and DMS-0915110 and DHS grants 2009-ST-062-000016 and 2010-ST-062-000039.	Allan J., 1998, P DARPA BROADC NEWS, P194; Allan J., 2001, P 24 ANN INT ACM SIG, P10, DOI 10.1145/383952.383954; Baeza-Yates R. A., 1999, MODERN INFORM RETRIE; Barzilay R., 1999, P ACL; BAXENDALE PB, 1958, IBM J RES DEV, V2, P354; BLOEDORN I., 1997, AAAI IAAI, P622; Brants T, 2003, P 26 ANN INT ACM SIG, P330; Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.291025; CHI Y., 2007, P SIGKDD C; Conroy J.M., 2001, P 24 ANN INT ACM SIG, P406, DOI 10.1145/383952.384042; Ding C., 2005, P SIAM DAT MIN C; DUC, 2006, DUC; EDMUNDSO.HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519; ERKAN, 2004, P EMNLP; Fung GPC, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P300; GOLDSTEIN J., 1999, RES DEV INFORMATION, P121; JING H., 2000, P NAACL C; Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9; Kumaran G., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009044; LERMAN K., 2009, COMPANION VOLUME SHO, P113; LI T., 2008, P 2008 SIAM INT C DA; Li T, 2006, IEEE DATA MINING, P362; Li X., 2006, P CIKM 06, P238, DOI 10.1145/1183614.1183652; LIN C.-Y., 2003, P NLT NAACL C; LIU B, 2004, P SIGKDD C; LIU X, 2001, P SIGIR C; Makkonen J, 2004, INFORM RETRIEVAL, V7, P347, DOI 10.1023/B:INRT.0000011210.12953.86; Mani I., 1999, Information Retrieval, V1, DOI 10.1023/A:1009930203452; Mani I., 2001, AUTOMATIC SUMMARIZAT; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; Mihalcea R., 2005, P IJCNLP; Morinaga S., 2004, P 10 ACM SIGKDD INT, P811, DOI 10.1145/1014052.1016919; NEICKOVA A., 2007, T SPEECH LANG PROCES, V4, P2; Ning H., 2007, P SIAM DAT MIN C; Ou S., 2007, P INT C REC ADV NAT, P442; Paul M. J., 2010, P C EMP METH NAT LAN, P66; Petersen K. B., 2006, MATRIX COOKBOOK VERS; Radev DR, 2004, INFORM PROCESS MANAG, V40, P919, DOI 10.1016/j.ipm.2003.10.006; Shen C., 2010, P 23 INT C COMP LING, P984; Shen D., 2007, P 20 INT JOINT C ART, P2862; Wan X., 2008, P 31 ANN INT SIGIR C; Wang D., 2008, P 31 ANN INT ACM SIG, P307, DOI 10.1145/1390334.1390387; Wang D., 2009, P 18 ACM C INF KNOWL, P1963, DOI 10.1145/1645953.1646276; Wang Dengting, 2009, Proceedings of the 5th International Conference on Asian and Pacific Coasts. APAC 2009, DOI 10.3115/1667583.1667675; WANG D., 2008, P SIGIR C; Wang DD, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P809; Yang Y, 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953; Yu B, 2004, P SIGKDD C; Yu K., 2006, P ICML C; Zhang K., 2007, P SIGIR 2007, P215, DOI 10.1145/1277741.1277780; Zhang Y, 2002, P 25 ANN INT ACM SIG, P81; Zhao Q., 2007, P 22 NAT C ART INT, V2, P1501; Zhu SH, 2010, IEEE ACM T COMPUT BI, V7, P25, DOI 10.1109/TCBB.2008.35	53	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2012	6	3							12	10.1145/2362383.2362386		18	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	030HB	WOS:000310560600003	
J	Wang, ZX; Chan, LW				Wang, Zhenxing; Chan, Laiwan			Learning Bayesian Networks from Markov Random Fields: An Efficient Algorithm for Linear Models	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Bayesian networks; causal modeling; graphical models	PROBABILISTIC NETWORKS; DISCOVERY; INDUCTION	Dependency analysis is a typical approach for Bayesian network learning, which infers the structures of Bayesian networks by the results of a series of conditional independence (CI) tests. In practice, testing independence conditioning on large sets hampers the performance of dependency analysis algorithms in terms of accuracy and running time for the following reasons. First, testing independence on large sets of variables with limited samples is not stable. Second, for most dependency analysis algorithms, the number of CI tests grows at an exponential rate with the sizes of conditioning sets, and the running time grows of the same rate. Therefore, determining how to reduce the number of CI tests and the sizes of conditioning sets becomes a critical step in dependency analysis algorithms. In this article, we address a two-phase algorithm based on the observation that the structures of Markov random fields are similar to those of Bayesian networks. The first phase of the algorithm constructs a Markov random field from data, which provides a close approximation to the structure of the true Bayesian network; the second phase of the algorithm removes redundant edges according to CI tests to get the true Bayesian network. Both phases use Markov blanket information to reduce the sizes of conditioning sets and the number of CI tests without sacrificing accuracy. An empirical study shows that the two-phase algorithm performs well in terms of accuracy and efficiency.	[Wang, Zhenxing; Chan, Laiwan] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China	Wang, ZX (reprint author), Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.	zxwang@cse.cuhk.edu.hk			Research Grants Council of the Hong Kong Special Administration Region, China	The work described in this article was partially supported by a grant from the Research Grants Council of the Hong Kong Special Administration Region, China.	AGOGINO A. M., 1989, P UAI, P295; ALIFERIS C. F., 2010, J MACHINE LEARN RES, P11; Andreassen S, 1996, ELECTROMYOGR MOTOR C, V101, P129, DOI 10.1016/0924-980X(95)00252-G; Arnold A, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P66; Beinlich I. A., 1989, P 2 EUR C ART INT ME, V38, P247; Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Bollen K. A., 1989, STRUCTURAL EQUATIONS; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Chickering D. M., 1996, LEARNING DATA ARTIFI, P121; Chickering DM, 2004, J MACH LEARN RES, V5, P1287; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cussens J, 2011, P P 27 C ANN C UNC A, P153; Duncan O, 1975, INTRO STRUCTURAL EQU; Fox J., 1984, WILEY SERIES PROBABI; Glymour C., 1999, COMPUTATION CAUSATIO; HECKERMAN D., 1995, MACH LEARN, P20; Hoyer P. O., 2008, P UAI, P282; HYVRINEN A., 2008, P ICML, P424; Jensen A., 1996, P 12 ANN C UNC ART I, P349; KOIVISTO M., 2006, P 22 C UNC ART INT U, P241; Koivisto M, 2004, J MACH LEARN RES, V5, P549; Kristensen K, 2002, COMPUT ELECTRON AGR, V33, P197, DOI 10.1016/S0168-1699(02)00007-8; LAURITZEN SL, 1990, NETWORKS, V20, P491, DOI 10.1002/net.3230200503; MARGARITIS D., 2005, P 20 NAT C ART INT; Margaritis D, 2000, ADV NEUR IN, V12, P505; MARGARITIS D., 2001, P 17 C UNC ART INT; ORDYNIAK S., 2010, P UAI 2010 26 C UNC, P401; Parviainen P, 2009, P 25 C UNC ART INT U, P436; Pearl J., 1991, P 2 INT C PRINC KNOW; Pellet JP, 2008, J MACH LEARN RES, V9, P1295; RAMSEY J., 2006, P UAI; RICHARD J., 2002, APPL MULTIVARIATE ST; Scheines R., 1993, CAUSATION PREDICTION; Shimizu S, 2006, J MACH LEARN RES, V7, P2003; Spirtes P., 1991, Social Science Computer Review, V9, DOI 10.1177/089443939100900106; SPIRTES P., 1990, P ADV COMP SOC SCI; TOMAH J., 2010, P 13 INT C ART INT S, P358; Tsamardinos I, 2003, P 9 ACM SIGKDD INT C, P673, DOI DOI 10.1145/956750.956838; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; WANG Z., 2009, P INT DAT ENG AUT LE, P234; Wang Z.X., 2010, P KDD, P1109, DOI 10.1145/1835804.1835944; WERMUTH N, 1983, BIOMETRIKA, V70, P537, DOI 10.2307/2336490; [Anonymous], 2005, P AAAI, P825; [Anonymous], 2001, P UAI, P346	44	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2012	6	3							10	10.1145/2362383.2362384		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	030HB	WOS:000310560600001	
J	Gunopulos, D; Malerba, D; Vazirgiannis, M				Gunopulos, Dimitrios; Malerba, Donato; Vazirgiannis, Michalis			Guest Editors' Introduction: special issue of selected papers from ECML PKDD 2011	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Malerba, Donato] Univ Bari Aldo Moro, Dipartimento Informat, I-70125 Bari, Italy; [Gunopulos, Dimitrios] Univ Athens, Athens 15784, Greece; [Vazirgiannis, Michalis] Athens Univ Econ & Business, Athens 11257, Greece	Malerba, D (reprint author), Univ Bari Aldo Moro, Dipartimento Informat, Via Orabona 4, I-70125 Bari, Italy.	dg@di.uoa.gr; donato.malerba@uniba.it; mvazirg@aueb.gr					Gunnemann X, 2012, DATA MIN KNOWL DISC, V25, DOI [10.1007/s10618-012-0272-z, DOI 10.1007/S10618-012-0272-Z]; Gunopulos D., 2011, LECT NOTES COMPUTER, V6911; Gunopulos D., 2011, LECT NOTES COMPUTER, V6912; Gunopulos D., 2011, LECT NOTES COMPUTER, V6913; Narita A, 2012, DATA MIN KNOWL DISC, V25, P298, DOI 10.1007/s10618-012-0280-z; Severyn A, 2012, DATA MIN KNOWL DISC, V25, P325, DOI 10.1007/s10618-012-0276-8; Sra S, 2012, DATA MIN KNOWL DISC, V25, P358, DOI 10.1007/s10618-012-0277-7; Stojanova D, 2012, DATA MIN KNOWL DISC, V25, P378, DOI 10.1007/s10618-012-0278-6; Tatti N, 2012, DATA MIN KNOWL DISC, V25, P173, DOI 10.1007/s10618-012-0275-9; van Leeuwen M, 2012, DATA MIN KNOWL DISC, V25, P208, DOI 10.1007/s10618-012-0273-y; Zhuang HL, 2012, DATA MIN KNOWL DISC, V25, P270, DOI 10.1007/s10618-012-0274-x	11	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		169	172		10.1007/s10618-012-0282-x		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000001	
J	Tatti, N; Vreeken, J				Tatti, Nikolaj; Vreeken, Jilles			Comparing apples and oranges: measuring differences between exploratory data mining results	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Exploratory data mining; Distance; Maximum entropy model; Iterative data mining; Tiling; Binary data		Deciding whether the results of two different mining algorithms provide significantly different information is an important, yet understudied, open problem in exploratory data mining. Whether the goal is to select the most informative result for analysis, or to decide which mining approach will most likely provide the most novel insight, it is essential that we can tell how different the information is that different results by possibly different methods provide. In this paper we take a first step towards comparing exploratory data mining results on binary data. We propose to meaningfully convert results into sets of noisy tiles, and compare between these sets by maximum entropy modelling and Kullback-Leibler divergence, well-founded notions from Information Theory. We so construct a measure that is highly flexible, and allows us to naturally include background knowledge, such that differences in results can be measured from the perspective of what a user already knows. Furthermore, adding to its interpretability, it coincides with Jaccard dissimilarity when we only consider exact tiles. Our approach provides a means to study and tell differences between results of different exploratory data mining methods. As an application, we show that our measure can also be used to identify which parts of results best redescribe other results. Furthermore, we study its use for iterative data mining, where one iteratively wants to find that result that will provide maximal novel information. Experimental evaluation shows our measure gives meaningful results, correctly identifies methods that are similar in nature, automatically provides sound redescriptions of results, and is highly applicable for iterative data mining.	[Tatti, Nikolaj; Vreeken, Jilles] Univ Antwerp, Dept Math & Comp Sci, Adv Database Res & Modelling, B-2020 Antwerp, Belgium	Tatti, N (reprint author), Univ Antwerp, Dept Math & Comp Sci, Adv Database Res & Modelling, B-2020 Antwerp, Belgium.	nikolaj.tatti@ua.ac.be; jilles.vreeken@ua.ac.be			Post-Doctoral Fellowship of the Research Foundation-Flanders (FWO)	The authors wish to thank, in alphabetical order: Tijl De Bie for his information-theoretic noisy tile miner (De Bie 2011b); David Fuhry for his implementation of Hyper (Xiang et al. 2011); Matthijs van Leeuwen for major contributions to the implementation of KRIMP (Vreeken et al. 2011); Stijn Ligot for running experiments with PROCLUS (Aggarwal et al. 1999; Muller et al. 2009); Michael Mampaey for the implementations of Attribute Clustering (Mampaey and Vreeken 2010, 2012) as well as MTV (Mampaey et al. 2012); Pauli Miettinen for his implementation of ASSO (Miettinen 2008); Nikolaj Tatti and Jilles Vreeken are both supported by a Post-Doctoral Fellowship of the Research Foundation-Flanders (FWO).	Aggarwal C., 1999, P 1999 ACM SIGMOD IN, P61, DOI 10.1145/304182.304188; Agrawal R., 1994, P 20 INT C VER LARG, P487; Cover T.M., 2006, ELEMENTS INFORM THEO; CSISZAR I, 1975, ANN PROBAB, V3, P146, DOI 10.1214/aop/1176996454; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; De Bie T, 2011, P 17 ACM INT C KNOWL; De Bie T, 2011, DATA MIN KNOWL DISC, V23, P1; Fortelius M, 2006, PALEOBIOLOGY, V32, P206, DOI 10.1666/04087.1; Gallo A, 2008, P 8 SIAM INT C DAT M; Garriga GC, 2011, KNOWL INF SYST, V28, P197, DOI 10.1007/s10115-010-0319-7; Geerts F, 2004, LECT NOTES COMPUT SC, V3245, P278; Gionis A, 2004, LECT NOTES ARTIF INT, V3202, P173; Hanhijarvi S., 2009, P 15 ACM SIGKDD INT, P379, DOI 10.1145/1557019.1557065; Hollmen J, 2003, P 3 SIAM INT C DAT M; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; Knobbe AJ, 2006, LECT NOTES ARTIF INT, V4213, P577; Kontonasios KN, 2010, P 10 SIAM INT C DAT, P153; Kontonasios KN, 2011, P 11 IEEE INT C DAT; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; MacQueen J.B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Mampaey M, 2010, P EUR C MACH LEARN P, P321; Mampaey M, 2012, DATA MIN KN IN PRESS; Mampaey M, 2012, ACM T KNOWL IN PRESS; Mannila H, 2007, P 13 ACM SIGKDD INT, P489; Miettinen P, 2008, IEEE T KNOWL DATA EN, V20, P1348, DOI 10.1109/TKDE.2008.53; Miettinen P, 2008, INFORM PROCESS LETT, V108, P219, DOI 10.1016/j.ipl.2008.05.007; Mitchell-Jones A.J., 1999, ATLAS EUROPEAN MAMMA; Muller E, 2009, P 35 INT C VER LARG, P1270; Myllykangas S, 2006, ONCOGENE, V25, P7324, DOI 10.1038/sj.onc.1209717; Pensa RG, 2005, LECT NOTES ARTIF INT, V3721, P643; Puolamaki K, 2008, INFORM PROCESS LETT, V108, P45, DOI 10.1016/j.ipl.2008.03.013; Ramakrishnan N., 2004, P 10 ACM SIGKDD INT, P266, DOI 10.1145/1014052.1014083; Rasch G., 1960, PROBABILISTIC MODELS; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Siebes A, 2006, P SIAM C DAT MIN, P393; Tatti N, 2007, J MACH LEARN RES, V8, P131; Tatti N, 2011, P EUR C MACH LEARN P, P398; Tatti N, 2006, INFORM PROCESS LETT, V98, P183, DOI 10.1016/j.ipl.2006.02.003; VREEKEN J, 2007, P KDD 07, P765, DOI 10.1145/1281192.1281274; Vreeken J, 2011, DATA MIN KNOWL DISC, V23, P169, DOI 10.1007/s10618-010-0202-x; Wang C, 2006, P 12 ACM SIGKDD INT, P730, DOI 10.1145/1150402.1150495; Xiang Y, 2011, DATA MIN KNOWL DISC, V23, P215, DOI 10.1007/s10618-010-0203-9; Zaki M.J., 2005, P 11 ACM SIGKDD INT, P364, DOI DOI 10.1145/1081870.1081912	43	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		173	207		10.1007/s10618-012-0275-9		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000002	
J	van Leeuwen, M; Knobbe, A				van Leeuwen, Matthijs; Knobbe, Arno			Diverse subgroup set discovery	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Subgroup set discovery; Exceptional model mining; Pattern selection; Heuristic search; Diversity	PATTERN; ALGORITHM; SEARCH	Large data is challenging for most existing discovery algorithms, for several reasons. First of all, such data leads to enormous hypothesis spaces, making exhaustive search infeasible. Second, many variants of essentially the same pattern exist, due to (numeric) attributes of high cardinality, correlated attributes, and so on. This causes top-k mining algorithms to return highly redundant result sets, while ignoring many potentially interesting results. These problems are particularly apparent with subgroup discovery (SD) and its generalisation, exceptional model mining. To address this, we introduce subgroup set discovery: one should not consider individual subgroups, but sets of subgroups. We consider three degrees of redundancy, and propose corresponding heuristic selection strategies in order to eliminate redundancy. By incorporating these (generic) subgroup selection methods in a beam search, the aim is to improve the balance between exploration and exploitation. The proposed algorithm, dubbed DSSD for diverse subgroup set discovery, is experimentally evaluated and compared to existing approaches. For this, a variety of target types with corresponding datasets and quality measures is used. The subgroup sets that are discovered by the competing methods are evaluated primarily on the following three criteria: (1) diversity in the subgroup covers (exploration), (2) the maximum quality found (exploitation), and (3) runtime. The results show that DSSD outperforms each traditional SD method on all or a (non-empty) subset of these criteria, depending on the specific setting. The more complex the task, the larger the benefit of using our diverse heuristic search turns out to be.	[van Leeuwen, Matthijs] Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium; [van Leeuwen, Matthijs] Univ Utrecht, Fac Sci, Dept Informat & Comp Sci, Utrecht, Netherlands; [Knobbe, Arno] Leiden Univ, Leiden Inst Adv Comp Sci, Leiden, Netherlands	van Leeuwen, M (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium.	matthijs.vanleeuwen@cs.kuleuven.be; knobbe@liacs.nl			Netherlands Organisation for Scientific Research (NWO) through the EMM project [612.065.822]; Rubicon grant	The authors wish to thank Antti Ukkonen for sharing the Finnish elections data. This research is financially supported by the Netherlands Organisation for Scientific Research (NWO) through the EMM project (number 612.065.822) and a Rubicon grant.	Abudawood T, 2009, LECT NOTES ARTIF INT, V5781, P35; Atzmuller M, 2009, P ISMIS 09 PRAG, P35; Aumann Y., 1999, P 5 ACM SIGKDD INT C, P261, DOI 10.1145/312129.312243; Bailey J, 2007, IEEE INT C DAT MIN I; Bay SD, 2001, DATA MIN KNOWL DISC, V5, P213, DOI 10.1023/A:1011429418057; Bringmann B, 2007, IEEE DATA MINING, P63; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cover T.M., 2006, ELEMENTS INFORM THEO; Daly O., 2005, ENCY INFORM SCI TECH, P1144; Dong GZ, 1999, LECT NOTES ARTIF INT, V1721, P30; Duivesteijn W, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.53; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; Garriga GC, 2008, J MACH LEARN RES, V9, P559; Grosskreutz H, 2010, LECT NOTES ARTIF INT, V6332, P57, DOI 10.1007/978-3-642-16184-1_5; Grosskreutz H, 2011, P ECML PKDD 11 ATH, P533; Grosskreutz H, 2009, DATA MIN KNOWL DISC, V19, P210, DOI 10.1007/s10618-009-0136-3; Grosskreutz H, 2008, LECT NOTES ARTIF INT, V5211, P440, DOI 10.1007/978-3-540-87479-9_47; Grunwald P. D., 2007, MINIMUM DESCRIPTION; Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1; Heikinheimo H, 2007, J BIOGEOGR, V34, P1053, DOI 10.1111/j.1365-2699.2006.01664.x; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, P249; Klosgen W., 2002, HDB DATA MINING KNOW; Knobbe A, 2009, P ECML PKDD 09 WORKS, P77; Knobbe A. J., 2006, MULTIRELATIONAL DATA; Knobbe AJ, 2006, P 13 ACM SIGKDD INT, P237, DOI 10.1145/1150402.1150431; Knobbe AJ, 2006, LECT NOTES ARTIF INT, V4213, P577; Kocev D, 2007, LECT NOTES COMPUT SC, V4747, P134; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lavrac N, 2004, J MACH LEARN RES, V5, P153; Leman D, 2008, LECT NOTES ARTIF INT, V5212, P1, DOI 10.1007/978-3-540-87481-2_1; Lemmerich F, 2011, P ICDM 11 VANC; Lemmerich F, 2010, P FLAIRS DAYT BEACH; Liu B., 2001, P 7 ACM SIGKDD INT C, P335, DOI 10.1145/502512.502561; Lowerre B.T., 1976, THESIS; Mannila H., 1996, P 2 INT C KNOWL DISC, P189; Mitchell-Jones A.J., 1999, ATLAS EUROPEAN MAMMA; Morishita S., 2000, P 19 ACM SIGACT SIGM, P226, DOI 10.1145/335168.335226; NIJSSEN S, 2009, P 15 ACM SIGKDD INT, P647, DOI 10.1145/1557019.1557092; Novak PK, 2009, J MACH LEARN RES, V10, P377; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Pieters B., 2010, P PREF LEARN WORKSH; SHELL P, 1994, AAAI, P1323; Tsoumakas G., 2010, MULAN JAVA LIB MULTI; van Leeuwen M, 2010, DATA MIN KNOWL DISC, V21, P259, DOI [10.1007/s10618-010-0187-5, 10.1007/s10618-010-0186-6]; van Leeuwen M, 2011, P ECML PKDD 11 BLED, P459; Vreeken J, 2011, DATA MIN KNOWL DISC, V23, P169, DOI 10.1007/s10618-010-0202-x; Webb G. I., 2003, P 9 ACM SIGKDD INT C, P256; Webb GI, 1995, J ARTIF INTELL RES, V3, P431; Webb G. I., 2001, P 7 ACM SIGKDD INT C, P383, DOI 10.1145/502512.502569; Wrobel S, 1997, LECT NOTES ARTIF INT, V1263, P78; Yan X., 2002, P 2002 IEEE INT C DA, P721	53	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		208	242		10.1007/s10618-012-0273-y		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000003	
J	Gunnemann, S; Boden, B; Seidl, T				Guennemann, Stephan; Boden, Brigitte; Seidl, Thomas			Finding density-based subspace clusters in graphs with feature vectors	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph clustering; Dense subgraphs; Networks	HIGH-DIMENSIONAL DATA	Data sources representing attribute information in combination with network information are widely available in today's applications. To realize the full potential for knowledge extraction, mining techniques like clustering should consider both information types simultaneously. Recent clustering approaches combine subspace clustering with dense subgraph mining to identify groups of objects that are similar in subsets of their attributes as well as densely connected within the network. While those approaches successfully circumvent the problem of full-space clustering, their limited cluster definitions are restricted to clusters of certain shapes. In this work we introduce a density-based cluster definition, which takes into account the attribute similarity in subspaces as well as a local graph density and enables us to detect clusters of arbitrary shape and size. Furthermore, we avoid redundancy in the result by selecting only the most interesting non-redundant clusters. Based on this model, we introduce the clustering algorithm DB-CSC, which uses a fixed point iteration method to efficiently determine the clustering solution. We prove the correctness and complexity of this fixed point iteration analytically. In thorough experiments we demonstrate the strength of DB-CSC in comparison to related approaches.	[Guennemann, Stephan; Boden, Brigitte; Seidl, Thomas] Rhein Westfal TH Aachen, Data Management & Data Explorat Grp, Aachen, Germany	Gunnemann, S (reprint author), Rhein Westfal TH Aachen, Data Management & Data Explorat Grp, Aachen, Germany.	guennemann@cs.rwth-aachen.de; boden@cs.rwth-aachen.de; seidl@cs.rwth-aachen.de			UMIC Research Centre; RWTH Aachen University, Germany; B-IT Research School of the Bonn-Aachen International Center for Information Technology	This work has been supported by the UMIC Research Centre, RWTH Aachen University, Germany, and the B-IT Research School of the Bonn-Aachen International Center for Information Technology.	Aggarwal CC, 2010, ADV DATABASE SYST, V40, P1, DOI 10.1007/978-1-4419-6045-0; Agrawal R., 1998, SIGMOD 98, P94; Assent I., 2008, CIKM, P1093; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Dorogovtsev S, 2006, PHYS REV LETT, V96, P40; Du N., 2007, WEBKDD SNA KDD 07, P16; Ester M., 2006, SDM; Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining; Gunnemann S, 2010, SIAM SDM, P385; Gunnemann S., 2009, CIKM, P1317; Gunnemann S., 2011, ECML PKDD ECML ATH, P565; Gunnemann S, 2011, CIKM, P1363; Gunnemann S, 2010, ICDM, P845; Hinneburg A., 1998, KNOWLEDGE DISCOVERY, P58; Janson S, 2007, RANDOM STRUCT ALGOR, V30, P50, DOI 10.1002/rsa.20147; Kailing K, 2004, SIAM PROC S, P246; Kriegel H.P., 2009, ACM T KNOWL DISCOV D, V3, P1; Kubica J., 2003, ICDM, P573; Long B, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P470; Long B, 2006, KDD, P317; Moise G., 2008, KDD, P533; Moser F., 2009, SDM, P593; Muller E, 2009, IEEE DATA MINING, P377, DOI 10.1109/ICDM.2009.10; Muller E., 2009, VLDB, P1270; Parsons L., 2004, SIGKDD EXPLORATIONS, V6, P90, DOI DOI 10.1145/1007730.1007731; Pei J., 2005, KDD, P228; Ruan J, 2007, IEEE DATA MINING, P643; Ulitsky I, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-8; Zhou Y., 2010, ICDM, P689; Zhou Y., 2009, PVLDB, V2, P718; Zimmer R., 2002, BIOINFORMATICS, V18, P145	31	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		243	269		10.1007/s10618-012-0272-z		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000004	
J	Zhuang, HL; Tang, J; Tang, WB; Lou, TC; Chin, A; Wang, X				Zhuang, Honglei; Tang, Jie; Tang, Wenbin; Lou, Tiancheng; Chin, Alvin; Wang, Xia			Actively learning to infer social ties	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Social ties; Partially labeled; Factor graph model; Active learning; Influence maximization; Distributed learning	COMPLEX NETWORKS	We study the extent to which social ties between people can be inferred in large social network, in particular via active user interactions. In most online social networks, relationships are lack of meaning labels (e.g., "colleague" and "intimate friends") due to various reasons. Understanding the formation of different types of social relationships can provide us insights into the micro-level dynamics of the social network. In this work, we precisely define the problem of inferring social ties and propose a Partially-Labeled Pairwise Factor Graph Model (PLP-FGM) for learning to infer the type of social relationships. The model formalizes the problem of inferring social ties into a flexible semi-supervised framework. We test the model on three different genres of data sets and demonstrate its effectiveness. We further study how to leverage user interactions to help improve the inferring accuracy. Two active learning algorithms are proposed to actively select relationships to query users for their labels. Experimental results show that with only a few user corrections, the accuracy of inferring social ties can be significantly improved. Finally, to scale the model to handle real large networks, a distributed learning algorithm has been developed.	[Zhuang, Honglei; Tang, Jie; Tang, Wenbin] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; [Lou, Tiancheng] Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing 100084, Peoples R China; [Chin, Alvin; Wang, Xia] Nokia Res Ctr, Beijing, Peoples R China	Tang, J (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	zhl09@mails.tsinghua.edu.cn; jietang@tsinghua.edu.cn; tangwb06@gmail.com; tiancheng.lou@gmail.com; alvin.chin@nokia.com; Xia.S.wang@nokia.com			Natural Science Foundation of China [61073073, 60973102, 61170061]; Chinese National Key Foundation Research [60933013,, 61035004]; National Basic Research Program of China [2011CB302302]; Nokia Research Center	The work is supported by the Natural Science Foundation of China (No. 61073073, No. 60973102, No. 61170061), Chinese National Key Foundation Research (No. 60933013, No. 61035004), and National Basic Research Program of China (No. 2011CB302302). It is also supported by a research funding from Nokia Research Center.	Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47; Backstrom L., 2011, WSDM, P635; Bilgic M., 2010, ICML, P79; Califf M.E., 1999, AAAI 99 IAAI 99, P328; Cesa-Bianchi N., 2010, COLT, P320; Crandall DJ, 2010, P NATL ACAD SCI USA, V107, P22436, DOI 10.1073/pnas.1006155107; Diehl C. P., 2007, AAAI, P546; Domingos P., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Eagle N, 2008, SOCIAL COMPUTING, BEHAVIORAL MODELING AND PREDICTION, P79, DOI 10.1007/978-0-387-77672-9_10; Faloutsos M, 1999, COMP COMM R, V29, P251; Getoor L, 2007, INTRO STAT RELATIONA; Golovin D, 2010, ABS10103091 CORR; Grob R, 2009, GROUP 2009 PROCEEDINGS, P81; Hammersley J. M., 1971, MARKOV FIELD F UNPUB; Hopcroft J. E., 2011, CIKM 11; Karypis G., 1998, METIS UNSTRCTURED GR; Kempe D., 2003, KDD 03, P137; Kimura M, 2010, DATA MIN KNOWL DISC, V20, P70, DOI 10.1007/s10618-009-0150-5; Kleinberg J, 2005, DATA STREAM MANAGEMN; Krause A, 2009, J ARTIF INTELL RES, V35, P557; Kuwadekar A, 2011, P 28 INT C MACH LEAR, P385; Lafferty J, 2001, P 18 INT C MACH LEAR, P282; Leskovec J, 2010, WWW, P641; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; Martinez O, 2008, COMP VIS PATT REC WO, P1; Menon AK, 2010, ICDM, P364; Murphy K., 1999, UNCERTAINTY ARTIFICI, V9, P467; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Popescul A., 2003, IJCAI03 WORKSH LEARN, V149, P172; Roth M., 2010, KDD, P233; Roy N., 2001, ICML, P441; Settles B, 2008, EMNLP, P1070; Shi L, 2011, ACM T INTELLIGENT SY; Strogatz SH, 2001, NATURE, V410, P268, DOI 10.1038/35065725; Tan C., 2010, KDD, P1049; Tan C, 2011, KDD, P1397; Tang J., 2008, KDD, P990, DOI DOI 10.1145/1401890.1402008; Tang J, 2012, WSDM 12; Tang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P807; Tang L, 2011, DATA MIN KNOWL DISC, V23, P447, DOI 10.1007/s10618-010-0210-x; Tang W., 2011, ECML PKDD 11, P381; Taskar B., 2003, NIPS; Wang Ch., 2010, KDD, P203; Wang D., 2011, KDD, P1100; Yang Z., 2010, CIKM, P1633	45	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		270	297		10.1007/s10618-012-0274-x		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000005	
J	Narita, A; Hayashi, K; Tomioka, R; Kashima, H				Narita, Atsuhiro; Hayashi, Kohei; Tomioka, Ryota; Kashima, Hisashi			Tensor factorization using auxiliary information	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Tensors; Multi-way arrays; CP-decomposition; Tucker decomposition; Side information	MATRIX COMPLETION	Most of the existing analysis methods for tensors (or multi-way arrays) only assume that tensors to be completed are of low rank. However, for example, when they are applied to tensor completion problems, their prediction accuracy tends to be significantly worse when only a limited number of entries are observed. In this paper, we propose to use relationships among data as auxiliary information in addition to the low-rank assumption to improve the quality of tensor decomposition. We introduce two regularization approaches using graph Laplacians induced from the relationships, one for moderately sparse cases and the other for extremely sparse cases. We also give present two kinds of iterative algorithms for approximate solutions: one based on an EM-like algorithms which is stable but not so scalable, and the other based on gradient-based optimization which is applicable to large scale datasets. Numerical experiments on tensor completion using synthetic and benchmark datasets show that the use of auxiliary information improves completion accuracy over the existing methods based only on the low-rank assumption, especially when observations are sparse.	[Narita, Atsuhiro; Hayashi, Kohei; Tomioka, Ryota; Kashima, Hisashi] Univ Tokyo, Dept Math Informat, Bunkyo Ku, Tokyo 1138656, Japan; [Kashima, Hisashi] Synth Knowledge Informat Oriented Soc, Basic Res Programs PRESTO, Tokyo, Japan	Kashima, H (reprint author), Univ Tokyo, Dept Math Informat, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.	atsuhiro_narita@mist.i.u-tokyo.ac.jp; kohei_hayashi@mist.i.u-tokyo.ac.jp; tomioka@mist.i.u-tokyo.ac.jp; kashima@mist.i.u-tokyo.ac.jp					Acar E., 2010, P 2010 SIAM INT C DA, P701; Adams R.P., 2010, P 26 C UNC ART INT, P1; Banerjee A, 2007, P 2007 SIAM INT C DA; Cai D, 2010, IEEE T PATTERN ANAL, V33, P2026; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061; Chu W., 2009, P 12 INT C ART INT S; Collins M., 2002, ADV NEURAL INFORM PR, V14; Dunlavy DM, 2011, ACM T KNOWL DISCOV D, V5, DOI 10.1145/1921632.1921636; Gandy S, 2010, INVERSE PROBL, V27; Harshman RA, 1970, UCLA WORKING PAPERS, V16, P84; Hayashi K, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.39; Kashima H., 2009, P 2009 SIAM INT C DA; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; LI WJ, 2009, P IJCAI, P1126; Lu Z., 2009, P 3 ACM C REC SYST, P13, DOI 10.1145/1639714.1639719; Nishimori Y, 2005, NEUROCOMPUTING, V67, P106, DOI 10.1016/j.neucom.2004.11.035; Plumbley MD, 2005, NEUROCOMPUTING, V67, P161, DOI 10.1016/j.neucom.2004.11.040; Porteous I., 2010, P 24 AAAI C ART INT, P563; RENDLE S., 2010, P 3 ACM INT C WEB SE, P81, DOI 10.1145/1718487.1718498; SALAKHUTDINOV R., 2008, ADV NEURAL INFORM PR, V20; Shashua A., 2005, P 22 INT C MACH LEAR, P792, DOI 10.1145/1102351.1102451; Srebro N., 2005, ADV NEURAL INFORM PR, V17; Srebro N., 2004, THESIS MIT CAMBRIDGE; Tomioka R, 2012, ADV NEURAL INFORM PR, V24; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Walczak B, 2001, CHEMOMETR INTELL LAB, V58, P15, DOI 10.1016/S0169-7439(01)00131-9; Yu K., 2009, P 25 INT C MACH LEAR, P1185	28	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		298	324		10.1007/s10618-012-0280-z		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000006	
J	Severyn, A; Moschitti, A				Severyn, Aliaksei; Moschitti, Alessandro			Fast support vector machines for convolution tree kernels	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Kernel methods; Tree kernels; Natural language processing; Large scale learning		Feature engineering is one of the most complex aspects of system design in machine learning. Fortunately, kernel methods provide the designer with formidable tools to tackle such complexity. Among others, tree kernels (TKs) have been successfully applied for representing structured data in diverse domains, ranging from bioinformatics and data mining to natural language processing. One drawback of such methods is that learning with them typically requires a large number of kernel computations (quadratic in the number of training examples) between training examples. However, in practice substructures often repeat in the data which makes it possible to avoid a large number of redundant kernel evaluations. In this paper, we propose the use of Directed Acyclic Graphs (DAGs) to compactly represent trees in the training algorithm of Support Vector Machines. In particular, we use DAGs for each iteration of the cutting plane algorithm (CPA) to encode the model composed by a set of trees. This enables DAG kernels to efficiently evaluate TKs between the current model and a given training tree. Consequently, the amount of total computation is reduced by avoiding redundant evaluations over shared substructures. We provide theory and algorithms to formally characterize the above idea, which we tested on several datasets. The empirical results confirm the benefits of the approach in terms of significant speedups over previous state-of-the-art methods. In addition, we propose an alternative sampling strategy within the CPA to address the class-imbalance problem, which coupled with fast learning methods provides a viable TK learning framework for a large class of real-world applications.	[Severyn, Aliaksei; Moschitti, Alessandro] Univ Trent, Dept Comp Sci & Engn, I-38123 Povo, TN, Italy	Severyn, A (reprint author), Univ Trent, Dept Comp Sci & Engn, Via Sommarive 5, I-38123 Povo, TN, Italy.	severyn@disi.unitn.it; moschitti@disi.unitn.it			European Community [247758, 288024]	The research described in this paper has been partially supported by the European Community's Seventh Framework Programme (FP7/2007-2013) under the grants #247758: ETERNALS-Trustworthy Eternal Systems via Evolving Software, Data and Knowledge, and #288024: LIMOSINE-Linguistically Motivated Semantic aggregation engiNes.	Aiolli F., 2007, CIDM, P308; Aiolli F, 2006, IEEE DATA MINING, P787; Asai T, 2002, SDM; Bsdi R, 2011, MATH PROGRAMMING A; Cancedda N, 2003, J MACH LEARN RES, V3, P1059, DOI 10.1162/153244303322533197; Carreras X., 2005, P 9 C NAT LANG LEARN; Charniak E., 2000, ANLP, P132; Chi Y, 2004, SSDBM 2004, P11; Chi Y, 2005, IEEE T KNOWL DATA EN, V17, P190; Collins M., 2002, ACL02, P263; Denoyer L., 2007, SIGIR FORUM, V41, P79; Franc V., 2008, ICML, P320; Giuglea AM, 2006, P ACL SYDN AUSTR; Giuglea AM, 2004, P WORKSH ONT KNOWL D; Haussler D., 1999, UCSCCRL9910; Joachims T., 2005, INT C MACH LEARN ICM, P377; Joachims T, 2009, MACH LEARN, V76, P179, DOI 10.1007/s10994-009-5126-6; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Joachims T., 2006, KDD; Kate R.J., 2006, ACL; Kuang R, 2004, 3 INT IEEE COMP SOC, P152; Kudo T., 2003, P ACL 03; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Marcu D, 2004, P DUC BOST; Marcus M., 1994, COMPUTATIONAL LINGUI, V19, P313; Mehdad Y, 2010, HLT NAACL, P1020; Moschitti A, 2008, P CIKM 08 NEW YORK U; Moschitti A, 2006, P ECML; Moschitti A., 2006, EACL; Moschitti A, 2004, P ACL 04 BARC SPAIN; Moschitti A, 2004, HLT NAACL 2004 WORKS, P17; Moschitti A, 2008, COMPUT LINGUIST, V34, P193, DOI 10.1162/coli.2008.34.2.193; Nguyen TVT, 2011, P 5 INT JOINT C NAT, P732; Noreen EW, 1989, COMPUTER INTENSIVE M; Pado S., 2006, USERS GUIDE SIGF SIG; Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264; Pighin D, 2009, P 2009 C EMP METH NA, P111; Pighin D, 2010, P 14 C COMP NAT LANG, P223; Pighin D., 2009, P 13 C COMP NAT LANG, P30, DOI 10.3115/1596374.1596383; Rieck K, 2010, J MACH LEARN RES, V11, P555; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; Severyn A, 2011, ECML; Severyn A, 2010, ECML PKDD, P229; Shasha D, 2004, PROC INT CONF DATA, P708, DOI 10.1109/ICDE.2004.1320039; Shervashidze N, 2009, P ADV NEUR INF PROC; Shi QF, 2009, J MACH LEARN RES, V10, P2615; Steinwart I., 2003, J MACHINE LEARNING R, V4, P1071, DOI 10.1162/jmlr.2003.4.6.1071; Termier A., 2004, ICDM, P543; Trentimi F, 2006, IEEE IJCNN, P1805; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Veropoulos K, 1999, P INT JOINT C ART IN, P55; Versley Y, 2008, 22 INT C COMP LING C; Wang C, 2004, LECT NOTES ARTIF INT, V3056, P441; Wu G., 2003, ICML 2003 WORKSH LEA, P49; Yang LH, 2004, KDD, P731; Yu C.N.J., 2008, KDD, P794; Zadrozny B., 2003, P ICDM; Zaki MJ, 2005, IEEE T KNOWL DATA EN, V17, P1021, DOI 10.1109/TKDE.2005.125	58	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		325	357		10.1007/s10618-012-0276-8		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000007	
J	Sra, S				Sra, Suvrit			Fast projections onto mixed-norm balls with applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Mixed-norm; Group sparsity; Fast projection; Multitask learning; Matrix norms; Stochastic gradient	GRADIENT METHODS; THRESHOLDING ALGORITHM; VARIABLE SELECTION; CONVEX-SETS; SHRINKAGE; POINT	Joint sparsity offers powerful structural cues for feature selection, especially for variables that are expected to demonstrate a "grouped" behavior. Such behavior is commonly modeled via group-lasso, multitask lasso, and related methods where feature selection is effected via mixed-norms. Several mixed-norm based sparse models have received substantial attention, and for some cases efficient algorithms are also available. Surprisingly, several constrained sparse models seem to be lacking scalable algorithms. We address this deficiency by presenting batch and online (stochastic-gradient) optimization methods, both of which rely on efficient projections onto mixed-norm balls. We illustrate our methods by applying them to the multitask lasso. We conclude by mentioning some open problems.	Max Planck Inst Intelligent Syst, Tubingen, Germany	Sra, S (reprint author), Max Planck Inst Intelligent Syst, Tubingen, Germany.	suvrit@tuebingen.mpg.de					Bach F., 2010, ADV NEURAL INFORM PR; Bach F, 2012, OPTIMIZATION FOR MACHINE LEARNING, P19; Bach FR, 2008, J MACH LEARN RES, V9, P1179; BARZILAI J, 1988, IMA J NUMER ANAL, V8, P141, DOI 10.1093/imanum/8.1.141; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertsekas DP, 1999, NONLINEAR PROGRAMMIN, V2; Bhatia R., 1997, MATRIX ANAL; Birgin EG, 2000, SIAM J OPTIMIZ, V10, P1196, DOI 10.1137/S1052623497330963; Birgin EG, 2003, IMA J NUMER ANAL, V23, P539, DOI 10.1093/imanum/23.4.539; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Combettes P.L., 2010, ARXIV09123522V4; Dai YH, 2005, NUMER MATH, V100, P21, DOI 10.1007/s00211-004-0569-y; Donoho D., 2002, IEEE T INFORM THEORY, V41, P613; Duchi J, 2009, J MACH LEARN RES; Evgeniou T, 2004, SIGKDD, P109; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Friedman J., 2010, ARXIV10010736V1MATHS; FUKUSHIMA M, 1981, INT J SYST SCI, V12, P989, DOI 10.1080/00207728108963798; Horn R.A, 1991, TOPICS MATRIX ANAL; Jenatton R, 2010, INT C MACH LEARN ICM, P487; Kim D, 2010, INT C MACH LEARN ICM, P519; Kiwiel KC, 2007, J OPTIMIZ THEORY APP, V134, P549, DOI 10.1007/s10957-007-9259-0; Kowalski M, 2009, APPL COMPUT HARMON A, V27, P303, DOI 10.1016/j.acha.2009.05.006; Lewis A., 1995, J CONVEX ANAL, V2, P173; Liu H, 2009, ICML 09, P649; Liu J, 2010, NEURAL INFORM PROCES; Liu J., 2010, ARXIV10094766V1; Liu J., 2009, SLEP SPARSE LEARNING; Liu J, 2009, INT C MACH LEARN, P657; MAIRAL J., 2010, ADV NEURAL INFORM PR; MICHELOT C, 1986, J OPTIMIZ THEORY APP, V50, P195, DOI 10.1007/BF00938486; Obonzinski G, 2006, MBASASOFT GEDIT WIND; Patriksson M, 2005, MBASASOFT GEDIT WIND, V33; Polyak B. T., 1987, INTRO OPTIMIZATION; Quattoni A, 2009, INT C MACH LEARN ICM; Rakotomamonjy A, 2010, HAL00509608 INSA; Rice U., 2010, COMPRESSIVE SENSING; Rish I., 2010, SPARSE MODELING ICML; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; Schmidt M., 2011, ADV NEURAL INFORM PR; Schmidt M, 2009, ARTIFICIAL INTELLIGE; Simila T, 2007, COMPUT STAT DATA AN, V52, P406, DOI 10.1016/j.csda.2007.01.025; Sra S, 2011, EUR C MACH LEARN ECM; Tomioka R, 2012, OPTIMIZATION FOR MACHINE LEARNING, P255; Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031; Turlach BA, 2005, TECHNOMETRICS, V47, P349, DOI 10.1198/004017005000000139; van den Berg E., 2008, TR200809 U BRIT COL; Yuan M., 2004, 1095 U WISC DEP STAT; Zhang Y, 2010, NEURAL INFORM PROCES; Zhao P, 2009, ANN STAT, V37, P3468, DOI 10.1214/07-AOS584	50	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		358	377		10.1007/s10618-012-0277-7		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000008	
J	Stojanova, D; Ceci, M; Appice, A; Dzeroski, S				Stojanova, Daniela; Ceci, Michelangelo; Appice, Annalisa; Dzeroski, Saso			Network regression with predictive clustering trees	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Autocorrelation; Predictive clustering trees; Regression inference; Network data	SPATIAL AUTOCORRELATION; DEPENDENCE	Network data describe entities represented by nodes, which may be connected with (related to) each other by edges. Many network datasets are characterized by a form of autocorrelation, where the value of a variable at a given node depends on the values of variables at the nodes it is connected with. This phenomenon is a direct violation of the assumption that data are independently and identically distributed. At the same time, it offers an unique opportunity to improve the performance of predictive models on network data, as inferences about one entity can be used to improve inferences about related entities. Regression inference in network data is a challenging task. While many approaches for network classification exist, there are very few approaches for network regression. In this paper, we propose a data mining algorithm, called NCLUS, that explicitly considers autocorrelation when building regression models from network data. The algorithm is based on the concept of predictive clustering trees (PCTs) that can be used for clustering, prediction and multi-target prediction, including multi-target regression and multi-target classification. We evaluate our approach on several real world problems of network regression, coming from the areas of social and spatial networks. Empirical results show that our algorithm performs better than PCTs learned by completely disregarding network information, as well as PCTs that are tailored for spatial data, but do not take autocorrelation into account, and a variety of other existing approaches.	[Stojanova, Daniela; Dzeroski, Saso] Jozef Stefan Inst, Jozef Stefan Int Postgrad Sch, Dept Knowledge Technol, Ctr Excellence Integrated Approaches Chem & Biol, Ljubljana 1000, Slovenia; [Ceci, Michelangelo; Appice, Annalisa] Univ Bari Aldo Moro, Dipartimento Informat, I-70125 Bari, Italy	Stojanova, D (reprint author), Jozef Stefan Inst, Jozef Stefan Int Postgrad Sch, Dept Knowledge Technol, Ctr Excellence Integrated Approaches Chem & Biol, Jamova Cesta 39, Ljubljana 1000, Slovenia.	daniela.stojanova@ijs.si; ceci@di.uniba.it; appice@di.uniba.it; saso.dzeroski@ijs.si			Fondazione Cassa di Risparmio di Puglia; Italian Ministry of University and Research (MIUR); Slovenian Research Agency [P2-0103, J2-0734, J2-2285]; European Commission [HEALTH-2008-223451, ICT-2010-266722, ICT-2011-287713]; European Regional Development Fund [OP13.1.1.2.02.0005]; Slovenian Ministry of Higher Education, Science and Technology	This work is in partial fulfillment of the research objectives of the project "EMP3: Efficiency Monitoring of Photovoltaic Power Plants" funded by Fondazione Cassa di Risparmio di Puglia and the PRIN 2009 project "Learning Techniques in Relational Domains and Their Applications" funded by the Italian Ministry of University and Research (MIUR). Dzeroski is supported by the Slovenian Research Agency (Grants P2-0103, J2-0734, and J2-2285), the European Commission (Grants HEALTH-2008-223451, ICT-2010-266722, and ICT-2011-287713). He is also supported by Operation no. OP13.1.1.2.02.0005 financed by the European Regional Development Fund (85%) and the Slovenian Ministry of Higher Education, Science and Technology (15%). Stojanova is supported by the Slovenian Research Agency (Grant J2-2285). Thanks to Rich Davies for generating the MovieLens Dataset.	Aha D, 1991, MACHINE LEARNING J, V6; Angin P, 2008, IEEE DATA MINING, P707, DOI 10.1109/ICDM.2008.147; Antulov-Fantulin N, 2011, ECML PKDD 2011 DISC, P7; Appice A, 2009, LECT NOTES ARTIF INT, V5808, P36; Arthur G., 2008, GEOGR ANAL, V40, P297; BILGIC M., 2008, P 14 ACM SIGKDD INT, P43, DOI 10.1145/1401890.1401901; Blockeel H, 1998, P 15 INT C MACH LEAR, P55; Breiman L, 1984, CLASSIFICATION REGRE; Brent R. P., 1973, ALGORITHMS MINIMIZAT; Chuhay R, 2010, 2010118 FOND EN ENR; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Cortez P., 2007, P 13 EPIA 2007 PORT, P512; Cressie N.A.C., 1993, STAT SPATIAL DATA; Debeljak M, 2012, ECOL MODEL, V245, P75, DOI 10.1016/j.ecolmodel.2012.04.015; Demsar D., 2005, 90 ESA ANN M EC SOC, P152; Dubin RA, 1998, J HOUS ECON, V7, P304, DOI 10.1006/jhec.1998.0236; Dzeroski S, 2007, LECT NOTES COMPUT SC, V4747, P63; ENGLE RF, 1982, ECONOMETRICA, V50, P987, DOI 10.2307/1912773; Epperson BK, 2000, ECOL MODEL, V132, P63, DOI 10.1016/S0304-3800(00)00305-7; Fotheringham AS, 2002, GEOGRAPHICALLY WEIGH; Gallagher B, 2008, P 14 ACM SIGKDD INT, P256, DOI 10.1145/1401890.1401925; Ghimire J, 2008, NOVEL NODE CONNECTIV; Glotsos D, 2004, HELS UNIV TECHNOL S, V46, P296; Gora G, 2002, LECT NOTES ARTIF INT, V2430, P111; Grcar M, 2011, P 14 INT C DISC SCI, V6926, P107; Griffith D., 2003, ADV SPATIAL SCI; Hasan M. A., 2006, P SDM WORKSH LINK AN; Jahani S, 2011, INT S COMP NETW DIST, P136; Jensen D., 2004, P 10 ACM SIGKDD INT, P593, DOI 10.1145/1014052.1014125; Jin F, 2010, 20 ANN M MIDW EC GRO; Kwak H, 2010, P 19 INT C WORLD WID, P591, DOI DOI 10.1145/1772690.1772751; LEGENDRE P, 1993, ECOLOGY, V74, P1659, DOI 10.2307/1939924; LeSage JP, 2001, MASSIVE COMP, V2, P439; Li HF, 2007, GEOGR ANAL, V39, P357, DOI 10.1111/j.1538-4632.2007.00708.x; [李新宇 Li Xinyu], 2007, [现代制造工程, Modern Manufacturing Engineering], P1; Macskassy SA, 2007, J MACH LEARN RES, V8, P935; Macskassy S.A., 2007, P 22 AAAI C ART INT, P590; McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415; Michalski R. S., 1983, MACHINE LEARNING ART, P331; Namata G, 2008, AI MAG, V29, P3; Neville J, 2004, P WORKSH STAT REL LE, P290; Neville J, 2007, J MACH LEARN RES, V8, P653; Newman M, 2006, STRUCTURE DYNAMICS N; Orkin M., 1990, VITAL STAT; Pace P., 1997, GEOGR ANAL, V29, P232; Patranabis DC, 2007, NEURAL INF PROCESS L, V11, P203; Popescul A, 2003, P IJCAI WORKSH LEARN, P172; Quinlan R.J., 1993, C4 5 PROGRAMS MACHIN; Rahmani H, 2010, J MACH LEARN RES, V8, P82; Randic M, 1998, ACTA CHIM SLOV, V45, P239; Steinhaeuser Karsten, 2011, Statistical Analysis and Data Mining, V4, DOI 10.1002/sam.10100; Stojanova D, 2011, ECML PKDD, P333; Stojanova D, 2011, P 14 INT C DISC SCI, V6926, P307; Vapnik V. N., 1998, STAT LEARNING THEORY; Wang Y., 1997, P 9 EUR C MACH LEARN, P128; Weng J, 2010, P 3 ACM INT C WEB SE, P261, DOI DOI 10.1145/1718487.1718520; Witten IH, 2005, DATA MINING PRACTICA; Zhu X, 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663; Ziegler C.N., 2005, P 14 INT WORLD WID W, P22, DOI DOI 10.1145/1060745.1060754	59	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2012	25	2			SI		378	413		10.1007/s10618-012-0278-6		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	974MG	WOS:000306439000009	
J	Bhattacharya, I; Godbole, S; Joshi, S; Verma, A				Bhattacharya, Indrajit; Godbole, Shantanu; Joshi, Sachindra; Verma, Ashish			Cross-Guided Clustering: Transfer of Relevant Supervision across Tasks	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Multitask; transfer; cluster alignment		Lack of supervision in clustering algorithms often leads to clusters that are not useful or interesting to human reviewers. We investigate if supervision can be automatically transferred for clustering a target task, by providing a relevant supervised partitioning of a dataset from a different source task. The target clustering is made more meaningful for the human user by trading-off intrinsic clustering goodness on the target task for alignment with relevant supervised partitions in the source task, wherever possible. We propose a cross-guided clustering algorithm that builds on traditional k-means by aligning the target clusters with source partitions. The alignment process makes use of a cross-task similarity measure that discovers hidden relationships across tasks. When the source and target tasks correspond to different domains with potentially different vocabularies, we propose a projection approach using pivot vocabularies for the cross-domain similarity measure. Using multiple real-world and synthetic datasets, we show that our approach improves clustering accuracy significantly over traditional k-means and state-of-the-art semi-supervised clustering baselines, over a wide range of data characteristics and parameter settings.	[Bhattacharya, Indrajit] Indian Inst Sci, Bangalore, Karnataka, India; [Godbole, Shantanu; Joshi, Sachindra; Verma, Ashish] IBM Res India, New Delhi, India	Bhattacharya, I (reprint author), Indian Inst Sci, Bangalore, Karnataka, India.	indrajit@csa.iisc.ernet.in; shantanugodbole@in.ibm.com; jsachindra@in.ibm.com; vashish@in.ibm.com			Department of Science and Technology, Government of India [SR/S3/EECE/0064/2011(C)]	I. Bhattacharya is partly supported by Research Grant (SR/S3/EECE/0064/2011(C)) from the Department of Science and Technology, Government of India.	Argyriou A., 2006, ADV NEURAL INFORM PR; Basu S, 2002, P 19 INT C MACH LEAR, P27; Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Berkhin P., 2002, SURVEY CLUSTERING DA; Bhattacharya I, 2009, IEEE DATA MINING, P41, DOI 10.1109/ICDM.2009.33; Bhattacharya I, 2007, ACM T KNOWL DISCOV D, V1, P5, DOI 10.1145/1217299.1217304; Bilenko M., 2003, P 9 ACM SIGKDD INT C, P39; Blitzer J., 2007, BIOGRAPHIES BOLLYWOO; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; CARUANA R, 1993, P 10 INT C MACH LEAR, P41; Chen J., 2009, P ICML, P137; Dai W., 2008, P 25 INT C MACH LEAR, P200, DOI 10.1145/1390156.1390182; Dai W., 2009, P 26 ANN INT C MACH, P193; Dai WY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P210; Daume H, 2006, J ARTIF INTELL RES, V26, P101; Davidov D., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009036; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; EVGENIOU T., 2004, P 10 ACM SIGKDD INT, P109, DOI 10.1145/1014052.1014067; Finley T., 2005, P INT C MACH LEARN I, P217, DOI 10.1145/1102351.1102379; Gao J., 2008, P 14 ACM SIGKDD INT, P283, DOI 10.1145/1401890.1401928; Gu QQ, 2009, IEEE DATA MINING, P159, DOI 10.1109/ICDM.2009.32; KLEIN D., 2002, P INT C MACH LEARN I; Kuhn H., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Li T, 2007, IEEE DATA MINING, P577; Ling X, 2008, P 14 ACM SIGKDD INT, P488, DOI 10.1145/1401890.1401951; MICCHELLI C., 2004, ADV NEURAL INFORM PR; Pan SJ, 2008, P 23 AAAI C ART INT, P677; RAINA R., 2006, P INT C MACH LEARN I; Raina R., 2007, P 24 INT C MACH LEAR, P759, DOI 10.1145/1273496.1273592; Slonim N., 1999, ADV NEURAL INFORM PR; Slonim N, 2000, P 23 ANN INT ACM SIG, P208, DOI 10.1145/345508.345578; THRUN S., 1998, LEARNING LEARN, V1, P3; Wagstaff K., 2001, P 18 INT C MACH LEAR, P577; WANG F., 2008, P SIAM INT C DAT MIN; WU P., 2004, P 21 INT C MACH LEAR, P110	36	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2012	6	2							9	10.1145/2297456.2297461		28	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	989DP	WOS:000307540800005	
J	Das, S; Magdon-Ismail, M				Das, Sanmay; Magdon-Ismail, Malik			A Model for Information Growth in Collective Wisdom Processes	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Collective intelligence; social networks; dynamical systems		Collaborative media such as wikis have become enormously successful venues for information creation. Articles accrue information through the asynchronous editing of users who arrive both seeking information and possibly able to contribute information. Most articles stabilize to high-quality, trusted sources of information representing the collective wisdom of all the users who edited the article. We propose a model for information growth which relies on two main observations: (i) as an article's quality improves, it attracts visitors at a faster rate (a rich-get-richer phenomenon); and, simultaneously, (ii) the chances that a new visitor will improve the article drops (there is only so much that can be said about a particular topic). Our model is able to reproduce many features of the edit dynamics observed on Wikipedia; in particular, it captures the observed rise in the edit rate, followed by 1/t decay. Despite differences in the media, we also document similar features in the comment rates for a segment of the LiveJournal blogosphere.	[Das, Sanmay; Magdon-Ismail, Malik] Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12181 USA	Das, S (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12181 USA.	sanmay@cs.rpi.edu; magdon@cs.rpi.edu			National Science Foundation CAREER [IIS-0952918]; NSF [IIS-0621303, IIS-0522672, IIS-0324947, CNS-0323324, IIS-0634875]; U.S. ONR [N00014-06-1-0466]; US DHS through ONR [N00014-07-1-0150]; U.S. Army Research Laboratory [W911NF-09-2-0053]	This work is supported by a National Science Foundation CAREER award (IIS-0952918), by NSF grants IIS-0621303, IIS-0522672, IIS-0324947, CNS-0323324, IIS-0634875, by U.S. ONR Contract N00014-06-1-0466, and by US DHS through ONR grant N00014-07-1-0150 to Rutgers University. This research is continuing through participation in the Network Science Collaborative Technology Alliance sponsored by the U.S. Army Research Laboratory under Agreement Number W911NF-09-2-0053. The content of this article does not necessarily reflect the position or policy of the U.S. Government, no official endorsement should be inferred or implied.	Akoglu L, 2010, P MACH LEARN KNOWL D, P354; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Butler B, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1101; Capocci A, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036116; Faloutsos M, 1999, COMP COMM R, V29, P251; Giles J, 2005, NATURE, V438, P900, DOI 10.1038/438900a; GOTZ M., 2009, P INT C WEBL SOC MED, P26; Kittur A, 2007, P SIGCHI C HUM FACT, P453, DOI DOI 10.1145/1240624.1240698; Kumar R, 2004, COMMUN ACM, V47, P35, DOI 10.1145/1035134.1035162; Leskovec J, 2008, P 14 ACM SIGKDD INT, P462, DOI 10.1145/1401890.1401948; MAGDON-ISMAIL M., 2010, P ACM C EL COMM, P231, DOI 10.1145/1807342.1807380; Silva L, 2009, INFORM SYST J, V19, P55, DOI 10.1111/j.1365-2575.2008.00304.x; Spinellis D, 2008, COMMUN ACM, V51, P68, DOI 10.1145/1378704.1378720; SPOERRI A., 2007, 1 MONDAY, V12, P4; WILKINSON D. M., 2007, 1 MONDAY, V12, P4; Wu F, 2007, P NATL ACAD SCI USA, V104, P17599, DOI 10.1073/pnas.0704916104	16	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2012	6	2							6	10.1145/2297456.2297458		10	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	989DP	WOS:000307540800002	
J	Mavroeidis, D; Magdalinos, P				Mavroeidis, Dimitrios; Magdalinos, Panagis			A Sequential Sampling Framework for Spectral k-Means Based on Efficient Bootstrap Accuracy Estimations: Application to Distributed Clustering	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Asymptotic convergence; bootstrapping; clustering; distributed clustering; matrix perturbation theory; sampling; spectral	DATA STREAMS; ALGORITHMS; STABILITY	The scalability of learning algorithms has always been a central concern for data mining researchers, and nowadays, with the rapid increase in data storage capacities and availability, its importance has increased. To this end, sampling has been studied by several researchers in an effort to derive sufficiently accurate models using only small data fractions. In this article we focus on spectral k-means, that is, the k-means approximation as derived by the spectral relaxation, and propose a sequential sampling framework that iteratively enlarges the sample size until the k-means results (objective function and cluster structure) become indistinguishable from the asymptotic (infinite-data) output. In the proposed framework we adopt a commonly applied principle in data mining research that considers the use of minimal assumptions concerning the data generating distribution. This restriction imposes several challenges, mainly related to the efficiency of the sequential sampling procedure. These challenges are addressed using elements of matrix perturbation theory and statistics. Moreover, although the main focus is on spectral k-means, we also demonstrate that the proposed framework can be generalized to handle spectral clustering. The proposed sequential sampling framework is consecutively employed for addressing the distributed clustering problem, where the task is to construct a global model for data that resides in distributed network nodes. The main challenge in this context is related to the bandwidth constraints that are commonly imposed, thus requiring that the distributed clustering algorithm consumes a minimal amount of network load. This illustrates the applicability of the proposed approach, as it enables the determination of a minimal sample size that can be used for constructing an accurate clustering model that entails the distributional characteristics of the data. As opposed to the relevant distributed k-means approaches, our framework takes into account the fact that the choice of the number of clusters has a crucial effect on the required amount of communication. More precisely, the proposed algorithm is able to derive a statistical estimation of the required relative sizes for all possible values of k. This unique feature of our distributed clustering framework enables a network administrator to choose an economic solution that identifies the crude cluster structure of a dataset and not devote excessive network resources for identifying all the "correct" detailed clusters.	[Mavroeidis, Dimitrios] Radboud Univ Nijmegen, Nijmegen, Netherlands; [Magdalinos, Panagis] Univ Athens, Dept Informat & Telecommun, Fac Sci, Athens 15784, Greece	Mavroeidis, D (reprint author), Univ Nijmegen, Fac Sci, Postbus 9010, NL-6500 GL Nijmegen, Netherlands.	mavroeidis@cs.ru.nl; panagis@di.uoa.gr					AILON N., 2009, ADV NEURAL INFORM SY, V22, P10; Arai B, 2007, IEEE DATA MINING, P23; AWAN A., 2006, P 39 ANN HAW INT C S; Bai ZD, 1999, STAT SINICA, V9, P611; Bandyopadhyay S., 2003, P 22 ANN JOINT C IEE; Bandyopadhyay S, 2006, INFORM SCIENCES, V176, P1952, DOI 10.1016/j.ins.2005.11.007; BANERJEE A., 2002, P 2 SIAM INT C DAT M; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chung K. L., 1974, COURSE PROBABILITY T; Datta S, 2009, IEEE T KNOWL DATA EN, V21, P1372, DOI 10.1109/TKDE.2008.222; DATTA S., 2006, P 6 SIAM INT C DAT M; Dhillon IS, 2000, LECT NOTES ARTIF INT, V1759, P245, DOI 10.1007/3-540-46502-2_13; Ding C., 2004, P 21 INT C MACH LEAR; Domingo C, 2002, DATA MIN KNOWL DISC, V6, P131, DOI 10.1023/A:1014091514039; Domingos P, 2001, P 18 INT C MACH LEAR, P106; Drineas P, 1999, PROCEEDINGS OF THE TENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P291; Efron B., 1993, INTRO BOOTSTRAP; Forman G, 2000, SIGKDD EXPLORATIONS, V2, P34; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; GORDON A., 1977, BIOMETRICS; HAMMOUDA K. M., 2007, P 7 SIAM INT C DAT M; HUANG L., 2009, P 22 ANN C NEUR INF, P705; Januzaj E, 2004, LECT NOTES ARTIF INT, V3202, P231; Kargupta H, 2000, LECT NOTES COMPUT<D>, V1910, P452; Klusch M., 2003, P 18 INT JOINT C ART, P485; KRIEGEL H.-P., 2005, P ICDM, P258; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Mavroeidis D, 2008, IEEE DATA MINING, P462, DOI 10.1109/ICDM.2008.120; Mavroeidis D, 2010, KNOWL INF SYST, V23, P243, DOI 10.1007/s10115-009-0215-1; Mavroeidis D, 2007, LECT NOTES ARTIF INT, V4701, P226; Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275505; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Qi H., 2004, STAT DATA MINING KNO, P327; Scheffer T, 2003, J MACH LEARN RES, V3, P833, DOI 10.1162/jmlr.2003.3.4-5.833; SCHOLZ M., 2005, P 11 ACM SIGKDD INT, P265, DOI 10.1145/1081870.1081902; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Stewart G. W., 1990, MATRIX PERTURBATION; Tasoulis DK, 2004, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING AND NETWORKS, P347; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; von Luxburg U, 2008, ANN STAT, V36, P555, DOI 10.1214/009053607000000640; Wu JJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P877; YOUNIS O., 2004, P IEEE 23 ANN JOINT; Zha H., 2001, ADV NEURAL INFORM PR, V14, P1057; Zhang Q, 2008, PROC INT CONF DATA, P1131, DOI 10.1109/ICDE.2008.4497522; ZHOU A., 2007, P 23 INT C DAT ENG, P736	47	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2012	6	2							5	10.1145/2297456.2297457		37	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	989DP	WOS:000307540800001	
J	Wang, SJ; Schuurmans, D; Zhao, YX				Wang, Shaojun; Schuurmans, Dale; Zhao, Yunxin			The Latent Maximum Entropy Principle	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Maximum entropy; iterative scaling; expectation maximization; latent variable models; information geometry	EM ALGORITHM; MODELS; MINIMIZATION; LIKELIHOOD; FRAMEWORK; NETWORKS; GEOMETRY	We present an extension to Jaynes' maximum entropy principle that incorporates latent variables. The principle of latent maximum entropy we propose is different from both Jaynes' maximum entropy principle and maximum likelihood estimation, but can yield better estimates in the presence of hidden variables and limited training data. We first show that solving for a latent maximum entropy model poses a hard nonlinear constrained optimization problem in general. However, we then show that feasible solutions to this problem can be obtained efficiently for the special case of log-linear models-which forms the basis for an efficient approximation to the latent maximum entropy principle. We derive an algorithm that combines expectation-maximization with iterative scaling to produce feasible log-linear solutions. This algorithm can be interpreted as an alternating minimization algorithm in the information divergence, and reveals an intimate connection between the latent maximum entropy and maximum likelihood principles. To select a final model, we generate a series of feasible candidates, calculate the entropy of each, and choose the model that attains the highest entropy. Our experimental results show that estimation based on the latent maximum entropy principle generally gives better results than maximum likelihood when estimating latent variable models on small observed data samples.	[Wang, Shaojun] Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA; [Schuurmans, Dale] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; [Zhao, Yunxin] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA	Wang, SJ (reprint author), Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.						ACKLEY DH, 1985, COGNITIVE SCI, V9, P147, DOI 10.1016/S0364-0213(85)80012-4; Amari SI, 1995, NEURAL NETWORKS, V8, P1379, DOI 10.1016/0893-6080(95)00003-8; Amari S.-I., 2000, METHODS INFORM GEOME; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bertsekas D.P., 1999, NONLINEAR PROGRAMMIN; Blei DM, 2002, ADV NEUR IN, V14, P601; BYRNE W, 1992, IEEE T NEURAL NETWOR, V3, P612, DOI 10.1109/72.143375; Censor Y., 1997, PARALLEL OPTIMIZATIO; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; Cover T. M., 1991, ELEMENTS INFORM THEO; CSISZAR I, 1975, ANN PROBAB, V3, P146, DOI 10.1214/aop/1176996454; Csiszar I., 1984, STATISTICS DECISIO S, V1, P205; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Eisner J., 2002, P 40 ANN M ASS COMP, P1; Fang S., 1997, ENTROPY OPTIMIZATION; Fisher RA, 1936, ANN EUGENIC, V7, P179; Ganchev K, 2010, J MACH LEARN RES, V11, P2001; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Golan A., 1996, MAXIMUM ENTROPY ECON; Goodman J., 2002, P 40 ANN M ASS COMP, P9; GRACA J., 2007, ADV NEURAL INFORM PR; Hagenaars J. A., 1993, LOGLINEAR MODELS LAT; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Huang FL, 2010, J MACH LEARN RES, V11, P815; Jaakkola Tommi, 1999, ADV NEURAL INFORM PR, P470; Jaynes E. T., 1983, PAPERS PROBABILITY S; JEBARA T., 2000, THESIS MIT; Jelinek F., 1998, STAT METHODS SPEECH; Lafferty J, 2001, P 18 INT C MACH LEAR, P282; Lau R., 1993, P ICASSP, P45; LAURITZEN SL, 1995, COMPUT STAT DATA AN, V19, P191, DOI 10.1016/0167-9473(93)E0056-A; Lauritzen SL, 1996, GRAPHICAL MODELS; Little R.J.A., 2002, STAT ANAL MISSING DA; MacKay D., 1995, NAT LANG ENG, V1, P289; Malouf R., 2002, P 6 C NAT LANG LEARN, P49; MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.2307/2337198; MINKA T., 2003, COMP NUMERICAL 1169; RIEZLER S., 1999, THESIS U STUTTGART; RIEZLER S., 2000, P 38 ANN M ASS COMP; Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011; Wainwright MJ, 2003, IEEE T INFORM THEORY, V49, P1120, DOI 10.1109/TIT.2003.810642; WANG S., 2009, CONSISTENCY GEN BOUN; WANG S., 2001, P IEEE WORKSH AUT SP; WANG S., 2003, P 20 INT C MACH LEAR, P784; WANG S., 2003, P 19 C UNC ART INT U, P567; Wang SJ, 2005, MACH LEARN, V60, P229, DOI 10.1007/s10994-005-0928-7; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085; Zhu J, 2009, J MACH LEARN RES, V10, P2531; Zhu Jun, 2008, ADV NEURAL INFORM PR, P1977	52	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2012	6	2							8	10.1145/2297456.2297460		42	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	989DP	WOS:000307540800004	
J	Xu, TB; Zhang, ZF; Yu, PS; Long, B				Xu, Tianbing; Zhang, Zhongfei; Yu, Philip S.; Long, Bo			Generative Models for Evolutionary Clustering	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Evolutionary clustering; DPChain; HDP-HTM; iHMS; hierarchical transition matrix	NONPARAMETRIC PROBLEMS; DIRICHLET; MIXTURES	This article studies evolutionary clustering, a recently emerged hot topic with many important applications, noticeably in dynamic social network analysis. In this article, based on the recent literature on nonparametric Bayesian models, we have developed two generative models: DPChain and HDP-HTM. DPChain is derived from the Dirichlet process mixture (DPM) model, with an exponential decaying component along with the time. HDP-HTM combines the hierarchical dirichlet process (HDP) with a hierarchical transition matrix (HTM) based on the proposed Infinite hierarchical Markov state model (iHMS). Both models substantially advance the literature on evolutionary clustering, in the sense that not only do they both perform better than those in the existing literature, but more importantly, they are capable of automatically learning the cluster numbers and explicitly addressing the corresponding issues. Extensive evaluations have demonstrated the effectiveness and the promise of these two solutions compared to the state-of-the-art literature.	[Xu, Tianbing; Zhang, Zhongfei] SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA; [Zhang, Zhongfei] Zhejiang Univ, Dept Informat Sci & Elect Engn, Zhejiang Prov Key Lab Informat Network Technol, Hangzhou, Zhejiang, Peoples R China; [Yu, Philip S.] Univ Illinois, Dept Comp Sci, Chicago, IL USA; [Long, Bo] Yahoo Inc, Sunnyvale, CA USA	Xu, TB (reprint author), SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA.				NSF [IIS-0535162, IIS-0812114, CCF-1017828, IIS 0905215, IIS-0914934, DBI-0960443, OISE-0968341, CNS-1115234, OIA-0963278]; Google; National Basic Research Program of China [2012CB316400]	This work is supported in part by NSF (IIS-0535162, IIS-0812114, CCF-1017828, IIS 0905215, IIS-0914934, DBI-0960443, OISE-0968341, CNS-1115234, and OIA-0963278), Google Mobile 2014 Program, and National Basic Research Program of China (2012CB316400). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies.	ABOU-RJEILI A., 2006, PAR DISTR PROC S IPD; Ahmed A, 2009, P NATL ACAD SCI USA, V106, P11878, DOI 10.1073/pnas.0901910106; Aldous D., 1983, ECOLE ETE PROBABILIT, VXIII, P1; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; BEAL M. J., 2002, NIPS, V14; Bishop C. M., 2007, PATTERN RECOGNITION; BLACKWEL.D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blei D. M., 2006, P 23 INT C MACH LEAR; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boyd-Graber J., 2008, NEURAL INFORM PROCES; CASELLA G, 1992, AM STAT, V46, P167, DOI 10.2307/2685208; Chakrabarti D., 2006, P 12 ACM SIGKDD INT, P554, DOI 10.1145/1150402.1150467; Chi Y, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P153; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; GAEL J. V., 2008, P 25 INT C MACH LEAR; GHAHRAMANI Z., 2005, CMUCALD05104; Griffiths T. L., 2005, ADV NEURAL INFORM PR, P537; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Gruber A., 2007, ARTIFICIAL INTELLIGE; Heinrich G., 2004, PARAMETER ESTIMATION; ISHWARAN H., 2001, J AM STAT ASSOC, V96, P453; MacKay D., 1997, ENSEMBLE LEARNING HI; McCallum A, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P786; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Neal R M, 1993, CRGTR931; Ng A, 2002, NIPS, V14; Ni K., 2007, P 24 INT C MACH LEAR, P689, DOI 10.1145/1273496.1273583; PATHAK N., 2008, P 2 ACM WORKSH SOC N; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Scott JP, 2000, P 20 C UNC ART INT; SETHURAMAN J, 1994, STAT SINICA, V4, P639; SHI J., 2000, IEEE T PATTERN ANAL, V22, P8, DOI DOI 10.1109/34.868688; STREHL A., 2002, P AAAI; SUDDERTH E. B., 2007, DEV TEMPERED HDP HMM; Teh Y., 2007, J AM STAT ASSOC, V101, P1566; Teh Y. W., 2007, ENCY MACHINE LEARNIN; TRESP V., 2008, P 2 ACM WORKSH SOC N; Wallach H. M., 2006, P 23 INT C MACH LEAR, P977, DOI DOI 10.1145/1143844.1143967; WANG C., 2008, P 24 C UNC ART INT U; Wang X., 2006, P 12 ACM SIGKDD INT, P424, DOI 10.1145/1150402.1150450; Zhang HB, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE & ENGINEERING (14TH) VOLS 1-3, P663; ZHANG H., 2007, PEKING ARCH, P27; Zhang H., 2007, P IEEE INT C INT SEC, P200; ZHANG Z., 2008, P ICDM	48	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2012	6	2							7	10.1145/2297456.2297459		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	989DP	WOS:000307540800003	
J	Tang, L; Wang, XF; Liu, H				Tang, Lei; Wang, Xufei; Liu, Huan			Community detection via heterogeneous interaction analysis	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Community detection; Heterogeneous interactions; Network integration; Multi-dimensional networks; Social media	SOCIAL NETWORKS; SETS	The pervasiveness of Web 2.0 and social networking sites has enabled people to interact with each other easily through various social media. For instance, popular sites like Del.icio.us, Flickr, and YouTube allow users to comment on shared content (bookmarks, photos, videos), and users can tag their favorite content. Users can also connect with one another, and subscribe to or become a fan or a follower of others. These diverse activities result in a multi-dimensional network among actors, forming group structures with group members sharing similar interests or affiliations. This work systematically addresses two challenges. First, it is challenging to effectively integrate interactions over multiple dimensions to discover hidden community structures shared by heterogeneous interactions. We show that representative community detection methods for single-dimensional networks can be presented in a unified view. Based on this unified view, we present and analyze four possible integration strategies to extend community detection from single-dimensional to multi-dimensional networks. In particular, we propose a novel integration scheme based on structural features. Another challenge is the evaluation of different methods without ground truth information about community membership. We employ a novel cross-dimension network validation (CDNV) procedure to compare the performance of different methods. We use synthetic data to deepen our understanding, and real-world data to compare integration strategies as well as baseline methods in a large scale. We study further the computational time of different methods, normalization effect during integration, sensitivity to related parameters, and alternative community detection methods for integration.	[Tang, Lei] Yahoo Labs Silicon Valley, Santa Clara, CA 95054 USA; [Wang, Xufei; Liu, Huan] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA	Tang, L (reprint author), Yahoo Labs Silicon Valley, Santa Clara, CA 95054 USA.	L.Tang@asu.edu; Xufei.Wang@asu.edu; Huan.Liu@asu.edu			Air Force Office of Scientific Research (AFOSR); Office of Naval Research (ONR)	This work was, in part, supported by Air Force Office of Scientific Research (AFOSR) and Office of Naval Research (ONR) grants.	Abou-Rjeili A., 2006, P 20 INT C PAR DISTR, P124; Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; Aleman-Meza B., 2006, WWW, P407; Argyriou A., 2006, ADV NEURAL INFORM PR, V18, P67; Asur S, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P913; Backstrom L., 2006, P 12 ACM INT C SIGKD, P44; Bansal N, 2007, VLDB, P806; Bickel S, 2004, ICDM 04, P19; Borg I., 2005, MODERN MULTIDIMENSIO; Chaudhuri K, 2009, ICML 09, P1; Clauset A, 2007, 706 ARXIV, P706; Clauset A, 2004, CONDMAT0408187 ARXIV; de Sa V. R., 2005, P 22 INT C MACH LEAR, P20; DEMMEL J, 2000, TEMPLATES SOLUTION A; Fern X.Z., 2004, ICML 04, P36; Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Goder A, 2008, P WORKSH ALG ENG EXP; Good BH, 2010, PHYS REV E, V81, DOI 10.1103/PhysRevE.81.046106; Guimera R, 2005, NATURE, V433, P895, DOI 10.1038/nature03288; Hopcroft J, 2003, KDD 03, P541; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hu T, 2005, INTELL DATA ANAL, V9, P551; Jung JJ, 2007, LECT NOTES COMPUT SC, V4519, P267; Kang H, 2007, SIGKDD EXPLORATIONS, V9, P13; Kemp C., 1999, P NAT C ART INT, V21, P381; KETTENRI.JR, 1971, BIOMETRIKA, V58, P433, DOI 10.2307/2334380; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Lancichinetti A, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.056117; Leskovec J., 2010, WWW 10, P631; Lin YR, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1514888.1514891; Lin Y.-R., 2008, P 17 INT C WORLD WID, P685, DOI 10.1145/1367497.1367590; Lizorkin D, 2009, WWW 09, P1221, DOI DOI 10.1145/1526709.1526938; Long B., 2008, P SIAM INT C DAT MIN, P822; LUXBURG, 2007, STAT COMPUT, V17, P395; McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415; Mika P, 2007, J WEB SEMANT, V5, P5, DOI 10.1016/j.websem.2006.11.002; Miller K, 2009, ADV NEURAL INFORM PR, V22, P1276; Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487; Mucha PJ, 2010, SCIENCE, V328, P876, DOI 10.1126/science.1184819; Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103; Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104; Nguyen N, 2007, IEEE DATA MINING, P607; Palla G, 2007, NATURE, V446, P664, DOI 10.1038/nature05670; Richardson M., 2002, KDD 02, P61; Rosvall M, 2008, P NATL ACAD SCI USA, V105, P1118, DOI 10.1073/pnas.0706851105; Sarkar P., 2005, SIGKDD EXPLOR NEWSL, V7, P31; Specia L., 2007, P 4 EUR SEM WEB C ES, P624; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Tang L., 2009, CIKM 09, P1107, DOI [10.1145/1645953.1646094, DOI 10.1145/1645953.1646094]; Tang L, 2009, IEEE DATA MINING, P503, DOI 10.1109/ICDM.2009.20; Tang L, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P817; Tang L, 2008, KDD 08, P677, DOI DOI 10.1145/1401890.1401972; Tang W, 2009, IEEE DATA MINING, P1016, DOI 10.1109/ICDM.2009.125; Topchy Alexander P., 2003, ICDM 03, P331; Wasserman S, 1994, SOCIAL NETWORK ANAL; White S, 2005, SIAM PROC S, P274; Witten IH, 2005, DATA MINING PRACTICA; Yingzi Jin YM, 2008, WWW 08, P21; Yu K, 2005, ADV NEURAL INFORM PR, V18, P1553; Zhou D, 2008, WWW 08, P141; Zhou D., 2007, ICML 07, P1159, DOI DOI 10.1145/1273496.1273642	62	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2012	25	1					1	33		10.1007/s10618-011-0231-0		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LM	WOS:000302479100001	
J	Tatti, N; Cule, B				Tatti, Nikolaj; Cule, Boris			Mining closed strict episodes	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Frequent episode mining; Closed episodes; Level-wise algorithm	SEQUENTIAL PATTERNS; EVENT SEQUENCES; FREQUENT	Discovering patterns in a sequence is an important aspect of data mining. One popular choice of such patterns are episodes, patterns in sequential data describing events that often occur in the vicinity of each other. Episodes also enforce in which order the events are allowed to occur. In this work we introduce a technique for discovering closed episodes. Adopting existing approaches for discovering traditional patterns, such as closed itemsets, to episodes is not straightforward. First of all, we cannot define a unique closure based on frequency because an episode may have several closed superepisodes. Moreover, to define a closedness concept for episodes we need a subset relationship between episodes, which is not trivial to define. We approach these problems by introducing strict episodes. We argue that this class is general enough, and at the same time we are able to define a natural subset relationship within it and use it efficiently. In order to mine closed episodes we define an auxiliary closure operator. We show that this closure satisfies the needed properties so that we can use the existing framework for mining closed patterns. Discovering the true closed episodes can be done as a post-processing step. We combine these observations into an efficient mining algorithm and demonstrate empirically its performance in practice.	[Tatti, Nikolaj; Cule, Boris] Univ Antwerp, B-2020 Antwerp, Belgium	Tatti, N (reprint author), Univ Antwerp, B-2020 Antwerp, Belgium.	nikolaj.tatti@ua.ac.be; boris.cule@ua.ac.be			Research Foundation Flanders (FWO)	Nikolaj Tatti is supported by a Post-doctoral Fellowship of the Research Foundation Flanders (FWO).	Agrawal R., 1995, 11 INT C DAT ENG, P3; Agrawal R., 1994, P 20 INT C VER LARG, P487; Calders T, 2007, IEEE DATA MINING, P83; Casas-Garriga G, 2005, SIAM PROC S, P380; Casas-Garriga G, 2003, LECT NOTES ARTIF INT, V2838, P83; Cule B, 2009, P SIAM INT C DAT MIN, P317; Garofalakis M, 2002, IEEE T KNOWL DATA EN, V14, P530, DOI 10.1109/TKDE.2002.1000341; Gwadera R, 2005, KNOWL INF SYST, V7, P415, DOI 10.1007/s10115-004-0174-5; Gwadera R, 2005, SIAM PROC S, P404; LAXMAN S, 2007, P 13 ACM SIGKDD INT, P410, DOI 10.1145/1281192.1281238; Laxman S, 2006, SADHANA-ACAD P ENG S, V31, P173, DOI 10.1007/BF02719780; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Meger N, 2004, LECT NOTES COMPUTER, P313; Pasquier N, 1999, ICDT, P398; Pei J, 2006, IEEE T KNOWL DATA EN, V18, P1467, DOI 10.1109/TKDE.2006.172; Tatti N, 2010, P 10 IEEE INT C DAT; Tatti N, 2009, IEEE DATA MINING, P513, DOI 10.1109/ICDM.2009.23; Tzvekov P., 2003, P 3 IEEE INT C DAT M, P347; Wang J. T.-L., 1994, ACM SIGMOD REC, V23, P115, DOI 10.1145/191843.191863; Wang JY, 2004, PROC INT CONF DATA, P79, DOI 10.1109/ICDE.2004.1319986; Yan XF, 2003, SIAM PROC S, P166; Zhou W, 2010, P 14 PAC AS C KNOWL, V1, P310	22	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2012	25	1					34	66		10.1007/s10618-011-0232-z		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LM	WOS:000302479100002	
J	Achar, A; Laxman, S; Viswanathan, R; Sastry, PS				Achar, Avinash; Laxman, Srivatsan; Viswanathan, Raajay; Sastry, P. S.			Discovering injective episodes with general partial orders	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Episode mining; General partial order; Non-overlapped count; Bidirectional evidence	FREQUENT EPISODES; SPIKE TRAINS; SEQUENCES; PATTERNS	Frequent episode discovery is a popular framework for temporal pattern discovery in event streams. An episode is a partially ordered set of nodes with each node associated with an event type. Currently algorithms exist for episode discovery only when the associated partial order is total order (serial episode) or trivial (parallel episode). In this paper, we propose efficient algorithms for discovering frequent episodes with unrestricted partial orders when the associated event-types are unique. These algorithms can be easily specialized to discover only serial or parallel episodes. Also, the algorithms are flexible enough to be specialized for mining in the space of certain interesting subclasses of partial orders. We point out that frequency alone is not a sufficient measure of interestingness in the context of partial order mining. We propose a new interestingness measure for episodes with unrestricted partial orders which, when used along with frequency, results in an efficient scheme of data mining. Simulations are presented to demonstrate the effectiveness of our algorithms.	[Achar, Avinash; Sastry, P. S.] Indian Inst Sci, Bangalore 560012, Karnataka, India; [Laxman, Srivatsan; Viswanathan, Raajay] Microsoft Res, Bangalore, Karnataka, India	Achar, A (reprint author), Indian Inst Sci, Bangalore 560012, Karnataka, India.	achar.avinash@gmail.com; slaxman@microsoft.com; raajay.v@gmail.com; sastry@ee.iisc.ernet.in					Achar A, 2010, THESIS INDIAN I SCI; Achar A, 2009, ARXIV09021227V2CSAI; Agrawal R., 1995, P 11 INT C DAT ENG T; Bouqata B, 2006, LECT NOTES ARTIF INT, V4213, P42; Brown EN, 2004, NAT NEUROSCI, V7, P456, DOI 10.1038/nn1228; CASAS-GARRIGA G, 2005, P 2005 SIAM INT C DA; Casas-Garriga G, 2003, P 7 EUR C PRINC PRAC, P83; Diekman CO, 2009, J NEUROSCI METH, V182, P279, DOI 10.1016/j.jneumeth.2009.06.018; Hatonen K, 1996, PROC INT CONF DATA, P115, DOI 10.1109/ICDE.1996.492095; Iwanuma K, 2004, P 2004 IEEE C CYB IN, V1, P213; LAXMAN S, 2007, P 13 ACM SIGKDD INT, P410, DOI 10.1145/1281192.1281238; Laxman S, 2005, IEEE T KNOWL DATA EN, V17, P1505; Laxman S, 2007, IEEE T KNOWL DATA EN, V19, P1188, DOI [10.1109/TKDE.2007.1055, 10.1109/TKDE.2007.1055.]; Laxman S, 2008, P 14 ACM SIGKDD INT, P453, DOI 10.1145/1401890.1401947; Laxman S, 2006, THESIS INDIAN I SCI; Luo JX, 2000, INT J INTELL SYST, V15, P687, DOI 10.1002/1098-111X(200008)15:8<687::AID-INT1>3.0.CO;2-X; Mannila H., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347122; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Nag A, 2003, P 7 PAC AS C KNOWL D, P27; Patnaik D, 2008, SCI PROGRAMMING-NETH, V16, P49, DOI 10.3233/SPR-2008-0242; Pei J, 2006, IEEE T KNOWL DATA EN, V18, P1467, DOI 10.1109/TKDE.2006.172; Sastry PS, 2010, NEURAL COMPUT, V22, P1025, DOI 10.1162/neco.2009.12-08-928; Tatti N, 2010, P 2010 IEEE INT C DA; Tatti N, 2009, P 2009 IEEE INT C DA; Unnikrishnan KP, 2009, U.S. Patent, Patent No. 7509234; Wagenaar DA, 2006, BMS NEUROSCI; Wang J, 2004, 20 INT C DAT ENG BOS; Wang M-F, 2008, P 22 INT C ADV INF N, P1246	28	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2012	25	1					67	108		10.1007/s10618-011-0233-y		42	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LM	WOS:000302479100003	
J	Noto, K; Brodley, C; Slonim, D				Noto, Keith; Brodley, Carla; Slonim, Donna			FRaC: a feature-modeling approach for semi-supervised and unsupervised anomaly detection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Anomaly detection; Unsupervised learning		Anomaly detection involves identifying rare data instances (anomalies) that come from a different class or distribution than the majority (which are simply called "normal" instances). Given a training set of only normal data, the semi-supervised anomaly detection task is to identify anomalies in the future. Good solutions to this task have applications in fraud and intrusion detection. The unsupervised anomaly detection task is different: Given unlabeled, mostly-normal data, identify the anomalies among them. Many real-world machine learning tasks, including many fraud and intrusion detection tasks, are unsupervised because it is impractical (or impossible) to verify all of the training data. We recently presented FRaC, a new approach for semi-supervised anomaly detection. FRaC is based on using normal instances to build an ensemble of feature models, and then identifying instances that disagree with those models as anomalous. In this paper, we investigate the behavior of FRaC experimentally and explain why FRaC is so successful. We also show that FRaC is a superior approach for the unsupervised as well as the semi-supervised anomaly detection task, compared to well-known state-of-the-art anomaly detection methods, LOF and one-class support vector machines, and to an existing feature-modeling approach.	[Noto, Keith; Brodley, Carla; Slonim, Donna] Tufts Univ, Dept Comp Sci, Medford, MA 02155 USA	Noto, K (reprint author), Tufts Univ, Dept Comp Sci, 161 Coll Ave, Medford, MA 02155 USA.	noto@cs.tufts.edu; brodley@cs.tufts.edu; slonim@cs.tufts.edu	Zhang, JinYuan/C-1542-2010		Eunice Kennedy Shriver National Institute of Child Health and Human Development [R01-HD-058880]; NSF [IIS-0803409]	This research was supported by award number R01-HD-058880 from the Eunice Kennedy Shriver National Institute of Child Health and Human Development. The content is solely the responsibility of the authors and does not necessarily reflect the views of the NICHD or the National Institutes of Health. C. B. was supported by NSF Grant IIS-0803409. Availability: All code, documentation, and complete experimental results are available online at bcb.cs.tufts.edu/frac.	ASUNCION A., 2007, UCI MACHINE LEARNING; Breunig MM, 2000, SIGMOD REC, V29, P93; Byers S, 1998, J AM STAT ASSOC, V93, P577, DOI 10.2307/2670109; Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Guttormsson SE, 1999, IEEE T ENERGY CONVER, V14, P16, DOI 10.1109/60.749142; Phillips A., 1985, SIGKDD EXPLORATIONS, V31, P329, DOI DOI 10.1145/1656274.1656278; Huang YA, 2003, ICDCS 03; John G.H, 1995, P 11 C UNC ART INT, P338; Lazarevic A., 2005, P 11 ACM SIGKDD INT, P157, DOI 10.1145/1081870.1081891; Leon D, 2005, P INT S SOFTW REL EN, P311; Mitchell T. M, 1997, MACHINE LEARNING; Noto K, 2010, P 10 IEEE INT C DAT; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1990, PROBABILISTIC DECISI, V3, P140; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709; Smith R, 2002, P INT ENG SYST ART N, P579; Spackman K.A., 1989, P 6 INT WORKSH MACH, P160; Tang J, 2002, LECT NOTES COMPUTER, P535	23	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2012	25	1					109	133		10.1007/s10618-011-0234-x		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LM	WOS:000302479100004	
J	Kenig, B; Tassa, T				Kenig, Batya; Tassa, Tamir			A practical approximation algorithm for optimal k-anonymity	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Privacy-preserving data mining; k-Anonymity; l-Diversity; Approximation algorithms for NP-hard problems; Frequent generalized itemsets	ANONYMIZATION	k-Anonymity is a privacy preserving method for limiting disclosure of private information in data mining. The process of anonymizing a database table typically involves generalizing table entries and, consequently, it incurs loss of relevant information. This motivates the search for anonymization algorithms that achieve the required level of anonymization while incurring a minimal loss of information. The problem of k-anonymization with minimal loss of information is NP-hard. We present a practical approximation algorithm that enables solving the k-anonymization problem with an approximation guarantee of O(ln k). That algorithm improves an algorithm due to Aggarwal et al. (Proceedings of the international conference on database theory (ICDT), 2005) that offers an approximation guarantee of O(k), and generalizes that of Park and Shim (SIGMOD '07: proceedings of the 2007 ACM SIGMOD international conference on management of data, 2007) that was limited to the case of generalization by suppression. Our algorithm uses techniques that we introduce herein for mining closed frequent generalized records. Our experiments show that the significance of our algorithm is not limited only to the theory of k-anonymization. The proposed algorithm achieves lower information losses than the leading approximation algorithm, as well as the leading heuristic algorithms. A modified version of our algorithm that issues a""-diverse k-anonymizations also achieves lower information losses than the corresponding modified versions of the leading algorithms.	[Kenig, Batya; Tassa, Tamir] Open Univ, Div Comp Sci, Raanana, Israel	Tassa, T (reprint author), Open Univ, Div Comp Sci, Raanana, Israel.	tamirta@openu.ac.il					Aggarwal G, 2005, ICDT, P246; Agrawal R, 2000, ACM SIGMOD C MAN DAT, P439; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bayardo RJ, 2005, PROC INT CONF DATA, P217; Byun J-W, 2007, DASFAA, P188; Ghinita G, 2009, ACM T DATABASE SYST, V34; Gionis A, 2009, IEEE T KNOWL DATA EN, V21, P206, DOI 10.1109/TKDE.2008.129; Gionis A, 2008, PROC INT CONF DATA, P744, DOI 10.1109/ICDE.2008.4497483; Goldberger J., 2010, TDP, V3, P149; Grahne G, 2005, IEEE T KNOWL DATA EN, V17, P1347, DOI 10.1109/TKDE.2005.166; Iyengar VS, 2002, KDD, P279; LeFevre K, 2005, ACM INT C MAN DAT, P49; LeFevre K, 2006, ICDE 06, P25; Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, P1; Meyerson A., 2004, P 23 ACM SIGMOD SIGA, P223, DOI 10.1145/1055558.1055591; Nergiz ME, 2007, DATA KNOWL ENG, V63, P622, DOI 10.1016/j.datak.2007.03.009; Ninghui LI, 2007, P IEEE INT C DAT ENG, P106, DOI DOI 10.1109/ICDE.2007.367856; Park H, 2007, SIGMOD, P67; Pei J, 2000, WORKSH RES ISS DAT M, P21; Samarati P., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275508; Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193; Srikant R., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases; Sweeney L., 2000, LIDAPWP4; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Truta T, 2007, LECT NOTES COMPUT SC, P124; Wong R, 2006, ALPHA K ANONYMITY EN, P754; Xiao X, 2006, VLDB, P139; Zaki MJ, 2005, IEEE T KNOWL DATA EN, V17, P462, DOI 10.1109/TKDE.2005.60	28	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2012	25	1					134	168		10.1007/s10618-011-0235-9		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LM	WOS:000302479100005	
J	Spiliopoulou, M; Mobasher, B; Nasraoui, O; Zaiane, O				Spiliopoulou, Myra; Mobasher, Bamshad; Nasraoui, Olfa; Zaiane, Osmar			Guest editorial: special issue on a decade of mining the Web	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material						Web mining; Clickstream mining; Social Web mining; Semantic Web mining; Web mining and privacy; Web mining and recommenders		As editors of the Special Issue on a Decade of Mining the Web, we provide a brief overview of how Web mining evolved from the first Web mining workshop (WEBKDD'99) till today. We then introduce the papers of the special issue. Each of them is in a domain of Web mining research; it contains a survey of the past and a vision for the future.	[Spiliopoulou, Myra] Otto Von Guericke Univ, Magdeburg, Germany; [Mobasher, Bamshad] Depaul Univ, Chicago, IL 60604 USA; [Nasraoui, Olfa] Univ Louisville, Louisville, KY 40292 USA; [Zaiane, Osmar] Univ Alberta, Edmonton, AB, Canada	Spiliopoulou, M (reprint author), Otto Von Guericke Univ, Magdeburg, Germany.	myra@iti.cs.uni-magdeburg.de; mobasher@cs.depaul.edu; olfa.nasraoui@louisville.edu; zaiane@ualberta.ca					Aggarwal C, 2005, WEBKDD 05 POSTWORKSH, P139; Agosti M, 2012, DATA MIN KNOWL DISC, V24, P663, DOI 10.1007/s10618-011-0228-8; Baumgarten M, 1999, WEBKDD 99 POSTWORKSH, P70; Berendt B, 2012, DATA MIN KNOWL DISC, V24, P697, DOI 10.1007/s10618-012-0254-1; Berendt B, 2005, WEBKDD 05 POSTWORKSH, P18; Broder A, 1999, WEBKDD 99 POSTWORKSH, P51; Castillo C, 2008, WEBKDD 08 WORKSH, P29; Chan PK, 1999, WEBKDD 99 POSTWORKSH, P34; Cooley R, 1999, WEBKDD 99 POSTWORKSH, P160; DeLong C, 2005, WEBKDD 05 POSTWORKSH, P77; Fu Y, 1999, WEBKDD 99 POSTWORKSH, P16; Getoor L, 1999, WEBKDD 99 ONL NOT; Grcar M, 2005, WEBKDD 05 POSTWORKSH, P58; Kim HR, 2005, WEBKDD 05 POSTWORKSH, P158; Lan B, 1999, WEBKDD 99 POSTWORKSH, P108; Lee JM, 1999, ACTA HORTIC, P123; Lu L, 2005, WEBKDD 05 POSTWORKSH, P1; Masand B, 2000, LNAI, V1836; Mobasher B, 2005, WEBKDD 05 POSTWORKSH, P96; Nasraoui O, 2008, 10 INT WORKSH KNOWL; Nasraoui O, 2006, LNAI, V4198; Papadimitriou A, 2012, DATA MIN KNOWL DISC, V24, P555, DOI 10.1007/s10618-011-0215-0; Papadopoulos S, 2012, DATA MIN KNOWL DISC, DOI [10.1007/s10618-011-224-z, DOI 10.1007/S10618-011-224-Z]; Rettinger A, 2012, DATA MIN KNOWL DISC, V24, P613, DOI 10.1007/s10618-012-0253-2; Schickel-Zuber V, 2005, WEBKDD 05 POSTWORKSH, P39; Spiliopoulou M, 1999, WEBKDD 99 POSTWORKSH, P139; Suryavanshi BS, 2005, WEBKDD 05 POSTWORKSH, P119; Tsytsarau M, 2012, DATA MIN KNOWL DISC, DOI [10.1007/s10618-011-0238-z, DOI 10.1007/S10618-011-0238-Z]; Tuzhilin A, 2012, DATA MIN KNOWL DISC, V24, P584, DOI 10.1007/s10618-012-0256-z; Zhang H, 2007, LECT NOTES ARTIF INT, V5439	30	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2012	24	3			SI		473	477		10.1007/s10618-012-0257-y		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LK	WOS:000302478900001	
J	Tsytsarau, M; Palpanas, T				Tsytsarau, Mikalai; Palpanas, Themis			Survey on mining subjective data on the web	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Sentiment analysis; Opinion mining; Contradiction analysis	SENTIMENT	In the past years we have witnessed Sentiment Analysis and Opinion Mining becoming increasingly popular topics in Information Retrieval and Web data analysis. With the rapid growth of the user-generated content represented in blogs, wikis and Web forums, such an analysis became a useful tool for mining the Web, since it allowed us to capture sentiments and opinions at a large scale. Opinion retrieval has established itself as an important part of search engines. Ratings, opinion trends and representative opinions enrich the search experience of users when combined with traditional document retrieval, by revealing more insights about a subject. Opinion aggregation over product reviews can be very useful for product marketing and positioning, exposing the customers' attitude towards a product and its features along different dimensions, such as time, geographical location, and experience. Tracking how opinions or discussions evolve over time can help us identify interesting trends and patterns and better understand the ways that information is propagated in the Internet. In this study, we review the development of Sentiment Analysis and Opinion Mining during the last years, and also discuss the evolution of a relatively new research direction, namely, Contradiction Analysis. We give an overview of the proposed methods and recent advances in these areas, and we try to layout the future research directions in the field.	[Tsytsarau, Mikalai; Palpanas, Themis] Univ Trent, I-38100 Trento, TN, Italy	Tsytsarau, M (reprint author), Univ Trent, I-38100 Trento, TN, Italy.	tsytsarau@disi.unitn.eu; themis@disi.unitn.eu					Alm C. O., 2005, P HUM LANG TECHN C C, P579, DOI DOI 10.3115/1220575.1220648; Annett M, 2008, P CAN SOC COMP STUD, P25; Antweiler W, 2004, J FINANC, V59, P1259, DOI 10.1111/j.1540-6261.2004.00662.x; ARCHAK N, 2007, P 13 ACM SIGKDD INT, P56, DOI 10.1145/1281192.1281202; Bermingham A, 2010, CIKM, P1833; Bestgen Y, 2008, P 6 INT C LANG RES E; Bifet A, 2010, P 13 INT C DISC SCI, P1; Bodendorf F., 2009, P 2 ACM WORKSH SOC W, P65, DOI DOI 10.1145/1651437.1651448; Bollen J, 2010, CORR; Carenini G., 2005, P 3 INT C KNOWL CAPT, P11, DOI DOI 10.1145/1088622.1088626; Carenini G, 2006, P 11 C EUR ASS COMP, P3; Chaovalit P, 2005, HAW INT C SYST SCI, V4, p112c, DOI [10.1109/HICSS.2005.445, DOI 10.1109/HICSS.2005.445]; Chen CM, 2006, IEEE S VIS ANAL, P59; Chen F, 2009, P 18 ACM C INF KNOWL, P1807, DOI [10.1145/1645953.1646235, DOI 10.1145/1645953.1646235]; Chevalier JA, 2006, J MARKETING RES, V43, P345, DOI 10.1509/jmkr.43.3.345; Choi Y, 2009, P INT CIKM WORKSH TO, P37, DOI [10.1145/1651461.1651469, DOI 10.1145/1651461.1651469]; Choudhury MD, 2008, CIKM, P1515; Church KW, 1989, P 27 ANN M ASS COMP, P76, DOI 10.3115/981623.981633; Dasgupta S., 2009, P 2009 C EMP METH NA, P580; Dave K., 2003, P 12 INT C WORLD WID, P519, DOI DOI 10.1145/775152.775226; De Marneffe M., 2008, P ASS COMP LING, P1039; Devitt A, 2007, 45 ANN M ASS COMP L; Ekman P., 1982, EMOTION HUMAN FACE, P39; Ennals R, 2010, P 4 ACM WORKSH INF C; Ennals R, 2010, P 19 INT C WORLD WID; Esuli A., 2006, P 5 INT C LANG RES E; Fahrni A., 2008, P AISB S AFF LANG HU, P60; Fellbaum C., 1998, WORDNET ELECT LEXICA; Feng S, 2009, P APWEB WAIM SUZH CH, P332, DOI [10.1007/978-3-642-00672-2_30, DOI 10.1007/978-3-642-00672-2_30]; Galley M., 2004, P 42 ANN M ASS COMP, P669, DOI 10.3115/1218955.1219040; Gamon M., 2004, P 20 INT C COMP LING, P841, DOI 10.3115/1220355.1220476; Giampiccolo D, 2008, P 1 TEXT AN C TAC 08; Gindl S, 2008, P 18 EUR C ART INT, P35; Go A., 2009, TWITTER SENTIMENT CL; Godbole N., 2007, P INT C WEBL SOC MED; Goldberg A, 2006, TEXTGRAPHS WORKSH GR; Harabagiu S., 2006, AAAI 06, P755; He B, 2008, CIKM, P1063; Hillard D., 2003, HLT NAACL; Hoffman T., 2008, COMPUTERWORLD; Horrigan John, 2008, ONLINE SHOPPING; Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073; HU M., 2004, AAAI 2004, P755; Jindal N., 2008, P INT C WEB SEARCH W, P219, DOI DOI 10.1145/1341531.1341560; Kamps J., 2004, P 4 INT C LANG RES E, VIV, P1115; Kim H. D., 2009, P 18 ACM C INF KNOWL, P385, DOI DOI 10.1145/1645953.1646004; Kim S.-M., 2004, P 20 INT C COMP LING, P1367, DOI 10.3115/1220355.1220555; Koppel M, 2006, COMPUT INTELL, V22, P100, DOI 10.1111/j.1467-8640.2006.00276.x; Ku L. W., 2006, P AAAI 2006 SPRING S; Ku LW, 2007, P 6 NTCIR WORKSH M E, P316; Ku L.-W., 2005, P 28 ANN INT ACM SIG, P627, DOI DOI 10.1145/1076034.1076161; Lerman K, 2009, P 12 C EUR ASS COMP; Leung C. W. K., 2006, ECAI 2006 WORKSH REC, P62; Lim E, 2010, CIKM TOR ON CAN; Lin C, 2009, P 18 ACM C INF KNOWL, P375, DOI DOI 10.1145/1645953.1646003; Liu B., 2005, P 14 INT C WORLD WID, P342, DOI DOI 10.1145/1060745.1060797; Liu B, 2010, CH CRC MACH LEARN PA, P627; Liu H., 2003, 8 INT C INT US INT, V8, P125; Liu J, 2009, P 3 INT C WEBL SOC M; Lu Y, 2010, P 19 INT C WORLD WID, P691, DOI [10.1145/1772690.1772761, DOI 10.1145/1772690.1772761]; McArthur R, 2008, AND, P47; Mei Q, 2007, WWW, P171; Melville P., 2009, P 15 ACM SIGKDD INT, P1275, DOI DOI 10.1145/1557019.1557156; Miao QL, 2009, EXPERT SYST APPL, V36, P7192, DOI 10.1016/j.eswa.2008.09.035; Missen MM, 2009, P 31 EUR C IR RES AD, P729, DOI [10.1007/978-3-642-00958-7_75, DOI 10.1007/978-3-642-00958-7_75]; Morinaga S., 2002, P 8 ACM SIGKDD INT C, P341, DOI 10.1145/775047.775098; Mullen T, 2006, AAAI SPRING S COMP A; Nadeau D, 2006, P WORKSH COMP AESTH; Nowson S, 2009, P INT CIKM WORKSH TO, P17, DOI [10.1145/1651461.1651465, DOI 10.1145/1651461.1651465]; O'Hare N, 2009, P INT CIKM WORKSH TO; Osherenko A, 2007, P AFF COMP INT INT A, P230, DOI [10.1007/978-3-540-74889-2_21, DOI 10.1007/978-3-540-74889-2_21]; Pado S, 2008, P 1 TEXT AN C TAC 08; Pak A., 2010, TWITTER CORPUS SENTI; Pang B., 2004, P 42 ANN M ASS COMP, P271, DOI DOI 10.3115/1218955.1218990; Pang B., 2005, ACL; Pang B., 2008, FDN TRENDS INFORM RE, V2, P1, DOI DOI 10.1561/1500000011; Pang B., 2002, EMNLP 02, P79; Prabowo R, 2009, J INFORMETR, V3, P143, DOI 10.1016/j.joi.2009.01.003; Read J., 2009, P 1 INT CIKM WORKSH, P45, DOI DOI 10.1145/1651461.1651470; Riloff E, 2005, AAAI, P1106; Shimada K, 2008, P 12 PAC AS C KNOWL, P1006; Stoyanov V., 2008, P 22 INT C COMP LING, P817; Taboada M., 2006, P 5 INT C LANG RES E, P427; Taboada M, 2006, P LREC WORKSH COMP M, P36; Tang HF, 2009, EXPERT SYST APPL, V36, P10760, DOI 10.1016/j.eswa.2009.02.063; Thet TT, 2009, P INT CIKM WORKSH TO; Thomas M., 2006, EMNLP 2006, P327; Tsytsarau M, 2011, 1 INT WORKSH KNOWL D; Tsytsarau M, 2010, P 19 INT C WORLD WID; Tumasjan A., 2010, ICWSM; Turney P. D., 2002, P 40 ANN M ASS COMP, P417; Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013; Varlamis I, 2008, ICDE WORKSH, P513; Voorhees EM, 2008, P 46 ANN M ACL HLT C, P63; Wiebe J, 2005, CICLING 2005; Wiebe J, 2001, P ACL WORKSH COLL CO, P24; Wilson T., 2005, HLT EMNLP; Yi Jeonghee, 2003, P IEEE INT C DAT MIN; Yu H., 2003, EMNLP, P129; Zhang JW, 2009, LECT NOTES COMPUT SC, V5802, P181; Zhou L, 2008, J AM SOC INF SCI TEC, V59, P98, DOI 10.1002/asi.20735; Zhu J, 2009, P INT CIKM WORKSH TO, P65, DOI [10.1145/1651461.1651474, DOI 10.1145/1651461.1651474]	102	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2012	24	3			SI		478	514		10.1007/s10618-011-0238-6		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LK	WOS:000302478900002	
J	Papadopoulos, S; Kompatsiaris, Y; Vakali, A; Spyridonos, P				Papadopoulos, Symeon; Kompatsiaris, Yiannis; Vakali, Athena; Spyridonos, Ploutarchos			Community detection in Social Media Performance and application considerations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Community detection; Large-scale networks; Social Media	COMPLEX NETWORKS; ALGORITHM; GRAPHS; CUTS; WEB	The proposed survey discusses the topic of community detection in the context of Social Media. Community detection constitutes a significant tool for the analysis of complex networks by enabling the study of mesoscopic structures that are often associated with organizational and functional characteristics of the underlying networks. Community detection has proven to be valuable in a series of domains, e.g. biology, social sciences, bibliometrics. However, despite the unprecedented scale, complexity and the dynamic nature of the networks derived from Social Media data, there has only been limited discussion of community detection in this context. More specifically, there is hardly any discussion on the performance characteristics of community detection methods as well as the exploitation of their results in the context of real-world web mining and information retrieval scenarios. To this end, this survey first frames the concept of community and the problem of community detection in the context of Social Media, and provides a compact classification of existing algorithms based on their methodological principles. The survey places special emphasis on the performance of existing methods in terms of computational complexity and memory requirements. It presents both a theoretical and an experimental comparative discussion of several popular methods. In addition, it discusses the possibility for incremental application of the methods and proposes five strategies for scaling community detection to real-world networks of huge scales. Finally, the survey deals with the interpretation and exploitation of community detection results in the context of intelligent web applications and services.	[Papadopoulos, Symeon; Kompatsiaris, Yiannis] Informat & Telemat Inst, CERTH, Thessaloniki, Greece; [Papadopoulos, Symeon; Vakali, Athena; Spyridonos, Ploutarchos] Aristotle Univ Thessaloniki, Dept Informat, GR-54006 Thessaloniki, Greece	Papadopoulos, S (reprint author), Informat & Telemat Inst, CERTH, Thessaloniki, Greece.	papadop@iti.gr; ikom@iti.gr; avakali@csd.auth.gr; plspyrid@csd.auth.gr			WeKnowIt; GLOCAL; European Commission [FP7-215453, FP7-248984]	This work was supported by the WeKnowIt and GLOCAL projects, partially funded by the European Commission, under contract numbers FP7-215453 and FP7-248984 respectively.	Agichtein E., 2008, P INT C WEB SEARCH W, P183, DOI DOI 10.1145/1341531.1341557; Andersen R, 2006, ANN IEEE SYMP FOUND, P475; Arenas A, 2006, PHYS REV LETT, V96, DOI 10.1103/PhysRevLett.96.114102; Asur S., 2007, P 13 ACM SIGKDD INT, P913, DOI 10.1145/1281192.1281290; Baeza-Yates R, 2007, LECT NOTES COMPUT SC, V4362, P1; Bagrow JP, 2008, J STAT MECH-THEORY E, V5; Barber MJ, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.066102; Batagelj V, 2003, ARXIVCS0310049; Begelman G, 2006, AUTOMATED TAG CLUSTE; Blondel VD, 2008, ARXIV08030476; BORGATTI SP, 1990, SOC NETWORKS, V12, P337, DOI 10.1016/0378-8733(90)90014-Z; BREIGER RL, 1975, J MATH PSYCHOL, V12, P328, DOI 10.1016/0022-2496(75)90028-0; BRON C, 1973, COMMUN ACM, V16, P575, DOI 10.1145/362342.362367; Cattuto C, 2008, P ISWC 2008 KARLSR G; Cattuto C, 2008, ADV COMPLEX SYST, V11, P597, DOI 10.1142/S0219525908001817; Chakrabarti D., 2006, P 12 ACM SIGKDD INT, P554, DOI 10.1145/1150402.1150467; Chakrabarti D, 2004, LECT NOTES ARTIF INT, V3202, P112; Chen J, 2009, INT C ADV SOC NETW A; Chi Y, 2009, IEEE T MULTIMEDIA, V11, P372, DOI 10.1109/TMM.2009.2012912; Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111; Clauset A, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.026132; Danon L, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/09/P09008; Dean J., 2004, Proceedings of the Sixth Symposium on Operating Systems Design and Implementation (OSDI'04); Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115; Djidjev HN, 2008, LECT NOTES COMPUT SC, V4936, P117, DOI 10.1007/978-3-540-78808-9_11; Donetti L, 2004, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2004/10/P10012; Duch J, 2005, PHYS REV E, V72, DOI [10.1103/PhysRevE.72.027104, 10.1103/PhysRecE.72.027104]; Falkowski T, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P112; Fenn D, 2009, ARXIV08113988; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; FORTUNATO S, 2007, ARXIV07122716; Fortunato S, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.056104; Fortunato S., 2009, ARXIV09060612; Franke Markus, 2009, Advances in Data Analysis and Classification, V3, DOI 10.1007/s11634-009-0039-6; Gallo G, 1989, SIAM J COMPUT, V18, P30; Gemmell J., 2008, LNCS, V5182, P196; Gibson D., 2005, P 31 INT C VER LARG, P721; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Gjoka M., 2009, ARXIV09060060; Arenas A, 2007, NEW J PHYS, V9, DOI 10.1088/1367-2630/9/6/176; Gregory S, 2009, ARXIV09105516; Hastings MB, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.035102; Hubler C, 2008, IEEE DATA MINING, P283, DOI 10.1109/ICDM.2008.124; Hui P, 2007, P 2 ACM IEEE INT WOR, P1, DOI DOI 10.1145/1366919.1366929; Ino H., 2005, P 14 INT C WORLD WID, P661, DOI 10.1145/1060745.1060841; Java A, 2008, P WEBKDD 2008 KDD WO; Java A, 2008, P INT C WEBL SOC MED; Kannan R, 2004, J ACM, V51, P497, DOI 10.1145/990308.990313; Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997; Kim M S, 2009, P VLDB ENDOWMENT, V2, P622; Kovacs IA, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012528; Kumar R, 1999, COMPUT NETW, V31, P1481, DOI 10.1016/S1389-1286(99)00040-7; Lancichinetti A, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.056117; Lancichinetti A, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.046110; Leskovec J., 2008, ARXIV08101355; Leskovec J., 2006, P 12 ACM SIGKDD INT, P631, DOI 10.1145/1150402.1150479; Leung IXY, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.066107; Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427; LIN YR, 2009, P 15 ACM SIGKDD INT, P527, DOI 10.1145/1557019.1557080; Lin Y.-R., 2008, P 17 INT C WORLD WID, P685, DOI 10.1145/1367497.1367590; Lin YR, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P48; Lorrain F., 1971, J MATH SOCIOL, V1, P49, DOI DOI 10.1080/0022250X.1971.9989788); Luo F., 2006, P 2006 IEEE WIC ACM, P233; Maiya A. S., 2010, P 19 INT C WORLD WID, P701, DOI 10.1145/1772690.1772762; Massen CP, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.046101; Mika P., 2005, P 4 INT SEM WEB C IS, P522; Moellic P., 2008, P 2008 INT C CONT BA, P269, DOI 10.1145/1386352.1386390; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Newman MEJ, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.056131; Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104; Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607; Palla G, 2007, NATURE, V446, P664, DOI 10.1038/nature05670; Papadopoulos S, 2010, IEEE MULTIMED MAG, V18, P52; Papadopoulos S, 2010, P DAWAK 10 BILB SPAI, P65; Papadopoulos S, 2009, P CKCAR 09 WORKSH CO; Papadopoulos S, 2010, BOOK COMMUNITY BUILT; Papadopoulos S., 2009, ARXIV09020871; Pons P, 2005, COMPUTER INFORM SCI; Porter M. A., 2009, NOT AM MATH SOC, V56, p[1082, 1164], DOI DOI 10.1063/1.3194108; Quack T., 2008, P INT C CONT BAS IM, P47, DOI DOI 10.1145/1386352.1386363; Radicchi F, 2004, P NATL ACAD SCI USA, V101, P2658, DOI 10.1073/pnas.0400054101; Raghavan P, 2000, ACM S PRINC DAT SYST; Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106; Reichardt J, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016110; Ribeiro-Neto B., 2005, P 28 ANN INT ACM SIG, P496, DOI 10.1145/1076034.1076119; Rosvall M, 2008, P NATL ACAD SCI USA, V105, P1118, DOI 10.1073/pnas.0706851105; Sayyadi H, 2009, P INT AAAI C WEBL SO; Schaeffer S.E., 2007, COMPUTER SCI REV, V1, P27, DOI DOI 10.1016/J.C0SREV.2007.05.001; Schlitter N, 2009, P INT C ADV SOC NETW; Schmitz C, 2006, ST CLASS DAT ANAL, P261, DOI 10.1007/3-540-34416-0_28; Scott J., 2000, SOCIAL NETWORK ANAL; Scripps J., 2007, P 9 WEBKDD 1 SNA KDD, P26, DOI 10.1145/1348549.1348553; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Sima J, 2006, P SOFSEM 2006 THEOR, P530; Simpson E, 2008, HPL200818; Specia L, 2007, LECT NOTES COMPUT SC, V4519, P624; Sun J., 2007, P 13 ACM SIGKDD INT, P687, DOI DOI 10.1145/1281192.1281266; Tang L, 2010, ADV DATABASE SYST, V40, P487, DOI 10.1007/978-1-4419-6045-0_16; Tsatsou D, 2010, ONLINE MULTIMEDIA AD, P233; Tyler JR, 2003, COMMUNITIES AND TECHNOLOGIES, P81; Van Dongen S, 2000, THESIS DUTCH NATL RE; von Luxburg U., 2006, 149 M PLANCK I BIOL; Vragovic I, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016105; Wang Y, 2008, ARXIV08044356; Wasserman S, 1994, SOCIAL NETWORK ANAL; Xu X, 2007, P 13 ACM SIGKDD INT, P824, DOI DOI 10.1145/1281192.1281280; Yang B, 2006, J COMPUT SCI TECH-CH, V21, P393, DOI 10.1007/s11390-006-0393-1; Yang S, 2009, P INT C DAT MIN WORK, P332; Ye S, 2010, P 12 INT AS PAC WEB; YEUNG CMA, 2009, P 20 ACM C HYP HYP T, P251; Zakharov P, 2006, ARXIVPHYS0602063; Zhang Y., 2009, P ACM INT C KNOWL DI, P997, DOI 10.1145/1557019.1557127; Zhao Q, 2007, P 22 AAAI C ART INT, P1501	114	1	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2012	24	3			SI		515	554		10.1007/s10618-011-0224-z		40	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LK	WOS:000302478900003	
J	Papadimitriou, A; Symeonidis, P; Manolopoulos, Y				Papadimitriou, Alexis; Symeonidis, Panagiotis; Manolopoulos, Yannis			A generalized taxonomy of explanations styles for traditional and social recommender systems	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Recommender systems; Explanations; Social justification		Recommender systems usually provide explanations of their recommendations to better help users to choose products, activities or even friends. Up until now, the type of an explanation style was considered in accordance to the recommender system that employed it. This relation was one-to-one, meaning that for each different recommender systems category, there was a different explanation style category. However, this kind of one-to-one correspondence can be considered as over-simplistic and non generalizable. In contrast, we consider three fundamental resources that can be used in an explanation: users, items and features and any combination of them. In this survey, we define (i) the Human style of explanation, which provides explanations based on similar users, (ii) the Item style of explanation, which is based on choices made by a user on similar items and (iii) the Feature style of explanation, which explains the recommendation based on item features rated by the user beforehand. By using any combination of the aforementioned styles we can also define the Hybrid style of explanation. We demonstrate how these styles are put into practice, by presenting recommender systems that employ them. Moreover, since there is inadequate research in the impact of social web in contemporary recommender systems and their explanation styles, we study new emerged social recommender systems i. e. Facebook Connect explanations (HuffPo, Netflix, etc.) and geo-social explanations that combine geographical with social data (Gowalla, Facebook Places, etc.). Finally, we summarize the results of three different user studies, to support that Hybrid is the most effective explanation style, since it incorporates all other styles.	[Papadimitriou, Alexis; Symeonidis, Panagiotis; Manolopoulos, Yannis] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece	Papadimitriou, A (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.	apapadi@csd.auth.gr; symeon@csd.auth.gr; manolopo@csd.auth.gr					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3; Adomavicius G., 2008, P 2008 ACM C REC SYS, P335, DOI DOI 10.1145/1454008.1454068; Andersen S., 1989, P 11 INT JOINT C ART, P1080; Backstrom Lars, 2010, WWW 10, P61; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Bilgic M., 2005, P REC SYST WORKSH IU; Billsus D., 1999, Proceedings of the Third International Conference on Autonomous Agents, DOI 10.1145/301136.301208; Buchanan BG, 1984, ADDISON WESLEY SERIE; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Czarkowski M., 2006, THESIS U SYDNEY; GOLBECK J., 2005, THESIS U MARYLAND CO; Guy I., 2009, P 3 ACM C REC SYST N, P53, DOI 10.1145/1639714.1639725; Herlocker J. L., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work; Hunt J. E., 1988, Engineering Applications of Artificial Intelligence, V1, DOI 10.1016/0952-1976(88)90002-4; Jin X., 2005, P 11 ACM SIGKDD INT, P612, DOI 10.1145/1081870.1081945; Lacave C, 2002, KNOWL ENG REV, V17, P107, DOI 10.1017/S026988890200019X; Liao L, 2005, P ADV NEURAL INFORM; LOPEZSUAREZ A, 1994, KNOWL-BASED SYST, V7, P177, DOI 10.1016/0950-7051(94)90004-3; Marinho LB, 2011, RECOMMENDER SYSTEMS HANDBOOK, P615, DOI 10.1007/978-0-387-85820-3_19; Massa P, 2007, RECSYS 07; McCarthy K, 2004, P ECCBR 2004 WORKSH, P115; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; Melville P., 2002, P 18 NAT C ART INT, P187; MOONEY R. J, 2000, P 5 ACM C DIG LIB, P195, DOI DOI 10.1145/336597.336662; Nielsen J, 1990, P SIGCHI C HUM FACT, P249, DOI DOI 10.1145/97243.97281; O'Sullivan D, 2004, USER MODEL USER-ADAP, P5; Paramythis A, 2001, P WORKSH EMP EV AD S, P9; Pazzani MJ, 2002, AUTON AGENT MULTI-AG, V5, P205, DOI 10.1023/A:1014849311433; Pu P., 2006, P 11 INT C INT US IN, P93, DOI 10.1145/1111449.1111475; Salter J, 2006, IEEE INTELL SYST, V21, P35, DOI 10.1109/MIS.2006.4; Sinha R., 2002, P C HUM FACT COMP SY, P830; Symeonidis P, 2008, P 10 INT ACM KDD WOR; Symeonidis P, 2008, IEEE T SYST MAN CY A, V38, P1262, DOI 10.1109/TSMCA.2008.2003969; Symeonidis P., 2009, P 3 ACM C REC SYST R, P317, DOI 10.1145/1639714.1639777; Tintarev N., 2007, WORKSH REC SYST INT; Tintarev N, 2011, RECOMMENDER SYSTEMS HANDBOOK, P479, DOI 10.1007/978-0-387-85820-3_15; Vig J, 2009, P INT US INT IUI2009; WICK MR, 1992, ARTIF INTELL, V54, P33, DOI 10.1016/0004-3702(92)90087-E; Wyatt D, 2005, P 20 NAT C ART INT; Zheng W, 2005, P 11 INT C UB COMP; Zheng W, 2010, WWW 10, P1029; [Anonymous], 2010, ECONOMIST	43	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2012	24	3			SI		555	583		10.1007/s10618-011-0215-0		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LK	WOS:000302478900004	
J	Tuzhilin, A				Tuzhilin, Alexander			Customer relationship management and Web mining: the next frontier	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Customer relationship management; Analytical CRM; Web mining; Personalization	PROFILES; EQUITY; CHURN	After a decade of successful development of new Web mining technologies, it is a good time to examine novel promising areas that will advance Web mining over the next decade. This paper argues that CRM is such an area that can benefit from and contribute to further advancements of the Web mining research. This is the case because CRM is an underexplored field that has many open and interesting problems important to the industry and academia. This paper reviews some of the key aspects of CRM, describes certain problems and promising research directions in the field, and discusses how Web mining can contribute to solving these problems.	NYU, Stern Sch Business, New York, NY 10003 USA	Tuzhilin, A (reprint author), NYU, Stern Sch Business, New York, NY 10003 USA.	atuzhili@stern.nyu.edu					Adomavicius G, 2005, COMMUN ACM, V48; Adomavicius G., 2005, IEEE T KNOWL DATA EN, V17; Adomavicius G., 2002, International Journal of Computational Intelligence and Applications, V2, DOI 10.1142/S1469026802000658; Adomavicius G, 2001, IEEE COMPUT, V34; Aksin Z, 2007, PROD OPER MANAG J, V16; Albrecht D, 2007, J USER MODEL USER AD, V17, P1; Allen C, 2001, CLICKZ          0410; Ansari A, 2000, J MARKETING RES, V37, P363, DOI 10.1509/jmkr.37.3.363.18779; Armony M, 2011, OPER RES, V59; Barkin E, 2011, CRM MAGAZINE     MAY; Bertsimas D, 2007, OPER RES, V55, P1120, DOI 10.1287/opre.1070.0427; BLATTBERG RC, 1991, SLOAN MANAGE REV, V33, P5; Blei D, 2006, P INT C MACH LEAR; Bolton RN, 1998, MARKET SCI, V17, P45, DOI 10.1287/mksc.17.1.45; Cadez, 2001, P ACM SIGKDD C KNOWL; Dreze X, 2002, PESTER LEAVE ALONE L; Dwyer FR, 1989, J DIRECT MARK, V3; Eirinaki M., 2003, ACM T INTERNET TECHN, V3, P1, DOI DOI 10.1145/643477.643478; Falkowski T, 2007, LECT NOTES ARTIF INT, V4511, P57; Gans N, 2002, MANAGE SCI, V48, P207, DOI 10.1287/mnsc.48.2.207.256; Gans N., 2003, Manufacturing & Service Operations Management, V5, DOI 10.1287/msom.5.2.79.16071; Geoffrion A, 2001, INTERFACES, V31; Gilead S, 2005, TW 05; Gupta S, 2004, J MARKETING RES, V41, P7, DOI 10.1509/jmkr.41.1.7.25084; Hagen P., 1999, SMART PERSONALIZATIO; Hair J, 2007, EUR BUS REV, V19; Jamal Z, 2006, J INTERACT MARK, V20, P16, DOI 10.1002/dir.20064; Jiang T, 2006, IEEE T KNOWL DATA EN, V18; Kakamura W, 2005, MARK LETT, V16; Kirk Donald E., 2004, OPTIMAL CONTROL THEO; Koren Y, 2009, P ACM SIGKDD C KNOWL; Kotler P, 2004, PR04, P11; Krol C, 2007, BTOB MAGAZINE    OCT; Kumar V, 2007, J ACAD MARKET SCI, V35, P157, DOI 10.1007/s11747-007-0028-2; Kumar V, 2006, J SERVICE RES, V9; Mahmood T, 2009, INFORM COMMUN TECHNO, V3, P149; Manavoglu E, 2003, P IEEE INT C DAT MIN; Mani DR, 1999, P ACM KDD C; Mobasher B, 2002, DATA MIN KNOWL DISC, V6, P61, DOI 10.1023/A:1013232803866; Mobasher B, 2009, USER MODEL USER ADAP, V19; Mobasher B, 2000, COMMUN ACM, V43; Moreau L, 2008, COMMUN ACM, V51; Nasraoui O, 2005, ENCY DATA WAREHOUSIN, P1235; Nasraoui O, 2008, IEEE T KNOWL DATA EN, V20; Neslin SA, 2006, J MARKETING RES, V43, P204, DOI 10.1509/jmkr.43.2.204; Nykamp M, 1999, DM REV MAGAZINE  NOV, V9; Padmanabhan B, 2001, P ACM SIGKDD C KNOWL; Padmanabhan B, 2003, MANAG SCI, V49; Pang B., 2008, FDN TRENDS INFORM RE, V2, P1, DOI DOI 10.1561/1500000011; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Peppers D., 2004, MANAGING CUSTOMER RE; Pine J, 1995, HARVARD BUS REV  MAR; Ramakrishnan R, 2005, DAGST SEM P, P04292; Raudenbush S., 2002, HIERARCHICAL LINEAR; Reichheld F, 1993, HARVARD BUS REV  MAR; Rosset S, 2002, P ACM INT C KNOWL DI; Rust RT, 2004, J MARKETING, V68, P109, DOI 10.1509/jmkg.68.1.109.24030; Schein A.I., 2002, P 25 ANN INT ACM SIG; SCHMITTLEIN DC, 1987, MANAGE SCI, V33, P1, DOI 10.1287/mnsc.33.1.1; Shankar V, 2006, J INTERACT MARK, V20, P2, DOI 10.1002/dir.20062; Smyth B, 2004, IEEE WIC ACM INT C W; Spiliopoulou M, 2000, COMMUN ACM, V43; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P1; Sun BH, 2006, J INTERACT MARK, V20, P82, DOI 10.1002/dir.20069; Swift R, 2002, DM REV           FEB; Swift R., 2001, ACCELERATING CUSTOME; Tuzhilin A, 2009, HDB INFORM SYSTEMS B, V3; Tuzhilin A, 2005, P INT WORKSH CUST RE; Tuzhilin A, 2008, IEEE T KNOWL DATA EN, V20; vanDoorn J, 2010, J SERV RES, P13; Venkatesan R, 2007, J MARK RES, V44; Wang R, 1996, J MANAG INFORM SYST, V12; Wedel M., 2000, MARKET SEGMENTATION; Yang Y, 2005, J ELECT COMMER RES, V6	74	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2012	24	3			SI		584	612		10.1007/s10618-012-0256-z		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LK	WOS:000302478900005	
J	Rettinger, A; Losch, U; Tresp, V; d'Amato, C; Fanizzi, N				Rettinger, Achim; Loesch, Uta; Tresp, Volker; d'Amato, Claudia; Fanizzi, Nicola			Mining the Semantic Web Statistical learning for next generation knowledge bases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Semantic Web; Ontology; Knowledge representation; Description logics; RDF; Linked data; Semantic similarity; Kernels; Multivariate prediction; First-order probabilistic learning; Relational graphical models	OF-THE-ART; DESCRIPTION LOGICS; KERNEL METHODS; MARKOV LOGIC; SIMILARITY; DL; ONTOLOGIES; RESOLUTION; RETRIEVAL; NETWORKS	In the Semantic Web vision of the World Wide Web, content will not only be accessible to humans but will also be available in machine interpretable form as ontological knowledge bases. Ontological knowledge bases enable formal querying and reasoning and, consequently, a main research focus has been the investigation of how deductive reasoning can be utilized in ontological representations to enable more advanced applications. However, purely logic methods have not yet proven to be very effective for several reasons: First, there still is the unsolved problem of scalability of reasoning to Web scale. Second, logical reasoning has problems with uncertain information, which is abundant on Semantic Web data due to its distributed and heterogeneous nature. Third, the construction of ontological knowledge bases suitable for advanced reasoning techniques is complex, which ultimately results in a lack of such expressive real-world data sets with large amounts of instance data. From another perspective, the more expressive structured representations open up new opportunities for data mining, knowledge extraction and machine learning techniques. If moving towards the idea that part of the knowledge already lies in the data, inductive methods appear promising, in particular since inductive methods can inherently handle noisy, inconsistent, uncertain and missing data. While there has been broad coverage of inducing concept structures from less structured sources (text, Web pages), like in ontology learning, given the problems mentioned above, we focus on new methods for dealing with Semantic Web knowledge bases, relying on statistical inference on their standard representations. We argue that machine learning research has to offer a wide variety of methods applicable to different expressivity levels of Semantic Web knowledge bases: ranging from weakly expressive but widely available knowledge bases in RDF to highly expressive first-order knowledge bases, this paper surveys statistical approaches to mining the Semantic Web. We specifically cover similarity and distance-based methods, kernel machines, multivariate prediction models, relational graphical models and first-order probabilistic learning approaches and discuss their applicability to Semantic Web representations. Finally, we present selected experiments which were conducted on Semantic Web mining tasks for some of the algorithms presented before. This is intended to show the breadth and general potential of this exiting new research and application area for data mining.	[d'Amato, Claudia; Fanizzi, Nicola] Univ Bari Aldo Moro, Dipartimento Informat, I-70125 Bari, Italy; [Tresp, Volker] Siemens Corp Technol, D-81739 Munich, Germany; [Rettinger, Achim; Loesch, Uta] Karlsruhe Inst Technol, Inst AIFB, D-76128 Karlsruhe, Germany	Fanizzi, N (reprint author), Univ Bari Aldo Moro, Dipartimento Informat, Campus Univ,Via Orabona 4, I-70125 Bari, Italy.	rettinger@kit.edu; uta.loesch@kit.edu; volker.tresp@siemens.com; claudia.damato@di.uniba.it; fanizzi@di.uniba.it	Fanizzi, Nicola/A-4517-2010; d'Amato, Claudia/C-1142-2013	Fanizzi, Nicola/0000-0001-5319-7933; d'Amato, Claudia/0000-0002-3385-987X			Baader F., 2003, DESCRIPTION LOGIC HD; Berners-Lee T., 2001, SEMANTIC WEB; Bicer V, 2011, LECT NOTES COMPUT SC, V6643, P47, DOI 10.1007/978-3-642-21034-1_4; Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bloehdorn S, 2006, SEMANTIC WEB RECHNOL; Bloehdorn S, 2007, LECT NOTES COMPUT SC, V4825, P58; Bock H, 1999, ANAL SYMBOLIC DATA E; Borgida A, 2005, CEUR WORKSHOP P; BRAZ RD, 2005, IJCAI, P1319; Brickley D., 2007, FOAF VOCABULARY SPEC; BRIGHT MW, 1994, ACM T DATABASE SYST, V19, P212, DOI 10.1145/176567.176569; Buitelaar P., 2004, P 1 EUR SEM WEB S ES; Bundschus M, 2009, IEEE INT C DAT MIN S; Carbonetto P, 2005, P 21 UAI; Cimiano P, 2005, TEXT 2 ONTO FRAMEWOR; Cimiano P, 2005, J ARTIF INTELL RES, V24, P305; COHEN WW, 1994, MOR KAUF R, P121; Cumby C., 2003, P 20 INT C MACH LEAR, P107; d'Amato C, 2008, LECT NOTES COMPUT SC, V5021, P288; d'Amato C, 2008, LECT NOTES ARTIF INT, V5268, P48, DOI 10.1007/978-3-540-87696-0_7; d'Amato C, 2008, LECT NOTES ARTIF INT, P336; d'Amato C, 2006, P 21 ANN ACM S APPL, V2, P1695; d'Amato C., 2005, P CONV IT LOG COMP C; d'Amato C, 2006, CEUR WORKSHOP P; De Raedt L, 2008, COGN TECHNOL, P1; De Raedt L., 2008, LECT NOTES COMPUTER; Dean M., 2004, W3C MEMBER SUBMISSIO, V21, P79; Ding L, 2007, ONTOLOGIES HDB PRINC, V14, P79, DOI 10.1007/978-0-387-37022-4_4; Ding Zhonil, 2005, THESIS U MARYLAND BA; Domingos P., 2007, INTRO STAT RELATIONA; Duda R.O., 2001, PATTERN CLASSIFICATI; Euzenat J, 2007, ONTOLOGY MATCHING; Fanizzi N, 2008, LECT NOTES ARTIF INT, V5194, P210, DOI 10.1007/978-3-540-85928-4_18; Fanizzi N, 2007, LECT NOTES COMPUT SC, V4692, P148; Fanizzi N, 2008, LECT NOTES COMPUT SC, V5318, P195, DOI 10.1007/978-3-540-88564-1_13; Fanizzi N, 2009, LECT NOTES COMPUT SC, V5554, P323, DOI 10.1007/978-3-642-02121-3_26; Fanizzi N, 2006, LECT NOTES ARTIF INT, V4203, P322; Fanizzi N, 2007, CEUR WORKSHOP P; Fanizzi N, 2008, INT J SEMANT WEB INF, V4, P44, DOI 10.4018/jswis.2008070103; Fanizzi N, 2008, LECT NOTES ARTIF INT, V5194, P107, DOI 10.1007/978-3-540-85928-4_12; Gartner T, 2004, MACH LEARN, V57, P205, DOI 10.1023/B:MACH.0000039777.23772.30; Gartner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11; Getoor L, 2007, INTRO STAT RELATIONA; Giugno R, 2002, JELIA 02, P86; Grobelnik M., 2006, SEMANTIC WEB TECHNOL; Hastie T., 2001, ELEMENTS STAT LEARNI; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Hitzler P, 2005, LECT NOTES COMPUT SC, V3729, P383; Horvath T., 2004, P 10 ACM SIGKDD INT, P158, DOI 10.1145/1014052.1014072; Huang Y, 2009, P INT WORKSH STAT RE; Huang Y, 2010, P 20 INT C IND LOG P; Huynh TN, 2011, P EUR C MACH LEARN P, V2, P81; Iannone L, 2007, APPL INTELL, V26, P139, DOI 10.1007/s10489-006-0011-5; iropanis T, 2009, WEB SCI 2009 C; Jaeger M, 1997, P 13 C UNC ART INT U; Janowicz K, 2007, LECT NOTES COMPUTER, P128; Janowicz K, 2009, LECT NOTES COMPUT SC, V5554, P353, DOI 10.1007/978-3-642-02121-3_28; Janowicz K, 2006, LECT NOTES COMPUT SC, V4278, P1681; Jarvelin K, 2000, SIGIR 00; KARATZOGLOU A., 2010, P 4 ACM C REC SYST R, P79, DOI 10.1145/1864708.1864727; Kersting K, 2001, BAYESIAN LOGIC PROGR; Kiefer C, 2008, ESWC 2008; Kifer M, 2008, LECT NOTES COMPUTER, P1; Koller D., 1997, AAAI IAAI, P390; Koller D, 1998, P NAT C ART INT C AR; Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI 10.1145/1401890.1401944; Lee D.D., 1999, NATURE; Lee J, 1993, J DOC, V2, P188; Lehmann J, 2009, J MACH LEARN RES, V10, P2639; Lehmann J, 2008, LNCS; Lippert C, 2008, RELATION PREDICTION; Lisi FA, 2005, P SWAP 2005 2 IT SEM; Lukasiewicz T, 2007, INT J APPROX REASON, V45, P288, DOI 10.1016/j.ijar.2006.06.012; Maedche A., 2004, HDB ONTOLOGIES, P173; Maynard D, 2006, P EON 2006 WORKSH; Mika P, 2004, P IEEE WIC ACM INT C, P285; Milch B, 2008, AAAI 08, P1062; Miles A, 2005, SKOS CORE GUIDE; Muggleton S, 1996, NEW GENERATION COMPU; Newman D, 2007, ADV NEURAL INFORM PR, V20, P17; Ng RT, 1990, SEMANTICAL FRAMEWORK; Nickel M., 2011, P 28 INT C MACH LEAR; Nixon LJB, 2008, KNOWL ENG REV, V23, P181, DOI 10.1017/S0269888907001221; Passerini A, 2006, J MACH LEARN RES, V7, P307; Pereira F., 2001, INT C MACH LEARN; Poole D, 1997, ARTIF INTELL, V94, P7, DOI 10.1016/S0004-3702(97)00027-1; Poole D., 2003, IJCAI, P985; Poon H, 2010, P 48 ANN M ASS COMP, P296; Porteous I, 2008, P 14 ACM SIGKDD INT, P569, DOI DOI 10.1145/1401890.1401960; Predoiu L, 2006, P WORKSH INF INT WEB; Predoiu L, 2008, SEMANTIC WEB KNOWLED; Punyakanok V, 2005, IJCAI 05, P1124; RADA R, 1989, IEEE T SYST MAN CYB, V19, P17, DOI 10.1109/21.24528; Rendle S., 2010, WSDM 2010; Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI 10.1145/1772690.1772773; Resnik P, 1999, J ARTIF INTELL RES, V11, P95; Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1; Sato T, 2005, INT JOINT C ART INT, P847; Sebag M., 1997, LNCS, V1297, P264; Shawe-Taylor J, 2004, KERNEL METHODS PATTE; Shervashidze N, 2009, ADV NEURAL INFORM PR, P1660; Singla P, 2006, IEEE DATA MINING, P572; Stumme G, 2006, J WEB SEMANT, V4, P124, DOI 10.1016/j.websem.2006.02.001; Takacs G, 2007, P KDD CUP WORKSH 200; Taskar B, 2002, UNC ART INT UAI; Thor A, 2011, LINK PREDICTION ANNO, P714; Tresp V, 2011, P INT C KNOWL DISC I; Tresp V, 2008, LNAI, V5327; Velardi P., 2005, ONTOLOGY LEARNING TE; Wermser H, 2011, P INT C ADV SOC NETW; Xu Z, 2007, P MIN LEARN GRAPHS M; Yu K, 2006, ADV NEURAL INFORM PR, V19; Yu S, 2005, ADV NEURAL INFORM PR, V18	114	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2012	24	3			SI		613	662		10.1007/s10618-012-0253-2		50	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LK	WOS:000302478900006	
J	Agosti, M; Crivellari, F; Di Nunzio, GM				Agosti, Maristella; Crivellari, Franco; Di Nunzio, Giorgio Maria			Web log analysis: a review of a decade of studies about information acquisition, inspection and interpretation of user interaction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Review						Web log; Query log; Search log; User study	ENGINE QUERY LOGS; SEARCH ENGINE; SUBJECT CATEGORIZATION; CLASSIFICATION; RETRIEVAL; FEEDBACK; TERMS	In the last decade, the importance of analyzing information management systems logs has grown, because log data constitute a relevant aspect in evaluating the quality of such systems. A review of 10 years of research on log analysis is presented in this paper. About 50 papers and posters from five major conferences and about 30 related journal papers have been selected to trace the history of the state-of-the-art in this field. The paper presents an overview of two main themes: Web search engine log analysis and Digital Library System log analysis. The problem of the analysis of different sources of log data and the distribution of data are investigated.	[Agosti, Maristella; Crivellari, Franco; Di Nunzio, Giorgio Maria] Univ Padua, Dept Informat Engn, I-35131 Padua, Italy	Di Nunzio, GM (reprint author), Univ Padua, Dept Informat Engn, Via Gradenigo 6-A, I-35131 Padua, Italy.	agosti@dei.unipd.it; crive@dei.unipd.it; dinunzio@dei.unipd.it			TELplus, European Commission [ECP-2006-DILI-510003]; TrebleCLEF, European Commission [215231]; PROMISE network of excellence, European Commission [258191]	The paper reports on work which originated in the context of the DELOS Network of Excellence on Digital Libraries (http://www.delos.info/). The work has been partially supported by the TELplus Targeted Project for digital libraries, as part of the eContentplus Program of the European Commission (Contract ECP-2006-DILI-510003), by the TrebleCLEF Coordination Action, as part of the 7th Framework Program of the European Commission, Theme ICT-1-4-1 Digital libraries and technology-enhanced learning (Grant agreement: 215231), and by the PROMISE (http://www.promise-noe.eu/) network of excellence (contract n. 258191) project, as part of the 7th Framework Program of the European Commission.	Agosti M, 2008, INFORM RETRIEVAL SER, V22, P1; Agosti M, 2010, LECT NOTES COMPUTER, V6360; Agosti M, 2007, LECT NOTES COMPUT SC, V4877, P104; Agosti M, 2009, P WORKSH CONT INF AC, P13; Anick P., 2003, P 26 ANN INT ACM SIG, P88; Arya S, 2009, J ACM, V57, DOI 10.1145/1613676.1613677; Assadi H, 2003, LECT NOTES COMPUT SC, V2769, P1; Baeza-Yates R. A., 1999, MODERN INFORM RETRIE; Bar-Yossef Z, 2009, P 18 INT C WORLD WID, P41, DOI 10.1145/1526709.1526716; BARYOSSEF Z, 2008, PVLDB, V1, P54; Beitzel S. M., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009048; Beitzel SM, 2007, J AM SOC INF SCI TEC, V58, P166, DOI 10.1002/asi.20464; Beitzel SM, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1229179.1229183; Buzikashvili N, 2007, P 16 INT C WORLD WID, P1213, DOI 10.1145/1242572.1242771; Buzikashvili N, 2006, SIGIR 2006, P623; Cao H., 2009, P 18 INT C WORLD WID, P191, DOI DOI 10.1145/1526709.1526736; Carman MJ, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P123, DOI 10.1145/1571941.1571965; Chen R, 2009, LECT NOTES COMPUT SC, V5714, P364; Christel MG, 2009, P 9 ACM IEEE CS JOIN, P371, DOI 10.1145/1555400.1555468; Chuang SL, 2000, P 23 ANN INT ACM SIG, P334, DOI 10.1145/345508.345630; Chuang SL, 2003, ONLINE INFORM REV, V27, P243, DOI 10.1108/14684520310489032; Chuang SL, 2003, DECIS SUPPORT SYST, V35, P113, DOI 10.1016/S0167-9236(02)00099-4; Clough P., 2009, SIGIR FORUM, V43, P71, DOI DOI 10.1145/1670564.1670578; Cooper A, 2008, ACM T WEB, V2, DOI 10.1145/1409220.1409222; CUI H., 2002, P 11 INT C WORLD WID, P325, DOI DOI 10.1145/511446.511489; Cui H, 2003, IEEE T KNOWL DATA EN, V15, P829; Di Nunzio GM, 2011, LECT NOTES COMPUT SC, P675; Freyne J, 2004, ARTIF INTELL REV, V21, P229, DOI 10.1023/B:AIRE.0000036257.77059.40; Fuhr Norbert, 2007, International Journal on Digital Libraries, V8, DOI 10.1007/s00799-007-0011-z; Gao W, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1740592.1740594; Gao W., 2007, SIGIR 2007, P463, DOI DOI 10.1145/1277741.1277821; Goncalves MA, 2002, LNCS, P129; Goncalves M. A., 2003, Proceedings 2003 Joint Conference on Digital Libraries; Goncxalves MA, 2002, P JCDL 2002 2 ACM IE, P263; Grimes C, 2007, WORKSH 16 INT WORLD; Hopfgartner F, 2008, PVLDB, V1, P1604, DOI 10.1145/1454159.1454233; Hopfgartner F, 2008, P 8 ACM IEEE CS JOIN, P454, DOI 10.1145/1378889.1378999; Hu R, 2008, P 31 ANN INT ACM SIG, P749, DOI 10.1145/1390334.1390484; Huang CC, 2004, ACM T ASIAN LANG INF, V3, P190, DOI 10.1145/1037811.1037812; Hung CM, 2007, J AM SOC INF SCI TEC, V58, P88, DOI 10.1002/asi.20442; Ingwersen P, 2005, TURN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jansen BJ, 2006, LIBR INFORM SCI RES, V28, P407, DOI 10.1016/j.lisr.2006.06.005; Jones R, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1247715.1247720; Jones R, 2006, LANG RESOUR EVAL, V40, P219, DOI 10.1007/s10579-007-9021-0; Jones R, 2008, INT J GEOGR INF SCI, V22, P229, DOI 10.1080/13658810701626186; Jones S., 2000, International Journal on Digital Libraries, V3, DOI 10.1007/s007999900022; KAMVAR M., 2009, P WWW, P801, DOI 10.1145/1526709.1526817; Kim S, 2005, LECT NOTES COMPUT SC, V3652, P186; Klas CP, 2006, LECT NOTES COMPUT SC, V4172, P267; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Koch T., 2004, Proceedings of the Fourth ACM/IEEE Joint Conference on Digital Libraries (IEEE Cat. No.04TH8766), DOI 10.1145/996350.996444; Korolova A., 2009, P 18 INT C WORLD WID, P171, DOI 10.1145/1526709.1526733; KRAUTH W, 1987, J PHYS A-MATH GEN, V20, pL745, DOI 10.1088/0305-4470/20/11/013; Lavrenko V., 2001, SIGIR Forum; Levene M, 2010, INTRO SEARCH ENGINES; Levenshtein V., 1966, SOV PHYS DOKL, V10, P707; Mahoui M, 2000, LECT NOTES COMPUT SC, V1923, P418; Mahoui M., 2001, LECT NOTES COMPUTER, V2163, P13; Mandl T, 2010, LNCS; Maslov M, 2006, P 15 INT C WORLD WID, P931, DOI 10.1145/1135777.1135950; Miller J. C., 2001, SIGIR Forum; Murray GC, 2007, SIGIR FORUM, V41, P112; Parikh J, 2006, SIGIR 2006, P689; Pharo N, 2004, INFORM PROCESS MANAG, V40, P633, DOI 10.1016/j.ipm.2003.08.005; Poblete B, 2010, ACM T WEB, V4, DOI 10.1145/1806916.1806919; Pu HT, 2002, J AM SOC INF SCI TEC, V53, P617, DOI 10.1002/asi.10071; Sakai T, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P780, DOI 10.1145/1571941.1572125; Sekine S, 2007, P 16 INT C WORLD WID, P1223, DOI 10.1145/1242572.1242777; SHI X., 2006, P 15 INT C WORLD WID, P943, DOI 10.1145/1135777.1135956; Shi XD, 2007, J AM SOC INF SCI TEC, V58, P1871, DOI 10.1002/asi.20632; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Smyth B, 2004, USER MODEL USER-ADAP, V14, P383, DOI 10.1007/s11257-004-5270-4; Smyth B, 2006, INFORM RETRIEVAL, V9, P165, DOI 10.1007/s10791-006-7148-z; Srikant R, 2001, WORLD WIDE WEB, P430; Subasic I, 2010, KNOWL INF SYST, V23, P293, DOI 10.1007/s10115-009-0227-x; Sun Y, 2007, P INT WORLD WID WEB, P1141, DOI 10.1145/1242572.1242735; Teevan J, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1402256.1402258; Teevan J, 2006, SICIR 2006 ACM, P703; Teevan J, 2007, SIGIR 07, P151; Tolle J. E., 1983, Proceedings of the Sixth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Wang G, 2009, P 18 INT C WORLD WID, P1051, DOI 10.1145/1526709.1526851; Wang JH, 2006, J AM SOC INF SCI TEC, V57, P660, DOI 10.1002/asi.20328; Wang X., 2007, SIGIR 2007, P87; White R.W., 2007, P 30 ANN INT ACM SIG, P831, DOI DOI 10.1145/1277741.1277931; White RW, 2002, LECT NOTES COMPUT SC, V2291, P93; White RW, 2005, ACM T INFORM SYST, V23, P325, DOI 10.1145/1080343.1080347; Wu LC, 2000, LECT NOTES COMPUTER, V1873, P859; Xiao X, 2010, TWEB, V4, P8; Zhang Z., 2006, P 15 INT C WORLD WID, P1039, DOI 10.1145/1135777.1136004; Zhang ZY, 2008, APPL SOFT COMPUT, V8, P1326, DOI 10.1016/j.asoc.2007.11.004	91	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2012	24	3			SI		663	696		10.1007/s10618-011-0228-8		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LK	WOS:000302478900007	
J	Berendt, B				Berendt, Bettina			More than modelling and hiding: towards a comprehensive view of Web mining and privacy	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Web mining; Privacy; Knowledge discovery cycle; Web usage (mining); Social network analysis	DIFFERENTIAL PRIVACY; SOCIAL NETWORKS; E-COMMERCE; COMMUNITIES; LAW	Over the last decade, privacy has been widely recognised as one of the major problems of data collections in general and the Web in particular. This concerns specifically data arising from Web usage (such as querying or transacting) and social networking (characterised by rich self-profiling including relational information) and the inferences drawn from them. The data mining community has been very conscious of these issues and has addressed in particular the inference problems through various methods for "privacy-preserving data mining" and "privacy-preserving data publishing". However, it appears that these approaches by themselves cannot effectively solve the privacy problems posed by mining. We argue that this is due to the underlying notions of privacy and of data mining, both of which are too narrow. Drawing on notions of privacy not only as hiding, but as control and negotiation, as well as on data mining not only as modelling, but as the whole cycle of knowledge discovery, we offer an alternative view. This is intended to be a comprehensive view of the privacy challenges as well as solution approaches along all phases of the knowledge discovery cycle. The paper thus combines a survey with an outline of an agenda for a comprehensive, interdisciplinary view of Web mining and privacy.	Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium	Berendt, B (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium.	bettina.berendt@cs.kuleuven.be					Acquisti A, 2011, SPION DELIVERABLE 2; Acquisti A, 2006, LECT NOTES COMPUT SC, V4258, P36; Aggarwal C., 2008, ADV DATABASE SYST, P11; Aggarwal CC, 2008, ADV DATABASE SYST, V34, P1, DOI 10.1007/978-0-387-70992-5; Agrawal R., 2000, SIGMOD C, P439; Agrawal R., 2002, VLDB, P143, DOI 10.1016/B978-155860869-6/50021-4; Agre Philip E., 2001, TECHNOLOGY PRIVACY N; Aimeur E, 2008, INT J INF SECUR, V7, P307, DOI 10.1007/s10207-007-0049-3; Anderson R. J., 2008, SECURITY ENG; Arzteblatt, 2011, ARZTEBLATT; Azevedo A., 2008, IADIS EUR C DAT MIN, P182; Backstrom L., 2007, WWW, P181; Baeza-Yates R, 2010, PRIVACY AWARE KNOWLE; Barbaro Michael, 2006, NY TIMES; Berendt B, 2008, INT J ELECTRON COMM, V12, P115, DOI 10.2753/JEC1086-4415120306; Berendt B, 2005, COMMUN ACM, V48, P101, DOI 10.1145/1053291.1053295; Berkovsky S, 2007, P WORKSH DAT MIN US; Bertino E, 2008, PRIVACY PRESERVING D, P181; Binder J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P965; Bone RG, 1998, CALIF LAW REV, V86, P241, DOI 10.2307/3481134; Bonneau J, 2009, WEIS 2009; Borra E, 2007, REPURPOSING WIKISCAN; Boyd D.M., 2007, J COMPUT-MEDIAT COMM, V13, P1; Boyens C, 2003, LECT NOTES COMPUT SC, V2738, P216; Burton TM, 2002, WALL STREET J   0708; Calders T, 2010, DATA MIN KNOWL DISC, V21, P277, DOI 10.1007/s10618-010-0190-x; Camenisch J, 2009, LECT NOTES COMPUT SC, V5443, P196; Canny J., 2002, SIGIR, P238; Carminati B, 2009, ACM T INFORM SYST SE, V13, DOI 10.1145/1609956.1609962; Carminati B, 2010, PRIVACY AWARE KNOWLE; Chor B, 1998, J ACM, V45, P965, DOI 10.1145/293347.293350; Ciriani V, 2008, PRIVACY PRESERVING D, P103; Clifton C, 2004, KARGUPTA HDATA MININ; CRISP-DM, 2000, CRISP DM 1 0 STEP BY; Dalenius T., 1977, STAT TIDSKRIFT, V15, P429; Danezis G, 2008, MSRTR200835 MICR RE; Danezis G, 2007, LECT NOTES COMPUT SC, V4779, P423; Department of Homeland Security, 2007, STAT HOM SEC CHIEF P; Diaz C, 2005, THESIS KU LEUVEN; Domingo-Ferrer J, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P990; Domingo-Ferrer J, 2007, LECT NOTES COMPUT SC, V4721, P193; Domscheit-Berg D., 2011, INSIDE WIKILEAKS MY; Donohue JJ, 2001, Q J ECON, V116, P379, DOI 10.1162/00335530151144050; Dorr D, 2000, BIG BROTHER MENSCHEN; Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1; Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1; Electronic Privacy Information Center, 2010, NETFL CANC CONT PRIV; Electronic Privacy Information Center, 2011, RE FAC; Electronic Privacy Information Center, 2011, PRIV PROP GOOGL DOUB; Electronic Privacy Information Center, 2007, COMPL REQ INJ REQ IN; Electronic Privacy Information Center, EPIC ONL GUID PRACT; Electronic Privacy Information Center, 2011, FAC PRIV; Electronic Privacy Information Center, 2010, AUT TARG SYST; ereleases, 2001, FLOR BAN DWARF TOSS; Eysenbach G, 2001, BRIT MED J, V323, P1103, DOI 10.1136/bmj.323.7321.1103; Fayyad UM, 1996, IEEE EXPERT, V11, P20; Fleischer P, 2008, ARE IP ADDRESSES PER; Frankowski D., 2006, SIGIR 06, P565; FTC, 2000, PRIV ONL FAIR INF PR; Fung BCM, 2010, ACM COMPUT SURV, V42, P14; Gao B, 2011, P 20 MACH LEARN C BE; GermanWorking Group on Data Retention (AK Vorrat), PROS CONS DAT RET; Goldberg I, 2007, DIGITAL PRIVACY THEO, P3, DOI 10.1201/9781420052183.ch1; Gostin LO, 2004, JAMA-J AM MED ASSOC, V291, P2623, DOI 10.1001/jama.291.21.2623; Guarda P, 2009, INFORM SOFTWARE TECH, V51, P337, DOI 10.1016/j.infsof.2008.04.004; Gurses S, 2008, ICIS; Gurses S, 2010, DATA PROTECTION PROF, P301, DOI 10.1007/978-90-481-8865-9_19; Gurses S, 2010, PRIVACY AWARE KNOWLE; Gurses S, 2006, P WORKSH UB KNOWL DI, P51; Gurses S, 2010, THESIS KU LEUVEN; Hajian S, 2011, IEEE SSCI 2011; Hancock J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P517; Hansen M, 2008, P ECHALLENGES, P1585; Hay M, 2010, PRIVACY AWARE KNOWLE; Hildebrandt M., 2008, PROFILING EUROPEAN C; Hildebrandt M, 2006, PRIVACY CRIMINAL LAW, P43; Hu J., 2007, WWW 2007, P151; King SA, 1998, GACKENBACH JPSYCHOLO; Kohavi R, 1998, GLOSSARY TERMS; Korolova A, 2009, WWW, P171; Lederer S, 2004, PERS UBIQUIT COMPUT, V8, P440, DOI 10.1007/s00779-004-0304-9; Li N., 2007, ICDE, P106; Lindamood J, 2009, WWW, P1145; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; Lipford HR, 2008, USABILITY PSYCHOL SE, P1; Liu H, 2006, INT J SEMANT WEB INF, V2, P42, DOI 10.4018/jswis.2006010102; M Du, 2009, DBTA, P128; Machanavajjhala A., 2006, ICDE, P24; Nakashima E, 2011, BRADLEY MANNING WIKI; Narayanan A., 2009, P 30 IEEE S SEC PRIV; Nguyen D.H., 2002, GITGVU0216; OECD, 1980, GUID PROT PRIV TRANS; Owad T, 2006, DATA MINING 101 FIND; Palen L., 2003, CHI 03, P129; Pedreschi D., 2008, KDD 2008, P560; Pedreschi D., 2009, SDM 2009, P581; Pfitzmann A, 2006, ANONYMITY UNLINKABIL; Phillips DJ, 2004, NEW MEDIA SOC, V6, P691, DOI 10.1177/146144804042523; Pilkington E, 2006, GUARDIAN        1202; Poblete B, 2007, LNCS, V4890, P80; Poblete B, 2010, TWEB, V4, P10; Preibusch S, 2006, LECT NOTES COMPUT SC, V3841, P604; Preibusch Soren, 2007, P WORKSH DAT MIN US; Privacy International, 2007, RAC BOTT PRIV RANK I; Reuters, 2006, AOL CHIEF TECHN OFF; Richardson M., 2002, KDD 02, P61; Rowe M, 2010, J WEB SEMANT, V8; Sagar R, 2011, WIKILEAKS FOLGEN, P201; Sagar R, 2007, J POLIT PHILOS, V15, P404, DOI 10.1111/j.1467-9760.2007.00283.x; Shearer C, 2000, J DATA WAREHOUSING, V5, P13; Sinus Sociovision, SIN MIL; Smarr J, 2001, TECHNICAL PRIVACY CH; Smith-Spark L., 2006, BBC NEWS; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Teltzrow M, 2003, CHI 2003 WORKSH DES, DOI doi=10.1.1.10.8180; Venkayala S., 2007, JAVA DATA MINING STR; Verykios VS, 2004, SIGMOD REC, V33, P50; W3C, 2006, PLATF PRIV PREF P3P; W3C, 2006, WORKSH LANG PRIV POL; Wardlow Daniel L, 1996, GAYS LESBIANS CONSUM; Warren S.D., 1890, HARVARD LAW REV, V4, P193, DOI DOI 10.2307/1321160; Westin A., 1970, PRIVACY FREEDOM; Wu X, 2010, ADV DATABASE SYST, P421; Xiao X, 2006, SIGMOD, P229; Zhou B., 2008, ACM SIGKDD EXPLORATI, V<IT>10</IT>, P12; [Anonymous], 2002, GUARDIAN; [Anonymous], 2008, BBC NEWS	127	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2012	24	3			SI		697	737		10.1007/s10618-012-0254-1		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	921LK	WOS:000302478900008	
J	Ienco, D; Pensa, RG; Meo, R				Ienco, Dino; Pensa, Ruggero G.; Meo, Rosa			From Context to Distance: Learning Dissimilarity for Categorical Data Clustering	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Categorical data; clustering; distance learning	ALGORITHM; VALUES	Clustering data described by categorical attributes is a challenging task in data mining applications. Unlike numerical attributes, it is difficult to define a distance between pairs of values of a categorical attribute, since the values are not ordered. In this article, we propose a framework to learn a context-based distance for categorical attributes. The key intuition of this work is that the distance between two values of a categorical attribute A(i) can be determined by the way in which the values of the other attributes A(j) are distributed in the dataset objects: if they are similarly distributed in the groups of objects in correspondence of the distinct values of A(i) a low value of distance is obtained. We propose also a solution to the critical point of the choice of the attributes A(j). We validate our approach by embedding our distance learning framework in a hierarchical clustering algorithm. We applied it on various real world and synthetic datasets, both low and high-dimensional. Experimental results show that our method is competitive with respect to the state of the art of categorical data clustering approaches. We also show that our approach is scalable and has a low impact on the overall computational time of a clustering task.	[Ienco, Dino; Pensa, Ruggero G.; Meo, Rosa] Univ Turin, Dipartimento Informat, I-10149 Turin, Italy	Ienco, D (reprint author), Univ Turin, Dipartimento Informat, Corso Svizzera 185, I-10149 Turin, Italy.	ienco@di.unito.it; pensa@di.unito.it; meo@di.unito.it	Meo, Rosa/E-9345-2012; Pensa, Ruggero/B-5994-2011	Pensa, Ruggero/0000-0001-5145-3438	Regione Piemonte	R. G. Pensa is co-funded by Regione Piemonte.	Ahmad A, 2007, PATTERN RECOGN LETT, V28, P110, DOI 10.1016/j.patrec.2006.06.006; ANDRITSOS P., 2004, P INT C EXT DAT TECH, P123; Barbara D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Bishop C. M., 2006, PATTERN RECOGNITION; Blake C, 1998, UCI REPOSITORY MACHI; Boriah S, 2008, P 8 SIAM INT C DAT M, P243; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Ganti V., 1999, P 5 ACM SIGKDD INT C, P73, DOI 10.1145/312129.312201; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HAN J, 2000, SERIES DATA MANAGEME; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Kasif S, 1998, ARTIF INTELL, V104, P287, DOI 10.1016/S0004-3702(98)00046-0; LI T., 2004, P 21 INT C MACH LEAR, P536; Mahalanobis P. C., 1936, P NAT I SCI INDIA, V2, P49; MELLI G, 2008, DATASET GENERATOR PE; Quinlan R.J., 1993, C4 5 PROGRAMS MACHIN; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STREHL, 2002, J MACHINE LEARNING R, V3, P583; Tan P.N, 2005, INTRO DATA MINING; VERDUGO L. A., 1978, IEEE T INFORM THEORY, V24, P120; Yang Y., 2002, P 8 ACM SIGKDD INT C, P682; Yu L., 2003, P 20 INT C MACH LEAR, P856; Zaki MJ, 2005, PROC INT CONF DATA, P355; Zhu XQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P378	26	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2012	6	1							1	10.1145/2133360.2133361		25	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	926WR	WOS:000302863100001	
J	Jin, Y; Duffield, N; Erman, J; Haffner, P; Sen, S; Zhang, ZL				Jin, Yu; Duffield, Nick; Erman, Jeffrey; Haffner, Patrick; Sen, Subhabrata; Zhang, Zhi-Li			A Modular Machine Learning System for Flow-Level Traffic Classification in Large Networks	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Communications network; traffic classification; machine learning		The ability to accurately and scalably classify network traffic is of critical importance to a wide range of management tasks of large networks, such as tier-1 ISP networks and global enterprise networks. Guided by the practical constraints and requirements of traffic classification in large networks, in this article, we explore the design of an accurate and scalable machine learning based flow-level traffic classification system, which is trained on a dataset of flow-level data that has been annotated with application protocol labels by a packet-level classifier. Our system employs a lightweight modular architecture, which combines a series of simple linear binary classifiers, each of which can be efficiently implemented and trained on vast amounts of flow data in parallel, and embraces three key innovative mechanisms, weighted threshold sampling, logistic calibration, and intelligent data partitioning, to achieve scalability while attaining high accuracy. Evaluations using real traffic data from multiple locations in a large ISP show that our system accurately reproduces the labels of the packet level classifier when runs on (unlabeled) flow records, while meeting the scalability and stability requirements of large ISP networks. Using training and test datasets that are two months apart and collected from two different locations, the flow error rates are only 3% for TCP flows and 0.4% for UDP flows. We further show that such error rates can be reduced by combining the information of spatial distributions of flows, or collective traffic statistics, during classification. We propose a novel two-step model, which seamlessly integrates these collective traffic statistics into the existing traffic classification system. Experimental results display performance improvement on all traffic classes and an overall error rate reduction by 15%. In addition to a high accuracy, at runtime, our implementation easily scales to classify traffic on 10Gbps links.	[Jin, Yu; Duffield, Nick; Erman, Jeffrey; Haffner, Patrick; Sen, Subhabrata] AT&T Labs Res, AT&T Shannon Lab, Florham Pk, NJ 07932 USA; [Zhang, Zhi-Li] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55416 USA	Jin, Y (reprint author), AT&T Labs Res, AT&T Shannon Lab, Bldg 103,180 Pk Ave, Florham Pk, NJ 07932 USA.	yjin@research.attt.com; duffield@research.attt.com; erman@research.attt.com; haffner@research.attt.com; sen@research.attt.com; zhzhang@cs.umn.edu			NSF [CNS-0905037, CNS-1017647]; ATT VURI	The work of Z.-L. Zhang was supported in part by the NSF grants CNS-0905037 and CNS-1017647, and an AT&T VURI gift grant.	BERNAILLE L., 2006, P CONEXT 06; But J., 2007, P 6 ACM SIGCOMM WORK, P123, DOI 10.1145/1326257.1326279; CHEN A., 2010, P 29 C INF COMM INFO, P206; Crotti M, 2007, COMPUT COMMUN REV, V37, P5; Duda R. O., 2000, PATTERN CLASSIFICATI; DUFFIELD N., 2010, P ACM SIGMETRICS 10; DUFFIELD N., 2010, P 22 INT TEL C ITC 2; Erman J, 2007, PERFORM EVALUATION, V64, P1194, DOI 10.1016/j.peva.2007.06.014; Freund Y., 1995, P 2 EUR C COMP LEARN; GALLAGHER B, 2007, P 7 IEEE INT C DAT M, P411; HAFFNER P., 2005, P SIGCOMM WORKHS MIN; ILIOFOTOU M., 2009, P CONEXT 09; ILIOFOTOU M., 2009, P 28 IEEE INT C COMP, P37; ILIOFOTOU M., 2007, P ACM INT MEAS C IMC; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; JIANG H., 2007, P 2007 SIGCOMM WORKS; KARAGIANNIS T., 2004, P ACM INT MEAS C IMC; KARAGIANNIS T., 2005, P ACM SIGCOMM 05; LEVCHENKO K., 2006, P ACM INT MEAS C IMC; MCDANIEL P., 2006, P 13 ANN NETW DISTR; MOORE A. W., 2005, P ACM SIGMETRICS 05; Namata G, 2008, AI MAG, V29, P3; NEVILLE J., 2000, P AAAI WORKSH LEARN; NGUYEN T, 2006, P AUSTR TEL NETW APP, P293; NGUYEN T, 2006, P 31 C LOC COMP NETW; Phillips SJ, 2004, P 21 INT C MACH LEAR; PLATT J, 1999, P 13 C NEUR INF PROC; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SHARAFUDDIN E., 2009, P SIGMETRICS 09, P49, DOI 10.1145/1555349.1555356; SPATSCHECK O., 2004, P 13 INT WORLD WID W; TRESTIAN I., 2008, P ACM SIGCOMM 08; WILLIAMS N, 2006, SIGCOMM COMPUT COMMU, V36, P5; Witten I.H., 1999, DATA MINING PRACTICA; Xu K., 2005, P ACM SIGCOMM	35	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2012	6	1							4	10.1145/2133360.2133364		34	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	926WR	WOS:000302863100004	
J	Li, C; Yang, QY; Wang, JY; Li, M				Li, Chun; Yang, Qingyan; Wang, Jianyong; Li, Ming			Efficient Mining of Gap-Constrained Subsequences and Its Various Applications	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Sequential pattern; closed subsequence; repetitive subsequence; gap-constraint	SEQUENTIAL PATTERNS; DISCOVERY; SEQUENCES; CLASSIFICATION; ALGORITHM; GROWTH	Mining frequent subsequence patterns is a typical data-mining problem and various efficient sequential pattern mining algorithms have been proposed. In many application domains (e.g., biology), the frequent subsequences confined by the predefined gap requirements are more meaningful than the general sequential patterns. In this article, we propose two algorithms, Gap-BIDE for mining closed gap-constrained subsequences from a set of input sequences, and Gap-Connect for mining repetitive gap-constrained subsequences from a single input sequence. Inspired by some state-of-the-art closed or constrained sequential pattern mining algorithms, the Gap-BIDE algorithm adopts an efficient approach to finding the complete set of closed sequential patterns with gap constraints, while the Gap-Connect algorithm efficiently mines an approximate set of long patterns by connecting short patterns. We also present several methods for feature selection from the set of gap-constrained patterns for the purpose of classification and clustering. Our extensive performance study shows that our approaches are very efficient in mining frequent subsequences with gap constraints, and the gap-constrained pattern based classification/clustering approaches can achieve high-quality results.	[Li, Chun; Yang, Qingyan; Wang, Jianyong; Li, Ming] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	Li, C (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	socrates.lee@gmail.com; dateyan04@gmail.com; jianyong@tsinghua.edu.cn; lm0909@gmail.com			National Natural Science Foundation of China [60873171]; National Basic Research Program of China [2011CB302206]; State Education Ministry of China [NCET-07-0491]	This article was supported in part by National Natural Science Foundation of China under grant no. 60873171, National Basic Research Program of China under grant no. 2011CB302206, and Program for New Century Excellent Talents in University under grant no. NCET-07-0491, State Education Ministry of China.	AGGARWAL CC, 2007, P 13 ACM SIGKDD INT, P46, DOI 10.1145/1281192.1281201; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Ayres J., 2002, P 8 ACM SIGKDD INT C, P429; CASAS-GARRIGA G, 2005, P 2005 SIAM INT C DA; CHANDONIA J. M., 2004, NUCL ACIDS RES, V32; CHANG C.C., 2001, LIBSVM LIBRARY SUPPO; Chen Jinlin, 2007, P 16 INT C WORLD WID, P1177, DOI 10.1145/1242572.1242753; Cheng H, 2008, PROC INT CONF DATA, P169; Deshpande M, 2005, IEEE T KNOWL DATA EN, V17, P1036, DOI 10.1109/TKDE.2005.127; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Edwards S, 2008, INFORM PROCESS MANAG, V44, P400, DOI 10.1016/j.ipm.2007.02.009; GAO C, 2008, P 17 INT C WORLD WID, P1051, DOI 10.1145/1367497.1367651; Garofalakis MN, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P223; Han J., 2000, P 6 ACM SIGKDD INT C, P355, DOI 10.1145/347090.347167; Han JW, 1999, PROC INT CONF DATA, P106; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Ji X, 2005, P 5 IEEE INT C DAT M, P194; Karypis George, 2002, P PAKDD 02, P417; Leslie Christina, 2002, Pac Symp Biocomput, P564; Li Z., 2004, P 3 USENIX C FIL STO, P173; Li ZM, 2006, IEEE T SOFTWARE ENG, V32, P176, DOI 10.1109/TSE.2006.28; Lo D., 2006, P 14 ACM SIGSOFT INT, P265, DOI 10.1145/1181775.1181808; LODHI H., 2000, P NEUR INF PROC SYST, P563; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Masseglia F, 1998, LECT NOTES ARTIF INT, V1510, P176; Pei J, 2001, PROC INT CONF DATA, P215; Pei J, 2007, J INTELL INF SYST, V28, P133, DOI 10.1007/s10844-006-0006-z; Rigoutsos I, 1998, BIOINFORMATICS, V14, P55, DOI 10.1093/bioinformatics/14.1.55; Rish I., 2001, IJCAI 01 WORKSH EMP; Saigo H., 2008, P 14 ACM SIGKDD INT, P578, DOI 10.1145/1401890.1401961; Seno M., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183937; She R., 2003, P 9 ACM SIGKDD INT C, P436; Srikant R.R., 1996, LNCS, V1057, P3; WANG J, 2005, P 2005 SIAM INT C DA; WANG J., 2005, P 5 IEEE INT C DAT M, P753; Wang JY, 2007, IEEE T KNOWL DATA EN, V19, P1042, DOI 10.1109/TKDE.2007.1043; Wang JY, 2009, DATA MIN KNOWL DISC, V18, P1, DOI 10.1007/s10618-008-0100-7; XIE T, 2006, P 12 ACM SIGKDD INT; Yan XF, 2003, SIAM PROC S, P166; Yang J., 2002, P 2002 ACM SIGMOD IN, P406; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315; ZHANG M., 2007, ACM T KNOWL DISCOV D, V1, P7, DOI 10.1145/1267066.1267068; ZHANG M., 2007, ACM T KNOWL DISCOV D, V1, P2; ZHU F., 2007, ICDE, P706; Zhu FD, 2007, IEEE DATA MINING, P751; ZHU X, 2007, P 20 INT JOINT C ART, P2934	46	0	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2012	6	1							2	10.1145/2133360.2133362		39	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	926WR	WOS:000302863100002	
J	Liu, FT; Ting, KM; Zhou, ZH				Liu, Fei Tony; Ting, Kai Ming; Zhou, Zhi-Hua			Isolation-Based Anomaly Detection	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Anomaly detection; outlier detection; ensemble methods; binary tree; random tree ensemble; isolation; isolation forest	DISTANCE-BASED OUTLIERS; LOCAL OUTLIERS; SUPPORT; FOREST; TREES	Anomalies are data points that are few and different. As a result of these properties, we show that, anomalies are susceptible to a mechanism called isolation. This article proposes a method called Isolation Forest (iForest), which detects anomalies purely based on the concept of isolation without employing any distance or density measure-fundamentally different from all existing methods. As a result, iForest is able to exploit subsampling (i) to achieve a low linear time-complexity and a small memory-requirement and (ii) to deal with the effects of swamping and masking effectively. Our empirical evaluation shows that iForest outperforms ORCA, one-class SVM, LOF and Random Forests in terms of AUC, processing time, and it is robust against masking and swamping effects. iForest also works well in high dimensional problems containing a large number of irrelevant attributes, and when anomalies are not available in training sample.	[Liu, Fei Tony; Ting, Kai Ming] Monash Univ, Churchill, Vic 3842, Australia; [Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China	Liu, FT (reprint author), Monash Univ, Gippsland Campus, Churchill, Vic 3842, Australia.	feitony.liu@gmail.com; kaiming.ting@monash.edu; zhouzh@lamda.nju.edu.cn			Australian Postgraduate Awards (APA); Information and Communications Technologies (ICT) Postgraduate Research Scholarships; National Science Foundation of China [61073097, 61021062]; National Fundamental Research Program of China [2010CB327903]; Jiangsu Science Foundation [BK2008018]	This research was supported by the Australian Postgraduate Awards (APA) and the Information and Communications Technologies (ICT) Postgraduate Research Scholarships, the National Science Foundation of China (61073097, 61021062), the National Fundamental Research Program of China (2010CB327903) and the Jiangsu Science Foundation (BK2008018).	Abe N., 2006, P 12 ACM SIGKDD INT, P504, DOI 10.1145/1150402.1150459; Angiulli F, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497581; ASUNCION A., 2007, UCI MACHINE LEARNING; Bay SD, 2003, P 9 ACM SIGKDD INT C, P29; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breunig MM, 2000, SIGMOD REC, V29, P93; Caputo B., 2002, P NIPS WORKSH STAT M; Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882; Chaudhary A, 2002, P ACM SIGMOD WORKSH; Fan HQ, 2006, LECT NOTES ARTIF INT, V3918, P557; Ghoting A., 2004, P 4 IEEE INT C DAT M, P387; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; He ZY, 2003, PATTERN RECOGN LETT, V24, P1641, DOI 10.1016/S0167-8655(03)00003-5; He ZY, 2005, LECT NOTES COMPUT SC, V3739, P632; Joanes DN, 1998, J ROY STAT SOC D-STA, V47, P183; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Knuth D.E., 2006, ART COMPUTER PROGRAM, V4; Lazarevic A., 2005, P 11 ACM SIGKDD INT, P157, DOI 10.1145/1081870.1081891; LIU F. T., 2010, TR20102 MON U; Liu FT, 2010, P EUR C MACH LEARN P, P274; Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17; Liu FT, 2008, J ARTIF INTELL RES, V32, P355; Liu RY, 1999, ANN STAT, V27, P783; Murphy R.B., 1951, THESIS PRINCETON U; Papadimitriou S, 2003, PROC INT CONF DATA, P315, DOI 10.1109/ICDE.2003.1260802; Preiss H.R., 1999, DATA STRUCTURES ALGO; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Rocke DM, 1996, J AM STAT ASSOC, V91, P1047, DOI 10.2307/2291724; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; RUSKEY F, 1980, SIAM J ALGEBRA DISCR, V1, P43, DOI 10.1137/0601007; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Shi T, 2006, J COMPUT GRAPH STAT, V15, P118, DOI 10.1198/106186006X94072; Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623; Song XY, 2007, IEEE T KNOWL DATA EN, V19, P631, DOI 10.1109/TKDE.2007.1009; Tan P.N, 2005, INTRO DATA MINING; Tang J., 2002, P 6 PAC AS C ADV KNO, P535; Tao Y., 2006, P 12 ACM SIGKDD INT, P394, DOI 10.1145/1150402.1150447; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tukey J.W., 1977, EXPLORATORY DATA ANA; Williams G., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1184035; WU M, 2006, P 12 ACM SIGKDD INT, P767; Yamanishi K., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347160; Yu XA, 2009, IEEE DATA MINING, P617, DOI 10.1109/ICDM.2009.44	45	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2012	6	1							3	10.1145/2133360.2133363		39	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	926WR	WOS:000302863100003	
J	Morik, K; Bhaduri, K; Kargupta, H				Morik, Katharina; Bhaduri, Kanishka; Kargupta, Hillol			Introduction to data mining for sustainability	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material							GRASSLAND		[Morik, Katharina] TU Dortmund Univ, Fac Comp Sci, Artificial Intelligence Grp, Dortmund, Germany; [Bhaduri, Kanishka] NASA, Ames Res Ctr, Mission Crit Technol Inc, Moffett Field, CA 94035 USA; [Kargupta, Hillol] Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA	Morik, K (reprint author), TU Dortmund Univ, Fac Comp Sci, Artificial Intelligence Grp, Dortmund, Germany.	katharina.morik@tu-dortmund.de; Kanishka.Bhaduri-1@nasa.gov; hillol@cs.umbc.edu					Andrienko G, 2010, INT J GEOGR INF SCI, V24, P1577, DOI 10.1080/13658816.2010.508043; ANDRIENKO GL, 2009, SIGKDD EXPLOR, V11, P19; Bay SD, 2003, P 9 ACM SIGKDD INT C, P29; Bhaduri K, 2010, NASA C INT DAT UND C, P109; Blanke V, 2007, RESTOR ECOL, V15, P307, DOI 10.1111/j.1526-100X.2007.00214.x; Boriah S, 2008, P KNOWL DISC DAT KDD; Boriah S, 2004, P KNOWL DISC DAT KDD; Chandola V., 2009, ACM COMPUT SURV, V41, P15; Cross PC, 2005, ECOL LETT; Das M, 2009, SENSORKDD; Dietterich TG, 2009, P 21 IJCAI AAAI; Ekasingh B, 2005, J ENVIRON MANAGE, V77, P315, DOI 10.1016/j.jenvman.2005.06.015; Ferraro R, 2003, P INT GEOSC REM SENS; Flasch O, 2010, P IEEE C EV COMP BAR, P1; Fricke P, 2010, WORKSH MIN UB SOC EN; Furnkranz J, 2010, DATA MIN KNOWL DISC, V21, P1, DOI 10.1007/s10618-010-0169-7; Ganguly AR, 2009, P IEEE INT C DAT MIN, P385; Hart JK, 2006, EARTH-SCI REV, V78, P177, DOI 10.1016/j.earscirev.2006.05.001; Kumar V, 2001, P JOINT STAT M AM ST; Li X, 2008, EARTH SCI INFORM, P49; Lorenz L, 2001, ICCD 01; Marwah M, 2009, COMPUTE; May M, 2010, LECT NOTES ARTIFICIA; Mazzoni D, 2007, REMOTE SENS ENVIRON, V107, P138, DOI 10.1016/j.rse.2006.08.014; Morik K, 2005, LECT NOTES COMPUTER, V3539; Ramaswamy S, 2000, SIGMOD REC, V29, P427; Sarkar K., 2010, P 16 ACM SIGKDD INT, P37, DOI 10.1145/1835804.1835812; Scholkopf B, 2001, NEURAL COMPUT, V13; Schwabacher Mark, 2007, Computational Discovery of Scientific Knowledge. Introduction, Techniques, and Applications in Environmental and Life Sciences; Srivastava AN, 2011, GREENER AVIATION VIR; Steinbach M, 2003, P KDD; Steinke S, 2002, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, 2002 PROCEEDINGS, P409; Stojanova D, 2011, DATA MIN KNOWL DISCO; Thurau C, 2011, DATA MIN KNOWL DISCO; Tilman D, 1996, NATURE, V379, P718, DOI 10.1038/379718a0	35	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2012	24	2			SI		311	324		10.1007/s10618-011-0239-5		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	875TD	WOS:000299057000001	
J	Thurau, C; Kersting, K; Wahabzada, M; Bauckhage, C				Thurau, Christian; Kersting, Kristian; Wahabzada, Mirwaes; Bauckhage, Christian			Descriptive matrix factorization for sustainability Adopting the principle of opposites	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Matrix factorization; Convex combinations; Distance geometry; Large-scale data analysis	ENDMEMBER EXTRACTION; ARCHETYPAL ANALYSIS; ALGORITHM	Climate change, the global energy footprint, and strategies for sustainable development have become topics of considerable political and public interest. The public debate is informed by an exponentially growing amount of data and there are diverse partisan interest when it comes to interpretation. We therefore believe that data analysis methods are called for that provide results which are intuitively understandable even to non-experts. Moreover, such methods should be efficient so that non-experts users can perform their own analysis at low expense in order to understand the effects of different parameters and influential factors. In this paper, we discuss a new technique for factorizing data matrices that meets both these requirements. The basic idea is to represent a set of data by means of convex combinations of extreme data points. This often accommodates human cognition. In contrast to established factorization methods, the approach presented in this paper can also determine over-complete bases. At the same time, convex combinations allow for highly efficient matrix factorization. Based on techniques adopted from the field of distance geometry, we derive a linear time algorithm to determine suitable basis vectors for factorization. By means of the example of several environmental and developmental data sets we discuss the performance and characteristics of the proposed approach and validate that significant efficiency gains are obtainable without performance decreases compared to existing convexity constrained approaches.	[Thurau, Christian; Kersting, Kristian; Wahabzada, Mirwaes; Bauckhage, Christian] Fraunhofer Inst Intelligent Anal & Informat Syst, St Augustin, Germany	Thurau, C (reprint author), Fraunhofer Inst Intelligent Anal & Informat Syst, St Augustin, Germany.	christian.thurau@iais.fraunhofer.de; kristian.kersting@iais.fraunhofer.de; mirwaes.wahabzada@iais.fraunhofer.de; christian.bauckhage@iais.fraunhofer.de			Fraunhofer ATTRACT Fellowship STREAM	The authors would like to thank Katharina Morik for her encouragement and the anonymous reviewers for their comments. Kristian Kersting and Mirwaes Wahabzada were supported by the Fraunhofer ATTRACT Fellowship STREAM.	Achlioptas D, 2007, J ACM, V54, P1; Aguilar O, 1998, BAYESIAN STAT; Blumenthal L. M., 1953, THEORY APPL DISTANCE; Chan BHP, 2003, MON NOT R ASTRON SOC, V338, P790, DOI 10.1046/j.1365-8711.2003.06099.x; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P2804, DOI 10.1109/TGRS.2006.881803; Crippen G.M., 1988, DISTANCE GEOMETRY MO; CUTLER A, 1994, TECHNOMETRICS, V36, P338, DOI 10.2307/1269949; Dean J, 2008, COMMUN ACM, V51, P107, DOI 10.1145/1327452.1327492; Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277; Drineas P, 2006, SIAM J COMPUT, V36, P184, DOI 10.1137/S0097539704442702; Faloutsos C, 1995, P ACM SIGMOD INT C M; Foster DH, 2004, VISUAL NEUROSCI, V21, P331, DOI 10.1017/S0952523804043330; Gomes C, 2009, BRIDGE NATL ACAD ENG, V39, P6; Goreinov S.A., 2001, CONT MATH, V208, P47; Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888; Kersting K, 2010, P 2 AS C MACH LEARN; Lee DD, 1999, NATURE, V401, P788; Lucas A, 2003, APPL MATH FINANCE, V10, P337; Mackay D.J.C., 2009, SUSTAINABLE ENERGY H; Miao LD, 2007, IEEE T GEOSCI REMOTE, V45, P765, DOI 10.1109/TGRS.2006.888466; Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293; Ostrouchov G, 2005, IEEE T PATTERN ANAL, V27, P1340, DOI 10.1109/TPAMI.2005.164; SIPPL MJ, 1986, P NATL ACAD SCI USA, V83, P2283, DOI 10.1073/pnas.83.8.2283; Spearman C, 1904, AM J PSYCHOL, V15, P201, DOI 10.2307/1412107; Thurau C, 2011, KNOWL INF SYST, V29, P457, DOI 10.1007/s10115-010-0352-6; Thurau C., 2009, P IEEE INT C DAT MIN; Winter ME, 1999, P INT C APPL GEOL RE	27	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2012	24	2			SI		325	354		10.1007/s10618-011-0216-z		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	875TD	WOS:000299057000002	
J	Li, ZH; Han, JW; Ding, BL; Kays, R				Li, Zhenhui; Han, Jiawei; Ding, Bolin; Kays, Roland			Mining periodic behaviors of object movements for animal and biological sustainability studies	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Data mining; Object movements; Periodicity; Pattern analysis; Animal and environmental studies	ECOLOGY; RESOURCES; NETWORKS	Periodicity is one of the most frequently occurring phenomena for moving objects. Animals usually have periodic movement behaviors, such as daily foraging behaviors or yearly migration behaviors. Such periodic behaviors are the keys to understand animal movement and they also reflect the seasonal, climate, or environmental changes of the ecosystem. However, periodic behaviors could be complicated, involving multiple interleaving periods, partial time span, and spatiotemporal noises and outliers. In this paper, we address the problem of mining periodic behaviors for moving objects. It involves two sub-problems: how to detect the periods in complex movements, and how to mine periodic behaviors. A period is usually a single value, such as 24 h. And a periodic behavior is a statistical description of the periodic movement for one specific period. For example, we could describe an animal's daily behavior in the way that "From 6 pm to 6 am, it has 90% probability staying at location A and from 7 am to 5 pm, it has 70% probability staying at location B and 30% probability staying at location C". So our tasks is to first detect the periods and then describe each periodic behavior according to different periods. Our main assumption is that the observed movement is generated from multiple interleaved periodic behaviors associated with certain reference locations. Based on this assumption, we propose a two-stage algorithm, Periodica, to solve the problem. At the first stage, the notion of reference spot is proposed to capture the reference locations. Through reference spots, multiple periods in the movement can be retrieved using a method that combines Fourier transform and autocorrelation. At the second stage, a probabilistic model is proposed to characterize the periodic behaviors. For a specific period, periodic behaviors are statistically generalized from partial movement sequences through hierarchical clustering. Finally, we show two extensions to the Periodica algorithm: (1) missing data interpolation, and (2) future movement prediction. Empirical studies on both synthetic and real data sets demonstrate the effectiveness of the proposed method.	[Li, Zhenhui; Han, Jiawei; Ding, Bolin] Univ Illinois, Champaign, IL USA; [Kays, Roland] New York State Museum & Sci Serv, New York, NY USA	Li, ZH (reprint author), Univ Illinois, Champaign, IL USA.	zli28@uiuc.edu; hanj@uiuc.edu; bding3@uiuc.edu; rkays@mail.nysed.gov			NSF [IIS-1017362, CNS-0931975]; NASA [NRA-NNH10ZDA001N]; U.S. Air Force Office of Scientific Research MURI [FA9550-08-1-0265]; Boeing company; U.S. Army Research Laboratory [W911NF-09-2-0053]	The work was supported in part by the NSF IIS-1017362, NSF CNS-0931975, NASA NRA-NNH10ZDA001N, U.S. Air Force Office of Scientific Research MURI award FA9550-08-1-0265, Boeing company, and by the U.S. Army Research Laboratory under Cooperative Agreement Number W911NF-09-2-0053 (NS-CTA). The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U. S. Government. The U. S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.	Bar-David S, 2009, ECOLOGY, V90, P2467, DOI 10.1890/08-1532.1; Berberidis C, 2002, ECAI; Cao H, 2004, PAKDD; CAO H, 2005, ICDM, P82; Cooke S. J., 2004, TRENDS ECOL EVOL, V19, P335; Cross PC, 2005, ECOL LETT, V8, P587, DOI 10.1111/j.1461-0248.2005.00760.x; Dalziel BD, 2008, AM NAT, V172, P248, DOI 10.1086/589448; Elfeky MG, 2005, IEEE T KNOWL DATA EN, V17, P875, DOI 10.1109/TKDE.2005.114; Elfeky MG, 2005, ICDM, P138; Getz WM, 2008, P NATL ACAD SCI USA, V105, P19066, DOI 10.1073/pnas.0801732105; Han J., 1998, KDD NEW YORK NY US, P214; Han J, 1999, ICDE; Hewitson L, 2005, ANIM BEHAV, V69, P1069, DOI 10.1016/j.anbehav.2004.09.004; Indyk P, 2000, VLDB; Jensen C.S., 2004, VLDB, P768; Jeung H, 2008, ICDE; Lahiri M, 2008, IEEE DATA MINING, P373, DOI 10.1109/ICDM.2008.104; Li Z, 2010, KDD, P1099; Li Z., 2010, P VLDB END, V3, P723; Ma S, 2001, ICDE; Mamoulis N, 2004, KDD; McIntyre CL, 1999, JSTOR; McNaughton SJ, 1997, SCIENCE, V278, P1798, DOI 10.1126/science.278.5344.1798; MCNAUGHTON SJ, 1985, ECOL MONOGR, V55, P259, DOI 10.2307/1942578; Nathan R, 2008, P NATL ACAD SCI USA, V105, P19052, DOI 10.1073/pnas.0800375105; Patel JM, 2004, SIGMOD C, P637; Patterson TA, 2008, TRENDS ECOL EVOL, V23, P87, DOI 10.1016/j.tree.2007.10.009; Polis GA, 1997, ANNU REV ECOL SYST, V28, P289, DOI 10.1146/annurev.ecolsys.28.1.289; Saltenis S, 2000, SIGMOD, P331; Sugden A, 2006, SCIENCE, V313, P775, DOI 10.1126/science.313.5788.775; Tao Y., 2004, SIGMOD, P611; Tao YF, 2003, ACM T DATABASE SYST, V28, P101, DOI 10.1145/777943.777944; Tao Yufei, 2003, VLDB, P790, DOI DOI 10.1016/B978-012722442-8/50075-6; Vlachos M., 2005, SDM; Wang C, 2006, KDD; Wang W, 2001, ICDM; Wang Y, 2003, LECT NOTES COMPUT SC, P287; Wittemyer G, 2008, P NATL ACAD SCI USA, V105, P19108, DOI 10.1073/pnas.0801744105; WORTON BJ, 1989, ECOLOGY, V70, P164, DOI 10.2307/1938423; Yan X., 2005, KDD; Yang J, 2004, DATA MIN KNOWL DISC, V9, P189, DOI 10.1023/B:DAMI.0000031631.84034.af; Yang J, 2002, ICDM; Yang J, 2000, KDD; Zhang M, 2005, SIGMOD C	44	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2012	24	2			SI		355	386		10.1007/s10618-011-0227-9		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	875TD	WOS:000299057000003	
J	Gunnemann, S; Kremer, H; Laufkotter, C; Seidl, T				Guennemann, Stephan; Kremer, Hardy; Laeufkotter, Charlotte; Seidl, Thomas			Tracing Evolving Subspace Clusters in Temporal Climate Data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article							TIME-SERIES DATA	Analysis of temporal climate data is an active research area. Advanced data mining methods designed especially for these temporal data support the domain expert's pursuit to understand phenomena as the climate change, which is crucial for a sustainable world. Important solutions for mining temporal data are cluster tracing approaches, which are used to mine temporal evolutions of clusters. Generally, clusters represent groups of objects with similar values. In a temporal context like tracing, similar values correspond to similar behavior in one snapshot in time. Each cluster can be interpreted as a behavior type and cluster tracing corresponds to tracking similar behaviors over time. Existing tracing approaches are for datasets satisfying two specific conditions: The clusters appear in all attributes, i.e., fullspace clusters, and the data objects have unique identifiers. These identifiers are used for tracking clusters by measuring the number of objects two clusters have in common, i.e. clusters are traced based on similar object sets. These conditions, however, are strict: First, in complex data, clusters are often hidden in individual subsets of the dimensions. Second, mapping clusters based on similar objects sets does not reflect the idea of tracing similar behavior types over time, because similar behavior can even be represented by clusters having no objects in common. A tracing method based on similar object values is needed. In this paper, we introduce a novel approach that traces subspace clusters based on object value similarity. Neither subspace tracing nor tracing by object value similarity has been done before.	[Guennemann, Stephan; Kremer, Hardy; Seidl, Thomas] Rhein Westfal TH Aachen, Data Management & Data Explorat Grp, Aachen, Germany; [Laeufkotter, Charlotte] ETH, Inst Biogeochem & Pollutant Dynam, Zurich, Switzerland	Kremer, H (reprint author), Rhein Westfal TH Aachen, Data Management & Data Explorat Grp, Aachen, Germany.	guennemann@cs.rwth-aachen.de; kremer@cs.rwth-aachen.de; charlotte.laufkoetter@env.ethz.ch; seidl@cs.rwth-aachen.de			UMIC Research Centre, RWTH Aachen University	We thank the Alfred Wegener Institute for Polar and Marine Research for providing the Oceanographic Grid Data. This article has been supported by the UMIC Research Centre, RWTH Aachen University.	Aggarwal C.C., 2003, VLDB, P81; Aggarwal CC, 2005, IEEE T KNOWL DATA EN, V17, P587, DOI 10.1109/TKDE.2005.78; Aggarwal C.C., 2004, VLDB, P852; Agrawal R., 1998, ACM SIGMOD INT C MAN, P94; Barnett TP, 2001, SCIENCE, V292, P270, DOI 10.1126/science.1058304; Boriah S, 2008, ACM SIGKDD, P857; Bottcher M., 2008, ACM SIGKDD EXPL, V10, P3; Brodeur RD, 1999, FISH OCEANOGR, V8, P296, DOI 10.1046/j.1365-2419.1999.00115.x; Cao F, 2006, SIAM PROC S, P328; Dempster A., 1977, J ROYAL STAT SOC B, P1; Ester M, 1996, ACM SIGKDD, P226; Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007; Gaffney S, 1999, ACM SIGKDD, P63; Gunnemann S, 2010, SIAM SDM, P385; Hinneburg A., 2000, VLDB J, P506; Hoegh-Guldberg O, 1999, MAR FRESHWATER RES, V50, P839, DOI 10.1071/MF99078; Hoffman FM, 2005, EARTH INTERACT, V9, P1, DOI DOI 10.1175/EI110.1; Huntington TG, 2006, J HYDROL, V319, P83, DOI 10.1016/j.jhydrol.2005.07.003; Jensen CS, 2007, IEEE T KNOWL DATA EN, V19, P1161, DOI [10.1109/TKDE.2007.1054, 10.1109/TKDE.2007.1054.]; Kalnis P, 2005, SSTD, P364; Kremer H, 2010, IEEE ICDM WORKSH, P96; Kremer H., 2011, ACM SIGKDD, P868; Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578; Li Y, 2004, ACM SIGKDD 04 SEATTL, P617; Liao TW, 2005, PATTERN RECOGN, V38, P1857, DOI 10.1016/j.patcog.2005.01.025; Longhurst A., 1998, ECOLOGICAL GEOGRAPHY; Muller E., 2009, VLDB, P1270; Parsons L., 2004, SIGKDD EXPLORATIONS, V6, P90, DOI DOI 10.1145/1007730.1007731; Patrikainen A, 2006, IEEE T KNOWL DATA EN, V18, P902, DOI 10.1109/TKDE.2006.106; Procopiuc C. M., 2002, ACM SIGMOD, P418; Rosswog J., 2008, IEEE INT C DAT MIN W, P448; Siegel DA, 2002, SCIENCE, V296, P730, DOI 10.1126/science.1069174; Spiliopoulou M., 2006, ACM SIGKDD 2006, P706; Steinbach M, 2003, ACM SIGKDD, P446; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; Yiu M. L., 2003, IEEE ICDM, P689; Zhou D, 2005, INT C MACH LEARN, P1028	37	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2012	24	2			SI		387	410		10.1007/s10618-011-0237-7		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	875TD	WOS:000299057000004	
J	Stojanova, D; Kobler, A; Ogrinc, P; Zenko, B; Dzeroski, S				Stojanova, Daniela; Kobler, Andrej; Ogrinc, Peter; Zenko, Bernard; Dzeroski, Saso			Estimating the risk of fire outbreaks in the natural environment	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Fire outbreaks; Fire prediction; Greenhouse emission; Remote sensing; Classification; Rules; Trees; Ensembles	ALGORITHMS	A constant and controlled level of emission of carbon and other gases into the atmosphere is a pre-condition for preventing global warming and an essential issue for a sustainable world. Fires in the natural environment are phenomena that extensively increase the level of greenhouse emissions and disturb the normal functioning of natural ecosystems. Therefore, estimating the risk of fire outbreaks and fire prevention are the first steps in reducing the damage caused by fire. In this study, we build predictive models to estimate the risk of fire outbreaks in Slovenia, using data from a GIS, Remote Sensing imagery and the weather prediction model ALADIN. The study is carried out on three datasets, from three regions: one for the Kras region, one for the coastal region and one for continental Slovenia. On these datasets, we apply both classical statistical approaches and state-of-the-art data mining algorithms, such as ensembles of decision trees, in order to obtain predictive models of fire outbreaks. In addition, we explore the influence of fire fuel information on the performance of the models, measured in terms of accuracy, Kappa statistic, precision and recall. Best results in terms of predictive accuracy are obtained by ensembles of decision trees.	[Stojanova, Daniela; Zenko, Bernard; Dzeroski, Saso] Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana 1000, Slovenia; [Kobler, Andrej; Ogrinc, Peter] Slovenian Forestry Inst, Ljubljana 1000, Slovenia	Stojanova, D (reprint author), Jozef Stefan Inst, Dept Knowledge Technol, Jamova Cesta 39, Ljubljana 1000, Slovenia.	daniela.stojanova@ijs.si			Slovenian Research Agency [P2-0103, J2-0734, J2-2285]; European Commission [HEALTH-F4-2008-223451]; Centre of Excellence for Integrated Approaches in Chemistry and Biology of Proteins [OP13.1.1.2.02.005]; Jozef Stefan International Postgraduate School; ARVALIS-Institut du vegetal, Pau, France; Jozef Stefan Institute; Ministry of Education, Science and Sports [M1-0032]; Ministry of Defence of Slovenia	Saso Dzeroski is supported by the Slovenian Research Agency (through the grants P2-0103, J2-0734, and J2-2285), the European Commission (through the grant HEALTH-F4-2008-223451), the Centre of Excellence for Integrated Approaches in Chemistry and Biology of Proteins (operation no.\OP13.1.1.2.02.005) and the Jozef Stefan International Postgraduate School. Daniela Stojanova is supported by two joint projects between the ARVALIS-Institut du vegetal, Pau, France and the Jozef Stefan Institute, as well as the above mentioned grant J2-2285. Preliminary work on this application, including the data acquisition and pre-processing, was performed within the project "Forecasting GIS model of fire danger in the natural environment" (M1-0032) financed by the Ministry of Education, Science and Sports and the Ministry of Defence of Slovenia.	Agresti A, 1996, INTRO CATEGORICAL DA; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alonzo-Betanzos A, 2003, EXPERT SYST APPL, V11, P545; Bouckaert R, 2005, BAYESIAN NETWORK CLA; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Cheng Tao, 2008, Transactions in GIS, V12, P591; Chu D.A., 2002, GEOPHYS RES LETT, V29, P1; Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Connor S, 2006, INDEPENDENT UK  0815; Cortex P., 2007, NEW TRENDS ARTIFICIA, P512; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dzeroski S, 2006, MANAGING ENV KNOWLED, P125; European Commission, 2008, 8 EUR COMM I ENV SUS; Felber A, 2003, P 4 INT WORKSH REM S, P100; Fischer C, 2006, Q J ROY METEOR SOC, V613, P3477, DOI DOI 10.1256/QJ.05.115; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Fujii T., 2005, LASER REMOTE SENSING; Giglio L, 1999, INT J REMOTE SENS, V20, P1947, DOI 10.1080/014311699212290; Giglio L, 2003, REMOTE SENS ENVIRON, V87, P273, DOI 10.1016/S0034-4257(03)00184-6; Holden ZA, 2009, FOREST ECOL MANAG, V258, P2399, DOI 10.1016/j.foreco.2009.08.017; Hosmer Jr D.W., 1989, APPL LOGISTIC REGRES; Hsu WM, 2002, J INTELL INF SYST, V19, P7, DOI 10.1023/A:1015508302797; John G.H, 1995, P 11 C UNC ART INT, P338; Kandola J, 2003, ADV NEURAL INFORM PR, V15, P657; King M. D., 2003, EOS DATA PRODUCTS HD; Kobler A, 2006, FINAL REPORT RESULTS; Kobler A, 2001, FINAL REPORT RESULTS; Li Z, 2001, GLOBAL REGIONAL VEGE; Locatelli B, 2008, P 13 PORT C ART INT, P15; Mack P, 1991, SCIENCE, V254, P314; Markuzon N, 2009, 38 IEEE APPL IM PATT; Mazzoni D, 2005, AGU FALL M, pB853+; Nemenyi P., 1963, THESIS PRINCETON U P; Niculescu-Mizil A, 2005, MACH LEARN, P625; Preisler K, 2008, INT J WILDLAND FIRE, V17, P305; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Ruddell S, 2007, J FOREST, V105, P314; Sabins F. F, 1978, REMOTE SENSING PRINC; Saravanan N, 2008, EXPERT SYST APPL, V35, P351; Slovenia Forest Service, 2005, INF FOR FIR SLOV PER; Stojanova D, 2010, ECOL INFORM, V5, P256, DOI 10.1016/j.ecoinf.2010.03.004; Stojanova D, 2006, P 9 INT MULT INF SOC, P255; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; TURNER J.A., 1978, BCX177 CAN FOR SERV; Vega-Garcia C, 1996, AI APPLICATIONS, V10, P9; Witten IH, 2005, DATA MINING PRACTICA	49	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2012	24	2			SI		411	442		10.1007/s10618-011-0213-2		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	875TD	WOS:000299057000005	
J	Srivastava, AN				Srivastava, Ashok N.			Greener aviation with virtual sensors: a case study	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Ensemble learning; Gaussian process; Aviation; Environmental systems; Anomaly detection		The environmental impact of aviation is enormous given the fact that in the US alone there are nearly 6 million flights per year of commercial aircraft. This situation has driven numerous policy and procedural measures to help develop environmentally friendly technologies which are safe and affordable and reduce the environmental impact of aviation. However, many of these technologies require significant initial investment in newer aircraft fleets and modifications to existing regulations which are both long and costly enterprises. We propose to use an anomaly detection method based on Virtual Sensors to help detect overconsumption of fuel in aircraft which relies only on the data recorded during flight of most existing commercial aircraft, thus significantly reducing the cost and complexity of implementing this method. The Virtual Sensors developed here are ensemble-learning regression models for detecting the overconsumption of fuel based on instantaneous measurements of the aircraft state. This approach requires no additional information about standard operating procedures or other encoded domain knowledge. We present experimental results on three data sets and compare five different Virtual Sensors algorithms. The first two data sets are publicly available and consist of a simulated data set from a flight simulator and a real-world turbine disk. We show the ability to detect anomalies with high accuracy on these data sets. These sets contain seeded faults, meaning that they have been deliberately injected into the system. The second data set is from real-world fleet of 84 jet aircraft where we show the ability to detect fuel overconsumption which can have a significant environmental and economic impact. To the best of our knowledge, this is the first study of its kind in the aviation domain.	NASA, Ames Res Ctr, Intelligent Data Understanding Grp, Intelligent Syst Div, Moffett Field, CA 94035 USA	Srivastava, AN (reprint author), NASA, Ames Res Ctr, Intelligent Data Understanding Grp, Intelligent Syst Div, Moffett Field, CA 94035 USA.	ashok.n.srivastava@nasa.gov			NASA	The author would like to thank Irving Statler for extremely thoughtful and useful discussions throughout this project. The author also thanks Timothy Woodbury for valuable discussions and Don Simon of NASA Glenn Research Center for providing key references and analytical advice. He would also like to acknowledge Nikunj Oza for valuable discussions and the reviewers for their constructive feedback. The author also thanks our airline partner in providing access to their flight operational data to enable this study. This research was conducted with the support of the NASA Aviation Safety Program's System-Wide Safety and Assurance project. The code used for many of the algorithms in this paper is available as opensource and can be found on DASHlink at https://c3.nasa.gov/dashlink/projects/7/.	Abdul-Aziz A, 2010, PROPULSION HLTH MONI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chandola V, 2010, P SIGKDD WORKSH LARG; Chandola V., 2009, ACM COMPUT SURV, V41, P15; Chen T, 2009, NEUROCOMPUTING, V72, P1605, DOI 10.1016/j.neucom.2008.09.002; Chu E, 2010, P AIAA INF AER C ATL; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Committee on Aeronautics Research and Technology for Environmental Compatibility, 2002, GREEN SKIES RED ENV; Foster L, 2009, J MACH LEARN RES, V10, P857; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Friedman J, 2010, J STAT SOFTW, V33, P1; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 2009, GLMNET MATLAB; Litt JS, 2007, USERS GUIDE COMMERCI; Matthews B, 2010, P JOINT ARM NAV NASA; Nabney Ian T., 2001, NETLAB ALGORITHMS PA; Oza N, 2010, FLTZ SIMULATED DATA; Penner JE, 1999, GLOBAL AVIATION ATMO; Petrovskaya A, 2009, MODEL BASED VEHICLE; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Sallee GP, 1980, PERFORMANCE DE UNPUB; Seber G.A.F., 1989, NONLINEAR REGRESSION; Simon DL, 2010, ANN C PROGN HLTH MAN; Srivastava AN, 2009, IEEE T SYST MAN CY C, V39; Srivastava AN, 2005, IEEE T GEOSCIENCE RE, V43; Statler IC, 2007, NASA TECHNICAL PUBLI; Way MJ, 2006, ASTROPHYS J, V647, P102, DOI 10.1086/505293; Wulf R. H., 1980, CR159867 NASA; [Anonymous], 2010, MATL STAT TOOLB VER	29	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2012	24	2			SI		443	471		10.1007/s10618-011-0240-z		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	875TD	WOS:000299057000006	
J	Chen, JH; Liu, J; Ye, JP				Chen, Jianhui; Liu, Ji; Ye, Jieping			Learning Incoherent Sparse and Low-Rank Patterns from Multiple Tasks	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Multitask learning; low-rank and sparse patterns; trace norm	SHRINKAGE	We consider the problem of learning incoherent sparse and low-rank patterns from multiple tasks. Our approach is based on a linear multitask learning formulation, in which the sparse and low-rank patterns are induced by a cardinality regularization term and a low-rank constraint, respectively. This formulation is nonconvex; we convert it into its convex surrogate, which can be routinely solved via semidefinite programming for small-size problems. We propose employing the general projected gradient scheme to efficiently solve such a convex surrogate; however, in the optimization formulation, the objective function is nondifferentiable and the feasible domain is nontrivial. We present the procedures for computing the projected gradient and ensuring the global convergence of the projected gradient scheme. The computation of the projected gradient involves a constrained optimization problem; we show that the optimal solution to such a problem can be obtained via solving an unconstrained optimization subproblem and a Euclidean projection subproblem. We also present two projected gradient algorithms and analyze their rates of convergence in detail. In addition, we illustrate the use of the presented projected gradient algorithms for the proposed multitask learning formulation using the least squares loss. Experimental results on a collection of real-world data sets demonstrate the effectiveness of the proposed multitask learning formulation and the efficiency of the proposed projected gradient algorithms.	[Chen, Jianhui; Liu, Ji; Ye, Jieping] Arizona State Univ, Ctr Evolutionary Med & Informat, Biodesign Inst, Tempe, AZ 85287 USA; [Chen, Jianhui; Liu, Ji; Ye, Jieping] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA	Chen, JH (reprint author), Arizona State Univ, Ctr Evolutionary Med & Informat, Biodesign Inst, Tempe, AZ 85287 USA.	jianhui.chen@asu.edu; ji.liu@asu.edu; jieping.ye@asu.edu			NSF [HS-0812551, IIS-0953662, CCF-1025177]; NIH [LM010730]	This work was supported by NSF HS-0812551, IIS-0953662, CCF-1025177, and NIH LM010730.	Abernethy J, 2009, J MACH LEARN RES, V10, P803; Ando R.K., 2007, P 2 BIOCREATIVE CHAL; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Bach F, 2012, OPTIMIZATION FOR MACHINE LEARNING, P19; Bakker B., 2003, J MACH LEARN RES, V4, P83; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertsekas D. P., 2003, CONVEX ANAL OPTIMIZA; Bertsekas D.P., 1999, NONLINEAR PROGRAMMIN; BICKEL S., 2008, P INT C MACH LEARN I; Boyd S., 2004, CONVEX OPTIMIZATION; Candes E., 2009, J ACM, V58, P1; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; CHANDRASEKARAN V., 2009, P 15 IFAC S SYST ID; Chang C, 2011, ACM T INTEL SYST TEC, V2, P1, DOI DOI 10.1145/1961189.1961199; CHEN J., 2009, P INT C MACH LEARN I; CHEN X., 2009, P IEEE INT C DAT MIN; CHEN X., 2010, ABS10054717V3 CORR; CHEN X., 2010, ABS10053579 CORR; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; FAZEL M., 2001, P AM CONTR C ACC; Fowlkes CC, 2008, CELL, V133, P364, DOI 10.1016/j.cell.2008.01.053; Golub G.H., 1996, MATRIX COMPUTATIONS; Gonzalez R. C., 2002, DIGITAL IMAGE PROCES; JACOB L, 2008, P C ADV NEUR INF PRO; JALALI A, 2010, P C ADV NEUR INF PRO; Ji S., 2009, P INT SIGKDD C KNOWL; Ji S., 2009, P INT C MACH LEARN I; KIM S., 2010, P INT C MACH LEARN I; LAWRENCE N. D., 2004, P INT C MACH LEARN I; Lecuyer E, 2007, CELL, V131, P174, DOI 10.1016/j.cell.2007.08.003; Liu J., 2009, P C UNC ART INT UAI; Liu J., 2009, P INT C MACH LEARN I; Liu J., 2009, SLEP SPARSE LEARNING; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinez A.M., 1998, 24 CVC; NEMIROVSKI A., 1995, LECT NOTES TECHNION; Nesterov Y., 1998, INTRO LECT CONVEX PR; Obozinski G, 2010, STAT COMPUT, V20, P231, DOI 10.1007/s11222-008-9111-x; PONG T. K., 2010, SIAM J OPTIM, V20, P6; Scholkopf B., 2002, LEARNING KERNELS SUP; SCHWAIGHOEER A., 2004, P C ADV NEUR INF PRO; SHAPIRO A, 1982, PSYCHOMETRIKA, V47, P243, DOI 10.1007/BF02294158; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; STURM J. F., 2001, OPTIM METHOD SOFTW, V11-12, P653; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; UEDA N., 2002, P INT SIGKDD C KNOWL; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; WATSON GA, 1992, LINEAR ALGEBRA APPL, V170, P33, DOI 10.1016/0024-3795(92)90407-2; WRIGHT J., 2009, P C ADV NEUR INF PRO; XIONG T., 2008, P EUR C MACH LEARN P; Xue Y, 2007, J MACH LEARN RES, V8, P35; YANG Y., 1997, P INT C MACH LEARN I; Yu K., 2005, P INT C MACH LEARN I; ZHANG J., 2005, P C ADV NEUR INF PRO; ZHANG X., 2010, ABS10110472 CORR; ZHANG Y., 2010, P C UNC ART INT UAI; ZHANG Y., 2010, P C ADV NEUR INF PRO; ZHOU J., 2011, P C ADV NEUR INF PRO	59	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2012	5	4			SI				22	10.1145/2086737.2086742		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	895WE	WOS:000300526600005	
J	Elkan, C; Koren, Y				Elkan, Charles; Koren, Yehuda			Guest Editorial for Special Issue KDD'10	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Editorial Material																	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2012	5	4			SI				18	10.1145/2086737.2086738		2	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	895WE	WOS:000300526600001	
J	Gomez-Rodriguez, M; Leskovec, J; Krause, A				Gomez-Rodriguez, Manuel; Leskovec, Jure; Krause, Andreas			Inferring Networks of Diffusion and Influence	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Networks of diffusion; information cascades; blogs; news media; meme-tracking; social networks	BAYESIAN NETWORKS; HEAVY TAILS; LASSO	Information diffusion and virus propagation are fundamental processes taking place in networks. While it is often possible to directly observe when nodes become infected with a virus or publish the information, observing individual transmissions (who infects whom, or who influences whom) is typically very difficult. Furthermore, in many applications, the underlying network over which the diffusions and propagations spread is actually unobserved. We tackle these challenges by developing a method for tracing paths of diffusion and influence through networks and inferring the networks over which contagions propagate. Given the times when nodes adopt pieces of information or become infected, we identify the optimal network that best explains the observed infection times. Since the optimization problem is NP-hard to solve exactly, we develop an efficient approximation algorithm that scales to large datasets and finds provably near-optimal networks. We demonstrate the effectiveness of our approach by tracing information diffusion in a set of 170 million blogs and news articles over a one year period to infer how information flows through the online media space. We find that the diffusion network of news for the top 1,000 media sites and blogs tends to have a core-periphery structure with a small set of core media sites that diffuse information to the rest of the Web. These sites tend to have stable circles of influence with more general news media sites acting as connectors between them.	[Gomez-Rodriguez, Manuel; Leskovec, Jure] Stanford Univ, Stanford, CA 94305 USA; [Krause, Andreas] Swiss Fed Inst Technol, Zurich, Switzerland; [Krause, Andreas] CALTECH, Pasadena, CA 91125 USA	Gomez-Rodriguez, M (reprint author), Stanford Univ, Stanford, CA 94305 USA.	manuelgr@stanford.edu			Albert Yu and Mary Benchmann Foundation; IBM; Lightspeed; Microsoft; Yahoo; ONR [N00014-09-1-1044]; NSF [CNS0932392, CNS1010921, IIS1016909, IIS0953413]; AFRL [FA8650-10-C-7058]; Okawa Foundation; Fundacion Caja Madrid; Fundacion Barrie de la Maza; Max Planck Society	This research was supported in part by the Albert Yu and Mary Benchmann Foundation, IBM, Lightspeed, Microsoft, Yahoo, grants ONR N00014-09-1-1044, NSF CNS0932392, NSF CNS1010921, NSF IIS1016909, NSF IIS0953413, AFRL FA8650-10-C-7058, and Okawa Foundation Research Grant. M. Gomez-Rodriguez has been supported in part by a Fundacion Caja Madrid Graduate Fellowship, by a Fundacion Barrie de la Maza Graduate Fellowship, and by the Max Planck Society.	ADAR E., 2004, P 13 INT WORLD WID W; Adar E., 2005, Proceedings. The 2005 IEEE/WIC/ACM International Conference on Web Intelligence; AHMED A., 2009, P NAT ACAD SCI, V106; ANDERSON R. M., 2002, INFECT DISS HUMANS D; BACKSTROM L., 2011, P ACM INT C WEB SEAR; Bailey NTJ, 1975, MATH THEORY INFECT D; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Barabasi AL, 2005, NATURE, V435, P207, DOI 10.1038/nature03459; Butte A.J., 2000, PAC S BIOCOMPUT, V5, P418; Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830; Crane R, 2008, P NATL ACAD SCI USA, V105, P15649, DOI 10.1073/pnas.0803685105; Domingos P., 2001, P 7 ACM SIGKDD INT C; EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032; Erdos P., 1960, EVOLUTION RANDOM GRA, V5, P17; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 1999, P 15 C UNC ART INT U; GETOOR L., 2003, J MACH LEARN RES, V3, P707; Ghahramani Z, 1998, ADAPTIVE PROCESSING; GHOSH R., 2011, P 4 ACM INT C WEB SE, P665, DOI 10.1145/1935826.1935917; GHOSH R., 2011, P 5 INT C WEBL SOC M; GOODMAN LA, 1961, ANN MATH STAT, V32, P148, DOI 10.1214/aoms/1177705148; Goyal A, 2010, P 3 ACM INT C WEB SE, P241, DOI 10.1145/1718487.1718518; Gruhl D., 2004, P 13 INT C WORLD WID, P491, DOI 10.1145/988672.988739; Heckathorn DD, 1997, SOC PROBL, V44, P174, DOI 10.1525/sp.1997.44.2.03x0221m; Hethcote HW, 2000, SIAM REV, V42, P599, DOI 10.1137/S0036144500371907; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Katz Elihu, 1955, PERSONAL INFLUENCE P; Kearns M, 2006, SCIENCE, V313, P824, DOI 10.1126/science.1127207; Kempe D, 2003, P 9 ACM SIGKDD INT C, P137; Khuller S, 1999, INFORM PROCESS LETT, V70, P39, DOI 10.1016/S0020-0190(99)00031-9; Knuth D, 1968, ART COMPUTER PROGRAM; Kumar R, 2004, COMMUN ACM, V47, P35, DOI 10.1145/1035134.1035162; Leskovec J., 2009, P 15 ACM SIGKDD INT, P497, DOI DOI 10.1145/1557019.1557077; Leskovec J, 2007, ACM T WEB, V1, DOI 10.1145/1232722.1232727; LESKOVEC J., 2007, P 24 INT C MACH LEAR, P504; Leskovec J, 2008, P 17 INT C WORLD WID; LESKOVEC J, 2007, P 13 ACM SIGKDD INT, P420, DOI 10.1145/1281192.1281239; LESKOVEC J, 2006, P 7 ACM C EL COMM EC, P228, DOI 10.1145/1134707.1134732; LESKOVEC J., 2006, P 10 PAC AS C KNOWL, P380; Leskovec J, 2005, P 11 ACM SIGKDD INT; LESKOVEC J., 2007, P SIAM C DAT MIN SDM; Liben-Nowell D, 2008, P NATL ACAD SCI USA, V105, P4633, DOI 10.1073/pnas.0708471105; Liben-Nowell D., 2003, P 12 INT C INF KNOWL, P556; LIPPERT C., 2009, P INT C ART INT STAT; Malmgren RD, 2008, P NATL ACAD SCI USA, V105, P18153, DOI 10.1073/pnas.0800332105; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; MYERS S., 2010, P C ADV NEUR INF PRO; NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971; Rogers E. M., 1995, DIFFUSION INNOVATION; Romero D. M., 2011, P 20 INT C WORLD WID, P695, DOI DOI 10.1145/1963405.1963503; SADIKOV S., 2011, P ACM INT C WEB SEAR; SCHMIDT M., 2007, P 21 C ART INT AAAI, V22; Scholkopf B, 2011, P 28 INT C MACH LEAR, P561; SONG L., 2009, P C ADV NEUR INF PRO; Strang D, 1998, ANNU REV SOCIOL, V24, P265, DOI 10.1146/annurev.soc.24.1.265; TASKAR B., 2003, P C ADV NEUR INF PRO; TUTTE W., 1948, P CAMBRIDGE PHILOS S, V44, P63; VERT J., 2005, P C ADV NEUR INF PRO; WAINWRIGHT M. J., 2006, P NAT ACAD SCI; Wallinga J, 2004, AM J EPIDEMIOL, V160, P509, DOI 10.1093/aje/kwh255; Watts DJ, 2007, J CONSUM RES, V34, P441, DOI 10.1086/518527	62	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2012	5	4			SI				21	10.1145/2086737.2086741		37	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	895WE	WOS:000300526600004	
J	Huh, S; Fienberg, SE				Huh, Seungil; Fienberg, Stephen E.			Discriminative Topic Modeling Based on Manifold Learning	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Topic modeling; dimensionality reduction; document clustering and classification; semisupervised learning	NONLINEAR DIMENSIONALITY REDUCTION; GEOMETRIC FRAMEWORK	Topic modeling has become a popular method used for data analysis in various domains including text documents. Previous topic model approaches, such as probabilistic Latent Semantic Analysis (pLSA) and Latent Dirichlet Allocation (LDA), have shown impressive success in discovering low-rank hidden structures for modeling text documents. These approaches, however do not take into account the manifold structure of the data, which is generally informative for nonlinear dimensionality reduction mapping. More recent topic model approaches, Laplacian PLSI (LapPLSI) and Locally-consistent Topic Model (LTM), have incorporated the local manifold structure into topic models and have shown resulting benefits. But they fall short of achieving full discriminating power of manifold learning as they only enhance the proximity between the low-rank representations of neighboring pairs without any consideration for non-neighboring pairs. In this article, we propose a new approach, Discriminative Topic Model (DTM), which separates non-neighboring pairs from each other in addition to bringing neighboring pairs closer together, thereby preserving the global manifold structure as well as improving local consistency. We also present a novel model-fitting algorithm based on the generalized EM algorithm and the concept of Pareto improvement. We empirically demonstrate the success of DTM in terms of unsupervised clustering and semisupervised classification accuracies on text corpora and robustness to parameters compared to state-of-the-art techniques.	[Huh, Seungil; Fienberg, Stephen E.] Carnegie Mellon Univ, Pittsburgh, PA 15232 USA	Huh, S (reprint author), Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15232 USA.	seungilh@cs.cmu.edu; fienberg@stat.cmu.edu			Samsung	Seungil Huh is partially supported by a Samsung Fellowship.	Barr N., 2004, EC WELFARE STATE; BELKIN M., 2001, P C ADV NEUR INF PRO, P586; Belkin M, 2006, J MACH LEARN RES, V7, P2399; BENGIO Y., 2004, P C ADV NEUR INF PRO; BLEI D., 2008, P C ADV NEUR INF PRO, P121; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boley D, 1998, DATA MIN KNOWL DISC, V2, P325, DOI 10.1023/A:1009740529316; Cai D., 2008, P ACM C INF KNOWL MA, P911, DOI 10.1145/1458082.1458202; Cai D., 2009, P 26 ANN INT C MACH, P105; Chung F, 1997, SPECTRAL GRAPH THEOR; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Hinton G., 2002, P NEUR INF PROC SYST, P833; Hofmann T., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312649; Huh S., 2010, P ACM SIGKDD SPEC IN, P653, DOI 10.1145/1835804.1835888; Jolliffe I.T., 2002, SPRINGER SERIES STAT, VXXIX; Kuhn H., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109; Lacoste-Julien S., 2008, P C ADV NEUR INF PRO, P897; Lee D. D., 2000, P NEUR INF PROC SYST, P556; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SHA F., 2003, P C ADV NEUR INF PRO, P1041; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Trosset MW, 2008, COMPUT STAT DATA AN, V52, P4643, DOI 10.1016/j.csda.2008.02.030; VAN DER MAATEN M., 2008, J MACH LEARN RES, V9, P2579; Xu W, 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Zhou D., 2003, P ADV NEUR INF PROC, P321; ZHU J., 2009, P INT C MACH LEARN I; Zhu X, 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663	30	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2012	5	4			SI				20	10.1145/2086737.2086740		25	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	895WE	WOS:000300526600003	
J	Iwata, T; Yamada, T; Sakurai, Y; Ueda, N				Iwata, Tomoharu; Yamada, Takeshi; Sakurai, Yasushi; Ueda, Naonori			Sequential Modeling of Topic Dynamics with Multiple Timescales	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Topic model; time-series analysis; online learning; multiscale	TRACKING	We propose an online topic model for sequentially analyzing the time evolution of topics in document collections. Topics naturally evolve with multiple timescales. For example, some words may be used consistently over one hundred years, while other words emerge and disappear over periods of a few days. Thus, in the proposed model, current topic-specific distributions over words are assumed to be generated based on the multiscale word distributions of the previous epoch. Considering both the long- and short-timescale dependency yields a more robust model. We derive efficient online inference procedures based on a stochastic EM algorithm, in which the model is sequentially updated using newly obtained data; this means that past data are not required to make the inference. We demonstrate the effectiveness of the proposed method in terms of predictive performance and computational efficiency by examining collections of real documents with timestamps.			iwata.tomoharu@lab.ntt.co.jp					AHMED A., 2008, P SIAM INT C DAT MIN; AHMED A., 2010, P 26 INT C UNC ART I; AlSumait L, 2008, IEEE DATA MINING, P3, DOI 10.1109/ICDM.2008.140; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; BANERJEE A., 2007, P SIAM INT C DAT MIN; Blei D, 2006, P 23 INT C MACH LEAR, P113, DOI DOI 10.1145/1143844.1143859; BLEI D., 2010, P INT C MACH LEARN I; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Canini K. R., 2009, P AISTATS2009, V5, P65; GERRISH S., 2010, P INT C MACH LEARN A; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; HOFFMAN M., 2010, P C ADV NEUR INF PRO; Hofmann T., 1999, P 15 C UNC ART INT U, P289; Hofmann T, 2003, P 26 ANN INT ACM SIG, P259; IWATA T., 2009, P IJCAI 09, P1427; Iwata T., 2008, P KDD, P363, DOI 10.1145/1401890.1401937; Minka T. P., 2000, ESTIMATING DIRICHLET; Nallapati RM, 2007, P 13 ACM SIGKDD INT, P520, DOI 10.1145/1281192.1281249; Papadimitriou S., 2003, P INT C VER LARG DAT, P560, DOI 10.1016/B978-012722442-8/50056-2; Papadimitriou S., 2005, P 31 INT C VER LARG, P697; Ren L., 2008, P 25 INT C MACH LEAR, P824, DOI 10.1145/1390156.1390260; Sakurai Y., 2005, P ACM SIGMOD BALT MA, P599, DOI DOI 10.1145/1066157.1066226; SATO I., 2010, P C ADV NEUR INF PRO; Stephens M, 2000, J ROY STAT SOC B, V62, P795, DOI 10.1111/1467-9868.00265; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Wang C, 2008, P UAI 08, P579; Wang X., 2006, P 12 ACM SIGKDD INT, P424, DOI 10.1145/1150402.1150450; Watanabe S, 2011, COMPUT SPEECH LANG, V25, P440, DOI 10.1016/j.csl.2010.07.006; Wei X, 2007, P IJCAI 07, P2909; Zhang J, 2010, P 16 ACM SIGKDD INT, P1079, DOI 10.1145/1835804.1835940	30	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2012	5	4			SI				19	10.1145/2086737.2086739		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	895WE	WOS:000300526600002	
J	Shahaf, D; Guestrin, C				Shahaf, Dafna; Guestrin, Carlos			Connecting Two (or Less) Dots: Discovering Structure in News Articles	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Coherence	WEB	Finding information is becoming a major part of our daily life. Entire sectors, from Web users to scientists and intelligence analysts, are increasingly struggling to keep up with the larger and larger amounts of content published every day. With this much data, it is often easy to miss the big picture. In this article, we investigate methods for automatically connecting the dots providing a structured, easy way to navigate within a new topic and discover hidden connections. We focus on the news domain: given two news articles, our system automatically finds a coherent chain linking them together. For example, it can recover the chain of events starting with the decline of home prices (January 2007), and ending with the health care debate (2009). We formalize the characteristics of a good chain and provide a fast search-driven algorithm to connect two fixed endpoints. We incorporate user feedback into our framework, allowing the stories to be refined and personalized. We also provide a method to handle partially-specified endpoints, for users who do not know both ends of a story. Finally, we evaluate our algorithm over real news data. Our user studies demonstrate that the objective we propose captures the users' intuitive notion of coherence, and that our algorithm effectively helps users understand the news.	[Shahaf, Dafna; Guestrin, Carlos] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Shahaf, D (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	dshahaf@cs.cmu.edu			ONR YIP [N00014-08-1-0752]; ARO MURI [W911NF0810242]; NSF [IIS-0644225]; Microsoft	This work was partially supported by ONR YIP N00014-08-1-0752, ARO MURI W911NF0810242, and NSF Career IIS-0644225. Dafna Shahaf was supported in part by a Microsoft Research Graduate Fellowship.	Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; CARBONELL J., 1998, P ANN ACM SIGIR C RE; CHOUDHARY R., 2008, P EUR C IR RES ECIR, P422; DECHTER R, 1985, J ACM, V32, P505, DOI 10.1145/3828.3830; EL-ARINI K., 2009, P 15 ACM SIGKDD INT, P289, DOI 10.1145/1557019.1557056; Faloutsos C., 2004, P 10 ACM SIGKDD INT, P118, DOI 10.1145/1014052.1014068; Gabrilovich E., 2004, P 13 INT C WORLD WID, P482, DOI 10.1145/988672.988738; Heath K, 2010, PROC CVPR IEEE, P3432, DOI 10.1109/CVPR.2010.5539991; HOSSAIN M. S., 2010, COMPUTING RES REPOSI; Kempe D, 2003, P 9 ACM SIGKDD INT C, P137; Khuller S, 1999, INFORM PROCESS LETT, V70, P39, DOI 10.1016/S0020-0190(99)00031-9; Kleinberg J., 2002, P 8 ACM SIGKDD INT C; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Kumar D, 2006, P 12 ACM SIGKDD INT, P604, DOI 10.1145/1150402.1150475; Lewis DD, 1997, INFORM PROCESS MANAG, V33, P209, DOI 10.1016/S0306-4573(96)00063-5; Masand B., 1992, P 15 ANN INT ACM SIG, P59, DOI 10.1145/133160.133177; McCallum AK, 2002, MALLET MACHINE LEARN; MEI Q, 2005, P 11 ACM SIGKDD INT, P98; Mitchell TM, 2009, LECT NOTES COMPUT SC, V5823, P998, DOI 10.1007/978-3-642-04930-9_66; Nallapati R., 2004, P 13 ACM INT C INF K, P446, DOI 10.1145/1031171.1031258; NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971; NIEHAUS J., 2009, P NAT C ART INT SPRI; ROWE J. P., 2009, P NAT C ART INT SPRI; Shahaf D., 2010, P 6 ACM SIGKDD INT C, P623, DOI 10.1145/1835804.1835884; Turner S., 1994, CREATIVE PROCESS COM; VATS N., 2004, 2004489 QUEENS U SCH; Yang CC, 2006, LECT NOTES COMPUT SC, V3975, P343; Yang Yiming, 2000, P 23 ANN INT ACM SIG, P65, DOI 10.1145/345508.345550; Yang YM, 1999, IEEE INTELL SYST APP, V14, P32, DOI 10.1109/5254.784083	30	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2012	5	4			SI				24	10.1145/2086737.2086744		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	895WE	WOS:000300526600007	
J	Yu, HF; Hsieh, CJ; Chang, KW; Lin, CJ				Yu, Hsiang-Fu; Hsieh, Cho-Jui; Chang, Kai-Wei; Lin, Chih-Jen			Large Linear Classification When Data Cannot Fit in Memory	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Block minimization methods; large-scale learning; linear classification; support vector machines	SUPPORT VECTOR MACHINES	Recent advances in linear classification have shown that for applications such as document classification, the training process can be extremely efficient. However, most of the existing training methods are designed by assuming that data can be stored in the computer memory. These methods cannot be easily applied to data larger than the memory capacity due to the random access to the disk. We propose and analyze a block minimization framework for data larger than the memory size. At each step a block of data is loaded from the disk and handled by certain learning methods. We investigate two implementations of the proposed framework for primal and dual SVMs, respectively. Because data cannot fit in memory, many design considerations are very different from those for traditional algorithms. We discuss and compare with existing approaches that are able to handle data larger than memory. Experiments using data sets 20 times larger than the memory demonstrate the effectiveness of the proposed method.	[Yu, Hsiang-Fu; Hsieh, Cho-Jui; Chang, Kai-Wei; Lin, Chih-Jen] Natl Taiwan Univ, Dept Comp Sci, Taipei 106, Taiwan	Yu, HF (reprint author), Natl Taiwan Univ, Dept Comp Sci, Taipei 106, Taiwan.	b93107@cise.ntu.edu.tw; b92085@cise.ntu.edu.tw; b92084@cise.ntu.edu.tw; cjlin@cise.ntu.edu.tw			National Science Council of Taiwan [98-2221-E-002-136-MY3]	This work was supported in part by the National Science Council of Taiwan via the grant 98-2221-E-002-136-MY3.	Bertsekas D.P., 1999, NONLINEAR PROGRAMMIN; Bottou L, 2007, STOCHASTIC GRADIENT; Boyd S., 2004, CONVEX OPTIMIZATION; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chakrabarti D., 2008, P 17 INT C WORLD WID, P417, DOI 10.1145/1367497.1367554; Chang C, 2011, ACM T INTEL SYST TEC, V2, P1, DOI DOI 10.1145/1961189.1961199; Chang E., 2008, ADV NEURAL INFORM PR, V20, P257; CHANG K.-W., 2011, P 17 ACM SIGICDD INT; CHEN W., 2009, P IEEE INT C DAT MIN; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Ferris MC, 2003, SIAM J OPTIMIZ, V13, P783; Hsieh C.-J., 2008, P 25 INT C MACH LEAR; HSIEH H.-P., 2010, JMLR WORKSH IN PRESS; Joachims T, 2006, P 12 ACM SIGKDD INT; JOACHIMS T., 1998, ADV KERNEL METHODS S, P169; KEERTHI S. S., 2008, P 14 ACM SIGKDD INT; Langford J., 2009, ADV NEURAL INFORM PR, V22, P2331; Langford J., 2009, J MACH LEARN RES, V10, P771; Langford J., 2007, VOWPAL WABBIT; LI P., 2010, P 19 INT C WORLD WID, P671, DOI 10.1145/1772690.1772759; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; Memisevic R., 2006, DUAL OPTIMIZATION CO; Morse K. G., 2005, LINUX J; PEREZ-CRUZ F., 2004, P LEARN; ROPING S., 2000, MYSVM ANOTHER ONE TH; Serafini T, 2005, OPTIM METHOD SOFTW, V20, P583, DOI 10.1080/10556780500140714; Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4; Tong S., 2010, LESSONS LEARNED DEV; Yu H, 2003, P 9 ACM SIGKDD INT C; Yu Hsiang-Fu, 2010, P 16 ACM SIGKDD INT; YUAN G.-X., 2011, P IEEE UNPUB; Zhang T, 2002, MACH LEARN, V46, P91, DOI 10.1023/A:1012498226479; Zinkevich M. A., 2010, ADV NEURAL INFORM PR, V23, P2595	34	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2012	5	4			SI				23	10.1145/2086737.2086743		23	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	895WE	WOS:000300526600006	
J	Jimenez, A; Berzal, F; Cubero, JC				Jimenez, Aida; Berzal, Fernando; Cubero, Juan-Carlos			Using trees to mine multirelational databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Multirelational databases; Frequent itemset mining; Association rules; Tree pattern mining	FREQUENT; CLASSIFICATION; PATTERNS; MODEL	This paper proposes a new approach to mine multirelational databases. Our approach is based on the representation of multirelational databases as sets of trees, for which we propose two alternative representation schemes. Tree mining techniques can thus be applied as the basis for multirelational data mining techniques, such as multirelational classification or multirelational clustering. We analyze the differences between identifying induced and embedded tree patterns in the proposed tree-based representation schemes and we study the relationships among the sets of tree patterns that can be discovered in each case. This paper also describes how these frequent tree patterns can be used, for instance, to mine association rules in multirelational databases.	[Jimenez, Aida; Berzal, Fernando; Cubero, Juan-Carlos] Univ Granada, ETSIIT, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Jimenez, A (reprint author), Univ Granada, ETSIIT, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	aidajm@decsai.ugr.es; fberzal@decsai.ugr.es; jc.cubero@decsai.ugr.es	Cubero, Juan-Carlos/C-2413-2012; Berzal, Fernando/C-6078-2012		Spanish Ministry of Science and Innovation [TIN2006-07262, TIN2009-08296]; Junta de Andalucia [P07-TIC-03175]	We would like to thank the anonymous referees for their valuable comments and suggestions, which gave us the chance to improve the quality of this manuscript. This work has been partially supported by research projects TIN2006-07262 (Spanish Ministry of Science and Innovation), TIN2009-08296 (Spanish Ministry of Science and Innovation), and P07-TIC-03175 (Junta de Andalucia).	Abe K., 2002, P 2 SIAM INT C DAT M, P158; Agrawal R., 1994, P 20 INT C VER LARG, P487; BAYARDO RJ, 2004, LECT NOTES ARTIF INT, P1; Berzal F, 2004, MACH LEARN, V54, P67, DOI 10.1023/B:MACH.0000008085.22487.a6; Berzal F., 2002, Intelligent Data Analysis, V6; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; Booch G, 2005, UNIFIED MODELING LAN; Chi Y., 2003, P 3 IEEE INT C DAT M, P509, DOI DOI 10.1109/ICDM.2003.1250964; Chi Y, 2005, FUND INFORM, V66, P161; Codd E.F., 1990, RELATIONAL MODEL DAT; DEKNIJF J, 2007, P 2007 ACM S APPL CO, P417, DOI 10.1145/1244002.1244099; DEKNIJF J, 2006, UUCS2006053 UTR U DE; Dzeroski S., 2003, SIGKDD EXPLORATIONS, V5, P1; FAGIN R, 1982, ACM T DATABASE SYST, V7, P343, DOI 10.1145/319732.319735; Garcia-Molina H., 2008, DATABASE SYSTEMS COM; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Jimenez A, 2010, KNOWL INF SYST, V23, P199, DOI 10.1007/s10115-009-0213-3; Jimenez A, 2010, INTELL DATA ANAL, V14, P603, DOI 10.3233/IDA-2010-0443; King RD, 2001, J COMPUT AID MOL DES, V15, P173, DOI 10.1023/A:1008171016861; KROGEL MA, 2003, 13 INT C IND LOG PRO; Lee AJT, 2007, INFORM SCIENCES, V177, P3453, DOI 10.1016/j.ins.2007.03.007; Leiva H. A., 2002, P 13 INT C IND LOG P, P38; MAIER D, 1983, ACM T DATABASE SYST, V8, P1, DOI 10.1145/319830.319831; MAIER D, 1984, ACM T DATABASE SYST, V9, P283, DOI 10.1145/329.318580; McGovern A, 2008, IEEE DATA MINING, P935, DOI 10.1109/ICDM.2008.134; Neville J., 2003, P 9 ACM SIGKDD INT C, P625; Paterson Jim, 2006, DEFINITIVE GUIDE DB4; Pei J., 2002, SIGKDD EXPLORATIONS, V4, P31; Perlich C, 2006, MACH LEARN, V62, P65, DOI 10.1007/s10994-006-6064-1; SILBERSCHATZ A, 2001, DATABASE SYSTEMS CON; SRIKANT R, 1997, P 3 INT C KNOWL DISC, P63; Srinivasan A., 1994, GMD STUDIEN, V237, P217; Tung AKH, 2003, IEEE T KNOWL DATA EN, V15, P43, DOI 10.1109/TKDE.2003.1161581; TURMEAUX T, 2003, P 7 EUR C PRINC PRAC, P471; Ullman J. D., 1988, PRINCIPLES DATABASE, VI; Ullman J.D, 1990, PRINCIPLES DATABASE, VII; Wang C, 2004, LECT NOTES ARTIF INT, V3056, P441; Xiao Y., 2003, P 3 IEEE INT C DAT M, P379; Yin X., 2005, P 2005 ACM SIGKDD IN, P344, DOI 10.1145/1081870.1081910; Yin XX, 2004, PROC INT CONF DATA, P399; Zaki MJ, 2005, IEEE T KNOWL DATA EN, V17, P1021, DOI 10.1109/TKDE.2005.125; Zaki MJ, 2005, FUND INFORM, V66, P33	42	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					1	39		10.1007/s10618-011-0218-x		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700001	
J	Park, SH; Furnkranz, J				Park, Sang-Hyeun; Fuernkranz, Johannes			Efficient prediction algorithms for binary decomposition techniques	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Binary decomposition; Pairwise classification; Ternary ECOC; Multiclass classification; Aggregation; Efficient decoding; Efficient voting	MULTICLASS CLASSIFICATION; CLASSIFIERS; CODES	Binary decomposition methods transform multiclass learning problems into a series of two-class learning problems that can be solved with simpler learning algorithms. As the number of such binary learning problems often grows super-linearly with the number of classes, we need efficient methods for computing the predictions. In this article, we discuss an efficient algorithm that queries only a dynamically determined subset of the trained classifiers, but still predicts the same classes that would have been predicted if all classifiers had been queried. The algorithm is first derived for the simple case of pairwise classification, and then generalized to arbitrary pairwise decompositions of the learning problem in the form of ternary error-correcting output codes under a variety of different code designs and decoding strategies.	[Park, Sang-Hyeun; Fuernkranz, Johannes] Tech Univ Darmstadt, Dept Comp Sci, Knowledge Engn Grp, Darmstadt, Germany	Park, SH (reprint author), Tech Univ Darmstadt, Dept Comp Sci, Knowledge Engn Grp, Darmstadt, Germany.	park@ke.tu-darmstadt.de; juffi@ke.tu-darmstadt.de			German Science Foundation (DFG)	We would like to thank the anonymous reviewers for their helpful suggestions and the Frankfurt Center for Scientific Computing for providing computational resources. This research was supported by the German Science Foundation (DFG).	Allwein E.L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Bose R.C., 1960, Information and Control, V3, DOI 10.1016/S0019-9958(60)90287-4; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Cardoso JS, 2007, J MACH LEARN RES, V8, P1393; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; Cutzu F, 2003, LECT NOTES COMPUT SC, V2714, P375; Cutzu F, 2003, LECT NOTES COMPUT SC, V2709, P115; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; ESCALERA S, 2006, LECT NOTES COMPUT SC, P753; Escalera S, 2010, IEEE T PATTERN ANAL, V32, P120, DOI 10.1109/TPAMI.2008.266; Frank A., 2010, UCI MACHINE LEARNING; Furnkranz J., 2003, Intelligent Data Analysis, V7; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Gallager R. G., 1968, INFORM THEORY RELIAB; GHANI R, 2001, THESIS CARNEGIE MELL; HASTIE T, 1997, ADV NEURAL INFORM PR, V10; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Hsu D., 2009, ADV NEURAL INFORM PR, V22, P772; Hullermeier E., 2004, P 10 INT C INF PROC; Hullermeier E, 2008, ARTIF INTELL, V172, P1897, DOI 10.1016/j.artint.2008.08.002; Kong E. B., 1995, P 12 INT C MACH LEAR, P313; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Lorena AC, 2008, ARTIF INTELL REV, V30, P19, DOI 10.1007/s10462-009-9114-9; MacWilliams F.J., 1983, THEORY ERROR CORRECT; Melvin I, 2007, J MACH LEARN RES, V8, P1557; Mencia EL, 2010, NEUROCOMPUTING, V73, P1164, DOI 10.1016/j.neucom.2009.11.024; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Park S.-H., 2007, P 18 EUR C MACH LEAR, P658; PARK SH, 2007, TUDKE200703 KNOWL EN; PARK SH, 2009, P EUR C MACH LEARN P, P189; Pimenta E, 2008, INT J ARTIF INTELL T, V17, P433, DOI 10.1142/S0218213008003984; Platt JC, 2000, ADV NEUR IN, V12, P547; PUJOL O, 2006, IEEE T PATTERN ANAL, V28, P10071; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Smith R.S., 2005, LECT NOTES COMPUT SC, P53; Windeatt T., 2003, Information Fusion, V4, DOI 10.1016/S1566-2535(02)00101-X; Witten IH, 2005, DATA MINING PRACTICA; Wu TF, 2004, J MACH LEARN RES, V5, P975; Yang Y, 1997, P 14 INT C MACH LEAR, P412	40	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					40	77		10.1007/s10618-011-0219-9		38	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700002	
J	Takada, T				Takada, Teruko			Mining local and tail dependence structures based on pointwise mutual information	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Nonparametric density estimation; Adaptive kernel; Risk control; Stock price changes; Volume; Dependence structure; Data visualization	DENSITY ESTIMATORS; TIME-SERIES; MODELS; VOLUME	The behavior of events that occur infrequently but have a large impact tends to differ from that of the central tendency, and identifying the tail dependence structure among key factors is critical for controlling risks. However, due to technical difficulties, conventional analyses of dependence have focused on the global average dependence. This article proposes a novel approach for analyzing the entire structure of nonlinear dependence between two data sets on the basis of accurate pointwise mutual information estimation. The emphasis is on fat-tailed distributions that tend to appear in events involving sudden large changes. The proposed pointwise mutual information estimator is sufficiently robust and efficient for exploring tail dependence, and its good performance was confirmed in an experimental study. The significance of the identified dependence structure was assessed using the proposed bootstrap procedure. New facts were discovered from its application to daily returns and volume on the New York stock Exchange (NYSE) Composite Index.	Osaka City Univ, Grad Sch Business, Osaka 558, Japan	Takada, T (reprint author), Osaka City Univ, Grad Sch Business, Osaka 558, Japan.	takada@bus.osaka-cu.ac.jp			Ishii Memorial Securities Research Promotion Foundation; Japan Society for the Promotion of Science; Japan Science and Technology Agency (PRESTO)	The author is deeply grateful to Roger Koenker and Shoji Takada for their many helpful suggestions and constructive comments. The author also wishes to thank the anonymous reviewers for their fruitful comments for improving this article. Financial support to the author from Ishii Memorial Securities Research Promotion Foundation, the Japan Society for the Promotion of Science (Grant-in-Aid for Scientific Research) and the Japan Science and Technology Agency (PRESTO) are gratefully acknowledged.	ABRAMSON IS, 1982, ANN STAT, V10, P1217, DOI 10.1214/aos/1176345986; Afshin-Pour B, 2011, HUM BRAIN MAPP, V32, P699, DOI 10.1002/hbm.21057; Barahona M, 1996, NATURE, V381, P215, DOI 10.1038/381215a0; BASU A, 1994, ANN I STAT MATH, V46, P683, DOI 10.1007/BF00773476; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; BREIMAN L, 1977, TECHNOMETRICS, V19, P135, DOI 10.2307/1268623; Charpentier A, 2009, J MULTIVARIATE ANAL, V100, P1521, DOI 10.1016/j.jmva.2008.12.015; Chaudhuri P, 2000, ANN STAT, V28, P408; CHERUBINI U, 2004, COPULAS METHODS FINA; Cover T.M., 2006, ELEMENTS INFORM THEO; Efron B., 1993, INTRO BOOTSTRAP; FRASER AM, 1986, PHYS REV A, V33, P1134, DOI 10.1103/PhysRevA.33.1134; Fukunaga K., 1972, INTRO STAT PATTERN R; GALLANT AR, 1992, REV FINANC STUD, V5, P199, DOI 10.1093/rfs/5.2.199; Gudendorf G., 2010, LECT NOTES STAT, V198, P127; Hlavackova-Schindler K, 2007, PHYS REP, V441, P1, DOI 10.1016/j.physrep.2006.12.004; Huisman R, 2001, J BUS ECON STAT, V19, P208, DOI 10.1198/073500101316970421; HWANG JN, 1994, IEEE T SIGNAL PROCES, V42, P2795; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Jeong J, 2001, CLIN NEUROPHYSIOL, V112, P827, DOI 10.1016/S1388-2457(01)00513-2; Joe H, 2010, J MULTIVARIATE ANAL, V101, P252, DOI 10.1016/j.jmva.2009.08.002; KARPOFF JM, 1987, J FINANC QUANT ANAL, V22, P109, DOI 10.2307/2330874; Khan S, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.026209; Kluppelberg C, 2007, BERNOULLI, V13, P229, DOI 10.3150/07-BEJ6047; Kotz S., 2004, MULTIVARIATE T DISTR; Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138; Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861; Lin CH, 2008, NONLINEAR ANAL-REAL, V9, P1702, DOI 10.1016/j.nonrwa.2007.05.011; Lindeberg T., 1994, SCALE SPACE THEORY C; Malevergne Y, 2006, EXTREME FINANCIAL RI; March TK, 2005, GEOPHYS RES LETT, V32, DOI 10.1029/2004GL021677; Mari D. D., 2001, CORRELATION DEPENDEN, P518; McNeil AJ, 2005, PRINC SER FINANC, P1; MOON YI, 1995, PHYS REV E, V52, P2318, DOI 10.1103/PhysRevE.52.2318; Nelsen R.B., 2006, INTRO COPULAS; Palus M, 2001, PHYS REV E, V63, part. no., DOI 10.1103/PhysRevE.63.046211; Papana Angeliki, 2008, Nonlinear Phenomena in Complex Systems, V11; Patton AJ, 2009, HDB FINANCIAL TIME S, P767, DOI 10.1007/978-3-540-71297-8_34; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; ROUSSEEUW PJ, 1990, J AM STAT ASSOC, V85, P633, DOI 10.2307/2289995; SHANNON CE, 1948, AT&T TECH J, V27, P379; Silverman B. W., 1986, DENSITY ESTIMATION S; Suzuki T, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-S1-S52; Takada T, 2008, ECONOMET J, V11, P573, DOI 10.1111/j.1368-423X.2008.00249.x; Takada T, 2009, COMPUT STAT DATA AN, V53, P2390, DOI 10.1016/j.csda.2008.06.017; TAKADA T, 2001, THESIS U ILLINOIS UR; Wicks RT, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.051125	47	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					78	102		10.1007/s10618-011-0220-3		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700003	
J	Xiong, TK; Wang, SR; Mayers, A; Monga, E				Xiong, Tengke; Wang, Shengrui; Mayers, Andre; Monga, Ernest			DHCC: Divisive hierarchical clustering of categorical data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Categorical data; Divisive hierarchical clustering; Subspace clustering	ALGORITHMS; NUMBER	Clustering categorical data poses two challenges defining an inherently meaningful similarity measure, and effectively dealing with clusters which are often embedded in different subspaces. In this paper, we propose a novel divisive hierarchical clustering algorithm for categorical data, named DHCC. We view the task of clustering categorical data from an optimization perspective, and propose effective procedures to initialize and refine the splitting of clusters. The initialization of the splitting is based on multiple correspondence analysis (MCA). We also devise a strategy for deciding when to terminate the splitting process. The proposed algorithm has five merits. First, due to its hierarchical nature, our algorithm yields a dendrogram representing nested groupings of patterns and similarity levels at different granularities. Second, it is parameter-free, fully automatic and, in particular, requires no assumption regarding the number of clusters. Third, it is independent of the order in which the data is processed. Fourth, it is scalable to large data sets. And finally, our algorithm is capable of seamlessly discovering clusters embedded in subspaces, thanks to its use of a novel data representation and Chi-square dissimilarity measures. Experiments on both synthetic and real data demonstrate the superior performance of our algorithm.	[Xiong, Tengke; Wang, Shengrui; Mayers, Andre] Univ Sherbrooke, Dept Comp Sci, Sherbrooke, PQ J1K 2R1, Canada; [Monga, Ernest] Univ Sherbrooke, Dept Math, Sherbrooke, PQ J1K 2R1, Canada	Xiong, TK (reprint author), Univ Sherbrooke, Dept Comp Sci, Sherbrooke, PQ J1K 2R1, Canada.	tengke.xiong@usherbrooke.ca; shengrui.wang@usherbrooke.ca; andre.mayers@usherbrooke.ca; ernest.monga@usherbrooke.ca			Natural Sciences and Engineering Research Council of Canada [319372, 121680]	This work was supported by the Natural Sciences and Engineering Research Council of Canada Collaborative Research and Development Grant No. 319372 and Discovery Grant No. 121680. The authors are grateful to the anonymous reviewers for their invaluable comments.	Abdi H., 2007, ENCY MEASUREMENT STA; Aggarwal C., 1999, P 1999 ACM SIGMOD IN, P61, DOI 10.1145/304182.304188; ANDRITSOS P, 2004, LECT NOTES COMPUTER; Barbara D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Bouguessa M, 2009, IEEE T KNOWL DATA EN, V21, P507, DOI 10.1109/TKDE.2008.162; Brand M, 2006, LINEAR ALGEBRA APPL, V415, P20, DOI 10.1016/j.laa.2005.07.021; Cesario E, 2007, IEEE T KNOWL DATA EN, V19, P1607, DOI 10.1109/TKDE.2007.190649; Chen HL, 2008, IEEE T KNOWL DATA EN, V20, P1458, DOI 10.1109/TKDE.2008.81; CHEN K, 2005, P INT C SCI STAT DAT, P253; CHEN K., 2006, P ACM C INF KNOWL MG, P367, DOI 10.1145/1183614.1183668; DAS K, 2007, P 13 ACM SIGKDD INT, P220, DOI 10.1145/1281192.1281219; Ding C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183896; DO H, 2008, LECT NOTES COMPUTER; Drineas P., 2003, LECT NOTES COMPUTER; Everitt B., 2001, CLUSTER ANAL, V4; Gan G., 2004, SIGKDD EXPLOR NEWSL, V6, P87; Ganti V., 1999, P 5 ACM SIGKDD INT C, P73, DOI 10.1145/312129.312201; Grabmeier J, 2002, DATA MIN KNOWL DISC, V6, P303, DOI 10.1023/A:1016308404627; Greenacre M, 2006, MULTIPLE CORRES ANAL; Greenacre M. J., 1993, CORRES ANAL PRACTICE; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Huang JZX, 2005, IEEE T PATTERN ANAL, V27, P657, DOI 10.1109/TPAMI.2005.95; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jin RM, 2009, KNOWL INF SYST, V19, P1, DOI 10.1007/s10115-008-0142-6; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; LI T., 2004, P 21 INT C MACH LEAR, P536; Lu YP, 2011, MACH LEARN, V82, P43, DOI 10.1007/s10994-009-5154-2; MESSAOUD R, 2006, P 12 ACM SIGKDD INT, P662, DOI 10.1145/1150402.1150484; Parsons L, 2004, ACM SIGKDD EXPLORATI, V6, P90, DOI 10.1145/1007730.1007731; Salvador S, 2004, PROC INT C TOOLS ART, P576; San O., 2004, INT J APPL MATH COMP, V14, P241; Sun HJ, 2004, PATTERN RECOGN, V37, P2027, DOI 10.1016/j.patcog.2004.03.012; Tan P.N, 2005, INTRO DATA MINING; Wang K, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P483, DOI 10.1145/319950.320054; Wu JJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P877; XIONG T, 2008, P KDD2008 WORKSH DAT, P32; Xiong TK, 2009, IEEE DATA MINING, P1058, DOI 10.1109/ICDM.2009.118; Yang Y., 2002, P 8 ACM SIGKDD INT C, P682; Zhao Y, 2005, DATA MIN KNOWL DISC, V10, P141, DOI 10.1007/s10618-005-0361-3	40	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					103	135		10.1007/s10618-011-0221-2		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700004	
J	Cieslak, DA; Hoens, TR; Chawla, NV; Kegelmeyer, WP				Cieslak, David A.; Hoens, T. Ryan; Chawla, Nitesh V.; Kegelmeyer, W. Philip			Hellinger distance decision trees are robust and skew-insensitive	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Imbalanced data; Decision tree; Hellinger distance	CLASSIFICATION LEARNING ALGORITHMS; CLASSIFIERS; TESTS	Learning from imbalanced data is an important and common problem. Decision trees, supplemented with sampling techniques, have proven to be an effective way to address the imbalanced data problem. Despite their effectiveness, however, sampling methods add complexity and the need for parameter selection. To bypass these difficulties we propose a new decision tree technique called Hellinger Distance Decision Trees (HDDT) which uses Hellinger distance as the splitting criterion. We analytically and empirically demonstrate the strong skew insensitivity of Hellinger distance and its advantages over popular alternatives such as entropy (gain ratio). We apply a comprehensive empirical evaluation framework testing against commonly used sampling and ensemble methods, considering performance across 58 varied datasets. We demonstrate the superiority (using robust tests of statistical significance) of HDDT on imbalanced data, as well as its competitive performance on balanced datasets. We thereby arrive at the particularly practical conclusion that for imbalanced data it is sufficient to use Hellinger trees with bagging (BG) without any sampling methods. We provide all the datasets and software for this paper online (http://www.nd.edu/similar to dial/hddt).	[Cieslak, David A.; Hoens, T. Ryan; Chawla, Nitesh V.; Kegelmeyer, W. Philip] Univ Notre Dame, Notre Dame, IN 46556 USA	Chawla, NV (reprint author), Univ Notre Dame, Notre Dame, IN 46556 USA.	nchawla@cse.nd.edu			NSF [ECCS-0926170]; US Department of Energy through ASC CSEE [DE-AC04-76DO00789]; Arthur J. Schmitt Fellowship	This work was supported in part by the Arthur J. Schmitt Fellowship, NSF ECCS-0926170, and the US Department of Energy through the ASC CSEE Data Discovery Program, administered by Sandia National Laboratories, contract number: DE-AC04-76DO00789. The authors would like to thank Ken Buch for his help with Avatar Tools, in addition to the reviewers and editor assigned to refereeing this report for their helpful feedback.	Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; ASUNCION A., 2007, UCI MACHINE LEARNING; BANFIELD R, 2007, IEEE T PATTERN ANAL, V29, P832; Batista G. E., 2004, SIGKDD EXPLORATIONS, V6, P20, DOI DOI 10.1145/1007730.1007735; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1998, ANN STAT, V26, P841; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chawla NV, 2008, DATA MIN KNOWL DISC, V17, P225, DOI 10.1007/s10618-008-0087-0; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; CHAWLA NV, 2003, ICML WORKSH LEARN IM, P1; Chawla NV, 2004, SIGKDD EXPLORATIONS, V6, P1; CIESLAK DA, 2008, EUR C MACH LEARN ECM, P241; CIESLAK DA, 2008, PAC AS C KNOWL DISC, P519; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich T.G., 1996, P 13 INT C MACH LEAR, P96; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Drummond C., 2003, ICML WORKSH LEARN IM, P1; Drummond C., 2000, ICML 2000, P239; FLACH PA, 2003, ICML, P194; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Halmos P. R., 1950, MEASURE THEORY; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HIDO S, 2008, STAT ANAL DATA MININ, P143; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HOLM S, 1979, SCAND J STAT, V6, P65; Japkowicz N, 2000, IC-AI'2000: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOL 1-III, P111; KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532; Kubat M., 1997, ICML, P179; NGUYEN X, 2007, ADV NEURAL INFORM PR, P1; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Quinlan R., 1986, MACH LEARN, V1, P81; Rao C. Radhakrishna, 1995, QUESTIIO, V19, P23; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Van Hulse J., 2007, ICML 07, P935; VILALTA R, 2000, ICML, P1087; Wu JJ, 2010, DATA MIN KNOWL DISC, V20, P191, DOI 10.1007/s10618-009-0146-1; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609	41	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					136	158		10.1007/s10618-011-0222-1		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700005	
J	Yoo, JS; Bow, M				Yoo, Jin Soung; Bow, Mark			Mining spatial colocation patterns: a different framework	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Spatial data mining; Spatial association patterns; Colocation mining	ITEMSETS	Recently, there has been considerable interest in mining spatial colocation patterns from large spatial datasets. Spatial colocation patterns represent the subsets of spatial events whose instances are often located in close geographic proximity. Most studies of spatial colocation mining require the specification of two parameter constraints to find interesting colocation patterns. One is a minimum prevalent threshold of colocations, and the other is a distance threshold to define spatial neighborhood. However, it is difficult for users to decide appropriate threshold values without prior knowledge of their task-specific spatial data. In this paper, we propose a different framework for spatial colocation pattern mining. To remove the first constraint, we propose the problem of finding N-most prevalent colocated event sets, where N is the desired number of colocated event sets with the highest interest measure values per each pattern size. We developed two alternative algorithms for mining the N-most patterns. They reduce candidate events effectively and use a filter-and-refine strategy for efficiently finding colocation instances from a spatial dataset. We prove the algorithms are correct and complete in finding the N-most prevalent colocation patterns. For the second constraint, a distance threshold for spatial neighborhood determination, we present various methods to estimate appropriate distance bounds from user input data. The result can help an user to set a distance for a conceptualization of spatial neighborhood. Our experimental results with real and synthetic datasets show that our algorithmic design is computationally effective in finding the N-most prevalent colocation patterns. The discovered patterns were different depending on the distance threshold, which shows that it is important to select appropriate neighbor distances.	[Yoo, Jin Soung; Bow, Mark] Indiana Univ Purdue Univ, Dept Comp Sci, Ft Wayne, IN 46805 USA	Yoo, JS (reprint author), Indiana Univ Purdue Univ, Dept Comp Sci, 2101 Coliseum Blvd E, Ft Wayne, IN 46805 USA.	yooj@ipfw.edu					Agarwal R., 1994, P INT C VER LARG DAT; APPICE A, 2003, P INT DAT AN; ARSHAD MU, 2006, IEEE INT C COMP SYST; BEMBENIK R, 2008, P INT INF PROC WEB M, P499; Berg M, 2000, COMPUTATIONAL GEOMET; CASTRO V, 1998, P INT PAC AS C KNOWL; CECI M, 2004, LECT NOTES COMPUTER, V3202; CHELGHOUM N, 2004, SPATIAL DATA MINING; Cheung YL, 2004, IEEE T KNOWL DATA EN, V16, P1052; Cormen T., 2003, INTRO ALGORITHMS; COVER T, 1995, KNOWL-BASED SYST, V6, P373; Cressie N.A.C., 1993, STAT SPATIAL DATA; DING W, 2008, P INT PAC AS C KNOWL; EASTER M, 1999, P INT C ART INT; EASTER MJ, 1991, P INT S ADV SPAT DAT; EICK CF, 2008, P 16 ACM SIGSPATIAL; FRANK R, 2009, P ACM INT C KNOWL DI; FU AW, 2000, INT S METH INT SYST; Gatrell A. C., 1995, INTERACTIVE SPATIAL; Goodchild M. F., 1986, SPATIAL AUTOCORRELAT; Griffith D, 1987, SPATIAL AUTOCORRELAT; Han J., 2000, P ACM SIGMOD C MAN D; HIRATE Y, 2004, P IEEE ICDM 04 WORKS; INOKUCHI A, 2000, P EUR C PRINC DAT MI; KOPERSKI K., 1995, P 4 INT S LARG SPAT, P47; KURAMOCHI M, 2001, P IEEE INT C DAT MIN; LI F, 2005, P 9 INT S ADV SPAT T; Miller H. J., 2001, GEOGRAPHIC DATA MINI; MILLER HJ, 2006, HDB GEOGRAPHIC INFOR; Morimoto Y, 2001, P ACM SIGKDD INT C K; Papadias D, 1997, INT J GEOGR INF SCI, V11, P111, DOI 10.1080/136588197242428; RIPLEY BD, 1976, J APPL PROBAB, V13, P255, DOI 10.2307/3212829; Santos MY, 2005, SOFT COMPUT, V9, P374, DOI 10.1007/s00500-004-0417-0; Schlossberg M, 2003, PLANNING PRACTICE RE, V18, P213, DOI 10.1080/0269745032000168269; Shekhar S, 2003, SPATIAL DATABASES TO; Shekhar S., 2004, DATA MINING NEXT GEN; SHEKHAR S, 2001, P INT S SPAT TEMP DA; TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141; TOOTS B, 1998, POINT PATTERN ANAL; Wan Y, 2008, INT J BUS INTELL DAT, V3, P375; Wang JY, 2005, IEEE T KNOWL DATA EN, V17, P652; Xiao X., 2008, P 16 ACM SIGSPATIAL; XIONG H, 2004, P SIAM INT C DAT MIN; YAN X, 2001, P IEEE INT C DAT MIN; Yoo J., 2004, P ACM INT S ADV GEOG; Yoo JS, 2009, P INT C DAT WAR KNOW; Yoo JS, 2006, IEEE T KNOWL DATA EN, V18, P1323, DOI 10.1109/TKDE.2006.150; ZHANG X, 2004, P ACM INT C KNOWL DI; ZOU L, 2000, P C INF KNOWL MAN; Zou S, 2005, P PAC AS C KNOWL DIS; *ESRI, ARCG; *US EPA, ENV INT TYP; *US EPA, US EPA ENV PROT AG F; CRIMESTAT; R STAT COMPUTING	55	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					159	194		10.1007/s10618-011-0223-0		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700006	
J	Bentham, J; Hand, DJ				Bentham, James; Hand, David J.			Data mining from a patient safety database: the lessons learned	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Knowledge Discovery; Data Mining; Information Extraction; Patient Safety	SPACE; MODEL	The issue of patient safety is an extremely important one; each year in the UK, hundreds of thousands of people suffer due to some sort of incident that occurs whilst they are in National Health Service care. The National Patient Safety Agency (NPSA) works to try to reduce the scale of the problem. One of its major projects is to collect a very large dataset, the Reporting and Learning System (RLS), which describes several million of these incidents. The RLS is used as the basis for research by the NPSA. However, the NPSA has identified a gap in their work between high-level quantitative analysis and detailed, manual analysis of small samples. This paper describes the lessons learned from a knowledge discovery process that attempted to fill this gap. The RLS contains a free text description of each incident. A high dimensional model of the text is calculated, using the vector space model with term weighting applied. Dimensionality reduction techniques are used to produce the final models of the text. These models are examined using an anomaly detection tool to find groups of incidents that should be coherent in meaning, and that might be of interest to the NPSA. A three stage process is developed for assessing the results. The first stage uses a quantitative measure based on the use of planted groups of known interest, the second stage involves manual filtering by a non-expert, and the third stage is assessment by clinical experts.	[Bentham, James] Kings Coll London, Dept Med & Mol Genet, London WC2R 2LS, England; [Hand, David J.] Univ London Imperial Coll Sci Technol & Med, Dept Math, London, England; [Hand, David J.] Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, London, England	Bentham, J (reprint author), Kings Coll London, Dept Med & Mol Genet, London WC2R 2LS, England.	james.bentham@kcl.ac.uk			EPSRC; NPSA; Royal Society	James Bentham would like to thank the EPSRC and NPSA for funding his CASE award. The work of David Hand was partially supported by a Royal Society Wolfson Research Merit Award. We would also like to thank two anonymous reviewers and an editor for their helpful comments.	Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Blum A, 1998, COLT, P92; Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; FOSTER J, 2008, P 46 ANN M ASS COMP, P221, DOI 10.3115/1557690.1557753; Hinneburg A., 2000, P 26 INT C VER LARG, P506; HONNIBAL M, 2009, P 2009 WORKSH PEOPL, P38, DOI 10.3115/1699765.1699771; Hyvarinen A., 2001, INDEPENDENT COMPONEN; LEASE M, 2005, 2 INT JOINT C NAT LA, P58; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Mannila H., 1996, Proceedings. Eighth International Conference on Scientific and Statistical Database Management (Cat. No.96TB100051), DOI 10.1109/SSDM.1996.505910; Manning CD, 2008, INTRO INFORM RETRIEV; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; Ripley B., 1996, PATTERN RECOGNITION; SAAD FH, 2006, P 2006 INT C DAT MIN; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salton G., 1983, INTRO MODERN INFORM; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Zhang X., 2008, INT J DATA WAREHOUS, V4, P62, DOI DOI 10.4018/JDWM.2008010104; ZHANG Z, 2005, P LNCS, P509; *DEP HLTH EXP GROU, 2000, ORG MEM	21	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					195	217		10.1007/s10618-011-0225-y		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700007	
J	Carmona, J				Carmona, Josep			Projection approaches to process mining using region-based techniques	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Process mining; Theory of regions; Petri nets	PETRI NETS; PROCESS MODELS; EVENT LOGS; SYSTEMS	Traces are everywhere from information systems that store their continuous executions, to any type of health care applications that record each patient's history. The transformation of a set of traces into a mathematical model that can be used for a formal reasoning is therefore of great value. The discovery of process models out of traces is an interesting problem that has received significant attention in the last years. This is a central problem in Process Mining, a novel area which tries to close the cycle between system design and validation, by resorting on methods for the automated discovery, analysis and extension of process models. In this work, algorithms for the derivation of a Petri net from a set of traces are presented. The methods are grounded on the theory of regions, which maps a model in the state-based domain (e.g., an automata) into a model in the event-based domain (e.g., a Petri net). When dealing with large examples, a direct application of the theory of regions will suffer from two problems: one is the state-explosion problem, i.e., the resources required by algorithms that work at the state-level are sometimes prohibitive. This paper introduces decomposition and projection techniques to alleviate the complexity of the region-based algorithms for Petri net discovery, thus extending its applicability to handle large inputs. A second problem is known as the overfitting problem for region-based approaches, which informally means that, in order to represent with high accuracy the trace set, the models obtained are often spaghetti-like. By focusing on special type of processes called conservative and for which an elegant theory and efficient algorithms can be devised, the techniques presented in this paper alleviate the overfitting problem and moreover incorporate structure into the models generated.	Univ Politecn Cataluna, Barcelona, Spain	Carmona, J (reprint author), Univ Politecn Cataluna, Barcelona, Spain.	jcarmona@lsi.upc.edu			FORMALISM [TIN2007-66523]; Intel Corporation	We would like to thank Jordi Cortadella and Mike Kishinevsky for interesting discussions, and Murali Talupur for providing the example of Sect. 5.1. The comments of the reviewers helped to improve considerably the paper. This work has been supported by the project FORMALISM (TIN2007-66523), and a grant by Intel Corporation.	Arnold Andre, 1994, FINITE TRANSITION SY; Badouel E, 1995, LECT NOTES COMPUT SC, V915, P364; Bergenthum R, 2008, FUND INFORM, V88, P437; CARMONA J, 2008, LSI0835R U POLITECNI; Carmona J, 2009, LECT NOTES COMPUT SC, V5701, P327; CARMONA J, 2008, 29 INT C APPL THEOR, V5062; Carmona J, 2010, IEEE T COMPUT, V59, P371, DOI 10.1109/TC.2009.131; Carmona J, 2008, LECT NOTES COMPUT SC, V5240, P358, DOI 10.1007/978-3-540-85758-7_26; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Cortadella J, 1998, IEEE T COMPUT, V47, P859, DOI 10.1109/12.707587; Cvetkovic D., 1997, EIGENSPACES GRAPHS; Desel J, 1996, ACTA INFORM, V33, P297, DOI 10.1007/s002360050046; DILL DL, 1992, COMPUTER AIDED VERIF, P522; DONGEN B, 2007, WORKSH FORM ASP BUS; EHRENFEUCHT A, 1990, ACTA INFORM, V27, P315, DOI 10.1007/BF00264611; Fiduccia CM, 1982, P 19 IEEE DES AUT C, P175, DOI 10.1145/800263.809204; Ghionna L, 2008, LECT NOTES ARTIF INT, V4994, P150; Greco G, 2006, IEEE T KNOWL DATA EN, V18, P1010, DOI 10.1109/TKDE.2006.123; Gunther C.W., 2009, THESIS TU EINDHOVEN; HACK M, 1972, THESIS MIT; HAREL D, 1987, SCI COMPUT PROGRAM, V8, P231, DOI 10.1016/0167-6423(87)90035-9; HOARE CAR, 1978, COMMUN ACM, V21, P666, DOI 10.1145/359576.359585; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kernighan B. W., 1970, Bell System Technical Journal, V49; Kindler E, 2006, LECT NOTES COMPUT SC, V4103, P105; Maruster L, 2006, DATA MIN KNOWL DISC, V13, P67, DOI 10.1007/s10618-005-0029-z; MCMILLAN K, 2001, LNCS, V2144, P179; MEDEIROS A, 2003, LECT NOTES COMPUTER, V2888, P389; Medeiros A., 2007, DATA MIN KNOWL DISC, V14, P245, DOI 10.1007/s10618-006-0061-7; MEDEIROS AA, 2008, LECT NOTES COMPUTER, V4928, P17; Milner R., 1980, LECT NOTES COMPUTER; Mukund M., 1992, International Journal of Foundations of Computer Science, V3, DOI 10.1142/S0129054192000231; MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143; PRETORIUS AJ, 2008, THESIS TU EINDHOVEN; Rozinat A, 2008, INFORM SYST, V33, P64, DOI 10.1016/j.is.2007.07.001; Schaefer M, 2007, THEOR COMPUT SCI, V388, P243, DOI 10.1016/j.tcs.2007.08.005; Silva M., 1998, LECT NOTES COMPUTER, V1491, P309; Talupur M, 2008, FORMAL METHODS COMPU, P1; van der Aalst W, 2004, IEEE T KNOWL DATA EN, V16, P1128, DOI 10.1109/TKDE.2004.47; van der Aalst WMP, 2005, LECT NOTES COMPUT SC, V3536, P48; van der Aalst WMP, 2010, SOFTW SYST MODEL, V9, P87, DOI 10.1007/s10270-008-0106-z; van der Aalst WMP, 2007, INT CONF APPL CONCUR, P3, DOI 10.1109/ACSD.2007.50; Verbeek H., 2007, P WORKSH PETR NETS S, P127; Vogler W., 1992, LNCS, V625; WEI YC, 1991, IEEE T COMPUT AID D, V10, P911, DOI 10.1109/43.87601; Weijters A., 2006, BETA WORKING PAPER S, V166; Wen L, 2007, DATA MIN KNOWL DISC, V15, P145, DOI 10.1007/s10618-007-0065-y; Wen LJ, 2009, J INTELL INF SYST, V32, P163, DOI 10.1007/s10844-007-0052-1; WERF J, 2008, LECT NOTES COMPUTER, V5062, P368	49	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					218	246		10.1007/s10618-011-0226-x		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700008	
J	Blockeel, H; Calders, T; Fromont, E; Goethals, B; Prado, A; Robardet, C				Blockeel, Hendrik; Calders, Toon; Fromont, Elisa; Goethals, Bart; Prado, Adriana; Robardet, Celine			An inductive database system based on virtual mining views	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Inductive databases; Query languages; Query processing	DISCOVERY; EXTENSION; SQL	Inductive databases integrate database querying with database mining. In this article, we present an inductive database system that does not rely on a new data mining query language, but on plain SQL. We propose an intuitive and elegant framework based on virtual mining views, which are relational tables that virtually contain the complete output of data mining algorithms executed over a given data table. We show that several types of patterns and models that are implicitly present in the data, such as itemsets, association rules, and decision trees, can be represented and queried with SQL using a unifying framework. As a proof of concept, we illustrate a complete data mining scenario with SQL queries over the mining views, which is executed in our system.	[Fromont, Elisa; Prado, Adriana] Univ St Etienne, Univ Lyon, Lab Hubert Curien, CNRS,UMR5516, F-42023 St Etienne, France; [Calders, Toon] Tech Univ Eindhoven, NL-5600 MB Eindhoven, Netherlands; [Blockeel, Hendrik] Leiden Univ, Leiden Inst Adv Comp Sci, Leiden, Netherlands; [Blockeel, Hendrik] Katholieke Univ Leuven, Louvain, Belgium; [Goethals, Bart] Univ Antwerp, Antwerp, Belgium; [Robardet, Celine] Univ Lyon, CNRS, INSA Lyon, LIRIS,UMR5205, F-69621 Lyon, France	Prado, A (reprint author), Univ St Etienne, Univ Lyon, Lab Hubert Curien, CNRS,UMR5516, F-42023 St Etienne, France.	hendrik.blockeel@cs.kuleuven.be; t.calders@tue.nl; elisa.fromont@univ-st-etienne.fr; bart.goethals@ua.ac.be; adriana.bechara.prado@univ-st-etienne.fr; celine.robardet@insa-lyon.fr			IQ [IST-FET FP6-516169, 2005/8]; FWO "Foundations for inductive databases"; BINGO2 [ANR-07-MDCO 014-02]; GOA [2003/8]	This work has been partially supported by the projects IQ (IST-FET FP6-516169) 2005/8, GOA 2003/8 "Inductive Knowledge bases", FWO "Foundations for inductive databases", and BINGO2 (ANR-07-MDCO 014-02). When this research was performed, Hendrik Blockeel was a postdoctoral fellow of the Research Foundation-Flanders (FWO-Vlaanderen), Elisa Fromont was working at the Katholieke Universteit Leuven, and Adriana Prado was working at the University of Antwerp.	Abiteboul S., 1995, FDN DATABASES; Agrawal R., 1994, P 20 INT C VER LARG, P487; BLOCKEEL H, 2008, P ACM SIGKDD INT C K; Blockeel H, 2008, PROC INT CONF DATA, P1608, DOI 10.1109/ICDE.2008.4497633; BLOCKEEL H, 2010, INDUCTIVE DATABASES, V1, P59; Bonchi F, 2009, INFORM SYST, V34, P3, DOI 10.1016/j.is.2008.02.007; CALDERS T, 2006, P 10 EUR C PRINC PRA, P454; Calders T, 2006, ACM T DATABASE SYST, V31, P1169, DOI 10.1145/1189769.1189770; Chen P., 1976, ACM T DATABASE SYST, V1, P1; FROMONT E, 2007, ECML PKDD WORKSH KDI, P81; Garcia-Molina H., 1999, DATABASE SYSTEM IMPL; Geerts F, 2004, LECT NOTES COMPUT SC, V3245, P278; Giannotti F, 2004, IEEE T KNOWL DATA EN, V16, P1232, DOI 10.1109/TKDE.2004.64; GOETHALS B, 2000, P DAWAK, P307; Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843; HAHSLER M, 2007, SIGKDD EXPLOR, V2; HAN J, 1996, ACM SIGMOD WORKSH DA; Harinarayan V., 1996, P ACM SIGMOD INT C M, P205, DOI 10.1145/233269.233333; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Imielinski T, 1999, DATA MIN KNOWL DISC, V3, P373, DOI 10.1023/A:1009816913055; Johnson T., 2000, P 26 INT C VER LARG, P21; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Meo R, 1998, DATA MIN KNOWL DISC, V2, P195, DOI 10.1023/A:1009774406717; Mitchell T. M, 1997, MACHINE LEARNING; Newman D.J., 1998, UCI REPOSITORY MACHI; NIJSSEN S, 2007, ECML PKDD WORKSH KNO, P189; PRADO A, 2009, THESIS U ANTWERP BEL; Ramakrishnan R., 2002, DATABASE MANAGEMENT; Tang Z.H., 2005, DATA MINING SQL SERV; WANG H, 2001, LOGIC BASED ARTIFICI, P523; Wang HX, 2003, SIAM PROC S, P130; WICKER J, 2008, P ECML PKDD, P690	32	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					247	287		10.1007/s10618-011-0229-7		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700009	
J	Wang, ZM				Wang, Zhimin			Entropy on covers	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Entropy; Cover; Feature selection; Soft clustering	INFORMATION; DISTANCE; CRITERIA	As a generalization of partitions, covers allow overlaps between their members. In this paper, we will propose a family of entropy-like measures over covers, which are anti monotonic with regard to the partial order defined by refinement relations of covers. In parallel to the entropy theory, we also develop their conditional forms, which in turn lead to a family of semi-metrics on covers. These make it possible to apply entropy-based techniques in data mining or machine learning to problems naturally modelled by covers.	Harvard Univ Herbaria, Cambridge, MA 02138 USA	Wang, ZM (reprint author), Harvard Univ Herbaria, 22 Divin Ave, Cambridge, MA 02138 USA.	zhimin.wangzm@gmail.com			NSF [0646266]	I would like to thank Javier Artiles and Enrique Amigo at UNED NLP & IR group, Madrid, Spain for running our clustering comparison metric on their data set, and anonymous reviewers for their insightful input. I am also very grateful to all those thoughtful comments and exposition suggestions from my thesis advisor Robert A. Morris. This research was supported in Part by NSF Grant DBI #0646266.	Amigo E, 2009, INFORM RETRIEVAL, V12, P461, DOI 10.1007/s10791-008-9066-8; ASUNCION A., 2007, UCI MACHINE LEARNING; Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25, DOI 10.1007/3-540-28349-8_2; Cheng C, 1999, KNOWLEDGE DISCOVERY, P84; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cover T. M., 2006, ELEMENTS INFORM THEO; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Frank E, 1998, GENERATING ACCURATE, P144; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Hall M.A., 1999, CORRELATION BASED FE; JEBARA TS, 2000, P 16 C UNC ART INT U, P291; JENSEN R, 2007, FUZZ SYST C 2007 FUZ, P1098; Kira K, 1992, P 10 NAT C ART INT, P129; Kononenko I., 1994, LECT NOTES ARTIF INT, V784, P171; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; Markov Z., 2006, SIGCSE Bulletin, V38, DOI 10.1145/1140123.1140127; Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013; Mirkin B, 1996, MATH CLASSIFICATION; Nguyen SH, 1997, LECT NOTES ARTIF INT, V1263, P265; Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452; Parthalain N., 2009, PATTERN RECOGN, V42, P655, DOI DOI 10.1016/J.PATCOG.2008.08.029; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Quinlan J. R., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; RIJSBERGEN V, 1974, J DOC, V30, P365; SHANNON CE, 1948, AT&T TECH J, V27, P379; Shen Q, 2002, PATTERN RECOGN, V35, P2425, DOI 10.1016/S0031-3203(01)00229-1; SIMOVICI DA, 2007, MULTIVALUED LOGIC SO, V13, P295; Stepaniuk J., 1998, Fundamenta Informaticae, V36; WANG Z, METRICS OVERLAPPING; Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290956	32	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2012	24	1					288	309		10.1007/s10618-011-0230-1		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	874OA	WOS:000298966700010	
J	Sun, XX; Wang, H; Li, JY; Pei, J				Sun, Xiaoxun; Wang, Hua; Li, Jiuyong; Pei, Jian			Publishing anonymous survey rating data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						(k epsilon)-anonymity; Survey rating data; Graphical representation	PRIVACY; ANONYMIZATION	We study the challenges of protecting privacy of individuals in the large public survey rating data in this paper. Recent study shows that personal information in supposedly anonymous movie rating records are de-identified. The survey rating data usually contains both ratings of sensitive and non-sensitive issues. The ratings of sensitive issues involve personal privacy. Even though the survey participants do not reveal any of their ratings, their survey records are potentially identifiable by using information from other public sources. None of the existing anonymisation principles (e.g., k-anonymity, l-diversity, etc.) can effectively prevent such breaches in large survey rating data sets. We tackle the problem by defining a principle called (k, epsilon)-anonymity model to protect privacy. Intuitively, the principle requires that, for each transaction t in the given survey rating data T, at least (k - 1) other transactions in T must have ratings similar to t, where the similarity is controlled by epsilon. The (k, epsilon)-anonymity model is formulated by its graphical representation and a specific graph-anonymisation problem is studied by adopting graph modification with graph theory. Various cases are analyzed and methods are developed to make the updated graph meet (k, epsilon) requirements. The methods are applied to two real-life data sets to demonstrate their efficiency and practical utility.	[Sun, Xiaoxun] Australian Council Educ Res, Camberwell, Vic, Australia; [Wang, Hua] Univ So Queensland, Dept Math Comp, Toowoomba, Qld 4350, Australia; [Li, Jiuyong] Univ S Australia, Sch Comp & Informat Sci, Adelaide, SA 5001, Australia; [Pei, Jian] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Sun, XX (reprint author), Australian Council Educ Res, 19 Prospect Hill Rd, Camberwell, Vic, Australia.	sun@acer.edu.au; jiuyong.li@unisa.edu.au; jpei@cs.sfu.ca			Australian Research Council (ARC) [DP0774450, DP0663414, DP110103142]	This research is supported by Australian Research Council (ARC) grant DP0774450, DP0663414 and DP110103142.	Aggarwal CC, 2005, VLDB, P901; Atzori M, 2005, ICDM 05, P561; Atzori M, 2008, VLDB J, V17, P703, DOI 10.1007/s00778-006-0034-x; Atzori M, 2005, PKDD, P10; Bayardo RJ, 2005, PROC INT CONF DATA, P217; Frankowski D., 2006, SIGIR 06, P565; Fung BCM, 2005, PROC INT CONF DATA, P205; Garey M. R., 1979, COMPUTERS INTRACTABI; Ghinita G, 2008, PROC INT CONF DATA, P715, DOI 10.1109/ICDE.2008.4497480; Hafner K, 2006, NY TIMES        1002; Hamming R.W., 1980, CODING INFORM THEORY; Hansell S, 2006, NY TIMES        0808; He Y., 2009, VLDB 2009; Iyengar V.S., 2002, SIGKDD, P279; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Kifer D., 2006, SIGMOD, P217; Lefevre K., 2006, KDD 06, P277; LeFevre K, 2006, ICDE 06, P25; Li N., 2007, ICDE, P106; Li TC, 2009, PROC INT CONF DATA, P6; Li T., 2009, P 15 ACM SIGKDD INT, P517, DOI 10.1145/1557019.1557079; Liu K., 2008, SIGMOD; Machanavajjhala A., 2006, ICDE, P24; Meyerson A., 2004, P 23 ACM SIGMOD SIGA, P223, DOI 10.1145/1055558.1055591; Narayanan A., 2008, IEEE S SEC PRIV, V0, P111; Samarati P., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275508; Samarati P, 1998, SRICSL9804; Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193; Sweeney L, 1997, J LAW MED ETHICS, V25, P98, DOI 10.1111/j.1748-720X.1997.tb01885.x; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Verykios VS, 2004, IEEE T KNOWL DATA EN, V16, P434, DOI 10.1109/TKDE.2004.1269668; Wang K, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P249; WANG K, 2006, ACM SIGKDD, P414; Witten IH, 2005, DATA MINING PRACTICA, P2; Wong RCW, 2006, KDD 06, P754; Xu Y, 2008, KDD, P767; ZHANG Q, 2007, ICDE, P116; Zhou B., 2008, ACM SIGKDD EXPLORATI, V<IT>10</IT>, P12	38	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2011	23	3					379	406		10.1007/s10618-010-0208-4		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	805FE	WOS:000293711000001	
J	De Bie, T				De Bie, Tijl			Maximum entropy models and subjective interestingness: an application to tiles in binary databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Maximum entropy principle; Subjective interestingness measures; Prior information; Rectangular databases; Swap randomizations	COMPLEX NETWORKS	Recent research has highlighted the practical benefits of subjective interestingness measures, which quantify the novelty or unexpectedness of a pattern when contrasted with any prior information of the data miner (Silberschatz and Tuzhilin, Proceedings of the 1st ACM SIGKDD international conference on Knowledge discovery and data mining (KDD95), 1995; Geng and Hamilton, ACM Comput Surv 38(3):9, 2006). A key challenge here is the formalization of this prior information in a way that lends itself to the definition of a subjective interestingness measure that is both meaningful and practical. In this paper, we outline a general strategy of how this could be achieved, before working out the details for a use case that is important in its own right. Our general strategy is based on considering prior information as constraints on a probabilistic model representing the uncertainty about the data. More specifically, we represent the prior information by the maximum entropy (MaxEnt) distribution subject to these constraints. We briefly outline various measures that could subsequently be used to contrast patterns with this MaxEnt model, thus quantifying their subjective interestingness. We demonstrate this strategy for rectangular databases with knowledge of the row and column sums. This situation has been considered before using computation intensive approaches based on swap randomizations, allowing for the computation of empirical p-values as interestingness measures (Gionis et al., ACM Trans Knowl Discov Data 1(3):14, 2007). We show how the MaxEnt model can be computed remarkably efficiently in this situation, and how it can be used for the same purpose as swap randomizations but computationally more efficiently. More importantly, being an explicitly represented distribution, the MaxEnt model can additionally be used to define analytically computable interestingness measures, as we demonstrate for tiles (Geerts et al., Proceedings of the 7th international conference on Discovery science (DS04), 2004) in binary databases.	Univ Bristol, Intelligent Syst Lab, Bristol, Avon, England	De Bie, T (reprint author), Univ Bristol, Intelligent Syst Lab, Bristol, Avon, England.	tijl.debie@gmail.com	De Bie, Tijl/B-2920-2013		EPSRC [EP/G056447/1]	This work is supported by the EPSRC grant EP/G056447/1. The author is grateful to Bart Goethals, Nello Cristianini, Jilles Vreeken, Akis Kontonasios, Eirini Spyropoulou and the anonymous reviewers for interesting discussions that have had a positive impact on both the content and the presentation of this work.	Agrawal R., 1994, P 20 INT C VER LARG, P487; ASUNCION A., 2007, UCI MACHINE LEARNING; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Boyd S., 2004, CONVEX OPTIMIZATION; Brijs T, 1999, P 5 INT C KNOWL DISC, P254, DOI 10.1145/312129.312241; Calders T, 2008, THEOR COMPUT SCI, V394, P84, DOI 10.1016/j.tcs.2007.11.003; Chung F., 2003, INTERNET MATH, V1, P91; Cover T. M., 1991, ELEMENTS INFORM THEO; DEBIE T, 2009, 123930 U BRIST; DEBIE T, 2009, 123931 U BRIST; De Raedt L, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P237; Gallo A., 2007, P 11 EUR C PRINC PRA, P438; Gallo A, 2009, 123936 U BRIST; Geerts F., 2004, P 7 INT C DISC SCI D, P278; Geng LQ, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132960.1132963; Gentle J. E., 2005, ELEMENTS COMPUTATION; Gionis A., 2007, ACM T KNOWL DISCOV D, V1, P14, DOI 10.1145/1297332.1297338; Gionis A., 2004, P 8 EUR C PRINC PRAC, P173; GULL SF, 1984, IEE PROC-F, V131, P646; Hanhijarvi S., 2009, P 15 ACM SIGKDD INT, P379, DOI 10.1145/1557019.1557065; Jaroszewicz S., 2004, P 10 ACM SIGKDD INT, P178, DOI 10.1145/1014052.1014074; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; Khuller S, 1999, INFORM PROCESS LETT, V70, P39, DOI 10.1016/S0020-0190(99)00031-9; Kontonasios KN, 2010, P 10 SIAM INT C DAT, P153; LEHMANN E, 1995, TESTING STAT HYPOTHE; MANNILA H, 2008, P 12 E EUR C ADV DAT, P1; Miettinen P, 2008, IEEE T KNOWL DATA EN, V20, P1348, DOI 10.1109/TKDE.2008.53; Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824; Minoux M, 1978, OPTIMIZATION TECHNIQ, P234; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Ojala M., 2008, P 2008 SIAM INT C DA, P494; Padmanabhan B., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347103; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Pavlov D, 2003, IEEE T KNOWL DATA EN, V15, P1409, DOI 10.1109/TKDE.2003.1245281; RASCHE G., 1961, P 4 BERK S MATH STAT, VIV, P321; Robins G, 2007, SOC NETWORKS, V29, P173, DOI 10.1016/j.socnet.2006.08.002; SAVINOV A, 2004, P SAC 04 ACM S APPL, P525, DOI 10.1145/967900.968011; Shewchuk J. R., 1994, INTRO CONJUGATE GRAD; Siebes A, 2006, P SIAM C DAT MIN, P393; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; Tatti N, 2008, KNOWL INF SYST, V17, P57, DOI 10.1007/s10115-008-0128-4; TOPSOE F, 1979, KYBERNETIKA, V15, P8; Tribus M., 1961, THERMOSTATICS THERMO; Wainwright Martin J, 2008, Foundations and Trends in Machine Learning, V1, DOI 10.1561/2200000001; Zaki MJ, 2002, SIAM PROC S, P457	46	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2011	23	3					407	446		10.1007/s10618-010-0209-3		40	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	805FE	WOS:000293711000002	
J	Tang, L; Liu, H				Tang, Lei; Liu, Huan			Leveraging social media networks for classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Social media; Social network analysis; Relational learning; Within-network classification; Collective inference	SCHOOL	Social media has reshaped the way in which people interact with each other. The rapid development of participatory web and social networking sites like YouTube, Twitter, and Facebook, also brings about many data mining opportunities and novel challenges. In particular, we focus on classification tasks with user interaction information in a social network. Networks in social media are heterogeneous, consisting of various relations. Since the relation-type information may not be available in social media, most existing approaches treat these inhomogeneous connections homogeneously, leading to an unsatisfactory classification performance. In order to handle the network heterogeneity, we propose the concept of social dimension to represent actors' latent affiliations, and develop a classification framework based on that. The proposed framework, SocioDim, first extracts social dimensions based on the network structure to accurately capture prominent interaction patterns between actors, then learns a discriminative classifier to select relevant social dimensions. SocioDim, by differentiating different types of network connections, outperforms existing representative methods of classification in social media, and offers a simple yet effective approach to integrating two types of seemingly orthogonal information: the network of actors and their attributes.	[Tang, Lei] Yahoo Labs, Santa Clara, CA 95054 USA; [Liu, Huan] Arizona State Univ, Tempe, AZ 85287 USA	Tang, L (reprint author), Yahoo Labs, Santa Clara, CA 95054 USA.	ltang@yahoo-inc.com; Huan.Liu@asu.edu			Air Force Office of Scientific Research [FA95500810132]	This research is, in part, sponsored by the Air Force Office of Scientific Research grant FA95500810132. We thank BlogCatalog and Flickr for providing APIs. We acknowledge Xufei Wang and Munmun De Choudhury for their help with data collection. We also wish to acknowledge Subbarao Kambhampati and Pat Langley for their suggestions to improve this work. We thank the anonymous reviewers wholeheartedly for their expert opinions and constructive suggestions.	Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; Almack JC, 1922, SCHOOL SOC, V16, P529; Bott H, 1928, GENET PSYCHOL MONOGR, V4, P44; Chakrabarti D, 2006, ACM COMPUT SURV, V38, P2, DOI DOI 10.1145/1132952.1132954; Chakrabarti S., 1998, SIGMOD 98, P307; CHANG E, 2007, ADV NEURAL INF PROCE, V20, P1081; CHEN G., 2008, P SIAM INT C DAT MIN, P410; CHEN WY, 2010, IEEE T PATTERN ANAL, V99; Fan R.-E, 2007, STUDY THRESHOLD SELE; Fiore A. T., 2005, C HUM FACT COMP SYST, P1371, DOI DOI 10.1145/1056808.1056919; Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104; GALLAGHER B, 2008, KDD 2008, P256; Geman S., 1990, STOCHASTIC RELAXATIO, P452; Getoor L, 2007, INTRO STAT RELATIONA; Golub G. H., 1996, MATRIX COMPUTATIONS, V3; GRAF H, 2005, ADV NEURAL INF PROCE, V17, P2; Handcock MS, 2007, J ROY STAT SOC A STA, V170, P301, DOI 10.1111/j.1467-985X.2007.00471.x; Hoff PD, 2002, J AM STAT ASSOC, V97, P1090, DOI 10.1198/016214502388618906; Hopcroft J, 2003, KDD 03, P541; Jensen D., 2004, KDD 04, P593; KONDOR RI, 2002, ICML NEW YORK NY US; Kumar R., 2006, KDD 06, P611; Leskovec J., 2010, WWW 10, P631; Leskovec J., 2008, WWW 08, P695, DOI DOI 10.1145/1367497.1367591; LIU Y, 2006, AAAI ORL FL US; LU Q, 2003, ICML NEW YORK NY US; Luxburg Ulrike, 2007, STAT COMPUT, V17, P395, DOI DOI 10.1007/s11222-007-9033-z; Macskassy SA, 2007, J MACH LEARN RES, V8, P935; Macskassy SA, 2003, P MULT DAT MIN WORKS; McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415; Menon A, 2010, DATA MIN KNOWL DISC, V21, P327, DOI 10.1007/s10618-010-0189-3; Neville J, 2005, MRDM 05, P49; Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103; Newman MEJ, 2006, PHYS REV E, V74; Nowicki K, 2001, J AM STAT ASSOC, V96, P1077, DOI 10.1198/016214501753208735; Sarkar P., 2005, SIGKDD EXPLOR NEWSL, V7, P31; Sen P, 2008, AI MAG, V29, P93; SHI J, 1997, CVPR, P731; Tang L., 2009, CIKM 09, P1107, DOI [10.1145/1645953.1646094, DOI 10.1145/1645953.1646094]; TANG L, 1996, COMMUNITY DETECTION; Tang L., 2009, WWW 09, P211; Tang L, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P817; Taskar B., 2001, IJCAI 01, P870; Taskar B., 2002, UAI, P485; Thelwall M, 2009, J AM SOC INF SCI TEC, V60, P219, DOI 10.1002/asi.20978; TRAVERS J, 1969, SOCIOMETRY, V32, P425, DOI 10.2307/2786545; Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101; Tsuda K, 2004, BIOINFORMATICS, V20, P326, DOI 10.1093/bioinformatics/bth906; Wasserman S, 1994, SOCIAL NETWORK ANAL; Wellman B, 1926, J EDUC RES, V14, P126; XU Z, 2008, KDD 2008 WORKSH SOC; Zha H., 2001, NIPS, P1057; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu X, 2006, SEMISUPERVISED LEARN; ZHU X, 2003, ICML NEW YORK NY US	55	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2011	23	3					447	478		10.1007/s10618-010-0210-x		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	805FE	WOS:000293711000003	
J	Sun, HJ; Wang, SR				Sun, Haojun; Wang, Shengrui			Measuring the component overlapping in the Gaussian mixture model	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Mixture model; Ridge curve; Overlap rate; Cluster analysis	ALGORITHMS	The ability of a clustering algorithm to deal with overlapping clusters is a major indicator of its efficiency. However, the phenomenon of cluster overlapping is still not mathematically well characterized, especially in multivariate cases. In this paper, we are interested in the overlap phenomenon between Gaussian clusters, since the Gaussian mixture is a fundamental data distribution model suitable for many clustering algorithms. We introduce the novel concept of the ridge curve and establish a theory on the degree of overlap between two components. Based on this theory, we develop an algorithm for calculating the overlap rate. As an example, we use this algorithm to calculate the overlap rates between the classes in the IRIS data set and clear up some of the confusion as to the true number of classes in the data set. We investigate factors that affect the value of the overlap rate, and show how the theory can be used to generate "truthed data" as well as to measure the overlap rate between a given pair of clusters or components in a mixture. Finally, we show an example of application of the theory to evaluate the well known clustering algorithms.	[Sun, Haojun] Shantou Univ, Coll Engn, Shantou 515063, Guangdong, Peoples R China; [Wang, Shengrui] Univ Sherbrooke, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada	Sun, HJ (reprint author), Shantou Univ, Coll Engn, Shantou 515063, Guangdong, Peoples R China.	haojunsun@stu.edu.cn			Nature Science Found of Guangdong Province, China [8151503101000016]; Natural Science Foundation of Guangdong Province, P. R. China [8351503101000001]; Natural Sciences and Engineering Research Council of Canada [121680]; Network Centers of Excellence on the Automobile of the 21st Century [NCE AUTO21]	This work has been supported by Nature Science Found of Guangdong Province, China (ID: 8151503101000016), the Natural Science Foundation of Guangdong Province, P. R. China for providing a grant (No: 8351503101000001) for this project, Natural Sciences and Engineering Research Council of Canada Discovery Grant No. 121680 and Network Centers of Excellence on the Automobile of the 21st Century (NCE AUTO21) as part of a project related to navigation data construction, management and mining.	AITNOURI E, 2002, J PATTERN RECOG IMAG, V12, P331; Bezdek J., 1981, PATTERN RECOGNITION; Bouguessa M, 2006, PATTERN RECOGN LETT, V27, P1419, DOI 10.1016/j.patrec.2006.01.015; CHAN H, 2003, 2003 C COMP VIS PATT, V2; DAY NE, 1969, BIOMETRIKA, V56, P463, DOI 10.2307/2334652; DO M, 2000, 2000 INT C IM PROC I, V3, P730; Fraley C, 1998, SIAM J SCI COMPUT, V20, P270, DOI 10.1137/S1064827596311451; Fukunaga K., 1990, INTRO STAT PATTERN R; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; HALGAMUGE SK, 1994, FUZZY SET SYST, V65, P1, DOI 10.1016/0165-0114(94)90242-9; HSU TH, 2000, P NATL SCI COUNC ROC, V10, P157; Kullback S, 1959, INFORM THEORY STAT; McLachlan GJ, 1988, MIXTURE MODELS INFER; MILLIGAN GW, 1980, PSYCHOMETRIKA, V45, P325, DOI 10.1007/BF02293907; Nicholls KH, 2001, CAN J FISH AQUAT SCI, V58, P231, DOI 10.1139/cjfas-58-2-231; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; Ramos V, 2000, LECT NOTES COMPUT SC, V1923, P319; SALVI G, 2003, 15 ICPHS INT C PHON, P1149; Sun HJ, 2004, Proceedings of the Second IASTED International Conference on Neural Networks and Computational Intelligence, P102; Sun HJ, 2004, PATTERN RECOGN, V37, P2027, DOI 10.1016/j.patcog.2004.03.012; TABBONE S, 1994, THESIS I NATL POLYTE; ZHANG H, 2003, COMPUT APPL SOFT, V2, P7	22	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2011	23	3					479	502		10.1007/s10618-011-0212-3		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	805FE	WOS:000293711000004	
J	Calders, T; Ramon, J; Van Dyck, D				Calders, Toon; Ramon, Jan; Van Dyck, Dries			All normalized anti-monotonic overlap graph measures are bounded	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph mining; Large network setting; Support measure; Anti-monotonicity; Morphism reductions		In graph mining, a frequency measure for graphs is anti-monotonic if the frequency of a pattern never exceeds the frequency of a subpattern. The efficiency and correctness of most graph pattern miners relies critically on this property. We study the case where frequent subgraphs have to be found in one graph. Vanetik et al. (Data Min Knowl Disc 13(2):243-260, 2006) already gave sufficient and necessary conditions for anti-monotonicity of graph measures depending only on the edge-overlaps between the instances of the pattern in a labeled graph. We extend these results to homomorphisms, isomorphisms and homeomorphisms on both labeled and unlabeled, directed and undirected graphs, for vertex- and edge-overlap. We show a set of reductions between the different morphisms that preserve overlap. As a secondary contribution, we prove that the popular maximum independent set measure assigns the minimal possible normalized frequency and we introduce a new measure based on the minimum clique partition that assigns the maximum possible normalized frequency. In that way, we obtain that all normalized anti-monotonic overlap graph measures are bounded from above and below. We also introduce a new measure sandwiched between the former two based on the polynomial time computable Lovasz theta-function.	[Ramon, Jan] Katholieke Univ Leuven, Kortrijk, Belgium; [Calders, Toon] Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands; [Van Dyck, Dries] Transnatl Univ Limburg, Hasselt Univ, Diepenbeek, Belgium	Ramon, J (reprint author), Katholieke Univ Leuven, Kortrijk, Belgium.	calders@tue.nl; Jan.Ramon@cs.kuleuven.be; Dries.VanDyck@UHasselt.be	Van Dyck, Dries/C-2308-2009; Ramon, Jan/E-8956-2010	Ramon, Jan/0000-0002-0558-7176	FWO; ERC [240186]; K.U. Leuven GOA	This work is supported by the FWO project 'Graph logic: Representation, Inference and Learning'. Jan Ramon is supported by ERC Starting Grant 240186 'MiGraNT: Mining Graphs and Networks, a Theory-based approach' and by K.U. Leuven GOA project 'Probabilistic Logic Languages'.	Bandyopadhyay S, 2006, GENOME RES, V16, P428, DOI 10.1101/gr.4526006; BOLOBAS B, 2001, RANDOM GRAPHS; BRINGMANN B, 2007, P MIN LEARN GRAPHS M; Crespi V, 2004, SIAM J DISCRETE MATH, V17, P670, DOI 10.1137/S089548010241852X; DERAEDT L, 2001, P 17 INT JOINT C ART, P853; FIEDLER M, 2007, P 5 WORKSH MIN LEARN; FURER M, 2008, P 11 INT WORKSH APPR, P416; Gross Jonathan L., 2004, HDB GRAPH THEORY; GRUNEWALD, 2007, MOLE BIOL EVOL, V24, P532; He HH, 2007, IEEE DATA MINING, P163; Hell P., 2004, GRAPHS HOMOMORPHISMS; Kashtan N, 2004, BIOINFORMATICS, V20, P1746, DOI 10.1093/bioinformatics/bth163; Knuth D. E., 1994, ELECTRON J COMB, V1, P1; Kuramochi M, 2005, DATA MIN KNOWL DISC, V11, P243, DOI 10.1007/s10618-005-0003-9; LAPAUGH AS, 1978, STOC 78, P40; MCGLOHON M, 2007, P INT C WEBL SOC MED, P26; MUGGLETON S, 1994, J LOGIC PROGRAM, V20, P629; Muzychuk M., 2004, P LOND MATH SOC, V3, P1; Papadimitriou C. H., 1994, COMPUTATIONAL COMPLE; RAMON J, 2000, LECT NOTES COMPUTER, V2063, P151; REINHARD D, 2000, GRAPH THEORY; Tong HH, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P737; VALENTIN EB, 2004, ELECT NOTES DISCR MA, V17, P63; Vanetik N, 2006, DATA MIN KNOWL DISC, V13, P243, DOI 10.1007/s10618-006-0044-8	24	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2011	23	3					503	548		10.1007/s10618-011-0217-y		46	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	805FE	WOS:000293711000005	
J	Xiang, Y; Jin, RM; Fuhry, D; Dragan, FF				Xiang, Yang; Jin, Ruoming; Fuhry, David; Dragan, Feodor F.			Summarizing transactional databases with overlapped hyperrectangles	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Hyperrectangle; Tile; Set cover; Summarization; Transactional database; Frequent itemset mining	MATRIX	Transactional data are ubiquitous. Several methods, including frequent itemset mining and co-clustering, have been proposed to analyze transactional databases. In this work, we propose a new research problem to succinctly summarize transactional databases. Solving this problem requires linking the high level structure of the database to a potentially huge number of frequent itemsets. We formulate this problem as a set covering problem using overlapped hyperrectangles (a concept generally regarded as tile according to some existing papers); we then prove that this problem and its several variations are NP-hard, and we further reveal its relationship with the compact representation of a directed bipartite graph. We develop an approximation algorithm Hyper which can achieve a logarithmic approximation ratio in polynomial time. We propose a pruning strategy that can significantly speed up the processing of our algorithm, and we also propose an efficient algorithm Hyper+ to further summarize the set of hyperrectangles by allowing false positive conditions. Additionally, we show that hyperrectangles generated by our algorithms can be properly visualized. A detailed study using both real and synthetic datasets shows the effectiveness and efficiency of our approaches in summarizing transactional databases.	[Xiang, Yang] Ohio State Univ, Dept Biomed Informat, Columbus, OH 43210 USA; [Fuhry, David] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; [Jin, Ruoming; Dragan, Feodor F.] Kent State Univ, Dept Comp Sci, Kent, OH 44242 USA	Xiang, Y (reprint author), Ohio State Univ, Dept Biomed Informat, Columbus, OH 43210 USA.	yang.xiang@osumc.edu; jin@cs.kent.edu; fuhry@cse.ohio-state.edu; dragan@cs.kent.edu			National Science Foundation [1019343]	This work was supported in part by the National Science Foundation under Grant #1019343 to the Computing Research Association for the CIFellows Project.	AFRATI FN, 2004, KDD, P12; AGRAWAL, 1993, P 1993 ACM SIGMOD, P207; Agrawal A, 1996, ADV KNOWLEDGE DISCOV, P307; Agrawal R., 1998, SIGMOD 98, P94; Agrawal R., 1994, P INT C VER LARG DAT; AGRAWAL Rakesh, 1989, SIGMOD C, P253; BESSON J, 2006, KDID, P11; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Burdick D, 2005, IEEE T KNOWL DATA EN, V17, P1490, DOI 10.1109/TKDE.2005.183; BYRON JG, 2006, ICDM, P200; BYRON JG, 2007, KDD, P310; Calders T, 2007, DATA MIN KNOWL DISC, V14, P171, DOI 10.1007/s10618-006-0054-6; Chandola V, 2007, KNOWL INF SYST, V12, P355, DOI 10.1007/s10115-006-0039-1; Chvatal V., 1979, Mathematics of Operations Research, V4, DOI 10.1287/moor.4.3.233; Faloutsos C, 2007, DATA MIN KNOWL DISC, V15, P3, DOI 10.1007/s10618-006-0057-3; Geerts F, 2004, LECT NOTES COMPUT SC, V3245, P278; Gionis A., 2004, P 8 EUR C PRINC PRAC, P173; Han J, 2006, DATA MINING CONCEPTS; HARPER LH, 1964, J SOC IND APPL MATH, V12, P131; HARTIGAN JA, 1972, J AM STAT ASSOC, V67, P123, DOI 10.2307/2284710; Jin RM, 2008, IEEE DATA MINING, P313, DOI 10.1109/ICDM.2008.102; Jin RM, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P417; JOHNSON D, 2004, VLDB 04, P13; Kellerer H., 2004, KNAPSACK PROBLEMS; Lakshmanan L. V. S., 2002, VLDB, P766, DOI 10.1016/B978-155860869-6/50073-1; LI T, 2005, KDD 05, P188; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; MINOUX M, 1977, 8 IFIP C OPT TECHN; Mirkin B, 1996, MATH CLASSIFICATION; Peeters R, 2003, DISCRETE APPL MATH, V131, P651, DOI 10.1016/S0166-218X(03)00333-0; Pei J, 2004, KNOWL INF SYST, V6, P570, DOI 10.1007/s10115-003-0133-6; Richardson T., 2008, MODERN CODING THEORY; Safro I, 2006, J ALGORITHM, V60, P24, DOI 10.1016/j.jalgor.2004.10.004; Siebes A., 2006, SDM; STEINBACH M, 2004, KDD, P296; VANLEEUWEN M, 2006, P ECML PKDD 06, P585; Vreeken J, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P765; Wang JY, 2006, KNOWL INF SYST, V9, P19, DOI 10.1007/s10115-005-0216-7; Xianfeng Yang, 2008, Key Engineering Materials; Xin D., 2005, VLDB, P709	40	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2011	23	2					215	251		10.1007/s10618-010-0203-9		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	752IR	WOS:000289685300001	
J	Wang, ET; Chen, ALP				Wang, En Tzu; Chen, Arbee L. P.			Mining frequent itemsets over distributed data streams by continuously maintaining a global synopsis	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Distributed data streams; Data mining; Frequent itemset; Continuous distributed model; Hash-based approach	PATTERNS; SETS	Mining frequent itemsets over data streams has attracted much research attention in recent years. In the past, we had developed a hash-based approach for mining frequent itemsets over a single data stream. In this paper, we extend that approach to mine global frequent itemsets from a collection of data streams distributed at distinct remote sites. To speed up the mining process, we make the first attempt to address a new problem on continuously maintaining a global synopsis for the union of all the distributed streams. The mining results therefore can be yielded on demand by directly processing the maintained global synopsis. Instead of collecting and processing all the data in a central server, which may waste the computation resources of remote sites, distributed computations over the data streams are performed. A distributed computation framework is proposed in this paper, including two communication strategies and one merging operation. These communication strategies are designed according to an accuracy guarantee of the mining results, determining when and what the remote sites should transmit to the central server (named coordinator). On the other hand, the merging operation is exploited to merge the information received from the remote sites into the global synopsis maintained at the coordinator. By the strategies and operation, the goal of continuously maintaining the global synopsis can be achieved. Rooted in the continuously maintained global synopsis, we propose a mining algorithm for finding global frequent itemsets. Moreover, the correctness guarantees of the communication strategies and merging operation, and the accuracy guarantee analysis of the mining algorithm are provided. Finally, a series of experiments on synthetic datasets and a real dataset are performed to show the effectiveness and efficiency of the distributed computation framework.	[Chen, Arbee L. P.] Natl Chengchi Univ, Dept Comp Sci, Taipei 11623, Taiwan; [Wang, En Tzu] Ind Technol Res Inst, Cloud Comp Ctr Mobile Applicat, Hsinchu, Taiwan	Chen, ALP (reprint author), Natl Chengchi Univ, Dept Comp Sci, 64 Chihnan Rd,Sec 2 Wenshan, Taipei 11623, Taiwan.	m9221009@em92.ndhu.edu.tw; alpchen@cs.nccu.edu.tw					Agrawal R., 1994, P INT C VER LARG DAT; Arlitt M. F., 1996, Performance Evaluation Review, V24; Babcock B., 2003, P ACM SIGMOD; Calders T, 2007, IEEE DATA MINING, P83; Chang J, 2003, 9 ACM SIGKDD, P487; Charikar M., 2002, P 29 INT C AUT LANG, P693; Cheng J., 2006, P 10 PAC AS C KNOWL, P462; Cormode G, 2005, J ALGORITHM, V55, P58, DOI 10.1016/j.jalgor.2003.12.001; Cormode G., 2005, SIGMOD, P25; Cormode G, 2010, VLDB J, V19, P3, DOI 10.1007/s00778-009-0172-z; Cormode G., 2005, P 31 INT C VER LARG; Cormode G., 2007, P 23 INT C DAT ENG I, P1036; Cormode G., 2006, P 22 INT C DAT ENG I, P57; Dang XH, 2008, KNOWL INF SYST, V16, P245, DOI 10.1007/s10115-007-0106-2; Das A., 2004, P 30 INT C VER LARG, P312, DOI 10.1016/B978-012088469-8/50030-9; Demaine E. D., 2002, P 10 ANN EUR S ALG, P348; FISCHER MJ, 1982, J ALGORITHMS, V3, P362; FULLER R, 2008, T MLDM, V1, P67; Giannella C, 2004, DATA MINING NEXT GEN, P191; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Jin C, 2003, P 12 INT C INF KNOWL, P287; Jin R., 2005, P 5 IEEE INT C DAT M, P210; Karp RM, 2003, ACM T DATABASE SYST, V28, P51, DOI 10.1145/762471.762473; Kashyap S, 2008, PROC INT CONF DATA, P526, DOI 10.1109/ICDE.2008.4497461; Leung CKS, 2006, IEEE DATA MINING, P928; Li H, 2004, 1 INT WORKSH KNOWL D; LIN CH, 2005, 2005 SIAM INT C DAT; Manjhi A, 2005, PROC INT CONF DATA, P767; Manku G. S., 2002, VLDB, P346, DOI 10.1016/B978-155860869-6/50038-X; METWALLY A, 2005, P 10 INT C DAT THEOR, P398; Mozafari B, 2008, PROC INT CONF DATA, P179, DOI 10.1109/ICDE.2008.4497426; Ramamirtham J., 2006, SIGMOD C; SAVASERE A, 1995, EFFICIENT ALGORITHM, P432; Wang ET, 2009, DATA MIN KNOWL DISC, V19, P132, DOI 10.1007/s10618-009-0129-2; Yu JX, 2004, VLDB, P204	35	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2011	23	2					252	299		10.1007/s10618-010-0204-8		48	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	752IR	WOS:000289685300002	
J	Tripathi, A; Klami, A; Oresic, M; Kaski, S				Tripathi, Abhishek; Klami, Arto; Oresic, Matej; Kaski, Samuel			Matching samples of multiple views	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Bipartite matching; Canonical correlation; Consensus matching; Co-occurrence data; Multi-view learning	ALGORITHM; MODELS	Multi-view learning studies how several views, different feature representations, of the same objects could be best utilized in learning. In other words, multi-view learning is analysis of co-occurrence data, where the observations are co-occurrences of samples in the views. Standard multi-view learning such as joint density modeling cannot be done in the absence of co-occurrence, when the views are observed separately and the identities of objects are not known. As a practical example, joint analysis of mRNA and protein concentrations requires mapping between genes and proteins. We introduce a data-driven approach for learning the correspondence of the observations in the different views, in order to enable joint analysis also in the absence of known co-occurrence. The method finds a matching that maximizes statistical dependency between the views, which is particularly suitable for multi-view methods such as canonical correlation analysis which has the same objective. We apply the method to translational metabolomics, to identify differences and commonalities in metabolic processes in different species or tissues. The metabolite identities and roles in the different species are not generally known, and it is necessary to search for a matching. In this paper we show, using different metabolomics measurement batches as the views so that the ground truth is known, that the metabolite identities can be reliably matched by a consensus of several matching solutions.	[Tripathi, Abhishek] Univ Helsinki, Dept Comp Sci, Helsinki Inst Informat Technol HIIT, SF-00510 Helsinki, Finland; [Klami, Arto] Aalto Univ, Dept Informat & Comp Sci, Helsinki Inst Informat Technol HIIT, Helsinki, Finland; [Oresic, Matej] VTT Tech Res Ctr Finland, Espoo, Finland	Tripathi, A (reprint author), Univ Helsinki, Dept Comp Sci, Helsinki Inst Informat Technol HIIT, Teollisuuskatu 23, SF-00510 Helsinki, Finland.	abhishek.tripathi@cs.helsinki.fi; arto.klami@tkk.fi; matej.oresic@vtt.fi; samuel.kaski@tkk.fi	Klami, Arto/E-7227-2012	Klami, Arto/0000-0002-7950-1355	Academy of Finland [133818]; EU Network of Excellence [PASCAL2, ICT 216886]; TEKES [40101/07]	AK and SK belong to Finnish Center of Excellence in Adaptive Informatics Research of the Academy of Finland. AK was supported by the Academy of Finland decision number 133818, and AT, AK and SK were partially supported by EU Network of Excellence PASCAL2, ICT 216886. This work was partially supported by TEKES (grant no. 40101/07).	Bach F., 2005, 688 U CAL DEP STAT; Barzilay R, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P25; Bickel S, 2005, LECT NOTES ARTIF INT, V3720, P35; Blei D. M, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460; Burkard R, 2009, OTHER TITL APPL MATH, V106, P1, DOI 10.1137/1.9780898717754; Damian D, 2007, METABOLOMICS, V3, P69, DOI 10.1007/s11306-006-0045-z; Duff IS, 2001, SIAM J MATRIX ANAL A, V22, P973, DOI 10.1137/S0895479899358443; Farquhar J.D.R., 2006, ADV NEURAL INFORM PR, V18, P355; GRETTON A, 2003, P ICASSP 03 IEEE INT; HAGHIGHI A., 2008, P 46 ANN M ASS COMP, P771; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710; KLAMI A, 2005, P ICASSP 05 IEEE INT; Klami A, 2008, NEUROCOMPUTING, V72, P39, DOI 10.1016/j.neucom.2007.12.044; Kuhn H., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109; Li YY, 2006, J INTELL INF SYST, V27, P117, DOI 10.1007/s10844-006-1627-y; Melamed D., 1999, COMPUTATIONAL LINGUI, V25, P107; Nikkilä Janne, 2008, Mol Syst Biol, V4, P197, DOI 10.1038/msb.2008.34; Oresic M, 2008, TRENDS BIOTECHNOL, V26, P647, DOI 10.1016/j.tibtech.2008.09.001; Oresic M, 2008, J EXP MED, V205, P2975, DOI 10.1084/jem.20081800; Quadrianto N., 2009, ADV NEURAL INFORM PR, V21, P1289; Rogers S, 2008, BIOINFORMATICS, V24, P2894, DOI 10.1093/bioinformatics/btn553; Rogers S, 2010, MACH LEARN, V79, P201, DOI 10.1007/s10994-009-5155-1; Smola A., 2007, LECT NOTES COMPUTER, P13; Tripathi A, 2010, Proceedings of the 2010 IEEE International Workshop on Machine Learning for Signal Processing (MLSP), DOI 10.1109/MLSP.2010.5589249; Tripathi A., 2008, TKKICSR8 HELS U TECH; VINOKOUROV A, 2003, P 4 INT S IND COMP A; Wang C., 2009, IJCAI 09, P1273; Wang C., 2008, P 25 INT C MACH LEAR, P1120, DOI 10.1145/1390156.1390297	29	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2011	23	2					300	321		10.1007/s10618-010-0205-7		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	752IR	WOS:000289685300003	
J	Kim, M; Pavlovic, V				Kim, Minyoung; Pavlovic, Vladimir			Sequence classification via large margin hidden Markov models	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Sequence classification; Hidden Markov models	SPEECH RECOGNITION	We address the sequence classification problem using a probabilistic model based on hidden Markov models (HMMs). In contrast to commonly-used likelihood-based learning methods such as the joint/conditional maximum likelihood estimator, we introduce a discriminative learning algorithm that focuses on class margin maximization. Our approach has two main advantages: (i) As an extension of support vector machines (SVMs) to sequential, non-Euclidean data, the approach inherits benefits of margin-based classifiers, such as the provable generalization error bounds. (ii) Unlike many algorithms based on non-parametric estimation of similarity measures that enforce weak constraints on the data domain, our approach utilizes the HMM's latent Markov structure to regularize the model in the high-dimensional sequence space. We demonstrate significant improvements in classification performance of the proposed method in an extensive set of evaluations on time-series sequence data that frequently appear in data mining and computer vision domains.	[Kim, Minyoung] Seoul Natl Univ Sci & Technol, Dept Elect & Informat Engn, Seoul 139743, South Korea; [Pavlovic, Vladimir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ USA	Kim, M (reprint author), Seoul Natl Univ Sci & Technol, Dept Elect & Informat Engn, Seoul 139743, South Korea.	mikim21@gmail.com; vladimir@cs.rutgers.edu					ALON J, 2003, COMPUTER VISION PATT; ALTUN, 2003, P ICML; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; Bertsekas D.P., 1999, NONLINEAR PROGRAMMIN; Boser B. E., 1992, P 5 ANN ACM WORKSH C; Boyd S., 2004, CONVEX OPTIMIZATION; Collins Michael, 2002, EMPIRICAL METHODS NA; Crammer K., 2001, J MACHINE LEARNING R, V2, P265; DEMPSTER A, 1977, JRSS B, V39; DUAN K, 2003, NEURAL INFORM PROCES; Durbin R., 2002, BIOL SEQUENCE ANAL; GREINER R, 2002, P ANN M AM ASS ART I; HASTIE T, 1998, NEURAL INFORM PROCES; HEIGOLD G, 2007, P INT C SPOK LANG PR; HETTICH, 1999, UCI KDD ARCH; JAAKKOLA T, 1999, INT C INT SYST MOL B; Keogh E., 2002, UCR TIME SERIES DATA; KESHET J, 2006, 9 INT C SPOK LANG PR; KROGH A, 1994, INT C PATT RECOG, P140, DOI 10.1109/ICPR.1994.576891; LAFFERTY, 2001, P 18 INT C MACH LEAR; LI J, 2006, INT C SPOK LANG PROC; LI X, 2005, INT C AC SPEECH SIGN; LIU C, 2005, INT C AC SPEECH SIGN; NADAS A, 1983, IEEE T ACOUST SPEECH, V31, P814, DOI 10.1109/TASSP.1983.1164173; Ng A, 2002, NEURAL INFORM PROCES; Noble W. S., 2002, P PAC S BIOC, V7, P566; PERNKOPF F, 2005, INT C MACH LEARN BON; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; JUANG BH, 1985, AT&T TECH J, V64, P391; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RATANAMAHATANA CA, 2005, SIAM INT C DAT MIN N; RATANAMAHATANA CA, 2004, SIAM INT C DAT MIN L; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SHA F, 2007, NEURAL INFORM PROCES; Sha F., 2003, P HUM LANG TECHN NAA; SHAWETAYLOR J, 1996, P 9 ANN C COMP LEARN; STARNER T, 1995, INT S COMP VIS COR G; TANAWONGSUWAN R, 2003, INT C AUD VID BAS BI; TASKAR, 2003, P NEUR INF PROC SYST; Taskar B., 2005, EMPIRICAL METHODS NA; TIAN TP, 2005, P IEEE WORKSH COMP V; Vapnik V.N., 1995, NATURE STAT LEARNING; VEERARAGHAVAN A, 2006, COMPUTER VISION PATT; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182; Zhang T, 2002, J MACH LEARN RES, V2, P527, DOI 10.1162/153244302760200713	46	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2011	23	2					322	344		10.1007/s10618-010-0206-6		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	752IR	WOS:000289685300004	
J	Shang, FH; Jiao, LC; Shi, JR; Gong, MG; Shang, RH				Shang, Fanhua; Jiao, L. C.; Shi, Jiarong; Gong, Maoguo; Shang, R. H.			Fast density-weighted low-rank approximation spectral clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Clustering; Data mining; Affinity propagation; Spectral clustering; Nystrom approximation; Manifold structure	NONLINEAR DIMENSIONALITY REDUCTION; NYSTROM METHOD; ALGORITHM; PROPAGATION; GRAPHS	While spectral clustering can produce high-quality clusterings on small data sets, computational cost makes it infeasible for large data sets. Affinity Propagation (AP) has a limitation that it is hard to determine the value of parameter 'preference' which can lead to an optimal clustering solution. These problems limit the scope of application of the two methods. In this paper, we develop a novel fast two-stage spectral clustering framework with local and global consistency. Under this framework, we propose a Fast density-Weighted low-rank Approximation Spectral Clustering (FWASC) algorithm to address the above issues. The proposed algorithm is a high-quality graph partitioning method, and simultaneously considers both the local and global structure information contained in the data sets. Specifically, we first present a new Fast Two-Stage AP (FTSAP) algorithm to coarsen the input sparse graph and produce a small number of final representative exemplars, which is a simple and efficient sampling scheme. Then we present a density-weighted low-rank approximation spectral clustering algorithm to operate those representative exemplars on the global underlying structure of data manifold. Experimental results show that our algorithm outperforms the state-of-the-art spectral clustering and original AP algorithms in terms of speed, memory usage, and quality.	[Shang, Fanhua; Jiao, L. C.; Shi, Jiarong; Gong, Maoguo; Shang, R. H.] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ China, Xian 710071, Peoples R China	Shang, FH (reprint author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ China, Mailbox 224,2 S TaiBai Rd, Xian 710071, Peoples R China.	shangfanhua@yahoo.com.cn			National Natural Science Foundation of China [60702062, 60703107, 60970067, 60803097]; National High Technology Research and Development Program ( 863 Program) of China [2008AA01Z125, 2009AA12Z210]; National Basic Research Program (973 Program) of China [2006CB705707]; Ministry of Education of China [108115]; National Science and Technology Ministry of China [XADZ2008159, 51307040103]; Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project) [B07048]; Fundamental Research Funds for the Central Universities [JY1000090200, JY10000902038, K50510020001]; China Postdoctoral Science Foundation [20090451369]; Provincial Natural Science Foundation of Shaanxi of China [2009JQ8015]; Program for New Century Excellent Talents in University [NCET-08-0811]; Program for New Scientific and Technological Star of Shaanxi Province [2010KJXX-03]	We would like to thank the anonymous reviewers for their valuable comments and suggestions to significantly improve the quality of this paper. We also thank Dr. Fei Wang of Healthcare Transformation Group, IBM T. J. Watson Research Center at Hawthorne, NY, USA for numerous discussions and suggestions. This work is supported by the National Natural Science Foundation of China Nos. 60702062, 60703107, 60970067, 60803097; the National High Technology Research and Development Program (863 Program) of China Nos. 2008AA01Z125 and 2009AA12Z210; the National Basic Research Program (973 Program) of China No. 2006CB705707; the Key Project of Ministry of Education of China No. 108115; the National Science and Technology Ministry of China Nos. XADZ2008159, 51307040103; the Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project) No. B07048; the Fundamental Research Funds for the Central Universities Nos. JY1000090200, JY10000902038, K50510020001; the China Postdoctoral Science Foundation funded project under Grant No. 20090451369; the Provincial Natural Science Foundation of Shaanxi of China under Grant No. 2009JQ8015; the Program for New Century Excellent Talents in University No. NCET-08-0811; the Program for New Scientific and Technological Star of Shaanxi Province No. 2010KJXX-03.	Baker C. T. H., 1977, NUMERICAL TREATMENT; BALASUBRAMANIAN M, 2002, SCIENCE, V295, pNIL1; Belabbas MA, 2009, P NATL ACAD SCI USA, V106, P369, DOI 10.1073/pnas.0810600105; Berkhin P., 2002, SURVEY CLUSTERING DA; Ding C. H. Q., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989507; DONATH WE, 1973, IBM J RES DEV, V17, P420; Drineas P, 2005, J MACH LEARN RES, V6, P2153; Duda, 2001, PATTERN CLASSIFICATI; Dueck D., 2007, SCIENCE, V315, P972; Fei-Fei L., 2004, IEEE COMP SOC C COMP, P178; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Freitas N.D., 2006, ADV NEURAL INFORM PR, V18, P251; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GIVONI I, 2009, P 14 INT WORKSH ART, V5, P161; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Han J., 2001, DATA MINING CONCEPTS; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jia Y., 2008, P ACM MULT, P639, DOI 10.1145/1459359.1459448; Johnson W., 1984, CONT MATH, V26, P189; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; KUMAR S, 2009, P 14 INT WORKSH ART, V5, P304; Lazebnik S., 2006, IEEE C COMP VIS PATT, P2169; Lee JA, 2005, NEUROCOMPUTING, V67, P29, DOI 10.1016/j.neucom.2004.11.042; Leone M, 2007, BIOINFORMATICS, V23, P2708, DOI 10.1093/bioinformatics/btm414; Liu T., 2005, ADV NEURAL INFORM PR, V17, P825; Liu W., 2010, P INT C MACH LEARN, P679; Madigan D, 2002, DATA MIN KNOWL DISC, V6, P173, DOI 10.1023/A:1014095614948; MAHADEVAN S, 2008, P AAAI C ART INT, P1472; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Ng AY, 2002, ADV NEUR IN, V14, P849; Ouimet M, 2005, P 10 INT WORKSH ART, P253; Papadimitriou C.H, 1998, COMBINATORIAL OPTIMI; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Song Y., 2008, P LEARN PRINC PRACT, P374; STREHL, 2002, J MACHINE LEARNING R, V3, P583; Talwalkar A., 2008, P IEEE C COMP VIS PA, P1; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vidal R, 2004, PROC CVPR IEEE, P510; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672; Williams CKI, 2001, ADV NEUR IN, V13, P682; Wittkop T, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-396; Wu M., 2007, ADV NEURAL INFORM PR, V19, P1529; Xiao J., 2007, P ICCV, P1; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; Yan DH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907; YANN L, 2009, MNIST DATABASE HANDW; Zelnik-Manor L., 2005, ADV NEURAL INFORM PR, V17, P1601; Zhang K., 2008, P 25 INT C MACH LEAR, P273; Zhang K, 2009, NEURAL COMPUT, V21, P121, DOI 10.1162/neco.2008.11-07-651; Zhou DY, 2004, ADV NEUR IN, V16, P321	51	7	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2011	23	2					345	378		10.1007/s10618-010-0207-5		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	752IR	WOS:000289685300005	
J	Lin, YR; Sun, JM; Sundaram, H; Kelliher, A; Castro, P; Konuru, R				Lin, Yu-Ru; Sun, Jimeng; Sundaram, Hari; Kelliher, Aisling; Castro, Paul; Konuru, Ravi			Community Discovery via Metagraph Factorization	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						MetaFac; metagraph factorization; relational hypergraph; nonnegative tensor factorization; community discovery; dynamic social network analysis	NETWORKS; ALGORITHM; WEB	This work aims at discovering community structure in rich media social networks through analysis of time-varying, multirelational data. Community structure represents the latent social context of user actions. It has important applications such as search and recommendation. The problem is particularly useful in the enterprise domain, where extracting emergent community structure on enterprise social media can help in forming new collaborative teams, in expertise discovery, and in the long term reorganization of enterprises based on collaboration patterns. There are several unique challenges: (a) In social media, the context of user actions is constantly changing and coevolving; hence the social context contains time-evolving multidimensional relations. (b) The social context is determined by the available system features and is unique in each social media platform; hence the analysis of such data needs to flexibly incorporate various system features. In this article we propose MetaFac (MetaGraph Factorization), a framework that extracts community structures from dynamic, multidimensional social contexts and interactions. Our work has three key contributions: (1) metagraph, a novel relational hypergraph representation for modeling multirelational and multidimensional social data; (2) an efficient multirelational factorization method for community extraction on a given metagraph; (3) an online method to handle time-varying relations through incremental metagraph factorization. Extensive experiments on real-world social data collected from an enterprise and the public Digg social media Web site suggest that our technique is scalable and is able to extract meaningful communities from social media contexts. We illustrate the usefulness of our framework through two prediction tasks: (1) in the enterprise dataset, the task is to predict users' future interests on tag usage, and (2) in the Digg dataset, the task is to predict users' future interests in voting and commenting on Digg stories. Our prediction significantly outperforms baseline methods (including aspect model and tensor analysis), indicating the promising direction of using metagraphs for handling time-varying social relational contexts.	[Lin, Yu-Ru; Sundaram, Hari; Kelliher, Aisling] Arizona State Univ, Tempe, AZ 85287 USA	Lin, YR (reprint author), Arizona State Univ, Tempe, AZ 85287 USA.	yuruliny@gmail.com			IBM; Kauffman Entrepreneur Scholarship	This article is based upon work supported in part by IBM Ph.D. Fellowship and a Kauffman Entrepreneur Scholarship.	Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1; AGGARWAL C., 2005, P SIAM C DAT MIN SDM; AHMED A., 2008, P IEEE INT C DAT MIN; Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; ASUR S., 2007, P ACM SIGKDD INT C K; BACKSTROM L., 2006, P 12 ACM SIGKDD INT, P44, DOI 10.1145/1150402.1150412; BADER B., 2006, SAND20062161 SAND NA; Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794; BANERJEE A., 2007, P SIAM C DAT MIN SDM; BARBER M., 2008, ARXIV8032854 AM I PH, P171; Basu A, 2007, INTEGR SER INFORM SY, V15, P1, DOI 10.1007/978-0-387-37234-1; Bekkerman Ron, 2005, P 22 INT C MACH LEAR, P41, DOI 10.1145/1102351.1102357; Berge Claude, 1976, GRAPHS HYPERGRAPHS; BERGER-WOLF T., 2006, P ACM SIGKDD INT C K; Borg I., 2005, MODERN MULTIDIMENSIO; Borgatti SP, 2003, MANAGE SCI, V49, P432, DOI 10.1287/mnsc.49.4.432.14428; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; CASTRO P., 2009, P ACM SIGKDD INT C K; Catral M, 2004, LINEAR ALGEBRA APPL, V393, P107, DOI 10.1016/j.laa.2003.11.024; Chakrabarti D., 2006, P 12 ACM SIGKDD INT, P554, DOI 10.1145/1150402.1150467; Chen P., 1976, ACM T DATABASE SYST, V1, P1; Chung F, 1997, SPECTRAL GRAPH THEOR; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DING C., 2005, P SIAM C DAT MIN SDM; Falkowski T, 2006, P 2006 IEEE WIC ACM, P52; FEINBERG Jonathan, 2006, P SIGCHI C HUM FACT, P111, DOI 10.1145/1124772.1124792; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Friedman N., 1999, P 16 INT JOINT C ART, P1300; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; GONG Y., 2008, P INT C KNOWL MAN; GRANOVETTER M, 1985, AM J SOCIOL, V91, P481, DOI 10.1086/228311; GRUJIC J., 2009, P INT C DIGL SIGN PR, P1; HARADA K., 2007, P IEEE INT C COMP IN, P915; Harshman R. A., 1970, UCLA WORKING PAPERS, V16, P1; Hitchcock F. L., 1927, J MATH PHYS, V6, P164; Hofman JM, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.258701; HOFMANN T., 1999, P ACM SIGIR C; HOLDER L., 2009, P ACM SIGKDD INT C K, P977, DOI 10.1145/1557019.1557125; HOLLAND PW, 1981, J AM STAT ASSOC, V76, P33, DOI 10.2307/2287037; JARVELIN K., 2000, P ACM SIGIR C; Kemp C., 2004, DISCOVERING LATENT C; Kemp C, 2006, P 21 NAT C ART INT, P381; KUMAR R., 2006, P ACM SIGKDD INT C K; LAHIRI M., 2008, P IEEE INT C DAT MIN, P373; Lee D. D., 2001, P NIPS VANC CAN, P556; LESKOVEC J., 2008, P ACM SIGKDD INT C K; Long B, 2007, P 13 ACM SIGKDD INT, P470, DOI DOI 10.1145/1281192.1281244; Lovasz L., 1986, MATCHING THEORY; Monge P. R., 2001, NEW HDB ORG COMMUNIC, P440; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Newman MEJ, 2007, P NATL ACAD SCI USA, V104, P9564, DOI 10.1073/pnas.0610537104; Palla G, 2007, NATURE, V446, P664, DOI 10.1038/nature05670; Popescul A, 2001, P 17 C UNC ART INT U, P437; RUGG R., 1984, CARTOGRAPHICA, V21, P179, DOI 10.3138/98M0-1Q05-6201-G572; Sarkar P., 2005, SIGKDD EXPLOR NEWSL, V7, P31; Scandura TA, 2000, ACAD MANAGE J, V43, P1248, DOI 10.2307/1556348; SCHEIN A. I., 2001, P SIGIR WORKSH REC S; SEIDMAN SB, 1981, MATH SOC SCI, V1, P381, DOI 10.1016/0165-4896(81)90016-0; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Simsek Z., 2000, ORGAN RES METHODS, V3, P93, DOI 10.1177/109442810031004; SINGH A., 2008, P ACM SIGKDD INT C K; Smith-Doerr L., 1996, ADM SCI Q, V41; SONG X., 2007, P ACM SIGKDD INT C K; Spiliopoulou M., 2006, P 12 ACM SIGKDD INT, P706, DOI 10.1145/1150402.1150491; Stanton JM, 2001, ORGAN RES METHODS, V4, P200, DOI 10.1177/109442810143002; Sun J., 2007, P 13 ACM SIGKDD INT, P687, DOI DOI 10.1145/1281192.1281266; SUNDARAM H, 2008, P INT WORLD WID WEB; SUNDARAM H., 2009, T KNOWL DISCOV DATA, V3, P2; TANG L., 2008, P ACM SIGKDD INT C K; Tantipathananandh C, 2007, P 13 ACM SIGKDD INT, P717, DOI 10.1145/1281192.1281269; TASKAR B., 2002, P C UNC ART INT UAI, P895; TRESP V., 2005, P C NEUR INF PROC SY; VAVASIS S., 2007, ARXIV07084149V2CSNA; Wang X., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148214; Wasserman S, 1994, SOCIAL NETWORK ANAL; YANG T., 2009, P SIAM INT C DAT MIN; Zhu S., 2007, P 30 ANN INT ACM SIG, P487, DOI 10.1145/1277741.1277825	77	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	AUG	2011	5	3							17	10.1145/1993077.1993081		44	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OY	WOS:000299342000004	
J	Maier, M; Rattigan, M; Jensen, D				Maier, Marc; Rattigan, Matthew; Jensen, David			Indexing Network Structure with Shortest-Path Trees	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Knowledge discovery in graphs; network structure index; social network analysis; weighted networks	SOCIAL NETWORKS; SMALL WORLD; CENTRALITY; ALGORITHM; SEARCH	The ability to discover low-cost paths in networks has practical consequences for knowledge discovery and social network analysis tasks. Many analytic techniques for networks require finding low-cost paths, but exact methods for search become prohibitive for large networks, and data sets are steadily increasing in size. Short paths can be found efficiently by utilizing an index of network structure, which estimates network distances and enables rapid discovery of short paths. Through experiments on synthetic networks, we demonstrate that one such novel network structure index based on the shortest-path tree outperforms other previously proposed indices. We also show that it generalizes across arbitrarily weighted networks of various structures and densities, provides accurate estimates of distance, and has efficient time and space complexity. We present results on real data sets for several applications, including navigation, diameter estimation, centrality computation, and clustering-all made efficient by virtue of the network structure index.	[Maier, Marc; Rattigan, Matthew; Jensen, David] Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA	Maier, M (reprint author), Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA.	maier.marc@gmail.com			Lawrence Livermore National Laboratory; Department of Energy [W7405-ENG-48]; National Science Foundation [IIS-0326249]	This research is supported by Lawrence Livermore National Laboratory and the Department of Energy under contract number W7405-ENG-48 and the National Science Foundation under contract number IIS-0326249.	Adamic LA, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.046135; ARCAUTE E., 2007, P 5 INT C ALG MOD WE, P187; Barrat A, 2004, P NATL ACAD SCI USA, V101, P3747, DOI 10.1073/pnas.0400087101; BENDER M., 2000, P 4 LAT AM S THEOR I; Brandes U, 2001, J MATH SOCIOL, V25, P163; Brandes U, 2007, INT J BIFURCAT CHAOS, V17, P2303, DOI 10.1142/S0218127407018403; CHOW E., 2004, UCRLJRNL202894 LAWR; Cohen E, 2001, J ALGORITHM, V38, P335, DOI 10.1006/jagm.2000.1117; DABEK F., 2004, P 2004 C APPL TECHN, P15, DOI 10.1145/1015467.1015471; Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; Erdos P, 1959, PUBL MATH-DEBRECEN, V6, P290; Faloutsos C., 2004, P 10 ACM SIGKDD INT, P118, DOI 10.1145/1014052.1014068; FAST A., 2007, P 13 ACM SIGKDD INT, P941, DOI 10.1145/1281192.1281293; Flake G.W., 2004, INTERNET MATH, V1, P385, DOI DOI 10.1080/15427951.2004.10129093; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7; Friedland L., 2007, P 13 ACM INT C SIGKD, P290, DOI 10.1145/1281192.1281226; Gavoille C, 2001, SIAM PROC S, P210; GEISBERGER R., 2008, P 10 WORKSH ALG ENG; Goldberg AV, 2005, PROCEEDINGS OF THE SIXTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P156; GRIFFIN T., 2005, P ACM IMC OCT, P125; Hadjiconstantinou E, 1999, NETWORKS, V34, P88, DOI 10.1002/(SICI)1097-0037(199909)34:2<88::AID-NET2>3.3.CO;2-T; HALPERIN S., 1996, P ANN S FDN COMP SCI, P452; HAREL D, 1984, SIAM J COMPUT, V13, P338, DOI 10.1137/0213024; Kleinberg J., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335325; Kleinberg J, 2009, J ACM, V56, DOI 10.1145/1568318.1568322; Kleinberg JM, 2000, NATURE, V406, P845, DOI 10.1038/35022643; KOREN Y., 2007, ACM T KNOWL DISCOV D, V1, P12, DOI 10.1145/1297332.1297336; KORF RE, 1985, ARTIF INTELL, V27, P97, DOI 10.1016/0004-3702(85)90084-0; KRIOUKOV D., 2004, P 23 IEEE C COMP COM; KUMAR R., 2006, P 14 ANN EUR S ALG, P480; KURUMIDA Y., 2006, P 1 INT C SCAL INF S; Leskovec J., 2008, THESIS CARNEGIE MELL; Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI 10.1145/1081870.1081893; Mao Y., 2004, P 4 ACM SIGCOMM C IN, P278, DOI 10.1145/1028788.1028827; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; Newman MEJ, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.056131; Pias M., 2003, P INT WORKSH PEER TO; Pollner P, 2006, EUROPHYS LETT, V73, P478, DOI 10.1209/epl/i2005-10414-6; POTAMIAS M., 2009, P 18 ACM C INF KNOWL; Provost F, 1999, P 5 ACM SIGKDD INT C; Rattigan M., 2007, P 24 INT C MACH LEAR, P783, DOI 10.1145/1273496.1273595; Rattigan M. J., 2006, P 12 ACM SIGKDD INT, P357, DOI 10.1145/1150402.1150443; ROLI A., 2005, P ADV ART INT AI IA, P13; Russell S., 1995, ARTIFICIAL INTELLIGE; Shavitt Y, 2004, IEEE ACM T NETWORK, V12, P993, DOI 10.1109/TNET.2004.838597; Simsek O, 2008, P NATL ACAD SCI USA, V105, P12758, DOI 10.1073/pnas.0800497105; Slivkins A, 2007, DISTRIB COMPUT, V19, P313, DOI 10.1007/s00446-006-0015-8; TANG L., 2004, P 5 PASS ACT MEAS WO; Tang L.Y., 2003, P 3 ACM SIGCOMM C IN, P143; TAURO S., 2001, P IEEE GLOB TEL C 3; Thorup M, 2005, J ACM, V52, P1, DOI 10.1145/1044731.1044732; TRAVERS J, 1969, SOCIOMETRY, V32, P425, DOI 10.2307/2786545; WALSH T, 1999, P 16 INT JOINT C ART, P1172; Wasserman S, 1994, SOCIAL NETWORK ANAL; Watts D. J., 1998, NATURE, V393, P409, DOI DOI 10.1038/30918; Watts DJ, 2002, SCIENCE, V296, P1302, DOI 10.1126/science.1070120; Wong B., 2005, P SIGCOMM, P85, DOI 10.1145/1080091.1080103; ZHANG H., 2002, P 21 IEEE C COMP COM; Zwick U., 2001, P 9 ESA, P33	60	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	AUG	2011	5	3							15	10.1145/1993077.1993079		25	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OY	WOS:000299342000002	
J	Wang, DD; Zhu, SH; Li, T; Chi, Y; Gong, YH				Wang, Dingding; Zhu, Shenghuo; Li, Tao; Chi, Yun; Gong, Yihong			Integrating Document Clustering and Multidocument Summarization	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Document clustering; multidocument summarization; nonnegative matrix factorization with given bases		Document understanding techniques such as document clustering and multidocument summarization have been receiving much attention recently. Current document clustering methods usually represent the given collection of documents as a document-term matrix and then conduct the clustering process. Although many of these clustering methods can group the documents effectively, it is still hard for people to capture the meaning of the documents since there is no satisfactory interpretation for each document cluster. A straightforward solution is to first cluster the documents and then summarize each document cluster using summarization methods. However, most of the current summarization methods are solely based on the sentence-term matrix and ignore the context dependence of the sentences. As a result, the generated summaries lack guidance from the document clusters. In this article, we propose a new language model to simultaneously cluster and summarize documents by making use of both the document-term and sentence-term matrices. By utilizing the mutual influence of document clustering and summarization, our method makes; (1) a better document clustering method with more meaningful interpretation; and (2) an effective document summarization method with guidance from document clustering. Experimental results on various document datasets show the effectiveness of our proposed method and the high interpretability of the generated summaries.	[Wang, Dingding; Li, Tao] Florida Int Univ, Sch Comp Sci, Miami, FL 33199 USA; [Zhu, Shenghuo; Chi, Yun; Gong, Yihong] NEC Labs Amer Inc, Cupertino, CA 95014 USA	Wang, DD (reprint author), Florida Int Univ, Sch Comp Sci, 11200 SW 8th St, Miami, FL 33199 USA.	dwang003@cs.fiu.edu; zsh@sv.nec-labs.com; taoli@cs.fiu.edu; ychi@sv.nec-labs.com; ygong@sv.nec-labs.com			Florida International University (FIU); NSF [IIS-0546280, CCF-0836359, DMS-0915110]	The work is partially supported by a Florida International University (FIU) Dissertation Year Fellowship and NSF Grants IIS-0546280, CCF-0836359, and DMS-0915110.	Blei DM, 2002, ADV NEUR IN, V14, P601; Cho H., 2004, P SIAM INT C DAT MIN; Conroy J.M., 2001, P 24 ANN INT ACM SIG, P406, DOI 10.1145/383952.384042; Dhillon I. S, 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Ding CH, 2006, P 12 ACM SIGKDD INT, P126, DOI 10.1145/1150402.1150420; Ding C. H. Q., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989507; Duda R.O., 2001, PATTERN CLASSIFICATI; Elkan C., 2006, P 23 INT C MACH LEAR, P289, DOI DOI 10.1145/1143844.1143881; Goldstein J., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312665; GONG Y., 2003, P ACM SIGIR C RES DE, P373; Gong Y., 2001, P INT ACM SIGIR C RE, P75; GOODMAN J., 2007, P IJCAI 2007, P1776; He Ji, 2004, P INT JOINT C NEUR N; HOFFMAN T., 1999, P 22 ANN INT SIGIR C; HOVY E., 2001, P 40 ANN M ASS COMP, P457, DOI 10.3115/1073083.1073160; Jing L, 2007, IEEE T KNOWL DATA EN, V19, P1026, DOI 10.1109/TKDE.2007.1048; Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9; LI T., 2005, P 11 ACM SIGKDD INT, P188, DOI 10.1145/1081870.1081894; Li T., 2004, P 27 ANN INT ACM SIG, P218, DOI 10.1145/1008992.1009031; Li Tao, 2006, P IEEE INT C DAT MIN, P362; Lin C., 2003, P 2003 C N AM CHAPT, P71; Long Bo, 2006, P 12 ACM SIGKDD INT, P317, DOI 10.1145/1150402.1150439; LONG C., 2009, P INT C DAT MIN ICDM; MANA-LOPEZ M. J., 2004, ACM T INFORM SYST; Mani I., 2001, AUTOMATIC SUMMARIZAT; MCKEOWN K., 2000, P ANN C N AM ASS COM; MCKEOWN K. R., 2002, P 2 INT C HUM LANG T; MIHALCEA R., 2005, P INT C NAT LANG PRO; MODHA S., 2001, P 7 ACM SIGKDD INT C, P89; Nastase V., 2008, P C EMP METH NAT LAN, P763, DOI 10.3115/1613715.1613812; PARK S., 2007, P C CURR TRENDS THEO; PECK R., 1977, STAT EXPLORATION ANA; Radev D., 2004, INFORM PROCESSING MA, P919; RADEV D., 2004, P INT C EMP METH NAT; RICARDO B., 1999, MODERN INFORM RETRIE; SCHLESINGER J., 2007, INFORM PROCESS MANAG; SEUNG H. S., 2001, P C NEUR INF PROC SY; Shen D., 2007, P 20 INT JOINT C ART, P2862; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; STREHL A., 2003, J MACH LEARN RES, P583; TANG J., 2009, P SIAM INT C DAT MIN; Turpin A., 2007, P 30 ANN INT ACM SIG, P127, DOI 10.1145/1277741.1277766; Wan X. J., 2007, P 20 INT JOINT C ART, P2903; Wan X. J., 2009, P 21 INT JOINT C ART, P1586; WANG D., 2009, P ANN M ASS COMP LIN; WANG D., 2008, P ACM SIGIR C RES DE; Wang D. D., 2008, P ACM 17 C INF KNOWL, P1435, DOI 10.1145/1458082.1458319; Wang F., 2007, P 2 INT C INT INF MA, P95, DOI 10.1145/1277741.1277760; Wei F., 2008, P 31 ANN INT ACM SIG, P283, DOI 10.1145/1390334.1390384; Xu W, 2004, P INT C RES DEV INF, P202, DOI 10.1145/1008992.1009029; YANG J., 2008, P 31 ACM ANN INT SIG; Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290956; Zha H., 2001, P 10 INT C INF KNOWL, P25; Zhong S, 2003, J MACHINE LEARNING R, V4, P1001, DOI 10.1162/jmlr.2003.4.6.1001; Zhong S, 2005, KNOWL INF SYST, V8, P374, DOI 10.1007/s10115-004-0194-1; ZHU S., 2003, P 3 ACM IEEE CS JOIN, P191; ZIEN J., 1999, IEEE T COMPUT AID DE, P1389	57	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	AUG	2011	5	3							14	10.1145/1993077.1993078		26	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OY	WOS:000299342000001	
J	Wong, RCW; Fu, AWC; Wang, K; Yu, PS; Pei, J				Wong, Raymond Chi-Wing; Fu, Ada Wai-Chee; Wang, Ke; Yu, Philip S.; Pei, Jian			Can the Utility of Anonymized Data be Used for Privacy Breaches?	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Privacy preservation; data publishing; l-diversity; k-anonymity	BACKGROUND KNOWLEDGE; UNCERTAIN DATA; INFORMATION	Group based anonymization is the most widely studied approach for privacy-preserving data publishing. Privacy models/definitions using group based anonymization includes k-anonymity, l-diversity, and t-closeness, to name a few. The goal of this article is to raise a fundamental issue regarding the privacy exposure of the approaches using group based anonymization. This has been overlooked in the past. The group based anonymization approach by bucketization basically hides each individual record behind a group to preserve data privacy. If not properly anonymized, patterns can actually be derived from the published data and be used by an adversary to breach individual privacy. For example, from the medical records released, if patterns such as that people from certain countries rarely suffer from some disease can be derived, then the information can be used to imply linkage of other people in an anonymized group with this disease with higher likelihood. We call the derived patterns from the published data the foreground knowledge. This is in contrast to the background knowledge that the adversary may obtain from other channels, as studied in some previous work. Finally, our experimental results show such an attack is realistic in the privacy benchmark dataset under the traditional group based anonymization approach.	[Wong, Raymond Chi-Wing] Hong Kong Univ Sci & Technol, Hong Kong, Hong Kong, Peoples R China; [Fu, Ada Wai-Chee] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China; [Wang, Ke; Pei, Jian] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada; [Yu, Philip S.] Univ Illinois, Chicago, IL 60680 USA	Wong, RCW (reprint author), Hong Kong Univ Sci & Technol, Hong Kong, Hong Kong, Peoples R China.	raywong@cse.ust.hk	WANG, Ke/H-6830-2013		HKRGC [GRF 621309]; NSERC; US NSF [IIS-0914934, OISE-0968341, OIA-0963278]	The research of Raymond Chi-WingWong was supported by HKRGC GRF 621309. The research of Ke Wang was supported by a Discovery Grant from NSERC. The research of Philip S. Yu was supported by US NSF through grants IIS-0914934, OISE-0968341, and OIA-0963278.	Aggarwal C.C., 2006, P 12 ACM SIGKDD INT, P510, DOI 10.1145/1150402.1150460; Aggarwal CC, 2008, PROC INT CONF DATA, P386, DOI 10.1109/ICDE.2008.4497447; AGGARWAL G., 2005, P 10 INT C DAT THEOR, P246; ANTOVA L., 2007, P 23 INT C DAT ENG I, P606; Blake E.K.C., 1998, UCI REPOSITORY MACHI; Brickell J., 2008, P 14 ACM SIGKDD INT, P70, DOI 10.1145/1401890.1401904; BURDICK D., 2007, P INT C VER LARG DAT, P39; BURDICK D., 2005, P INT C VER LARG DAT, P123; Chapra S. C., 2002, NUMERICAL METHODS EN; Cheng R, 2008, PROC INT CONF DATA, P973, DOI 10.1109/ICDE.2008.4497506; CLIFTON C., 2007, P INT C DAT ENG WORK, P622; Fung BCM, 2005, PROC INT CONF DATA, P205; Ganta S, 2008, P 14 ACM SIGKDD INT, P265, DOI 10.1145/1401890.1401926; IMIELINSKI T, 1984, J ACM, V31, P761, DOI 10.1145/1634.1886; Kifer D., 2006, P ACM SIGMOD INT C M, P217, DOI 10.1145/1142473.1142499; KIFER D., 2009, P ACM SIGMOD INT C M, P127, DOI 10.1145/1559845.1559861; Lefevre K., 2005, P ACM SIGMOD INT C M, P49, DOI 10.1145/1066157.1066164; Li TC, 2009, PROC INT CONF DATA, P6; Li TC, 2008, PROC INT CONF DATA, P446, DOI 10.1109/ICDE.2008.4497453; Machanavajjhala A., 2007, P INT C DAT ENG ICDE, P126; Machanavajjhala A., 2006, P 22 INT C DAT ENG I, P24, DOI DOI 10.1109/ICDE.2006.1; Ninghui LI, 2007, P IEEE INT C DAT ENG, P106, DOI DOI 10.1109/ICDE.2007.367856; SILVERSTEIN C., 1997, P ACM SIGMOD INT C M, P265; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Wang K., 2004, P 4 IEEE INT C DAT M, P249; Wong Raymond Chi-Wing, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.18; Wong RCW, 2007, P INT C VER LARG DAT, P543; Wong RC-W, 2006, P 12 ACM SIGKDD INT, P754; Xiao X., 2006, P 32 INT C VER LARG, P139; Xiao X., 2007, P ACM SIGMOD INT C M, P689, DOI DOI 10.1145/1247480.1247556; Zhang Qiu-yu, 2007, Proceedings International Conference on Informatics and Control Technologies 2006; Zhu ZT, 2009, PROC INT CONF DATA, P18	33	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	AUG	2011	5	3							16	10.1145/1993077.1993080		24	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OY	WOS:000299342000003	
J	Shan, HH; Banerjee, A				Shan, Hanhuai; Banerjee, Arindam			Mixed-membership naive Bayes models	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Naive Bayes; Latent Dirichlet allocation; Mixed-membership; Generative models; Variational inference; Logistic regression	MAXIMUM-LIKELIHOOD; EM ALGORITHM; DISTRIBUTIONS; IMAGES	In recent years, mixture models have found widespread usage in discovering latent cluster structure from data. A popular special case of finite mixture models is the family of naive Bayes (NB) models, where the probability of a feature vector factorizes over the features for any given component of the mixture. Despite their popularity, naive Bayes models do not allow data points to belong to different component clusters with varying degrees, i.e., mixed memberships, which puts a restriction on their modeling ability. In this paper, we propose mixed-membership naive Bayes (MMNB) models. On one hand, MMNB can be viewed as a generalization of NB by putting a Dirichlet prior on top to allow mixed memberships. On the other hand, MMNB can also be viewed as a generalization of latent Dirichlet allocation (LDA) with the ability to handle heterogeneous feature vectors with different types of features, e.g., real, categorical, etc.. We propose two variational inference algorithms to learn MMNB models. The first one is based on ideas originally used in LDA, and the second one uses substantially fewer variational parameters, leading to a significantly faster algorithm. Further, we extend MMNB/LDA to discriminative mixed-membership models for classification by suitably combining MMNB/LDA with multi-class logistic regression. The efficacy of the proposed mixed-membership models is demonstrated by extensive experiments on several datasets, including UCI benchmarks, recommendation systems, and text datasets.	[Shan, Hanhuai; Banerjee, Arindam] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Shan, HH (reprint author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	shan@cs.umn.edu; banerjee@cs.umn.edu			National Science Foundation [IIS-0812183, IIS-0916750, IIS-0953274]; National Aeronautics and Space Administration [NNX08AC36A]	We want to warmly thank Nikunj Oza for valuable input on discriminative mixed membership models. The research was supported by National Science Foundation grants IIS-0812183, IIS-0916750, National Science Foundation CAREER grant IIS-0953274, and National Aeronautics and Space Administration grant NNX08AC36A.	AIROLDI EM, 2008, J MACHINE LEARNING R, V9, P1823; BANERJEE A, 2004, P 21 INT C MACH LEAR; Banerjee A, 2005, J MACH LEARN RES, V6, P1345; BANERJEE A, 2007, P 7 SIAM INT C DAT M; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Barndorff-Nielsen O., 1978, INFORM EXPONENTIAL F; BLEI D, 2005, P 18 ANN C NEUR INF; BLEI D, 2003, ACM SIGIR, P127; BLEI D, 2007, P 20 ANN C NEUR INF; Blei D. M., 2006, P 23 INT C MACH LEAR; Blei DM, 2006, BAYESIAN ANAL, V1, P121; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; de Finetti B., 1990, THEORY PROBABILITY; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DeGroot M. H., 1970, OPTIMAL STAT DECISIO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dhillon I. S., 2003, KDD, P89; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Erosheva E, 2004, P NATL ACAD SCI USA, V101, P5220, DOI 10.1073/pnas.0307760101; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Flaherty P, 2005, BIOINFORMATICS, V21, P3286, DOI 10.1093/bioinformatics/bti515; Fu Q, 2008, IEEE DATA MINING, P791, DOI 10.1109/ICDM.2008.103; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; GHAHRAMANI Z, 1995, P 8 ANN C NEUR INF P; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Heller K. A., 2008, P 25 INT C MACH LEAR, P392, DOI 10.1145/1390156.1390206; HOFFMAN T, 1999, P 15 C UNC ART INT U; JAAKKOLA T, 2000, ALGORITHMS CLUSTERIN; KOUTSOURELAKIS P, 2008, P 23 NAT C ART INT A; LACOSTEJULIEN S, 2008, P 21 ANN C NEUR INF; Lang K., 1995, P 12 INT C MACH LEAR; MCLACHLAN G, 1996, EM ALGORTITHM EXTENS; Mimno D., 2008, P 24 C UNC ART INT U; Minka T., 2003, ESTIMATING DIRICHLET; MINKA T. P., 2003, COMP NUMERICAL OPTIM; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Mooney R, 2005, P 11 ACM SIGKDD INT, P532, DOI 10.1145/1081870.1081932; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; NEWMAN D, 2007, P 20 ANN C NEUR INF; NG A, 2001, P 14 ANN C NEUR INF; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pampel F, 2000, LOGISTIC REGRESSION; Porteous I, 2008, P 14 ACM SIGKDD INT, P569, DOI DOI 10.1145/1401890.1401960; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; SAUND E, 1994, P 7 ANN C NEUR INF P; Segal E, 2003, P 8 PAC S BIOC PSB; SHAHAMI M, 1997, P 14 INT C MACH LEAR, P435; Shan HH, 2008, IEEE DATA MINING, P530, DOI 10.1109/ICDM.2008.91; WAINWRIGHT M, 2003, 649 TR U CAL DEP STA; WANG C., 2009, P IEEE C COMP VIS PA; Wang H., 2008, P 8 IEEE INT C DAT M; Yousef M, 2007, BIOINFORMATICS, V23, P2987, DOI 10.1093/bioinformatics/btm484	54	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2011	23	1					1	62		10.1007/s10618-010-0198-2		62	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	744PH	WOS:000289106000001	
J	Desrosiers, C; Galinier, P; Hertz, A; Hansen, P				Desrosiers, Christian; Galinier, Philippe; Hertz, Alain; Hansen, Pierre			Improving constrained pattern mining with first-fail-based heuristics	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Constraint-based pattern mining; Frequent subgraph mining; First-fail heuristic	SEQUENTIAL PATTERNS; DISCOVERY	In this paper, we present a general framework to mine patterns with antimonotone constraints. This framework uses a technique that structures the pattern space in a way that facilitates the integration of constraints within the mining process. Furthermore, we also introduce a powerful strategy that uses background information on the data to speed-up the mining process. We illustrate our approach on a popular structured data mining problem, the frequent subgraph mining problem, and show, through experiments on synthetic and real-life data, that this general approach has advantages over state-of-the-art pattern mining algorithms.	[Desrosiers, Christian] Ecole Technol Super, Montreal, PQ H3C 1K3, Canada; [Galinier, Philippe; Hertz, Alain] Ecole Polytech, Montreal, PQ H3C 3A7, Canada; [Hansen, Pierre] HEC Montreal, Montreal, PQ H3T 2A7, Canada	Desrosiers, C (reprint author), Ecole Technol Super, 1100 Notre Dame O, Montreal, PQ H3C 1K3, Canada.	christian.desrosiers@etsmtl.ca; philippe.galinier@polymtl.ca; alain.hertz@polymtl.ca; pierre.hansen@gerad.ca					Agrawal R., 1993, 1993 ACM SIGMOD INT, P207; Asai T, 2002, SIAM PROC S, P158; BESSIERE C, 1996, MAC COMBINED HEURIST; Borgelt C, 2005, LECT NOTES COMPUT SC, V3571, P1002; CHEN Y, 2004, P ACM SIGGRAPH, P343; Dehaspe L, 1999, DATA MIN KNOWL DISC, V3, P7, DOI 10.1023/A:1009863704807; DESHPANDE M, 2002, P WORKSH DAT MIN BIO, P11; DESROSIERS C, 2007, G200712 CAH GERAD; Fortin S., 1996, 9620 U ALB; GADE K, 2004, P 10 ACM SIGKDD INT, P138, DOI 10.1145/1014052.1014070; GAREYMR, 1979, COMPUTERS INTRACTABI; Garofalakis M, 2002, IEEE T KNOWL DATA EN, V14, P530, DOI 10.1109/TKDE.2002.1000341; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J, 2002, ICDM, P721; Huan J, 2003, P 3 IEEE INT C DAT M, P549; Inokuchi A., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Kramer S., 2001, P 7 ACM SIGKDD INT C, P136, DOI 10.1145/502512.502533; Kuramochi M, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P313; Kuramochi M, 2005, DATA MIN KNOWL DISC, V11, P243, DOI 10.1007/s10618-005-0003-9; LEE SD, 2004, DATABASE SUPPORT DAT, P155; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; McKay B., 1981, C NUMERANTIUM, V30, P45; NG R, 1998, SIGMOD, P13; NIJSSEN S, 2001, IJCAI, P891; NIJSSEN S, 2004, P INT WORKSH GRAPH B, P281; Pei J, 2001, PROC INT CONF DATA, P215; Zaki M. J., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354849; Srikant R., 1996, EDBT, P3; STERNBERG MJE, 1995, MACH INTELL, V15, P328; Termier A, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P450, DOI 10.1109/ICDM.2002.1183987; Wang C, 2004, J COMPUT SCI TECH-CH, V19, P309, DOI 10.1007/BF02944901; Wang C K, 2005, P 7 AS PAC WEB C, P133; Yan X., 2004, P ACM SIGMOD INT C M, P335, DOI 10.1145/1007568.1007607; Zaki M. J., 2002, KDD 02, P71; Zaki MJ, 2004, BIOINFORMATICS, V20, P386, DOI 10.1093/bioinformatics/bth935; Zhu F, 2007, LECT NOTES COMPUT SC, V4426, P388; *NCI, 1999, DTP 2D 3D STRUCT INF	37	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2011	23	1					63	90		10.1007/s10618-010-0199-1		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	744PH	WOS:000289106000002	
J	Zhu, QA; Wang, XY; Keogh, E; Lee, SH				Zhu, Qiang; Wang, Xiaoyue; Keogh, Eamonn; Lee, Sang-Hee			An efficient and effective similarity measure to enable data mining of petroglyphs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Image processing; Similarity search; Cultural artifacts	CHARACTER-RECOGNITION; DISTANCE; CURVES; SECURITY; PICTURES	Rock art is an archaeological term for human-made markings on stone, including carved markings, known as petroglyphs, and painted markings, known as pictographs. It is believed that there are millions of petroglyphs in North America alone, and the study of this valued cultural resource has implications even beyond anthropology and history. Surprisingly, although image processing, information retrieval and data mining have had a large impact on many human endeavors, they have had essentially zero impact on the study of rock art. In this work we identify the reasons for this, and introduce a novel distance measure and algorithms which allow efficient and effective data mining of large collections of rock art.	[Zhu, Qiang; Wang, Xiaoyue; Keogh, Eamonn] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA; [Lee, Sang-Hee] Univ Calif Riverside, Dept Anthropol, Riverside, CA 92521 USA	Zhu, QA (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	qzhu@cs.ucr.edu; xwang@cs.ucr.edu; eamonn@cs.ucr.edu; sang-hee.lee@ucr.edu			NSF [0803410, 0808770]; National Geographic Society/Waitt Grant	This work was funded by NSF 0803410 and NSF 0808770. Field work for this project was funded by a National Geographic Society/Waitt Grant. We would like to thank the many donors of datasets, particularly Dr. Robert Mark and Evelyn Billo of www.rupestrian.com, Taryn T. Rampley of UCR and the Document Analysis Group of the Computer Vision Center in Universitat Autonoma de Barcelona.	ALT H, 1995, INT J COMPUT GEOM AP, V5, P75, DOI 10.1142/S0218195995000064; Valladas H, 2001, NATURE, V413, P479, DOI 10.1038/35097160; ASEYEV IV, 2008, ARCHAEOLOGY ETHNOLOG, V34, P96; Assent I, 2008, PROC INT CONF DATA, P307, DOI 10.1109/ICDE.2008.4497439; Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; Borji A, 2008, NEURAL PROCESS LETT, V28, P97, DOI 10.1007/s11063-008-9084-y; CHAUVET SC, 1935, LILE PAQUES SES MYST; Chellapilla K., 2005, P SIGCHI C HUM FACT, P711, DOI 10.1145/1054972.1055070; DICKINSON EA, W J COMMUN IN PRESS; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; MERLIN PM, 1975, IEEE T COMPUT, VC 24, P96, DOI 10.1109/T-C.1975.224087; Fornes A, 2008, LECT NOTES COMPUT SC, V5046, P51, DOI 10.1007/978-3-540-88188-9_6; FORNES A, 2009, THESIS U AUTONOMA BA; GERALD AS, 1975, INDIAN ROCK ART SO C; Grant Campbell, 1968, ROCK DRAWINGS COSO R; Henshilwood CS, 2002, SCIENCE, V295, P1278, DOI 10.1126/science.1067575; HOUGH PVC, 1966, Patent No. 3069654; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Keogh EJ, 2006, VLDB; Khosravi H, 2007, PATTERN RECOGN LETT, V28, P1133, DOI 10.1016/j.patrec.2006.12.022; Landon GV, 2006, MACH VISION APPL, V17, P361, DOI 10.1007/s00138-006-0044-0; MARK R, 2002, AM INDIAN ROCK ART, V28, P121; Mas J, 2005, LECT NOTES COMPUT SC, V3523, P115; MAS J, 2006, LECT NOTES COMPUTER, V3926, P252; MCDONALD JJ, 2007, P 22 VALC S, P327; Mueen A., 2009, SDM; Niels R., 2008, 11 INT C FRONT HANDW; PAN J, 2006, KDD; PATTERSON A, 1992, ROCK ART SYMBOLS GRE; PETTIGREW J, 2008, J ANTIQ; POWELL JW, 1888, ANN REPORT BUREAU AM; Sanchez G, 2004, LECT NOTES COMPUT SC, V3163, P389; TAKAKI R, 2006, FORMA, V21, P243; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; Veltkamp R. C., 2001, INT C SHAP MOD APPL; von Ahn L, 2006, COMPUTER, V39, P92, DOI 10.1109/MC.2006.196; von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294; von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379; WALT H, 2006, INT ROCK ART DATABAS; Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008; Zhu Q, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1057; Ziou D., 1998, INT J PATTERN RECOGN, V8, P537	46	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2011	23	1					91	127		10.1007/s10618-010-0200-z		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	744PH	WOS:000289106000003	
J	Ikonomovska, E; Gama, J; Dzeroski, S				Ikonomovska, Elena; Gama, Joao; Dzeroski, Saso			Learning model trees from evolving data streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Non-stationary data streams; Stream data mining; Regression trees; Model trees; Incremental algorithms; On-line learning; Concept drift; On-line change detection	REGRESSION TREES; DRIFT	The problem of real-time extraction of meaningful patterns from time-changing data streams is of increasing importance for the machine learning and data mining communities. Regression in time-changing data streams is a relatively unexplored topic, despite the apparent applications. This paper proposes an efficient and incremental stream mining algorithm which is able to learn regression and model trees from possibly unbounded, high-speed and time-changing data streams. The algorithm is evaluated extensively in a variety of settings involving artificial and real data. To the best of our knowledge there is no other general purpose algorithm for incremental learning regression/model trees able to perform explicit change detection and informed adaptation. The algorithm performs online and in real-time, observes each example only once at the speed of arrival, and maintains at any-time a ready-to-use model tree. The tree leaves contain linear models induced online from the examples assigned to them, a process with low complexity. The algorithm has mechanisms for drift detection and model adaptation, which enable it to maintain accurate and updated regression models at any time. The drift detection mechanism exploits the structure of the tree in the process of local change detection. As a response to local drift, the algorithm is able to update the tree structure only locally. This approach improves the any-time performance and greatly reduces the costs of adaptation.	[Ikonomovska, Elena; Dzeroski, Saso] Jozef Stefan Inst, Ljubljana 1000, Slovenia; [Gama, Joao] Univ Porto, LIAAD INESC, P-4050190 Oporto, Portugal; [Gama, Joao] Univ Porto, Fac Econ, P-4200 Oporto, Portugal; [Ikonomovska, Elena] Ss Cyril & Methodius Univ, Fac Elect Engn & Informat Technol, Skopje 1000, Macedonia	Ikonomovska, E (reprint author), Jozef Stefan Inst, Jamova Cesta 39, Ljubljana 1000, Slovenia.	elena.ikonomovska@ijs.si			Slovenian Research Agency; European Commission; Knowledge Discovery from Ubiquitous Data Streams [PTDC/EIA/098355/2008]	We thank Claude Sammut and Duncan Potts for providing the code of their algorithm, and to Raquel Sebastiao and Dejan Gjorgjevik who coauthored the paper (Ikonomovska et al. 2009). Elena Ikonomovska is supported by a young researcher grant from the Slovenian Research Agency. Saso Dzeroski is supported by the grants "Advanced Machine Learning Methods for Automated Modeling of Dynamic Systems", "Data Mining for Integrative Analysis in Systems Biology" and "Knowledge Technologies" from the Slovenian Research Agency and the grant PHAGOSYS (Systems Biology of Phagosome Formation and Maturation - Modulation by Intracellular Pathogens) by the European Commission. Joao Gama is supported by the grant "Knowledge Discovery from Ubiquitous Data Streams" (PTDC/EIA/098355/2008).	Aggarwal C. C., 2006, DATA STREAMS MODELS; Basseville M., 1993, DETECTION ABRUPT CHA; Blake C., 1999, UCI REPOSITORY MACHI; Breiman L., 1998, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; CHAUDHURI P, 1994, STAT SINICA, V4, P143; CHEN Y., 2002, P 28 INT C VER LARG, P323; Dasu T., 2009, P IDA 09, P21; DAWID AP, 1984, J ROY STAT SOC A STA, V147, P278, DOI 10.2307/2981683; Dobra A., 2002, P 8 ACM SIGKDD INT C, P481; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347107; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gama J., 2004, P 2004 ACM S APPL CO, P632, DOI 10.1145/967900.968033; Gama J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P329; GAMA J, 2004, LNCS, V4093, P42; Gama J., 2003, P 9 ACM SIGKDD INT C, P523, DOI DOI 10.1145/956750.956813; Gammerman A, 2002, THEOR COMPUT SCI, V287, P209, DOI 10.1016/S0304-3975(02)00100-7; Gammerman A, 2007, COMPUT J, V50, P151, DOI [10.1093/comjnl/bx1065, 10.1093/comjnl/bxl065]; GAO J, 2007, P 7 INT C DAT MIN; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GRATCH J, 1996, P 13 NAT C ART INT, V1, P779; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Hulten G., 2001, SIGKDD, P97; Ikonomovska E, 2009, LECT NOTES ARTIF INT, V5808, P121; Ikonotnovska E, 2008, LECT NOTES COMPUT SC, V5255, P52, DOI 10.1007/978-3-540-88411-8_8; Jin R., 2003, P 9 ACM SIGKDD INT C, P571; Karalic A., 1992, P ECAI 92, P440; Kifer D., 2004, P 30 INT C VER LARG, P180, DOI 10.1016/B978-012088469-8/50019-X; Klinkenberg R, 1998, LEARNING TEXT CATEGO, P33; Klinkenberg R., 2000, P 17 INT C MACH LEAR, P487; Loh WY, 2002, STAT SINICA, V12, P361; Malerba D, 2002, LECT NOTES ARTIF INT, V2366, P393; Mouss H., 2004, P 5 AS CONTR C, V2, P815; MUSICK R, 1993, P 10 INT C MACH LEAR, P212; PANG KP, 2005, LNCS, V3339, P402; Pfahringer B, 2008, LECT NOTES ARTIF INT, V5012, P296, DOI 10.1007/978-3-540-68125-0_27; Potts D, 2005, MACH LEARN, V61, P5, DOI 10.1007/s10994-005-1121-8; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Rajaraman K., 2001, LNCS, V2035, P102; RODRIGUES PP, 2008, P IEEE INT C DAT MIN, P36; SEBASTIAO R, 2009, P IEEE INT C DAT MIN, P248; SICILANO R, 1994, P COMP STAT COMPSTAT, P172; Song XY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P667; Subramaniam S., 2006, P 32 INT C VER LARG, P187; Torgo L., 1997, P 14 INT C MACH LEAR, P385; Vogel DS, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P757; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280; [Anonymous], 2009, ASA SECTIONS STAT CO; *RULEQUEST RES, 2009, CUBIST; *VFML, 2003, TOOLK MIN HIGH SPEED; *WEKA 3, 2005, DAT MIN SOFTW JAV	51	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2011	23	1					128	168		10.1007/s10618-010-0201-y		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	744PH	WOS:000289106000004	
J	Vreeken, J; van Leeuwen, M; Siebes, A				Vreeken, Jilles; van Leeuwen, Matthijs; Siebes, Arno			Krimp: mining itemsets that compress	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						MDL; Pattern mining; Pattern selection; Itemsets		One of the major problems in pattern mining is the explosion of the number of results. Tight constraints reveal only common knowledge, while loose constraints lead to an explosion in the number of returned patterns. This is caused by large groups of patterns essentially describing the same set of transactions. In this paper we approach this problem using the MDL principle: the best set of patterns is that set that compresses the database best. For this task we introduce the Krimp algorithm. Experimental evaluation shows that typically only hundreds of itemsets are returned; a dramatic reduction, up to seven orders of magnitude, in the number of frequent item sets. These selections, called code tables, are of high quality. This is shown with compression ratios, swap-randomisation, and the accuracies of the code table-based Krimp classifier, all obtained on a wide range of datasets. Further, we extensively evaluate the heuristic choices made in the design of the algorithm.	[Vreeken, Jilles; van Leeuwen, Matthijs; Siebes, Arno] Univ Utrecht, Dept Informat & Comp Sci, Fac Sci, Utrecht, Netherlands; [Vreeken, Jilles] Univ Antwerp, ADReM, Dept Math & Comp Sci, Fac Sci, B-2020 Antwerp, Belgium	Vreeken, J (reprint author), Univ Utrecht, Dept Informat & Comp Sci, Fac Sci, Utrecht, Netherlands.	jillesv@cs.uu.nl; mleeuwen@cs.uu.nl; arno@cs.uu.nl			NWO [612.065.822]; NBIC	Jilles Vreeken is supported by the NWO project Mining Factors of Celiac Disease, part of the Computational Life Sciences Programme. Matthijs van Leeuwen is supported by the NBIC Biorange Programme and the NWO project Exceptional Model Mining, under number 612.065.822. The authors would like to thank Sander Schuckmann for parallelising the KRIMP implementation.	AGRAWAL R, 1996, FAST DISCOVERY ASS R, P307; BATHOORN R, 2006, P IEEE C DAT MIN WOR, P55; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bringmann B, 2007, IEEE DATA MINING, P63; Calders T., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Chakrabarti D, 2004, P 10 ACM SIGKDD INT, P79, DOI 10.1145/1014052.1014064; Chakrabarti S, 1998, VLDB 98, P606; Chandola V, 2007, KNOWL INF SYST, V12, P355, DOI 10.1007/s10115-006-0039-1; COENEN F, 2004, LUCS KDD SOFTWARE LI; Coenen F., 2003, LUCS KDD DISCRETISED; Cover T.M., 2006, ELEMENTS INFORM THEO; CREMILLEUX B, 2002, P 22 ANN INT C KNOWL, P33; Duda R., 1973, PATTERN CLASSIFICATI; Faloutsos C, 2007, DATA MIN KNOWL DISC, V15, P3, DOI 10.1007/s10618-006-0057-3; Geerts F., 2004, P 7 INT C DISC SCI D, P278; GIONIS A, 2007, ACM T KDD, V1, P1; Goethals B., 2003, FREQUENT ITEMSET MIN; Grunwald P. D., 2005, ADV MINIMUM DESCRIPT; Grunwald P. D., 2007, MINIMUM DESCRIPTION; HAND DJ, 2002, PATTERN DETECTION DI; Heikinheimo H, 2009, P SIAM SDM, P569; Heikinheimo H, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P350; Karp R.M., 1972, COMPLEXITY COMPUTER, P85; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Keogh E, 2007, DATA MIN KNOWL DISC, V14, P99, DOI 10.1007/s10618-006-0049-3; Knobbe A., 2006, PKDD, P577; Knobbe AJ, 2006, P 13 ACM SIGKDD INT, P237, DOI 10.1145/1150402.1150431; KOHAVI R., 2000, SIGKDD EXPLORATIONS, V2, P86; Koopman A, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P437; KOOPMAN A, 2008, P SDM 08 SIAM, P108; Li M., 1993, INTRO KOLMOGOROV COM; Liu Bing, 1998, INTEGRATING CLASSIFI, P80; LIU G, 2004, P 2 WORKSH FREQ IT M; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Mannila H., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining; Mehta M., 1996, Advances in Database Technology - EDBT '96. 5th International Conference on Extending Database Technology. Proceedings; MERETAKIS D, 2000, P 15 EUR C MACH LEAR, P271; MIELIKAINEN T, 2003, PKDD, P327; Mitchell-Jones A.J., 1999, ATLAS EUROPEAN MAMMA; MORIK K, 2005, LOCAL PATTERN DETECT; MYLLYKANGAS S, 2006, ONCOGENE, V25; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; PFAHRINGER B, 1995, P IJCAI 95 WORKSH DA, P109; QUINLAN J, 1993, P ECML 93; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Siebes A, 2006, P SIAM C DAT MIN, P393; Sun JM, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P687; Tatti N, 2008, IEEE DATA MINING, P588, DOI 10.1109/ICDM.2008.39; VANLEEUWEN M, 2009, DATA MIN KNOWL DISC, V19, P173; VANLEEUWEN M, 2008, P ECMLPKDD 08, P672; VANLEEUWEN M, 2006, P ECML PKDD 06, P585; Vreeken J, 2007, IEEE DATA MINING, P685, DOI 10.1109/ICDM.2007.25; Vreeken J, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P765; Vreeken J, 2008, IEEE DATA MINING, P1067, DOI 10.1109/ICDM.2008.40; WALLACE CS, 2005, INF SCI STAT, pR5; Wang C, 2006, P 12 ACM SIGKDD INT, P730, DOI 10.1145/1150402.1150495; Wang JY, 2005, SIAM PROC S, P205; Wang JY, 2006, KNOWL INF SYST, V9, P19, DOI 10.1007/s10115-005-0216-7; WARNER HR, 1961, JAMA-J AM MED ASSOC, V177, P177; Witten IH, 2005, DATA MINING PRACTICA; Xiang Y., 2008, P 14 ACM SIGKDD INT, P758, DOI 10.1145/1401890.1401981; Xin D., 2005, P 31 INT C VER LARG, P709; Yan X., 2005, P 11 ACM SIGKDD INT, P314, DOI 10.1145/1081870.1081907; Yin XX, 2003, SIAM PROC S, P331; ZHANG X, 2000, P INT DAT ENG AUT LE, P48	66	10	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2011	23	1					169	214		10.1007/s10618-010-0202-x		46	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	744PH	WOS:000289106000005	
J	Li, T; Ding, C; Wang, F				Li, Tao; Ding, Chris; Wang, Fei			Guest editorial: special issue on data mining with matrices, graphs and tensors	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Li, Tao] Florida Int Univ, Sch Comp Sci, Miami, FL 33199 USA; [Ding, Chris] Univ Texas Arlington, CSE Dept, Arlington, TX 76019 USA; [Wang, Fei] IBM TJ Watson Res Ctr, Healthcare Transformat Grp, Yorktown Hts, NY USA	Li, T (reprint author), Florida Int Univ, Sch Comp Sci, Miami, FL 33199 USA.	taoli@cs.fiu.edu; chqding@uta.edu; fwang@us.ibm.com						0	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2011	22	3			SI		337	339		10.1007/s10618-011-0214-1		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	737GK	WOS:000288556900001	
J	Zhou, TY; Tao, DC; Wu, XD				Zhou, Tianyi; Tao, Dacheng; Wu, Xindong			Manifold elastic net: a unified framework for sparse dimension reduction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Manifold learning; Elastic net; Dimensionality reduction	DISCRIMINANT-ANALYSIS; GEOMETRIC FRAMEWORK; VARIABLE SELECTION; ORACLE PROPERTIES; RECOGNITION; LASSO; REGULARIZATION; REGRESSION	It is difficult to find the optimal sparse solution of a manifold learning based dimensionality reduction algorithm. The lasso or the elastic net penalized manifold learning based dimensionality reduction is not directly a lasso penalized least square problem and thus the least angle regression (LARS) (Efron et al., Ann Stat 32(2):407-499, 2004), one of the most popular algorithms in sparse learning, cannot be applied. Therefore, most current approaches take indirect ways or have strict settings, which can be inconvenient for applications. In this paper, we proposed the manifold elastic net or MEN for short. MEN incorporates the merits of both the manifold learning based dimensionality reduction and the sparse learning based dimensionality reduction. By using a series of equivalent transformations, we show MEN is equivalent to the lasso penalized least square problem and thus LARS is adopted to obtain the optimal sparse solution of MEN. In particular, MEN has the following advantages for subsequent classification: (1) the local geometry of samples is well preserved for low dimensional data representation, (2) both the margin maximization and the classification error minimization are considered for sparse projection calculation, (3) the projection matrix of MEN improves the parsimony in computation, (4) the elastic net penalty reduces the over-fitting problem, and (5) the projection matrix of MEN can be interpreted psychologically and physiologically. Experimental evidence on face recognition over various popular datasets suggests that MEN is superior to top level dimensionality reduction algorithms.	[Zhou, Tianyi; Tao, Dacheng] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Wu, Xindong] Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA	Tao, DC (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	dctao@ntu.edu.sg			NTU NAP [M58020010]; State Key Lab of CAD&CG, Zhejiang University [A1006]	This work was supported by NTU NAP Grant with project number M58020010 and the Open Project Program of the State Key Lab of CAD&CG (Grant No. A1006), Zhejiang University.	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Belkin M., 2004, ADV NEURAL INFORM PR; BIAN W, 2008, IEEE INT C PATT REC, P1; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Cai D., 2007, IEEE 11 INT C COMP V, P1; Cai D, 2008, IEEE T KNOWL DATA EN, V20, P1, DOI 10.1109/TKDE.2007.190669; CANDES E, 2005, ANN STAT, V35, P2392; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; DING CHQ, 2008, IEEE T PATTERN ANAL, V32, P45; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Efron B, 2004, ANN STAT, V32, P407; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Fan JQ, 2008, J ROY STAT SOC B, V70, P849, DOI 10.1111/j.1467-9868.2008.00674.x; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman J., 2009, SPRINGER SERIES STAT; Fyfe C, 2007, DATA MIN KNOWL DISC, V14, P207, DOI 10.1007/s10618-006-0047-5; Golub G. H., 1996, MATRIX COMPUTATIONS, V3; Graham D. B., 1998, NATO ASI SERIES F, V163, P446; He X., 2005, P 10 IEEE INT C COMP, V2, P1208; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Huang HCJ, 2008, LINGUISTICS, V46, P1, DOI 10.1515/LING.2008.001; James GM, 2009, J ROY STAT SOC B, V71, P127, DOI 10.1111/j.1467-9868.2008.00668.x; Kriegel HP, 2007, DATA MIN KNOWL DISC, V15, P87, DOI 10.1007/s10618-007-0067-9; Li T., 2007, ICML 07, P521; Li T, 2008, INFORM PROCESS MANAG, V44, P1684, DOI 10.1016/j.ipm.2008.03.005; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; Liu W, 2008, IEEE DATA MINING, P433, DOI 10.1109/ICDM.2008.101; Lv JC, 2009, ANN STAT, V37, P3498, DOI 10.1214/09-AOS683; Niyogi P., 2004, ADV NEURAL INFORM PR; Park M. Y., 2006, L1 REGULARIZATION PA; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Shakhnarovich G., 2004, HDB FACE RECOGNITION; SUN L, 2008, ICML, P1024; Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; TURK M, 1991, FACE RECOGNITION USI, P586; Wang F., 2008, CIKM 08, P1457; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Ye J., 2007, ICML, P1087; ZASS R, 2007, NEURAL INFORM PROCES, P1561; Zhang T., 2008, ECCV 08, P725; Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212; Zhang Z., 2005, SIAM J SCI COMPUT, V26, P313, DOI DOI 10.1016/J.PATCOG.2009.01.010; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H., 2006, J COMPUTATIONAL GRAP, V15, P262; Zou H, 2009, ANN STAT, V37, P1733, DOI 10.1214/08-AOS625	54	57	57	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2011	22	3			SI		340	371		10.1007/s10618-010-0182-x		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	737GK	WOS:000288556900002	
J	Yu, SP; Bi, JB; Ye, JP				Yu, Shipeng; Bi, Jinbo; Ye, Jieping			Matrix-variate and higher-order probabilistic projections	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Dimensionality reduction; Higher-order principle component analysis; Low-rank matrix factorization; Probabilistic projection	PRINCIPAL COMPONENT ANALYSIS; TENSOR OBJECTS; RECOGNITION; MODELS	Feature extraction from two-dimensional or higher-order data, such as face images and surveillance videos, have recently been an active research area. There have been several 2D or higher-order PCA-style dimensionality reduction algorithms, but they mostly lack probabilistic interpretations and are difficult to apply with, e.g., incomplete data. It is also hard to extend these algorithms for applications where a certain region of the data point needs special focus in the dimensionality reduction process (e.g., the facial region in a face image). In this paper we propose a probabilistic dimensionality reduction framework for 2D and higher-order data. It specifies a particular generative process for this type of data, and leads to better understanding of some 2D and higher-order PCA-style algorithms. In particular, we show it actually takes several existing algorithms as its (non-probabilistic) special cases. We develop efficient iterative learning algorithms within this framework and study the theoretical properties of the stationary points. The model can be easily extended to handle special regions in the high-order data. Empirical studies on several benchmark data and real-world cardiac ultrasound images demonstrate the strength of this framework.	[Yu, Shipeng] Siemens Med Solut USA, Malvern, PA 19355 USA; [Bi, Jinbo] Univ Connecticut, Dept Comp Sci & Engn, Storrs, CT 06269 USA; [Ye, Jieping] Arizona State Univ, Tempe, AZ USA	Yu, SP (reprint author), Siemens Med Solut USA, Malvern, PA 19355 USA.	shipeng.yu@siemens.com; jinbo@engr.uconn.edu; jieping.ye@asu.edu					Bartholomew D. J., 1999, LATENT VARIABLE MODE; CHU W, 2009, P INT C ART INT STAT; Ding C. H. Q., 2005, SDM; Gupta A., 1999, MATRIX VARIATE DISTR; INOUE K, 2006, CVPR, P154; Jolliffe, 2002, PRINCIPAL COMPONENT; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kolda T.G., 2007, SAND20076702 SAND NA; Kolda TG, 2001, SIAM J MATRIX ANAL A, V23, P243, DOI 10.1137/S0895479800368354; Lathauwer L., 2000, SIAM J MATRIX ANAL A, V21, P1324; Lee DD, 1999, NATURE, V401, P788; Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277; Lu HP, 2006, INT C PATT RECOG, P776; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Shashua A, 2001, PROC CVPR IEEE, P42; Sun J, 2006, KDD 06, P374; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Vasilescu M. A. O., 2002, P EUR C COMP VIS, P447; WANG H, 2005, SIGGRAPH; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131; Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6	22	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2011	22	3			SI		372	392		10.1007/s10618-010-0183-9		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	737GK	WOS:000288556900003	
J	Cao, B; Yang, QA; Sun, JT; Chen, Z				Cao, Bin; Yang, Qiang; Sun, Jian-Tao; Chen, Zheng			Learning bidirectional asymmetric similarity for collaborative filtering via matrix factorization	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Collaborative filtering; Matrix factorization; Similarity learning	ALGORITHMS	Memory-based collaborative filtering (CF) aims at predicting the rating of a certain item for a particular user based on the previous ratings from similar users and/or similar items. Previous studies in finding similar users and items have several drawbacks. First, they are based on user-defined similarity measurements, such as Pearson Correlation Coefficient (PCC) or Vector Space Similarity (VSS), which are, for the most part, not adaptive and optimized for specific applications and data. Second, these similarity measures are restricted to symmetric ones such that the similarity between A and B is the same as that for B and A, although symmetry may not always hold in many real world applications. Third, they typically treat the similarity functions between users and functions between items separately. However, in reality, the similarities between users and between items are inter-related. In this paper, we propose a novel unified model for users and items, known as Similarity Learning based Collaborative Filtering (SLCF) , based on a novel adaptive bidirectional asymmetric similarity measurement. Our proposed model automatically learns asymmetric similarities between users and items at the same time through matrix factorization. Theoretical analysis shows that our model is a novel generalization of singular value decomposition (SVD). We show that, once the similarity relation is learned, it can be used flexibly in many ways for rating prediction. To take full advantage of the model, we propose several strategies to make the best use of the proposed similarity function for rating prediction. The similarity can be used either to improve the memory-based approaches or directly in a model based CF approaches. In addition, we also propose an online version of the rating prediction method to incorporate new users and new items. We evaluate SLCF using three benchmark datasets, including MovieLens, EachMovie and Netflix, through which we show that our methods can outperform many state-of-the-art baselines.	[Cao, Bin; Yang, Qiang] Hong Kong Univ Sci & Technol, Kowloon, Hong Kong, Peoples R China; [Sun, Jian-Tao; Chen, Zheng] Microsoft Res Asia, Beijing, Peoples R China	Cao, B (reprint author), Hong Kong Univ Sci & Technol, Kowloon, Hong Kong, Peoples R China.	caobin@cs.ust.hk; qyang@cs.ust.hk; jtsun@microsoft.com; zhengc@microsoft.com			MSRA [MRA07/08.EG01]; RGC/NSFC [N_HKUST624/09]	Bin Cao and Qiang Yang are supported by a grant from MSRA (MRA07/08.EG01) and RGC/NSFC grant N_HKUST624/09. We thank the anonymous reviewers for their useful comments.	Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Almeida L. B., 1998, ON LINE LEARNING NEU, P111; BRAND M, 2003, P SIAM ICDM; Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998); CANNY, 2002, IEEE C SEC PRIV MAY; CAO B, 2008, P ECML PKDD 1, P178; Chen G, 2009, INFORM PROCESS MANAG, V45, P368, DOI 10.1016/j.ipm.2008.12.004; Delgado J., 1999, ACM SIGIR 99 WORKSH; Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776; Dhillon I., 2005, NEURAL INFORM PROCES, P283; DING C, 2006, LBNL60428 U CAL; FUNK S., 2006, NETFLIX UPDATE TRY T; Herlocker J, 2002, INFORM RETRIEVAL, V5, P287, DOI 10.1023/A:1020443909834; Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230; Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774; Jin R., 2004, P 27 ANN INT ACM SIG, P337, DOI 10.1145/1008992.1009051; Kirsch A., 1996, INTRO MATH THEORY IN; Ma H., 2007, SIGIR 07 P 30 ANN IN, P39; Park YJ, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P11; Press W., 1992, NUMERICAL RECIPES AR, V4; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Sarwar B., 2001, 10 INT WORLD WID WEB, P285; SCHRAUDOLPH NN, 1999, IDSIA0999; SI L, 2003, P 12 ICML; Srebro N., 2005, ADV NEURAL INFORM PR, V17, P1329; Vozalis MG, 2007, INFORM SCIENCES, V177, P3017, DOI 10.1016/j.ins.2007.02.036; Wang J., 2006, SIGIR 06, P501; Wu M., 2007, P KDD CUP WORKSH; XU, 2004, P SIGIR 04 NEW YORK, P202; Xue G., 2005, P 28 ANN INT ACM SIG, P114, DOI 10.1145/1076034.1076056; Zhang S., 2005, P 7 IEEE CEC, P257	31	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2011	22	3			SI		393	418		10.1007/s10618-011-0211-4		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	737GK	WOS:000288556900004	
J	Zafeiriou, S; Petrou, M				Zafeiriou, Stefanos; Petrou, Maria			Nonnegative tensor factorization as an alternative Csiszar-Tusnady procedure: algorithms, convergence, probabilistic interpretations and novel probabilistic tensor latent variable analysis algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Nonnegative Matrix Factorization; Nonnegative Tensor Factorization; Kullback-Leibler divergence; Probabilistic Latent Semantic Analysis	FACE-RECOGNITION ALGORITHMS; MATRIX FACTORIZATION; DECOMPOSITION; EQUIVALENCE; UNIQUENESS; PARAFAC2; ARRAYS; MODEL	In this paper we study Nonnegative Tensor Factorization (NTF) based on the Kullback-Leibler (KL) divergence as an alternative Csiszar-Tusnady procedure. We propose new update rules for the aforementioned divergence that are based on multiplicative update rules. The proposed algorithms are built on solid theoretical foundations that guarantee that the limit point of the iterative algorithm corresponds to a stationary solution of the optimization procedure. Moreover, we study the convergence properties of the optimization procedure and we present generalized pythagorean rules. Furthermore, we provide clear probabilistic interpretations of these algorithms. Finally, we discuss the connections between generalized Probabilistic Tensor Latent Variable Models (PTLVM) and NTF, proposing in that way algorithms for PTLVM for arbitrary multivariate probabilistic mass functions.	[Zafeiriou, Stefanos; Petrou, Maria] Univ London Imperial Coll Sci Technol & Med, Signal Proc & Commun Res Grp, Dept Elect & Elect Engn, London SW7 2AZ, England	Zafeiriou, S (reprint author), Univ London Imperial Coll Sci Technol & Med, Signal Proc & Commun Res Grp, Dept Elect & Elect Engn, S Kensington Campus, London SW7 2AZ, England.	s.zafeiriou@imperial.ac.uk			EPSRC [EP/E028659/1]	This work has been supported by the EPSRC project EP/E028659/1 Face Recognition using Photometric Stereo.	Bro R, 1999, J CHEMOMETR, V13, P295, DOI 10.1002/(SICI)1099-128X(199905/08)13:3/4<295::AID-CEM547>3.0.CO;2-Y; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Cichocki A, 2008, IEEE SIGNAL PROC MAG, V25, P142, DOI [10.1109/MSP.2008.4408452, 10.1109/MSP.2007.911394]; Cichocki A., 2007, P IEEE INT C AC SPEE, V3, P1393; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; Ding C, 2008, COMPUT STAT DATA AN, V52, P3913, DOI 10.1016/j.csda.2008.01.011; Ding C, 2005, SIAM PROC S, P606; DONOHO D, 2004, ADV NEURAL INF PROCE, V17; Finesso L, 2006, LINEAR ALGEBRA APPL, V416, P270, DOI 10.1016/j.laa.2005.11.012; FRIEDLANDER MP, 2006, TR200621 U BRIT COL; Gaussier E., 2005, P 28 ANN INT ACM SIG, P601, DOI 10.1145/1076034.1076148; GONZALEZ E, 2005, TR0502; Harshman R. A., 1970, FDN PARAFAC PROCEDUR; HAZAN T, 2005, 10 IEEE INT C COMP V, V1, P50, DOI 10.1109/ICCV.2005.228; Hofmann Thomas, 1999, P 22 ANN INT SIGIR C; Kiers HAL, 1999, J CHEMOMETR, V13, P275, DOI 10.1002/(SICI)1099-128X(199905/08)13:3/4<275::AID-CEM543>3.0.CO;2-B; KIM TK, 2008, IEEE T PATT IN PRESS; KIM YD, 2007, P IEEE CVPR 2007 WOR; Kim Y.-D., 2008, P IEEE INT C AC SPEE; Kolda T., 2009, SIAM REV IN PRESS, V5; Kotsia I, 2007, IEEE T INF FOREN SEC, V2, P588, DOI 10.1109/TIFS.2007.902017; KRUSKAL JB, 1977, LINEAR ALGEBRA APPL, V18, P95, DOI 10.1016/0024-3795(77)90069-6; Lee D., 2000, ADV NEURAL INFORM PR, P556; Lee DD, 1999, NATURE, V401, P788; Lin C. J., 2007, NEURAL COMP IN PRESS; LIN CJ, 2007, IEEE T NEUR IN PRESS; LU H, 2008, IEEE T NEURAL NETWOR, V18, P18; Messer K., 1999, AUDIO VIDEO BASED BI, P72; Morup M, 2008, NEURAL COMPUT, V20, P2112, DOI 10.1162/neco.2008.11-06-407; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Raj RG, 2008, IEEE T IMAGE PROCESS, V17, P259, DOI 10.1109/TIP.2007.916158; SHASHANKA M, 2008, COMPUT INTELL NEUROS; SHASHANKA MV, 2007, PROBABILISTIC UNPUB; Shashua A, 2005, INT C MACH LEARN ICM; SHASHUA A, 2006, P EUR C COMP VIS ECC; Shiryaev A.N., 1996, PROBABILITY; Sidiropoulos ND, 2000, J CHEMOMETR, V14, P229, DOI 10.1002/1099-128X(200005/06)14:3<229::AID-CEM587>3.0.CO;2-N; Smaragdis P., 2007, TR2007009 MITS EL RE; Smilde A., 2004, MULTIWAY ANAL APPL C; Sra S., 2006, TR0627 U TEX AUST DE; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; YAN S, 2007, IEEE T IMAGE PROCESS, V1, P212; Zafeiriou S., 2006, IEEE T NEURAL NETWOR, V14, P1063; Zafeiriou S, 2009, IEEE T NEURAL NETWOR, V20, P217, DOI 10.1109/TNN.2008.2005293; Zafeiriou S, 2009, ADV PATTERN RECOGNIT, P105, DOI 10.1007/978-1-84882-299-3_5	49	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2011	22	3			SI		419	466		10.1007/s10618-010-0196-4		48	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	737GK	WOS:000288556900005	
J	Cui, P; Liu, ZQ; Sun, LF; Yang, SQ				Cui, Peng; Liu, Zhi-Qiang; Sun, Li-Feng; Yang, Shi-Qiang			Hierarchical visual event pattern mining and its applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Video mining; Matrix factorization; Event recognition; Anomaly detection	DISCRIMINANT-ANALYSIS; RECOGNITION; TRACKING	In this paper, we propose a hierarchical visual event pattern mining approach and utilize the patterns to address the key problems in video mining and understanding field. We classify events into primitive events (PEs) and compound events (CEs), where PEs are the units of CEs, and CEs serve as smooth priors and rules for PEs. We first propose a tensor-based video representation and Joint Matrix Factorization (JMF) for unsupervised primitive event categorization. Then we apply frequent pattern mining techniques to discover compound event pattern structures. After that, we utilize the two kinds of event patterns to address the applications of event recognition and anomaly detection. First we extend the Sequential Monte Carlo (SMC) method to recognition of live, sequential visual events. To accomplish this task we present a scheme that alternatively recognizes primitive and compound events in one framework. Then, we categorize the anomalies into abnormal events (never seen events) and abnormal contexts (rule breakers), and the two kinds of anomalies are detected simultaneously by embedding a deviation criterion into the SMC framework. Extensive experiments have been conducted which demonstrate that the proposed approach is effective as compared to other major approaches.	[Cui, Peng; Sun, Li-Feng; Yang, Shi-Qiang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; [Liu, Zhi-Qiang] City Univ, Sch Creat Media, Kowloon, Hong Kong, Peoples R China	Cui, P (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	cuip@tsinghua.edu.cn			National Natural Science Foundation of China [60933013, 60833009]; National Basic Research Program of China [2006CB303103]; China Postdoctoral Science Foundation [20100470285]; Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 117806, 9041369]	This work is supported by National Natural Science Foundation of China, No. 60933013 and No. 60833009; National Basic Research Program of China, No. 2006CB303103; China Postdoctoral Science Foundation, No. 20100470285; and Research Grants Council of the Hong Kong Special Administrative Region, China, under General Research Fund (CityU 117806, and 9041369).	BLANK B, 2005, INT C COMP VIS; Boiman O., 2005, INT C COMP VIS; CHAN MT, 2004, INT C PATT REC; CHRIS D, 2006, INT C KNOWL DISC DAT; CUI P, 2007, INT C COMP VIS PATT; DAVIS JW, 2002, INT C PATT REC; Doucet A, 2001, SEQUENTIAL MONTE CAR; DU YT, 2006, INT C PATT REC; Duong T., 2005, INT C COMP VIS PATT; EFROS AA, 2003, P INT C CV; GILBERT A, 2009, INT C COMP VIS; HAKEEM A, 2005, NAT C ART INT; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; Kawanaka D, 2006, IEICE T INF SYST, VE89D, P2180, DOI 10.1093/ietisy/e89-d.7.2180; Ke Y., 2005, INT C COMP VIS; LI T, 2006, INT C DAT MIN; Lin Z., 2009, INT C COMP VIS; Ling H., 2007, ICCV; LIU HW, 2010, EURASIP J IMAGE VIDE; MAKRIS D, 2002, BRIT MACH VIS C; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Morup M., 2006, DECOMPOSING TIME FRE; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Robertson N, 2006, COMPUT VIS IMAGE UND, V104, P232, DOI 10.1016/j.cviu.2006.07.006; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; SUN XH, 2009, INT C COMP VIS PATT; Tao DC, 2008, NEUROCOMPUTING, V71, P1866, DOI 10.1016/j.neucom.2007.08.036; Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2008, IEEE T CIRC SYST VID, V18, P3, DOI 10.1109/TCSVT.2007.906936; VASWANI N, 2003, INT C COMP VIS PATT; WANG F, 2008, SIAM C DAT MIN; WANG F, 2007, INT S BIOINF BIOENG; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; XIANG T, 2005, INT C COMP VIS; XU W, 2003, SIGIR C RES DEV INF; Yamamoto M., 2006, INT C AUT FAC GEST R; YILMAZ A, 2005, INT C COMP VIS PATT; ZELNIKMANOR L, 2001, INT C COMP VIS PATT; ZHONG H, 2004, INT C COMP VIS PATT	41	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2011	22	3			SI		467	492		10.1007/s10618-010-0195-5		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	737GK	WOS:000288556900006	
J	Wang, F; Li, T; Wang, X; Zhu, SH; Ding, C				Wang, Fei; Li, Tao; Wang, Xin; Zhu, Shenghuo; Ding, Chris			Community discovery using nonnegative matrix factorization	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Community discovery; Nonnegative matrix factorization	SMALL-WORLD NETWORKS	Complex networks exist in a wide range of real world systems, such as social networks, technological networks, and biological networks. During the last decades, many researchers have concentrated on exploring some common things contained in those large networks include the small-world property, power-law degree distributions, and network connectivity. In this paper, we will investigate another important issue, community discovery, in network analysis. We choose Nonnegative Matrix Factorization (NMF) as our tool to find the communities because of its powerful interpretability and close relationship between clustering methods. Targeting different types of networks (undirected, directed and compound), we propose three NMF techniques (Symmetric NMF, Asymmetric NMF and Joint NMF). The correctness and convergence properties of those algorithms are also studied. Finally the experiments on real world networks are presented to show the effectiveness of the proposed methods.	[Wang, Fei; Li, Tao; Wang, Xin] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA; [Zhu, Shenghuo] NEC Res Lab Amer Cupertino, Cupertino, CA USA; [Ding, Chris] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA	Wang, F (reprint author), IBM TJ Watson Res Lab, Hawthorne, NY 10532 USA.	feiwang@cs.fiu.edu; taoli@cs.fiu.edu; xwang009@cs.fiu.edu			NSF [IIS-0546280, CCF-0830659, DMS-0915110]	The work is partially supported by NSF grants IIS-0546280, CCF-0830659, and DMS-0915110.	Albert R, 1999, NATURE, V401, P130; Amaral LAN, 2000, P NATL ACAD SCI USA, V97, P11149, DOI 10.1073/pnas.200327197; Barthelemy M, 1999, PHYS REV LETT, V82, P3180, DOI 10.1103/PhysRevLett.82.3180; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; CHEN G, 2007, ICDM WORKSH HIGH PER, P303; DING C, 2008, COMPUT STAT DATA AN, V52, P155; Ding C, 2005, SIAM PROC S, P606; DING C, 2006, 60428 LBNL; Ding CH, 2006, P 12 ACM SIGKDD INT, P126, DOI 10.1145/1150402.1150420; Faloutsos M., 1999, SIGCOMM, P251; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Girvan M, 2004, PHYS REV E, V69; Hofmann T, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P688; INO H, 2005, WWW, P661; Lee D., 2000, ADV NEURAL INFORM PR, P556; Lee DD, 1999, NATURE, V401, P788; Long B., 2007, P569, DOI 10.1145/1273496.1273568; MIAO G, 2008, 17 WWW WORKSH SOC WE; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Palla G, NATURE, V435, P814; Pauca VP, 2004, SIAM PROC S, P452; PENNOCK DM, 2000, UAI; PRIEBE C, 2005, P SIAM INT C DAT MIN; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; RUAN J, 2007, ICDM; Scott J., 2000, SOCIAL NETWORK ANAL; Sharan R, 2005, P NATL ACAD SCI USA, V102, P1974, DOI 10.1073/pnas.0409522102; STREHL, 2002, J MACHINE LEARNING R, V3, P583; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang D., 2008, P 31 ANN INT ACM SIG, P307, DOI 10.1145/1390334.1390387; Wang F, 2006, IEEE DATA MINING, P1119; WANG F, 2008, 8 SIAM INT C DAT MIN; Wasserman S, 1994, SOCIAL NETWORK ANAL; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Weiss Y., 1999, ICCV, P975; Xie YL, 1998, J CHEMOMETR, V12, P357, DOI 10.1002/(SICI)1099-128X(199811/12)12:6<357::AID-CEM523>3.0.CO;2-S; YU K, 2005, NIPS WORKSH IND TRAN; ZHANG H, 2007, AAAI, P663; Zhou D., 2005, P 22 INT C MACH LEAR, P1036, DOI 10.1145/1102351.1102482	41	7	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2011	22	3			SI		493	521		10.1007/s10618-010-0181-y		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	737GK	WOS:000288556900007	
J	Cheng, H; Zhou, Y; Yu, JX				Cheng, Hong; Zhou, Yang; Yu, Jeffrey Xu			Clustering Large Attributed Graphs: A Balance between Structural and Attribute Similarities	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Graph clustering; structural proximity; attribute similarity		Social networks, sensor networks, biological networks, and many other information networks can be modeled as a large graph. Graph vertices represent entities, and graph edges represent their relationships or interactions. In many large graphs, there is usually one or more attributes associated with every graph vertex to describe its properties. In many application domains, graph clustering techniques are very useful for detecting densely connected groups in a large graph as well as for understanding and visualizing a large graph. The goal of graph clustering is to partition vertices in a large graph into different clusters based on various criteria such as vertex connectivity or neighborhood similarity. Many existing graph clustering methods mainly focus on the topological structure for clustering, but largely ignore the vertex properties, which are often heterogenous. In this article, we propose a novel graph clustering algorithm, SA-Cluster, which achieves a good balance between structural and attribute similarities through a unified distance measure. Our method partitions a large graph associated with attributes into k clusters so that each cluster contains a densely connected subgraph with homogeneous attribute values. An effective method is proposed to automatically learn the degree of contributions of structural similarity and attribute similarity. Theoretical analysis is provided to show that SA-Cluster is converging quickly through iterative cluster refinement. Some optimization techniques on matrix computation are proposed to further improve the efficiency of SA-Cluster on large graphs. Extensive experimental results demonstrate the effectiveness of SA-Cluster through comparisons with the state-of-the-art graph clustering and summarization methods.	[Cheng, Hong; Zhou, Yang; Yu, Jeffrey Xu] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Shatin, Hong Kong, Peoples R China	Cheng, H (reprint author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, William MW Mong Engn Bldg,Room 609, Shatin, Hong Kong, Peoples R China.	hcheng@se.cuhk.edu.hk; zhouy@se.cuhk.edu.hk; yu@se.cuhk.edu.hk	Yu, Jeffrey/F-6005-2011; Cheng, Hong/F-7228-2011	Yu, Jeffrey/0000-0002-9738-827X; 	Research Grants Council of the Hong Kong SAR, China [419008]; Chinese University of Hong Kong [2050446, 2050473]	The work was supported in part by grants of the Research Grants Council of the Hong Kong SAR, China No. 419008 and the Chinese University of Hong Kong Direct Grants No. 2050446 and No. 2050473.	Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Apostol T.M., 1967, CALCULUS, VI; BOTTON L., 1994, P ADV NEUR INF PROC, P585; Cai D., 2005, P 3 INT WORKSH LINK, P58, DOI 10.1145/1134271.1134280; Descartes Rene, 1954, GEOMETRY RENE DESCAR; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Faloutsos C., 2004, P 10 ACM SIGKDD INT, P118, DOI 10.1145/1014052.1014068; Fine B., 1997, FUNDAMENTAL THEOREM; Gibson D., 1998, P 9 ACM C HYP HYP, P225, DOI 10.1145/276627.276652; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Hofmann T., 1998, P ACM SIGIR, P50; Jeh G, 2002, P 8 ACM SIGKDD INT C, P538, DOI 10.1145/775047.775126; Kaufman L., 1987, Statistical Data Analysis Based on the L1-Norm and Related Methods. First International Conference; Liu Z., 2008, P 2008 INT C DAT MIN; Manning CD, 2008, INTRO INFORM RETRIEV; Navlakha S., 2008, P 2008 ACM SIGMOD IN, P419, DOI 10.1145/1376616.1376661; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Ng R, 1994, P 20 INT C VER LARG, P144; Penrose R., 1956, MATH P CAMBRIDGE PHI, V52, P17, DOI 10.1017/S0305004100030929; Pons P, 2006, J GRAPH ALGORITHMS A, V10, P191; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Strang G., 2005, LINEAR ALGEBRA ITS A; Sun J., 2007, P 13 ACM SIGKDD INT, P687, DOI DOI 10.1145/1281192.1281266; Sun Y, 2009, P 12 INT C EXT DAT T, P565, DOI 10.1145/1516360.1516426; TIAN Y, 2008, P ACM SIGMOD INT C M, P567, DOI 10.1145/1376616.1376675; Tong H., 2006, P 6 IEEE INT C DAT M, P613; TONG H., 2006, P 12 ACM SIGKDD INT, P404, DOI 10.1145/1150402.1150448; Tsai CY, 2008, COMPUT STAT DATA AN, V52, P4658, DOI 10.1016/j.csda.2008.03.002; Xu X, 2007, P 13 ACM SIGKDD INT, P824, DOI DOI 10.1145/1281192.1281280; Zhai C., 2004, P 10 ACM SIGKDD INT, P743, DOI 10.1145/1014052.1014150; ZHOU Y, 2009, P INT C VER LARG DAT, P718	31	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2011	5	2							12	10.1145/1921632.1921638		33	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OV	WOS:000299341700006	
J	De Vries, T; Ke, H; Chawla, S; Christen, P				De Vries, Timothy; Ke, Hui; Chawla, Sanjay; Christen, Peter			Robust Record Linkage Blocking Using Suffix Arrays and Bloom Filters	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Record linkage; blocking; suffix arrays		Record linkage is an important data integration task that has many practical uses for matching, merging and duplicate removal in large and diverse databases. However, quadratic scalability for the brute force approach of comparing all possible pairs of records necessitates the design of appropriate indexing or blocking techniques. The aim of these techniques is to cheaply remove candidate record pairs that are unlikely to match. We design and evaluate an efficient and highly scalable blocking approach based on suffix arrays. Our suffix grouping technique exploits the ordering used by the index to merge similar blocks at marginal extra cost, resulting in a much higher accuracy while retaining the high scalability of the base suffix array method. Efficiently grouping similar suffixes is carried out with the use of a sliding window technique. We carry out an in-depth analysis of our method and show results from experiments using real and synthetic data, which highlight the importance of using efficient indexing and blocking in real-world applications where datasets contain millions of records. We extend our disk-based methods with the capability to utilise main memory based storage to construct Bloom filters, which we have found to cause significant speedup by reducing the number of costly database queries by up to 70% in real data. We give practical implementation details and show how Bloom filters can be easily applied to Suffix Array based indexing.	[De Vries, Timothy; Ke, Hui; Chawla, Sanjay] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia; [Christen, Peter] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT 0200, Australia	De Vries, T (reprint author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.	timothy.devries@gmail.com; hui.ke.it@gmail.com; chawla@it.usyd.edu.au; peter.christen@anu.edu.au			Capital Markets CRC	T. de Vries and S. Chawla gratefully acknowledge the financial support of the Capital Markets CRC.	Aizawa A., 2005, Proceedings. International Workshop on Challenges in Web Information Retrieval and Integration; BAWA M., 2003, P 29 INT C VER LARG, P922, DOI 10.1016/B978-012722442-8/50086-0; Baxter R., 2003, P WORKSH DAT CLEAN R; BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692; Broder A., 2004, INTERNET MATH, V1, P485, DOI 10.1080/15427951.2004.10129096; Chazelle B, 2004, P 15 ANN ACM SIAM S, P30; Christen P., 2007, TRCS0703 AUSTR NAT U; CHRISTEN P., 2006, P WORKSH MIN COMPL D; Christen P., 2008, P ACM INT C KNOWL DI, P1065, DOI 10.1145/1401890.1402020; de Vries T., 2009, P 18 ACM C INF KNOWL, P305, DOI 10.1145/1645953.1645994; Dunn H. L., 1956, AM J PUBLIC HEALTH, V36, P1412; Elfeky MG, 2002, PROC INT CONF DATA, P17, DOI 10.1109/ICDE.2002.994694; Elmagarmid AK, 2007, IEEE T KNOWL DATA EN, V19, P1, DOI 10.1109/TKDE.2007.250581; FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061; GILL L, 1993, J EPIDEMIOL COMMUN H, V47, P316, DOI 10.1136/jech.47.4.316; Gu L, 2003, RECORD LINKAGE CURRE; Hernandez MA, 1998, DATA MIN KNOWL DISC, V2, P9, DOI 10.1023/A:1009761603038; JARO MA, 1989, J AM STAT ASSOC, V84, P414, DOI 10.2307/2289924; Jin L., 2003, P INT C DAT SYST ADV, P137; Kirsch A, 2008, RANDOM STRUCT ALGOR, V33, P187, DOI 10.1002/rsa.20208; MARSHALL J. T., 1947, POPULATION STUDIES, P204; McCallum A., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347123; Mitzenmacher M, 2002, IEEE ACM T NETWORK, V10, P604, DOI 10.1109/TNET.2002.803864; NEWCOMBE HB, 1962, COMMUN ACM, V5, P563, DOI 10.1145/368996.369026; Schnell R, 2009, BMC MED INFORM DECIS, V9, DOI 10.1186/1472-6947-9-41; Winkler W.E., 2006, RR200602 US BUR CENS; Yan S, 2007, PROCEEDINGS OF THE 7TH ACM/IEE JOINT CONFERENCE ON DIGITAL LIBRARIES, P185, DOI 10.1145/1255175.1255213; ZOBEL J., 2006, ACM COMPUT SURV, V38, P2, DOI DOI 10.1145/1132956.1132959	28	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2011	5	2							9	10.1145/1921632.1921635		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OV	WOS:000299341700003	
J	Dunlavy, DM; Kolda, TG; Acar, E				Dunlavy, Daniel M.; Kolda, Tamara G.; Acar, Evrim			Temporal Link Prediction Using Matrix and Tensor Factorizations	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Link mining; link prediction; evolution; tensor factorization; CANDECOMP; PARAFAC		The data in many disciplines such as social networks, Web analysis, etc. is link-based, and the link structure can be exploited for many different data mining tasks. In this article, we consider the problem of temporal link prediction: Given link data for times 1 through T, can we predict the links at time T + 1? If our data has underlying periodic structure, can we predict out even further in time, i.e., links at time T + 2, T + 3, etc.? In this article, we consider bipartite graphs that evolve over time and consider matrix-and tensor-based methods for predicting future links. We present a weight-based method for collapsing multiyear data into a single matrix. We show how the well-known Katz method for link prediction can be extended to bipartite graphs and, moreover, approximated in a scalable way using a truncated singular value decomposition. Using a CANDECOMP/PARAFAC tensor decomposition of the data, we illustrate the usefulness of exploiting the natural three-dimensional structure of temporal link data. Through several numerical experiments, we demonstrate that both matrix-and tensor-based techniques are effective for temporal link prediction despite the inherent difficulty of the problem. Additionally, we show that tensor-based techniques are particularly effective for temporal data with varying periodic patterns.	[Dunlavy, Daniel M.] Sandia Natl Labs, Albuquerque, NM 87123 USA; [Kolda, Tamara G.] Sandia Natl Labs, Livermore, CA 94551 USA	Dunlavy, DM (reprint author), Sandia Natl Labs, Albuquerque, NM 87123 USA.	dmdunla@sandia.gov; tgkolda@sandia.gov; evrim.acar@bte.tubitak.gov.tr	Kolda, Tamara/B-1628-2009	Kolda, Tamara/0000-0003-4176-2493	Sandia National Laboratories; United States Department of Energy's National Nuclear Security Administration [DE-AC04-94AL85000]	This work was funded by the Laboratory Directed Research & Development (LDRD) program at Sandia National Laboratories, a multiprogram laboratory operated by Sandia Corporation, a Lockheed Martin Company, for the United States Department of Energy's National Nuclear Security Administration under Contract DE-AC04-94AL85000.	Acar E, 2009, IEEE T KNOWL DATA EN, V21, P6, DOI 10.1109/TKDE.2008.112; ACAR E., 2009, P 2009 IEEE INT C DA, P262; Acar E, 2006, LECT NOTES COMPUT SC, V3975, P213; ACAR E., 2010, J CHEMOMETR IN PRESS; BADER B. W., 2007, SURVEY TEXT MINING C, P147; Bader BW, 2007, SIAM J SCI COMPUT, V30, P205, DOI 10.1137/060676489; BAST H., 2005, P 28 INT C RES DEV I, P11, DOI 10.1145/1076034.1076040; Bell R. M., 2007, SIGKDD EXPLOR NEWSL, V9, P75, DOI DOI 10.1145/1345448.1345465; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; CHATFIELD C, 1988, J ROY STAT SOC D-STA, V37, P129; CLAUSET A., 2008, NATURE, P453; Dumas S.T., 1988, P CHI 88 C HUM FACT, P281, DOI 10.1145/57167.57214; Gardner ES, 2006, INT J FORECASTING, V22, P637, DOI 10.1016/j.ijforecast.2006.03.005; GETOOR, 2005, ACM SIGKDD EXPLORATI, V7, P3, DOI DOI 10.1145/1117454.1117456; Harshman R. A., 1970, UCLA WORKING PAPERS, V16, P1; HASAN M. A., 2006, P SIAM DAT MIN WORKS; Huang Z, 2009, INFORMS J COMPUT, V21, P286, DOI 10.1287/ijoc.1080.0292; Huang Z, 2005, Proceedings of the 5th ACM/IEEE Joint Conference on Digital Libraries, Proceedings, P141, DOI 10.1145/1065385.1065415; KATZ L, 1953, PSYCHOMETRIKA, V18, P39; KOLDA T., 2005, P 5 IEEE INT C DAT M, P242; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; KOREN Y, 2009, P 15 ACM SIGKDD INT, P447, DOI 10.1145/1557019.1557072; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Kruskal J.B., 1989, MULTIWAY DATA ANAL, P7; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; LIU Y., 2007, ACM SIGKDD EXPLORATI, V9, P62, DOI 10.1145/1345448.1345462; Makridakis S, 2000, INT J FORECASTING, V16, P451, DOI 10.1016/S0169-2070(00)00057-1; PAPADIMITRIOU S., 2009, P 9 SIAM INT C DAT M, P1064; Rattigan M., 2005, ACM SIGKDD EXPLORATI, V7, P41, DOI 10.1145/1117454.1117460; Saad Y., 1992, NUMERICAL METHODS LA; Sarkar P., 2007, P 11 INT C ART INT S; SHARAN U, 2008, P 8 IEEE INT C DAT M, P540, DOI DOI 10.1109/ICDM.2008.125; Smola A.J., 2003, LECT NOTES COMPUTER; STAGER M., 2006, P 26 IEEE INT C DIST, P58; Tong H, 2008, P SDM 08, P704; Tucker L, 1963, PROBLEMS MEASURING C, P122; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; WANG C, 2007, P 2007 7 IEEE INT C, P322; Xiong L., 2010, P SIAM INT C DAT MIN; Yan H, 2008, DATA KNOWL ENG, V65, P108, DOI 10.1016/j.datak.2007.10.005	40	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2011	5	2							10	10.1145/1921632.1921636		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OV	WOS:000299341700004	
J	Kang, U; Tsourakakis, CE; Appel, AP; Faloutsos, C; Leskovec, J				Kang, U.; Tsourakakis, Charalampos E.; Appel, Ana Paula; Faloutsos, Christos; Leskovec, Jure			HADI: Mining Radii of Large Graphs	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Radius plot; small web; HADI; hadoop; graph mining		Given large, multimillion-node graphs (e.g., Facebook, Web-crawls, etc.), how do they evolve over time? How are they connected? What are the central nodes and the outliers? In this article we define the Radius plot of a graph and show how it can answer these questions. However, computing the Radius plot is prohibitively expensive for graphs reaching the planetary scale. There are two major contributions in this article: (a) We propose HADI (HAdoop DIameter and radii estimator), a carefully designed and fine-tuned algorithm to compute the radii and the diameter of massive graphs, that runs on the top of the HADOOP/MAPREDUCE system, with excellent scale-up on the number of available machines (b) We run HADI on several real world datasets including YahooWeb (6B edges, 1/8 of a Terabyte), one of the largest public graphs ever analyzed. Thanks to HADI, we report fascinating patterns on large networks, like the surprisingly small effective diameter, the multimodal/bimodal shape of the Radius plot, and its palindrome motion over time.	[Kang, U.] Carnegie Mellon Univ, Dept Comp Sci, Sch Comp Sci, Pittsburgh, PA 15213 USA; [Appel, Ana Paula] Univ Sao Paulo, Sao Carlos, SP, Brazil; [Leskovec, Jure] Stanford Univ, Stanford, CA 94305 USA	Kang, U (reprint author), Carnegie Mellon Univ, Dept Comp Sci, Sch Comp Sci, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	ukang@cs.cmu.edu	Kang, U/A-2341-2013		National Science Foundation [IIS-0705359, IIS-0808661]; CAPES [3960-07-2]; CNPq; Fapesp; U.S. Department of Energy, Lawrence Livermore National Laboratory [DE-AC52-07NA27344]	This work was partially funded by the National Science Foundation under Grants No. IIS-0705359, IIS-0808661, CAPES (PDEE project number 3960-07-2), CNPq, Fapesp and under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under contract DE-AC52-07NA27344. Author's address: U. Kang, Computer Science Department, School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, 15213 Pittsburgh PA; email: ukang@cs.cmu.edu.	AGGARWAL C. C., 2009, P INT C VER LARG DAT; Albert R, 1999, NATURE, V401, P130; ALON N., 1996, P ANN ACM S THEOR CO; BADER D. A., 2008, PARAL COMPUT; BECCHETTI L., 2008, P ANN ACM SIGKDD C K; BEYER K., 2007, P ACM SIGMOD INT C M; BRODER A., 2000, COMPUT NETW, P33; CHAIKEN R., 2008, P INT C VER LARG DAT; CHAKRABARTI D., 2004, P ANN ACM SIGKDD C K; CHARIKAR M., 2000, P ACM SIGACT SIGMOD; CHENG J., 2009, P SIAM INT C DAT MIN; Cormen T.H., 1990, INTRO ALGORITHMS; DARURU S., 2009, P ANN ACM SIGKDD C K; DHILLON I. S., 2003, P ANN ACM SIGKDD C K; DHILLON I. S., 2007, IEEE T PATT ANAL MAC; Erdos P, 1959, PUBLICATIONES MATH; FERREZ J.-A., 1998, P INT S HIGH PERF CO; FLAJOLET P., 1985, J COMPUT SYST SCI; GAROFALAKIS M. N., 2001, P INT C VER LARG DAT; GROSSMAN R. L., 2008, P ANN ACM SIGKDD C K; HOLDER L. B., 2009, P ANN ACM SIGKDD C K; KANG U., 2010, P 2 WORKSH LARG SCAL; KANG U., 2010, P SIAM INT C DAT MIN; KANG U., 2010, KNOWL INFORM SYST; KANG U., 2009, P IEEE INT C DAT MIN; Karypis G, 1999, SIAM REV, V41, P278, DOI 10.1137/S0036144598334138; KOLDA T. G., 2008, P IEEE INT C DAT MIN; Leskovec J, 2007, ACM T WEB, V1, DOI 10.1145/1232722.1232727; LESKOVEC J., 2008, P INT WORLD WID WEB; LESKOVEC J., 2005, PKDD, P133; Lewis T. G., 2009, NETWORK SCI THEORY A; MA J., 1993, J COMPUT SCI TECHNOL; MCGLOHON M., 2008, P ANN ACM SIGKDD C K; NEWMAN M., 2005, SOCIAL NETW; Palmer C.R., 2002, P 8 ACM SIGKDD INT C, P81; PAPADIMITRIOU S., 2008, P IEEE INT C DAT MIN; Pavlo A, 2009, P ACM SIGMOD INT C M; PIKE R., 2005, SCI PROGRAM J; SATULURI V., 2009, P ANN ACM SIGKDD C K; SINHA B. P., 1986, IEEE T COMPUT; TSOURAKAKIS C. E., 2009, ABS09094969 CORR, Vabs/0909.4969; TSOURAKAKIS C. E., 2009, P ANN ACM SIGKDD C K; TSOURAKAKIS C. E., 2009, ABS09043761 CORR, Vabs/0904.3761; TSOURAKAKIS C. E., 2008, P IEEE INT C DAT MIN, P608; WANG C., 2004, P ANN ACM SIGKDD C K; YAN X, 2002, P IEEE INT C DAT MIN	46	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2011	5	2							8	10.1145/1921632.1921634		24	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OV	WOS:000299341700002	
J	Magdalinos, P; Doulkeridis, C; Vazirgiannis, M				Magdalinos, Panagis; Doulkeridis, Christos; Vazirgiannis, Michalis			Enhancing Clustering Quality through Landmark-Based Dimensionality Reduction	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Landmarks; dimensionality reduction; clustering quality	IMAGE RETRIEVAL; METRIC-SPACES; DISCRIMINANT-ANALYSIS; VANTAGE OBJECTS	Scaling up data mining algorithms for data of both high dimensionality and cardinality has been lately recognized as one of the most challenging problems in data mining research. The reason is that typical data mining tasks, such as clustering, cannot produce high quality results when applied on high-dimensional and/or large (in terms of cardinality) datasets. Data preprocessing and in particular dimensionality reduction constitute promising tools to deal with this problem. However, most of the existing dimensionality reduction algorithms share also the same disadvantages with data mining algorithms, when applied on large datasets of high dimensionality. In this article, we propose a fast and efficient dimensionality reduction algorithm (FEDRA), which is particularly scalable and therefore suitable for challenging datasets. FEDRA follows the landmark-based paradigm for embedding data objects in a low-dimensional projection space. By means of a theoretical analysis, we prove that FEDRA is efficient, while we demonstrate the achieved quality of results through experiments on datasets of higher cardinality and dimensionality than those employed in the evaluation of competitive algorithms. The obtained results prove that FEDRA manages to retain or ameliorate clustering quality while projecting in less than 10% of the initial dimensionality. Moreover, our algorithm produces embeddings that enable the faster convergence of clustering algorithms. Therefore, FEDRA emerges as a powerful and generic tool for data pre-processing, which can be integrated in other data mining algorithms, thus enhancing their performance.	[Magdalinos, Panagis; Vazirgiannis, Michalis] Athens Univ Econ & Business, Athens, Greece; [Doulkeridis, Christos] Norwegian Univ Sci & Technol, Trondheim, Norway	Magdalinos, P (reprint author), Athens Univ Econ & Business, Athens, Greece.	pmagdal@aueb.gr					ABU-KHZAM F., 2002, IASTED PDCS, P167; Achlioptas D., 2001, P ACM S PRINC DAT SY, P274, DOI 10.1145/375551.375608; Ailon N., 2006, P 38 ANN ACM S THEOR, P557, DOI 10.1145/1132516.1132597; Ailon N, 2010, COMMUN ACM, V53, P97, DOI 10.1145/1646353.1646379; Athitsos V, 2008, IEEE T PATTERN ANAL, V30, P89, DOI 10.1109/TPAMI.2007.1140; Beyer K., 1999, P 7 INT C DAT THEOR, P217; BOURGAIN J, 1985, ISRAEL J MATH, V52, P46, DOI 10.1007/BF02776078; CARREIRA-PERPINAN M. A., 1997, CS9609 U SHEF; Chakrabarti S, 2002, MINING WEB DISCOVERI; Dasgupta S, 2003, RANDOM STRUCT ALGOR, V22, P60, DOI 10.1002/rsa.10073; DATTA S., 2006, SIAM INT C DAT MIN S; de Silva V., 2004, SPARSE MULTIDIMENSIO; de Silva V., 2002, ADV NEURAL INFORM PR, P705; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Doulkeridis C, 2007, IEEE J SEL AREA COMM, V25, P25, DOI 10.1109/JSAC.2007.070104; Drineas P, 2006, SIAM J COMPUT, V36, P184, DOI 10.1137/S0097539704442702; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163, DOI 10.1145/223784.223812; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; Gabriela H., 1999, CLUSTER PRESERVING E; Hennig C, 2003, PATTERN RECOGN, V36, P2187, DOI 10.1016/S0031-3203(02)00326-6; Hjaltason GR, 2003, IEEE T PATTERN ANAL, V25, P530, DOI 10.1109/TPAMI.2003.1195989; Kargupta H., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); LEE RCT, 1977, IEEE T COMPUT, V26, P288; Li ZF, 2009, IEEE T PATTERN ANAL, V31, P755, DOI 10.1109/TPAMI.2008.174; Lian X, 2009, IEEE T KNOWL DATA EN, V21, P1447, DOI 10.1109/TKDE.2008.170; MAGDALINOS P., 2009, P SIAM INT C DAT MIN, P509; MAGDALINOS P., 2006, PKDD, P322; Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205106, 10.1073/pnas.0803205105]; OSTROUCHOV G., 2002, 5 INT WORKSH HIGH PE; PAYNE T. R., 1999, AUCSTR9910 CARN MELL; Qi H., 2004, STAT DATA MINING KNO, P327; Ratnasaour Sylvia, 2001, P 2001 C APPL TECHN, P161, DOI 10.1145/383059.383072; Sharma A, 2008, IEEE T KNOWL DATA EN, V20, P1336, DOI 10.1109/TKDE.2008.101; STEWART G. W., 2001, MATRIX ALGORITHMS, VI; Stewart G.W., 2001, MATRIX ALGORITHMS, VII; Stoica I., 2001, P ACM SIGCOMM; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Togerson W.S., 1958, THEORY METHODS SCALI; Vleugels J, 2002, PATTERN RECOGN, V35, P69, DOI 10.1016/S0031-3203(00)00120-5; Wang JTL, 2005, IEEE T SYST MAN CY B, V35, P973, DOI 10.1109/TSMCB.2005.848489; XIONG H., 2004, P 10 ACM SIGKDD INT, P364, DOI 10.1145/1014052.1014093; Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258	42	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2011	5	2							11	10.1145/1921632.1921637		44	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OV	WOS:000299341700005	
J	Menon, AK; Elkan, C				Menon, Aditya Krishna; Elkan, Charles			Fast Algorithms for Approximating the Singular Value Decomposition	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Singular value decomposition; low rank approximation; experimental evaluation	MONTE-CARLO ALGORITHMS; LOW-RANK APPROXIMATION; MATRIX	A low-rank approximation to a matrix A is a matrix with significantly smaller rank than A, and which is close to A according to some norm. Many practical applications involving the use of large matrices focus on low-rank approximations. By reducing the rank or dimensionality of the data, we reduce the complexity of analyzing the data. The singular value decomposition is the most popular low-rank matrix approximation. However, due to its expensive computational requirements, it has often been considered intractable for practical applications involving massive data. Recent developments have tried to address this problem, with several methods proposed to approximate the decomposition with better asymptotic runtime. We present an empirical study of these techniques on a variety of dense and sparse datasets. We find that a sampling approach of Drineas, Kannan and Mahoney is often, but not always, the best performing method. This method gives solutions with high accuracy much faster than classical SVD algorithms, on large sparse datasets in particular. Other modern methods, such as a recent algorithm by Rokhlin and Tygert, also offer savings compared to classical SVD algorithms. The older sampling methods of Achlioptas and McSherry are shown to sometimes take longer than classical SVD.	[Menon, Aditya Krishna; Elkan, Charles] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92037 USA	Menon, AK (reprint author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92037 USA.	akmenon@cs.ucsd.edu; elkan@cs.ucsd.edu					Achlioptas D, 2007, J ACM, V54, DOI 10.1145/1219092.1219098; Achlioptas D., 2001, P 33 ANN ACM S THEOR, P611, DOI 10.1145/380752.380858; Ailon N, 2008, PROCEEDINGS OF THE NINETEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1; ANDERSON E, 1992, LAPACK USERS GUIDE; Artin E., 1942, NOTRE DAME MATH LECT; AT&T LABORATORIES CAMBRIDGE, 2002, DAT FAC; BERRY M., 2005, HDB PARALLEL COMPUTI, P117; CHAN TF, 1982, ACM T MATH SOFTWARE, V8, P72, DOI 10.1145/355984.355990; Deshpande A, 2006, LECT NOTES COMPUT SC, V4110, P292; DRINEAS P., 2006, P 14 ANN EUR S ALG E, P304; Drineas P, 2006, SIAM J COMPUT, V36, P132, DOI 10.1137/S0097539704442684; Drineas P, 2006, SIAM J COMPUT, V36, P158, DOI 10.1137/S0097539704442696; DRINEAS P., 2001, P PANH C INF, P279; Drineas Petros, 2007, ABS07101435 CORR; DUFF I., 1998, HARWELL BOEING COLLE; Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367; Fradkin D., 2003, P 9 ACM SIGKDD INT C, P517; Frieze A., 1998, Proceedings 39th Annual Symposium on Foundations of Computer Science (Cat. No.98CB36280), DOI 10.1109/SFCS.1998.743487; Furnas G., 1988, P 11 ANN INT ACM SIG, P465, DOI 10.1145/62437.62487; Golub G.H., 1996, MATRIX COMPUTATIONS; GORRELL G., 2006, P C EUR CHAP ASS COM; Har-Peled S., 2006, LOW RANK MATRIX APPR; Horn R.A, 1991, TOPICS MATRIX ANAL; Jimeng Sun, 2008, STAT ANAL DATA MIN, V1, P6, DOI 10.1002/sam.102; Jolliffe I., 1986, PRINCIPAL COMPONENT; LARSEN R. M., 2005, PROPACK; Lewis D. D., 2004, REUTERS 21578 TEXT C; Liberty E, 2007, P NATL ACAD SCI USA, V104, P20167, DOI 10.1073/pnas.0709640104; Mirsky L, 1960, Q J MATH, V11, P50, DOI 10.1093/qmath/11.1.50; NGUYEN NH, 2009, P 41 ACM S THEOR COM, P215, DOI 10.1145/1536414.1536446; Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275505; Paterek A., 2007, P KDD CUP WORKSH; Rokhlin V, 2009, SIAM J MATRIX ANAL A, V31, P1100, DOI 10.1137/080736417; SARLOS T, 2006, P 47 ANN IEEE S FDN, P143; SUN J., 2007, P SIAM INT C DAT MIN; THOMAS G., 2007, FAST WALSH HADAMARD; Tjahyadi R., 2004, P 6 INT C OPT TECHN; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vempala S., 2004, DIMACS SERIES DISCRE, V65; Yarlagadda R. K., 1997, HADAMARD MATRIX ANAL; ZHANG Z., 2001, SIAM J MATRIX ANAL A, V23, P706	41	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2011	5	2							13	10.1145/1921632.1921639		36	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OV	WOS:000299341700007	
J	Sun, JM; Liu, Y; Tang, J; Apte, C				Sun, Jimeng; Liu, Yan; Tang, Jie; Apte, Chid			Introduction to Special Issue on Large-Scale Data Mining	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Editorial Material									[Liu, Yan] Univ So Calif, Los Angeles, CA 90089 USA; [Tang, Jie] Tsinghua Univ, Beijing, Peoples R China								0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	FEB	2011	5	2							7	10.1145/1921632.1921633		1	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	879OV	WOS:000299341700001	
J	Yu, H				Yu, Hwanjo			Selective sampling techniques for feedback-based data retrieval	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Selective sampling; Feedback-based data retrieval		As many databases have been brought online, data retrieval-finding relevant data from large databases-has become a nontrivial task. A feedback-based data retrieval system was proposed to provide user with an intuitive way for expressing their preferences in queries. The system iteratively receives a partial ordering on a sample of data from the user, learns a ranking function, and returns highly ranked results according to the function. An important issue in such retrieval systems is minimizing the number of iterations or the amount of feedback to learn an accurate ranking function. This paper proposes selective sampling (or active learning) techniques for RankSVM that can be used in the retrieval systems. The proposed techniques minimizes the amount of user interaction to learn an accurate ranking function thus facilitates users formulating a preference query in the data retrieval system.	Pohang Univ Sci & Technol POSTECH, Fac Dept Comp Sci & Engn, Pohang, Kyungbuk, South Korea	Yu, H (reprint author), Pohang Univ Sci & Technol POSTECH, Fac Dept Comp Sci & Engn, Pohang, Kyungbuk, South Korea.	hwanjoyu@postech.ac.kr			Korean Government [KRF-2009-0080667]	This work was supported by the Brain Korea 21 Project in 2009 and the Korea Research Foundation Grant funded by the Korean Government (KRF-2009-0080667).	BRINKER K, 2004, P INT C MACH LEARN I; Bruno N., 2002, P 18 INT C DAT ENG I; BURGES C, 2004, P 22 INT C MACH LEAR; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CAO Y, 2006, P 29 ANN INT ACM SIG; CAREY MJ, 1997, SIGMOD C, P219; CAREY MJ, 1998, VLDB, P158; Cauwenberghs G., 2000, NIPS, P409; CHANG E, 2001, P 9 ACM INT C MULT 2; CHANG KCC, 2002, SIGMOD 2002; Chauclhuri S., 1999, VLDB, P397; Christianini N, 2000, INTRO SUPPORT VECTOR; COHEN WW, 1998, P 1997 C ADV NEUR IN; DOMENICONI C, 2001, P 2001 IEEE INT C DA; FAGIN R, 2001, P 20 ACM SIGACT SIGM; FUNG G, 2002, P 2 SIAM INT C DAT M; FURNKRANZ J, 2003, P 14 EUR C MACH LEAR; HARPELED S, 2002, ADV NEURAL INFORM PR, V15; Herbrich R., 2000, LARGE MARGIN RANK BO; HERSH W, 1994, P 17 ANN ACM SIGIR C; HRISTIDIS V, 2001, P ACM SIGMOD INT C M; Joachims T, 2006, P 12 ACM SIGKDD INT; Joachims T., 2002, P ACM SIGKDD INT C K; LI C, 2005, P ACM SIGMOD INT C M; Nguyen T.Q., 2008, J COMPUT SCI ENG, V2, P26; QIN T, 2007, P 30 ANN INT ACM SIG; RADLINSKI F, 2005, P 11 ACM SIGKDD INT; Schohn G., 2000, P 17 INT C MACH LEAR, P839; Syed N, 1999, P WORKSH SUPP VECT M; TONG S, 2000, P 17 INT C MACH LEAR, P999; Vapnik V. N., 1998, STAT LEARNING THEORY; XIAO R, 2000, P 12 IEEE INT C TOOL; XU J, 2007, P 30 ANN INT ACM SIG; YU H, 2005, P INT C KNOWL DISC D; YU H, 2005, P INT C DAT ENG ICDE; Yu HJ, 2007, INFORM SYST, V32, P560, DOI 10.1016/j.is.2006.02.001; LETOR LEARNING RANK	37	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					1	30		10.1007/s10618-010-0168-8		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100001	
J	Mueen, A; Keogh, E; Zhu, QA; Cash, SS; Westover, MB; Bigdely-Shamlo, N				Mueen, Abdullah; Keogh, Eamonn; Zhu, Qiang; Cash, Sydney S.; Westover, M. Brandon; Bigdely-Shamlo, Nima			A disk-aware algorithm for time series motif discovery	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Time series motifs; Bottom-up search; Random references; Pruning	PATTERNS	Time series motifs are sets of very similar subsequences of a long time series. They are of interest in their own right, and are also used as inputs in several higher-level data mining algorithms including classification, clustering, rule-discovery and summarization. In spite of extensive research in recent years, finding time series motifs exactly in massive databases is an open problem. Previous efforts either found approximate motifs or considered relatively small datasets residing in main memory. In this work, we leverage off previous work on pivot-based indexing to introduce a disk-aware algorithm to find time series motifs exactly in multi-gigabyte databases which contain on the order of tens of millions of time series. We have evaluated our algorithm on datasets from diverse areas including medicine, anthropology, computer networking and image processing and show that we can find interesting and meaningful motifs in datasets that are many orders of magnitude larger than anything considered before.	[Mueen, Abdullah; Keogh, Eamonn; Zhu, Qiang] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA; [Cash, Sydney S.] Harvard Univ, Massachusetts Gen Hosp, Sch Med, Boston, MA USA; [Westover, M. Brandon] Brigham & Womens Hosp, Massachusetts Gen Hosp, Boston, MA 02115 USA; [Bigdely-Shamlo, Nima] Univ Calif San Diego, Swartz Ctr Computat Neurosci, San Diego, CA 92103 USA	Mueen, A (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	mueen@cs.ucr.edu; eamonn@cs.ucr.edu; qzhu@cs.ucr.edu; scash@partners.org; mwestover@partners.org; nima@sccn.ucsd.edu					Abe H., 2005, 1 INT C COMPL MED EN; Androulakis I., 2005, P FDN SYST BIOL ENG; ARITA D, 2005, P JSAI WORKSH CONV I, P25; BEAUDOIN P, 2008, MOTION MOTIF GRAPHS; BENTLEY JL, 1980, COMMUN ACM, V23, P214, DOI 10.1145/358841.358850; BIGDELYSHAMLO N, 2008, IEEE T NEURAL SYST R, V16; Bohm C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183884; Celly B., 2004, P 17 INT C COMP AN S; Gonzalez Edgar Chavez, 2008, IEEE Transactions on Pattern Analysis and Machine Intelligence, V30, DOI 10.1109/TPAMI.2007.70815; CHEUNG SS, 2005, ICIP, V3, P181; Chiu B., 2003, ACM SIGKDD WASH DC, P493; Corral A., 2000, SIGMOD; Delorme A, 2003, IEEE T NEUR SYS REH, V11, P133, DOI 10.1109/TNSRE.2003.814428; Ding H., 2008, VLDB; Dohnal V, 2003, LECT NOTES COMPUT SC, V2736, P484; Duchene F, 2007, ARTIF INTELL MED, V39, P25, DOI 10.1016/j.artmed.2006.07.004; Faloutsos C., 1994, SIGMOD, P419; FERREIRA P, 2006, DISCOV SCI; Goldberger AL, 2000, CIRCULATION, V101, pE215; Guyet T, 2007, J BIOMED INFORM, V40, P672, DOI 10.1016/j.jbi.2007.09.006; HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417; HAMID R, 2005, P 21 C UNC ART INT U; JAGADISH HV, 2005, ACM T DATABASE SYST, V30; KAFFKA S, 2000, PROTECTING HIGH YIEL; KEOGH E, 2003, P 7 EUR C PRINC PRAC, P253; KEOGH EJ, 2006, VLDB, P882; Koudas N, 2000, IEEE T KNOWL DATA EN, V12, P3, DOI 10.1109/69.842246; Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719; LIN J, 2002, 2 WORKSH TEMP DAT MI; LIU Z, 2005, PAKDD, P343; Loomis AL, 1938, J NEUROPHYSIOL, V1, P413; McGovern A., 2007, 5 C ART INT ITS APPL; Meng J., 2008, P EUROGRAPHICS; MINNEN D, 2007, 22 C ART INT; MINNEN D, 2007, IEEE ICDM; MOTZKIN D, 1982, INT J COMPUT INF SCI, V11, P381, DOI 10.1007/BF00996816; Mueen A., 2009, SDM; Murakami K, 2005, IEEE SYS MAN CYBERN, P3610; NANOPOULOS A, 2001, INT C VER LARG DAT B, P331; Niedermeyer E, 1999, ELECTROENCEPHALOGRAP; Nyberg C, 1995, VLDB J, V4, P603, DOI 10.1007/BF01354877; PATEL P, 2002, IEEE INT C DAT MIN; ROMBO S, 2004, P 6 INT C FLEX QUER, P84; SHIEH J, 2008, IGKDD, P623; SIMONA R, 2004, INT C QUER ANSW SYST, V3055, P84; STAFFORD C, 2009, CHARACTERIZATI UNPUB; Stefanovic B, 2007, J CEREBR BLOOD F MET, V27, P741, DOI 10.1038/sj.jcbfm.9600377; Stern J.M., 2004, ATLAS EEG PATTERNS; Tanaka Y, 2005, MACH LEARN, V58, P269, DOI 10.1007/s10994-005-5829-2; Tang H, 2008, KNOWL-BASED SYST, V21, P666, DOI 10.1016/j.knosys.2008.03.022; TATA S, 2007, THESIS U MICHIGAN; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; UENO K, 2006, P IEEE INT C DAT MIN; Weber R., 1998, VLDB, P194; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; YANKOV D, 2007, SIGKDD; YOSHIKI T, 2005, MACH LEARN, V58, P269; YU C, 2007, INF SOFTW TECHNOL, V49	58	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					73	105		10.1007/s10618-010-0176-8		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100003	
J	Gamez, JA; Mateo, JL; Puerta, JM				Gamez, Jose A.; Mateo, Juan L.; Puerta, Jose M.			Learning Bayesian networks by hill climbing: efficient methods based on progressive restriction of the neighborhood	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article							PROBABILISTIC NETWORKS; MODEL; ALGORITHMS; SPACE	Learning Bayesian networks is known to be an NP-hard problem and that is the reason why the application of a heuristic search has proven advantageous in many domains. This learning approach is computationally efficient and, even though it does not guarantee an optimal result, many previous studies have shown that it obtains very good solutions. Hill climbing algorithms are particularly popular because of their good trade-off between computational demands and the quality of the models learned. In spite of this efficiency, when it comes to dealing with high-dimensional datasets, these algorithms can be improved upon, and this is the goal of this paper. Thus, we present an approach to improve hill climbing algorithms based on dynamically restricting the candidate solutions to be evaluated during the search process. This proposal, dynamic restriction, is new because other studies available in the literature about restricted search in the literature are based on two stages rather than only one as it is presented here. In addition to the aforementioned advantages of hill climbing algorithms, we show that under certain conditions the model they return is a minimal I-map of the joint probability distribution underlying the training data, which is a nice theoretical property with practical implications. In this paper we provided theoretical results that guarantee that, under these same conditions, the proposed algorithms also output a minimal I-map. Furthermore, we experimentally test the proposed algorithms over a set of different domains, some of them quite large (up to 800 variables), in order to study their behavior in practice.	[Gamez, Jose A.; Mateo, Juan L.; Puerta, Jose M.] Univ Castilla La Mancha, Dept Comp Syst, Intelligent Syst & Data Min Grp I3A, Albacete 02071, Spain	Mateo, JL (reprint author), Univ Castilla La Mancha, Dept Comp Syst, Intelligent Syst & Data Min Grp I3A, Albacete 02071, Spain.	jgamez@dsi.uclm.es; juanlmc@dsi.uclm.es; jpuerta@dsi.uclm.es			Spanish Ministerio de Educacion y Ciencia [TIN2007-67418-C03-01]; Junta de Comunidades de Castilla-La Mancha [PBI-08-048]; FEDER	We are grateful to the anonymous reviewers for their valuable comments and suggestions that have greatly helped us to improve the paper. This work has been partially supported by the Spanish Ministerio de Educacion y Ciencia (TIN2007-67418-C03-01); Junta de Comunidades de Castilla-La Mancha (PBI-08-048) and FEDER funds.	Abellan J., 2006, P 3 EUR WORKSH PROB, P1, DOI 10.1109/IPDPS.2006.1639290; Acid S, 2001, INT J APPROX REASON, V27, P235, DOI 10.1016/S0888-613X(01)00041-X; Acid S, 2003, J ARTIF INTELL RES, V18, P445; Andreassen S., 1989, COMPUTER AIDED ELECT; BEINLICH IA, 1989, 2 EUR C ART INT MED, V38, P247; Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Blanco R, 2003, INT J INTELL SYST, V18, P205, DOI 10.1002/int.10084; Buntine W., 1991, P 7 C UNC ART INT, p[52, 524]; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Cano R, 2004, STUD FUZZ SOFT COMP, V146, P309; Chickering D., 1995, P 5 C ART INT STAT F, P112; Chickering D. M., 1996, LEARNING DATA ARTIFI, P121; Chickering D. M, 2002, J MACHINE LEARNING R, V3, p[507, 524]; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cowell R.G., 2003, PROBABILISTIC NETWOR; Dash D, 1999, P 15 C UNC ART INT, P142; de Campos LM, 2002, INT J APPROX REASON, V31, P291, DOI 10.1016/S0888-613X(02)00091-9; de Campos LM, 2006, J MACH LEARN RES, V7, P2149; DECAMPOS LM, 2001, 6 EUR C SYMB QUANT A, P228; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Friedman N, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P206; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Gamez JA, 2005, LECT NOTES COMPUT SC, V3571, P161; Geiger D, 2001, ANN STAT, V29, P505; HAUGHTON DMA, 1988, ANN STAT, V16, P342, DOI 10.1214/aos/1176350709; Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; HOLM S, 1979, COMPUT STAT Q, V6, P219; Jensen A., 1996, P 12 ANN C UNC ART I, P349; Jensen C.S., 1997, THESIS AALBORG U DEN; Jensen F. V., 2007, BAYESIAN NETWORKS DE, P515; Kristensen K, 2002, COMPUT ELECTRON AGR, V33, P197, DOI 10.1016/S0168-1699(02)00007-8; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; Margaritis D, 2003, THESIS CARNEGIE MELL; MORAL S, 2004, P 10 INT C INF PROC, P1307; NAGELE A, 2007, P 18 EUR C MACH LEAR, P238; Neapolitan R, 2003, LEARNING BAYESIAN NE; Pearl J., 1988, PROBABILISTIC REASON; Pena JM, 2007, INT J APPROX REASON, V45, P211, DOI 10.1016/j.ijar.2006.06.008; Robinson R. W., 1977, COMBINATORIAL MATH, V622, P28, DOI 10.1007/BFb0069178; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Spellman PT, 1998, MOL BIOL CELL, V9, p371A; Spirtes P., 1993, LECT NOTES STAT, V81; STATNIKOV A, 2003, TR0301 DSL VAND U; TSAMARDINOS I, 2006, P 19 INT FLOR ART IN, P592; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; VANDIJK S, 2003, PKDD, P132; Verma TS, 1991, P 6 ANN C UNC ART IN, P255; WENCHEN X, 2008, IEEE T KNOWL DATA EN, V20, P628; Witten IH, 2005, DATA MINING PRACTICA; Wong ML, 2004, IEEE T EVOLUT COMPUT, V8, P378, DOI 10.1109/TEVC.2004.830334	51	5	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					106	148		10.1007/s10618-010-0178-6		43	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100004	
J	Ye, LX; Keogh, E				Ye, Lexiang; Keogh, Eamonn			Time series shapelets: a novel technique that allows accurate, interpretable and fast classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Time series; Data mining; Classification; Decision tree		Classification of time series has been attracting great interest over the past decade. While dozens of techniques have been introduced, recent empirical evidence has strongly suggested that the simple nearest neighbor algorithm is very difficult to beat for most time series problems, especially for large-scale datasets. While this may be considered good news, given the simplicity of implementing the nearest neighbor algorithm, there are some negative consequences of this. First, the nearest neighbor algorithm requires storing and searching the entire dataset, resulting in a high time and space complexity that limits its applicability, especially on resource-limited sensors. Second, beyond mere classification accuracy, we often wish to gain some insight into the data and to make the classification result more explainable, which global characteristics of the nearest neighbor cannot provide. In this work we introduce a new time series primitive, time series shapelets, which addresses these limitations. Informally, shapelets are time series subsequences which are in some sense maximally representative of a class. We can use the distance to the shapelet, rather than the distance to the nearest neighbor to classify objects. As we shall show with extensive empirical evaluations in diverse domains, classification algorithms based on the time series shapelet primitives can be interpretable, more accurate, and significantly faster than state-of-the-art classifiers.	[Ye, Lexiang; Keogh, Eamonn] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA	Ye, LX (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	lexiangy@cs.ucr.edu; eamonn@cs.ucr.edu			NSF [0803410, 0808770]	We thank the reviewers for their helpful comments and suggestions. We thank Ralf Hartemink for help with the heraldic shields and Dr. Sang-Hee Lee and Taryn Rampley for their help with the projectile point dataset. This work was funded by NSF 0803410 and 0808770.	Berndt D, 1994, AAAI 94 WORKSH KNOWL; Breiman L, 1984, CLASSIFICATION REGRE; Briandet R, 1996, J AGR FOOD CHEM, V44, P170, DOI 10.1021/jf950305a; Chiu B., 2003, P 9 ACM SIGKDD INT C, P493; Ding H., 2008, P VLDB ENDOWMENT, V1, P1542, DOI DOI 10.1145/1454159.1454226; DING H, 2008, P VLDB END AUG 2008, V2, P1542; FALOUTSOS C, 1994, ACM SIGMOD REC 23 JU, V2, P419; Geurts P., 2001, LECT NOTES COMPUTER, V2168, P115; GRAMM J, 2003, LECT NOTES COMPUTER, V2751, P963; Jeong MK, 2006, TECHNOMETRICS, V48, P26, DOI 10.1198/004017005000000553; Kadous M. W., 1999, P 16 INT C MACH LEAR, P454; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; Keogh E., 2006, P 32 INT C VER LARG, P882; Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9; KOSCHORRECK W, 1981, FACSIMILE EDITION CO; LANG W, 2009, IEEE T KNOWLEDG 1015; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Montagu JA, 1840, GUIDE STUDY HERALDRY; Rodriguez J., 2004, P 2004 ACM S APPL CO, P548, DOI 10.1145/967900.968015; ROVERSO D, 2000, 3 ANS INT TOP M NUCL; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Veloso A, 2006, IEEE DATA MINING, P645; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; WILSON RH, 1994, MIDINFRARED SPECTROS; XI X, 2006, P 23 INT C MACH LEAR, V148, P1033; YAMADA Y, 2003, P 20 INT C MACH LEAR, P840; YE L, 2009, TIME SERIES SHAPELET; Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947; *CMU, CMU GRAPH LAB MOT CA; *WIK, WIK DESCR COFF; 1525, FOUNDERS BENEFECTORS	32	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					149	182		10.1007/s10618-010-0179-5		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100005	
J	Doran, D; Gokhale, SS				Doran, Derek; Gokhale, Swapna S.			Web robot detection techniques: overview and limitations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Web Crawler; Web Robot; WWW; Web Robot Detection; Web User Classification	DISCOVERY	Most modern Web robots that crawl the Internet to support value-added services and technologies possess sophisticated data collection and analysis capabilities. Some of these robots, however, may be ill-behaved or malicious, and hence, may impose a significant strain on a Web server. It is thus necessary to detect Web robots in order to block undesirable ones from accessing the server. Such detection is also essential to ensure that the robot traffic is considered appropriately in the performance and capacity planning of Web servers. Despite a variety of Web robot detection techniques, there is no consensus regarding a single technique, or even a specific "type" of technique, that performs well in practice. Therefore, to aid in the development of a practically applicable robot detection technique, this survey presents a critical analysis and comparison of the prevalent detection approaches. We propose a framework to classify the existing detection techniques into four categories based on their underlying detection philosophy. We compare the different classes to gain insights into those characteristics that make up an effective robot detection scheme. Finally, we discuss why the contemporary techniques fail to offer a general solution to the robot detection problem and propose a set of key ingredients necessary for strong Web robot detection.	[Doran, Derek; Gokhale, Swapna S.] Univ Connecticut, Dept Comp Sci & Engn, Storrs, CT 06269 USA	Doran, D (reprint author), Univ Connecticut, Dept Comp Sci & Engn, Storrs, CT 06269 USA.	derek.doran@engr.uconn.edu; ssg@engr.uconn.edu					AH LV, 2003, P EUR, P294; Bomhardt C, 2005, ST CLASS DAT ANAL, P113, DOI 10.1007/3-540-27373-5_14; BUZIKASHVILI N, 2008, P WORKSH INF, P35; Dikaiakos MD, 2005, COMPUT COMMUN, V28, P880, DOI 10.1016/j.comcom.2005.01.003; Doran Derek, 2009, Proceedings 21st International Conference on Software Engineering & Knowledge Engineering (SEKE 2009); DORAN D, 2008, P INT S NETW COMP AP, P275; Duskin O, 2009, P 2009 WORKSH WEB SE, P15, DOI 10.1145/1507509.1507512; Geens N, 2006, LECT NOTES ARTIF INT, V4065, P121; GILES C, 2010, P 19 INT C WORLD WID, P1101, DOI 10.1145/1772690.1772824; Gossweiler R., 2009, P 18 WWW C, P841, DOI 10.1145/1526709.1526822; Guo WG, 2005, INT C COMP SUPP COOP, P302; Huntington P, 2008, J INF SCI, V34, P726, DOI 10.1177/0165551507087237; Jansen BJ, 2000, INFORM PROCESS MANAG, V36, P207, DOI 10.1016/S0306-4573(99)00056-4; Kabe T., 2000, Proceedings Seventh International Conference on Parallel and Distributed Systems: Workshops, DOI 10.1109/PADSW.2000.884534; KANDULA S, 2005, P S NETW SYST DES IM, P287; KLUEVER KA, 2008, P IEEE W NEW YORK IM; Koster MA, 1994, STANDARD ROBOT EXCLU; Lee J, 2009, COMPUT SECUR, V28, P795, DOI 10.1016/j.cose.2009.05.004; Lin X., 2008, P INT TEST C ITC, P1, DOI 10.1109/PORTABLE-POLYTRONIC.2008.4681271; LU WZ, 2006, P INT C COMM CIRC SY, P1806; MOTOYAMA M, 2010, P USENIX SEC S 2010; ORILEY T, 2007, COMMUNICATIONS STRAT, P17; PARK KS, 2006, P ANN C USENIX 06 AN; PRINCE MB, 2005, 2 C EM ANT; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHIRALISHAHREZA HM, 2008, P 2008 ISECS INT C C, P318; SMITH JA, 2006, D LIB MAGAZINE, V12; Stassopoulou A, 2007, LECT NOTES COMPUT SC, V4505, P265; Tan PN, 2002, DATA MIN KNOWL DISC, V6, P9, DOI 10.1023/A:1013228602957; TURING A. M., 1950, MIND, VLIX, P433, DOI DOI 10.1093/MIND/LIX.236.433; YE S, 2004, P 2 AS PAC ADV NETW, P263; *AWSTATS, AWSTATS FREE LOG FIL; *PRINC U, 2003, PLANETLAB OP PLATF D	34	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					183	210		10.1007/s10618-010-0180-z		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100006	
J	Choi, YS				Choi, Yong Suk			Tree pattern expression for extracting information from syntactically parsed text corpora	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Tree pattern; Information extraction; Tree pattern-matching algorithm		With the public availability of a number of syntactically parsed text corpora, it has been increasingly important to efficiently extract desired information from such corpora. Many conventional works extract a desired text part by matching the parse tree of each sentence to a query that is represented as a structural form of relational predicates expressing a common structural pattern of desired text parts. However, although those works can be useful for limited types of simple queries, they are not very efficient in general because query formulations are sometimes very complicated for complex patterns of desired text parts and query matching tasks are likely to be exponentially time-consuming when considering a variety of complex sentential structures in a text corpus. In order to overcome such inadequacy, we present a novel tree pattern expression (TPE) that can represent various structural patterns intuitively and reduce pattern-matching complexity significantly. This paper first proposes TPE and its pattern-matching algorithm, and then theoretically analyzes the complexity of the proposed pattern-matching algorithm. It also illustrates a TPE-based information extraction system, which is applied to real text mining in a bio-text corpus. It finally shows some experimental results with some discussions in comparison with other systems.	Hanyang Univ, Seoul 133791, South Korea	Choi, YS (reprint author), Hanyang Univ, Seoul 133791, South Korea.	cys@hanyang.ac.kr					KEPSER S, 2003, P 10 C EUR CHAPT ASS, P179; Kim JD, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-10; Klein D., 2002, ADV NEURAL INFORM PR, V15, P3; KONIG E, 2003, TIGERSEARCH 2 1 USER; LAI C, 2004, P AUSTR LANG TECHN W, P139; Lee SK, 2003, J BIOTECHNOL, V105, P51, DOI 10.1016/S0168-1656(03)00183-4; Levy R., 2006, P 5 INT C LANG RES E; MIROVSKY J, 2008, P 3 INT JOINT C NAT, P945; NEMEC P, 2006, P 5 INT C LANG RES E, P2194; RIEDEL S, 2005, LEARN LANG LOG LLL05; ROHDE D, 2009, TGREP2; Rosario B., 2004, P 42 ANN M ASS COMP, P430, DOI 10.3115/1218955.1219010; SU KY, 1994, P 32 ANN M ASS COMP, P242, DOI 10.3115/981732.981765; Wallis S., 2000, Literary & Linguistic Computing, V15, DOI 10.1093/llc/15.3.339; YAKUSHIJI A, 2000, GENOME INFORM, V11, P446	15	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					211	231		10.1007/s10618-010-0184-8		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100007	
J	McGovern, A; Rosendahl, DH; Brown, RA; Droegemeier, KK				McGovern, Amy; Rosendahl, Derek H.; Brown, Rodger A.; Droegemeier, Kelvin K.			Identifying predictive multi-dimensional time series motifs: an application to severe weather prediction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Temporal data mining; Multi-dimensional; Severe weather	SYSTEM ARPS; ALGORITHM	We introduce an efficient approach to mining multi-dimensional temporal streams of real-world data for ordered temporal motifs that can be used for prediction. Since many of the dimensions of the data are known or suspected to be irrelevant, our approach first identifies the salient dimensions of the data, then the key temporal motifs within each dimension, and finally the temporal ordering of the motifs necessary for prediction. For the prediction element, the data are assumed to be labeled. We tested the approach on two real-world data sets. To verify the generality of the approach, we validated the application on several subjects from the CMU Motion Capture database. Our main application uses several hundred numerically simulated supercell thunderstorms where the goal is to identify the most important features and feature interrelationships which herald the development of strong rotation in the lowest altitudes of a storm. We identified sets of precursors, in the form of meteorological quantities reaching extreme values in a particular temporal sequence, unique to storms producing strong low-altitude rotation. The eventual goal is to use this knowledge for future severe weather detection and prediction algorithms.	[McGovern, Amy] Univ Oklahoma, Sch Comp Sci, Norman, OK 73019 USA; [Rosendahl, Derek H.; Droegemeier, Kelvin K.] Univ Oklahoma, Sch Meteorol, Norman, OK 73072 USA; [Brown, Rodger A.] NOAA, Natl Severe Storms Lab, Norman, OK 73072 USA	McGovern, A (reprint author), Univ Oklahoma, Sch Comp Sci, Norman, OK 73019 USA.	amcgovern@ou.edu; drose@ou.edu; Rodger.Brown@noaa.gov; kkd@ou.edu			National Science Foundation [REU/0453545, IIS/REU/0755462, IIS/CAREER/0746816, IIS/0840956, IIS/0938138]; NSF ERC Center for Collaborative Adaptive Sensing of the Atmosphere (CASA) [NSF ERC 0313747]; University of Oklahoma's College of Engineering; NSF [EIA-0196217]	This material is based upon work supported by the National Science Foundation under Grant No. REU/0453545, IIS/REU/0755462, IIS/CAREER/0746816 and corresponding REU Supplements IIS/0840956 and IIS/0938138, the NSF ERC Center for Collaborative Adaptive Sensing of the Atmosphere (CASA, NSF ERC 0313747), and the University of Oklahoma's College of Engineering. We would also like to thank Nathan Hiers, Adrianna Kruger, and Meredith Beaton for their preliminary work on this data. The motion capture data used in this project was obtained from mocap.cs.cmu.edu and their database was created with funding from NSF EIA-0196217.	Adlerman EJ, 2005, MON WEATHER REV, V133, P3595, DOI 10.1175/MWR3039.1; Agrawal R., 1994, FAST ALGORITHMS MINI, P487; Brotzge JA, 2006, TRANSPORT RES REC, P145; BURGESS DW, 1993, TORNADO ITS STRUCTUR, V79, P203; CHENG H, 2008, P INT C KNOWL DISC D, P133, DOI 10.1145/1401890.1401911; Chiu B, 2003, 9 ACM SIGKDD INT C K, P493; DAS G, 1998, KNOWLEDGE DISCOVERY, P16; DENTON A., 2005, P 5 IEEE INT C DAT M, P122; Donaldson R. J., 1975, 9 C SEV LOC STORMS N, P321; Faloutsos C., 1997, P COMPR COMPL SEQUEN, P2; GOLDIN D, 2006, P 15 ACM INT C INF K, P347, DOI 10.1145/1183614.1183666; HU M, 2004, 11 C AV RANG AER 22; IDE T, 2006, LECT NOTES COMPUTER; Johnson JT, 1998, WEATHER FORECAST, V13, P263, DOI 10.1175/1520-0434(1998)013<0263:TSCIAT>2.0.CO;2; Kahveci T, 2002, 14TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, PROCEEDINGS, P175; KASETTY S, 2008, P 20 IEEE INT C TOOL; Keogh E., 2003, P 3 IEEE INT C DAT M, P115; Keogh E., 2005, P 5 IEEE INT C DAT M, P226; Lee S.-L., 2000, P ICDE, P599; Lin J., 2003, P 8 ACM SIGMOD WORKS, P2; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; McGovern A, 2008, PATTERN RECOGN LETT, V29, P1252, DOI 10.1016/j.patrec.2008.01.024; MCGOVERN A, 2010, 2010 NASA C IN PRESS; McGovern A, 2008, IEEE DATA MINING, P935, DOI 10.1109/ICDM.2008.134; McGovern A., 2007, 5 C ART INT ITS APPL; Mueen A., 2009, P SIAM INT C DAT MIN, P473; Oates T., 1999, P 5 INT C KNOWL DISC, P322, DOI 10.1145/312129.312268; Oates T, 1996, P 13 INT C MACH LEAR, P346; OATES T, 1998, PREDICTING FUTURE AI, P73; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Rosendahl DH, 2008, THESIS U OKLAHOMA; SCHAEFER JT, 1990, WEATHER FORECAST, V5, P570, DOI 10.1175/1520-0434(1990)005<0570:TCSIAA>2.0.CO;2; SHIEH J, 2009, P IEEE INT C DAT MIN; SUPINIE T, 2009, P IEEE INT C DAT MIN; TANAKA Y, 2003, P 3 INT C MACH LEARN, P252; Vlachos M, 2006, VLDB J, V15, P1, DOI 10.1007/s00778-004-0144-2; Webb GI, 1995, J ARTIF INTELL RES, V3, P431; XI X, 2007, P SIAM INT C DAT MIN; Xue M, 2003, METEOROL ATMOS PHYS, V82, P139, DOI 10.1007/s00703-001-0595-6; Xue M, 2000, METEOROL ATMOS PHYS, V75, P161, DOI 10.1007/s007030070003; Xue M., 2001, METEOR ATMOS PHYS, V76, P134; Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947; Yin J, 2008, IEEE DATA MINING, P678, DOI 10.1109/ICDM.2008.58; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315; ZAKI MJ, 2005, INT C FORM CONC AN	45	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					232	258		10.1007/s10618-010-0193-7		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100008	
J	Shoemaker, L; Banfield, RE; Hall, LO; Bowyer, KW; Kegelmeyer, WP				Shoemaker, Larry; Banfield, Robert E.; Hall, Lawrence O.; Bowyer, Kevin W.; Kegelmeyer, W. Philip			Detecting and ordering salient regions	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Random forest; Saliency; Probabilistic voting; Imbalanced training data; Lift	SPATIALLY DISJOINT DATA; ENSEMBLES; CLASSIFIERS; SETS	We describe an ensemble approach to learning salient regions from arbitrarily partitioned data. The partitioning comes from the distributed processing requirements of large-scale simulations. The volume of the data is such that classifiers can train only on data local to a given partition. Since the data partition reflects the needs of the simulation, the class statistics can vary from partition to partition. Some classes will likely be missing from some or even most partitions. We combine a fast ensemble learning algorithm with scaled probabilistic majority voting in order to learn an accurate classifier from such data. Since some simulations are difficult to model without a considerable number of false positive errors, and since we are essentially building a search engine for simulation data, we order predicted regions to increase the likelihood that most of the top-ranked predictions are correct (salient). Results from simulation runs of a canister being torn and from a casing being dropped show that regions of interest are successfully identified in spite of the class imbalance in the individual training sets. Lift curve analysis shows that the use of data driven ordering methods provides a statistically significant improvement over the use of the default, natural time step ordering. Significant time is saved for the end user by allowing an improved focus on areas of interest without the need to conventionally search all of the data.	[Shoemaker, Larry; Banfield, Robert E.; Hall, Lawrence O.] Univ S Florida, Tampa, FL 33620 USA; [Bowyer, Kevin W.] Univ Notre Dame, South Bend, IN 46556 USA; [Kegelmeyer, W. Philip] Sandia Natl Labs, Livermore, CA 94551 USA	Shoemaker, L (reprint author), Univ S Florida, Tampa, FL 33620 USA.	lwshoema@cse.usf.edu; rbanfiel@cse.usf.edu; hall@cse.usf.edu; kwb@cse.nd.edu; wpk@sandia.gov			Department of Energy [DE-AC04-76DO00789]; National Science Foundation [EIA-0130768]	This research was partially supported by the Department of Energy through the ASCI CSEE Data Discovery Program, Contract number: DE-AC04-76DO00789 and the National Science Foundation under grant EIA-0130768.	Aggarwal CC, 2004, P 10 ACM SIGKDD INT, P503, DOI 10.1145/1014052.1014110; Baeza-Yates R. A., 1999, MODERN INFORM RETRIE; Banfield RE, 2007, IEEE T PATTERN ANAL, V29, P173, DOI 10.1109/TPAMI.2007.250609; Banfield RE, 2005, LECT NOTES COMPUT SC, V3541, P196; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRINKER K, 2004, P 21 INT C MACH LEAR, P129; Chawla NV, 2003, PATTERN RECOGN LETT, V24, P455, DOI 10.1016/S0167-8655(02)00269-6; Chawla NV, 2004, J MACH LEARN RES, V5, P421; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domingos P., 1999, KNOWLEDGE DISCOVERY, P155; Domingos Pedro, 2000, KNOWLEDGE DISCOVERY, P71; Erdem Z, 2005, LECT NOTES COMPUT SC, V3541, P246; ESCHRICH S, 2003, 12 IEEE INT C FUZZ S, V1, P666; Fan W, 2002, INT CON DISTR COMP S, P445; GIONIS A, 2006, P 12 ACM SIGKDD INT, P561, DOI 10.1145/1150402.1150468; HALL L, 2004, 2004 IEEE INT C SYST, V2, P1447, DOI 10.1109/ICSMC.2004.1399834; Henderson A., 2004, PARAVIEW GUIDE; HULLERMEIER E, 2005, P IDA 05 6 INT S INT, P180; KOEGLER WS, 2005, ADV INTELLIGENT DATA, V6, P192; Kong Rui, 2005, Control and Decision, V20; KORECKI JN, 2008, P 19 C INT ASS PATT; KOTSIANTIS S, 2006, GESTS INT T COMPUTER, V30, P25; KUSNEZOV DF, 2004, NAASC100R04 SAND NAT; Lazarevic A, 2002, DISTRIB PARALLEL DAT, V11, P203, DOI 10.1023/A:1013992203485; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Maloof MA, 2004, ARTIF INTELL, V154, P95, DOI 10.1016/j.artint.2003.04.001; Manning CD, 2008, INTRO INFORM RETRIEV; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PIATETSKYSHAPIR.G, 2000, SIGKDD EXPLORATIONS, V2, P76; SCHOOF LA, 1998, SAND922137 SAND NAT; Shipp C. A., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00051-9; Shoemaker L, 2006, PROC INT C TOOLS ART, P116; SHOEMAKER L, 2008, P 19 C INT ASS PATT; Shoemaker L, 2008, INFORM FUSION, V9, P120, DOI 10.1016/j.inffus.2007.08.001; Wang F, 2006, IEEE DATA MINING, P1119; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Wei Fan, 2004, KDD 04, P128; Weiss G. M., 2004, SIGKDD EXPLORATIONS, V6, P7; Witten IH, 2005, DATA MINING PRACTICA, P2	41	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					259	290		10.1007/s10618-010-0194-6		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100009	
J	Kantarcioglu, M; Xi, BW; Clifton, C				Kantarcioglu, Murat; Xi, Bowei; Clifton, Chris			Classifier evaluation and attribute selection against active adversaries	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Adversarial classification; Game theory; Attribute selection; Simulated annealing		Many data mining applications, such as spam filtering and intrusion detection, are faced with active adversaries. In all these applications, the future data sets and the training data set are no longer from the same population, due to the transformations employed by the adversaries. Hence a main assumption for the existing classification techniques no longer holds and initially successful classifiers degrade easily. This becomes a game between the adversary and the data miner: The adversary modifies its strategy to avoid being detected by the current classifier; the data miner then updates its classifier based on the new threats. In this paper, we investigate the possibility of an equilibrium in this seemingly never ending game, where neither party has an incentive to change. Modifying the classifier causes too many false positives with too little increase in true positives; changes by the adversary decrease the utility of the false negative items that are not detected. We develop a game theoretic framework where equilibrium behavior of adversarial classification applications can be analyzed, and provide solutions for finding an equilibrium point. A classifier's equilibrium performance indicates its eventual success or failure. The data miner could then select attributes based on their equilibrium performance, and construct an effective classifier. A case study on online lending data demonstrates how to apply the proposed game theoretic framework to a real application.	[Kantarcioglu, Murat] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA; [Xi, Bowei] Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA; [Clifton, Chris] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Kantarcioglu, M (reprint author), Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA.	muratk@utdallas.edu; xbw@stat.purdue.edu; clifton@cs.purdue.edu			Air Force Office of Scientific Research [FA9550 08-1-0265]; National Institutes of Health [1R01LM009989]; National Science Foundation [Career-0845803, DMS-0904548, CNS-0964350]	We thank the reviewers and the editors for their helpful comments that improved the presentation and the content of the article. This work was partially supported by Air Force Office of Scientific Research MURI Grant FA9550 08-1-0265, National Institutes of Health Grant 1R01LM009989, National Science Foundation Grants Career-0845803, DMS-0904548 and CNS-0964350.	ANDROUTSOPOULOS I, 2005, P 2 C EM ANT PAL ALT, P1; Basar T., 1999, DYNAMIC NONCOOPERATI; Cesa-Bianchi N., 2006, PREDICTION LEARNING; Dalvi N., 2004, P 10 ACM SIGKDD INT, P99, DOI 10.1145/1014052.1014066; Duda R.O., 2001, PATTERN CLASSIFICATI; El Ghaoui L., 2003, UCBCSD031279 EECS DE; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Fukunaga K., 1990, INTRO STAT PATTERN R; Globerson A., 2006, P 23 INT C MACH LEAR, P353, DOI 10.1145/1143844.1143889; Hulten G., 2001, SIGKDD, P97; Lanckriet G. R. G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303321897726; Lippmann R.P., 2000, P DARPA INF SURV C E, V2, P12; Lowd D., 2005, P 11 ACM SIGKDD INT, P641, DOI 10.1145/1081870.1081950; LOWD D, 2005, P 2 C EM ANT PAL ALT, P1; Mahoney M. V., 2002, P 8 ACM SIGKDD INT C, P376; McKelvey R.D., 2007, GAMBIT SOFTWARE TOOL; MITRA D, 1986, ADV APPL PROBAB, V18, P747, DOI 10.2307/1427186; Osborne M., 1999, COURSE GAME THEORY; PU C, 2006, P 3 C EM ANT MOUNT V, P1; ROBERT CP, 2004, MONT CARL STAT METH; STINSON E, 2008, P 2 C USENIX WORKSH, P1; Teo CH, 2008, ADV NEURAL INFORM PR, V20, P1489; VALLEE T, 1999, J COMPUT EC, V13, P201	23	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					291	335		10.1007/s10618-010-0197-3		45	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100010	
J	Silla, CN; Freitas, AA				Silla, Carlos N., Jr.; Freitas, Alex A.			A survey of hierarchical classification across different application domains	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Hierarchical classification; Tree-structured class hierarchies; DAG-structured class hierarchies	TEXT CATEGORIZATION; DECISION TREES; MULTILABEL CLASSIFICATION; FEATURE-SELECTION; GENE ONTOLOGY; CLASSIFIERS; ENSEMBLES; OPTIMIZATION; PERFORMANCE; TAXONOMIES	In this survey we discuss the task of hierarchical classification. The literature about this field is scattered across very different application domains and for that reason research in one domain is often done unaware of methods developed in other domains. We define what is the task of hierarchical classification and discuss why some related tasks should not be considered hierarchical classification. We also present a new perspective about some existing hierarchical classification approaches, and based on that perspective we propose a new unifying framework to classify the existing approaches. We also present a review of empirical comparisons of the existing methods reported in the literature as well as a conceptual comparison of those methods at a high level of abstraction, discussing their advantages and disadvantages.	[Silla, Carlos N., Jr.; Freitas, Alex A.] Univ Kent, Sch Comp, Canterbury, Kent, England	Silla, CN (reprint author), Univ Kent, Sch Comp, Canterbury, Kent, England.	cns2@kent.ac.uk; A.A.Freitas@kent.ac.uk	Freitas, Alex/H-1249-2011; Silla Jr., Carlos/F-7227-2012		CAPES [4871-06-5]	The first author is financially supported by CAPES-a Brazilian research-support agency (process number 4871-06-5). We also thank the anonymous reviewers for their insightful feedback on the earlier version of this manuscript.	Aleksovki D., 2009, P 1 WORKSH LEARN MUL, P5; ALTUN Y, 2003, P 8 EUR C SPEECH COM; Alves RT, 2008, LECT N BIOINFORMAT, V5167, P1; Ashburner M, 2000, NAT GENET, V25, P25; Astikainen K., 2008, BMC P S4, V2; Barbedo JGA, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/91741; Barrett Alan J., 1997, European Journal of Biochemistry, V250, P1; Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; BARUTCUOGLU Z, 2006, P IEEE C SHAP MOD AP; Bennett PN, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P11, DOI 10.1145/1571941.1571946; BINDER A, 2009, P 9 AS C COMP VIS; Blockeel H, 2006, LECT NOTES ARTIF INT, V4213, P18; Blockeel H, 2002, P ACM SIGKDD 2002 WO, P21; Brecheisen S, 2006, LECT NOTES COMPUT SC, V3896, P1164; BRECHEISEN S, 2006, P IEEE 7 INT C MULT, P1385; Burkhardt F., 2005, P INT, P1517; BURRED JJ, 2003, P 6 INT C DIG AUD EF, P8; Cai L, 2004, P 13 ACM INT C INF K, P78, DOI 10.1145/1031171.1031186; Cai L., 2007, P 20 INT JOINT C ART, P714; CECI M, 2007, J INTELL INF SYST, V28, P1; CECI M, 2008, P IEEE INT C DAT MIN, P184; CESABIANCHI N, 2009, 3 INT WORKSH MACH LE; Cesa-Bianchi N, 2006, J MACH LEARN RES, V7, P31; CESA-BIANCHI N., 2006, P 23 INT C MACH LEAR, P177, DOI 10.1145/1143844.1143867; Chakrabarti S, 1998, VLDB J, V7, P163, DOI 10.1007/s007780050061; CHEN Y, 2004, IEEE INT GEOSC REM S, V2, P949; Clare A, 2003, BIOINFORMATICS, V19, pII42, DOI 10.1093/bioinformatics/btg1058; CLARE A, 2004, THESIS U WALES ABERY; Costa EP, 2007, LECT NOTES COMPUT SC, V4643, P126; COSTA E, 2007, EVALUATION METHODS M, V2, P1; Costa EP, 2008, LECT N BIOINFORMAT, V5167, P35; D'Alessio S., 2000, P 6 INT C RECH INF A, P302; DECORO C, 2007, P 8 INT C MUS INF RE, P77; Dekel O., 2004, P 21 INT C MACH LEAR; DEKEL O, 2004, LECT NOTES COMPUTER, V3361, P146; DIMITROVSKI I, 2008, P 11 INT MULT INF SO, VA, P174; DOWNIE JS, 2002, P 3 INT C MUS INF RE, P299; Dumais Susan, 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593; EISNER R, 2005, P IEEE S COMP INT BI, P1; Esuli A, 2008, INFORM RETRIEVAL, V11, P287, DOI 10.1007/s10791-008-9047-y; FAGNI T, 2007, P 3 LANG TECHN C LTC, P24; FREITAS AA, 2007, RES TRENDS DATA MINI, P175; Freitas COA, 2008, J UNIVERS COMPUT SCI, V14, P211; Garcia S, 2008, J MACH LEARN RES, V9, P2677; Gauch S, 2009, J AM SOC INF SCI TEC, V60, P47, DOI 10.1002/asi.20951; Gerlt JA, 2000, GENOME BIOL, V1; GUAN Y, 2008, GENOME BIOL S1, V9, pNIL26; Hao PY, 2007, EXPERT SYST APPL, V33, P627, DOI 10.1016/j.eswa.2006.06.009; Hayete B, 2005, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2005, P127; Holden N, 2008, LECT NOTES COMPUT SC, V4973, P48, DOI 10.1007/978-3-540-78757-0_5; Holden N, 2009, SOFT COMPUT, V13, P259, DOI 10.1007/s00500-008-0321-0; Holden N., 2006, P IEEE SWARM INT S S, P77; HOLDEN N, 2005, P 2005 IEEE SWARM IN, P100, DOI 10.1109/SIS.2005.1501608; Jin B, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-525; KIRITCHENKO S, 2005, P ACL WORKSH LINK BI; Kiritchenko S, 2006, LECT NOTES ARTIF INT, V4013, P395; KOERICH AL, 2005, P IEEE INT C IM PROC, V2, P542; Koller D., 1997, P 14 INT C MACH LEAR, P170; Kriegel HP, 2004, SIAM PROC S, P102; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; Labrou Y, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P180, DOI 10.1145/319950.319976; Lee J. H., 2004, P 5 INT C MUS INF RE, P441; Li T, 2007, J INTELL INF SYST, V29, P211, DOI 10.1007/s10844-006-0019-7; Li T, 2005, INT CONF ACOUST SPEE, P197; LIU TY, 2005, ACM SIGKDD EXPLOR NE, V7, P36, DOI 10.1145/1089815.1089821; Lorena AC, 2004, LECT NOTES COMPUT SC, V2972, P272; McCallum A., 1998, P 15 INT C MACH LEAR, P359; McKay C., 2004, P INT C MUS INF RETR, P525; Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0; Otero FEB, 2009, LECT NOTES COMPUT SC, V5483, P68, DOI 10.1007/978-3-642-01184-9_7; Peng X., 2005, P INT C ART INT APPL, P362; PUNERA K, 2005, P SPEC INT TRACKS 14, P1010; Punera K., 2008, P 17 INT C WORLD WID, P151, DOI 10.1145/1367497.1367518; QIU X, 2009, P JOINT C 47 ANN M A, P165, DOI 10.3115/1667583.1667634; Rocchio J., 1971, RELEVANCE FEEDBACK I, P313; Rousu J, 2005, P 22 INT C MACH LEAR, P744, DOI 10.1145/1102351.1102445; Rousu J, 2006, J MACH LEARN RES, V7, P1601; Ruepp A, 2004, NUCLEIC ACIDS RES, V32, P5539, DOI 10.1093/nar/gkh894; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sasaki M, 1998, IEEE SYS MAN CYBERN, P2827; Secker A, 2007, EXPERT UPDATE MAGAZI, V9, P17; Secker A, 2010, INT J DATA MIN BIOIN, V4, P191; Seeger MW, 2008, J MACH LEARN RES, V9, P1147; Shilane P., 2004, P SHAP MOD INT; SILLA CN, 2009, P IEEE INT C SYST MA, P3599; Silla Carlos N  Jr., 2009, Proceedings of the 2009 Ninth IEEE International Conference on Data Mining (ICDM 2009), DOI 10.1109/ICDM.2009.85; Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002; Sun A, 2003, J AM SOC INF SCI TEC, V54, P1014, DOI 10.1002/asi.10298; Sun A., 2001, P 2001 IEEE INT C DA, P521; Sun AX, 2004, IEEE T KNOWL DATA EN, V16, P1305, DOI 10.1109/TKDE.2004.50; Tikk D, 2003, KYBERNETIKA, V39, P583; Tikk D., 2007, EMERGING TECHNOLOGIE, P244; TIKK D, 2003, P 4 INT S UNC MOD AN, P104; TIKK D, 2004, AUSTR J INTELLIGENT, V8, P123; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101; Valentini G, 2009, LECT NOTES COMPUT SC, V5519, P232, DOI 10.1007/978-3-642-02326-2_24; VALENTINI G, 2009, P 1 WORKSH LEARN MUL, P132; Vens C, 2008, MACH LEARN, V73, P185, DOI 10.1007/s10994-008-5077-3; Wang JH, 2009, J AM STAT ASSOC, V104, P1213, DOI 10.1198/jasa.2009.tm08084; Wang K, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P363; Wang k, 2001, P 1 SIAM INT C DAT M; Weigend A. S., 1999, Information Retrieval, V1, DOI 10.1023/A:1009983522080; Wu FH, 2005, LECT NOTES ARTIF INT, V3607, P313; XIAO Z, 2007, HIERARCHICAL CLASSIF; Xue G.-R., 2008, P 31 ANN INT ACM SIG, P619, DOI 10.1145/1390334.1390440; ZHANG T, 2003, P SPIE C INT MULT MA, P81	107	19	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2011	22	1-2					31	72		10.1007/s10618-010-0175-9		42	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	703SH	WOS:000286001100002	
J	Bouguessa, M; Wang, SR; Dumoulin, B				Bouguessa, Mohamed; Wang, Shengrui; Dumoulin, Benoit			Discovering Knowledge-Sharing Communities in Question-Answering Forums	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Clustering; transaction data; mixture models		In this article, we define a knowledge-sharing community in a question-answering forum as a set of askers and authoritative users such that, within each community, askers exhibit more homogeneous behavior in terms of their interactions with authoritative users than elsewhere. A procedure for discovering members of such a community is devised. As a case study, we focus on Yahoo! Answers, a large and diverse online question-answering service. Our contribution is twofold. First, we propose a method for automatic identification of authoritative actors in Yahoo! Answers. To this end, we estimate and then model the authority scores of participants as a mixture of gamma distributions. The number of components in the mixture is determined using the Bayesian Information Criterion (BIC), while the parameters of each component are estimated using the Expectation-Maximization (EM) algorithm. This method allows us to automatically discriminate between authoritative and nonauthoritative users. Second, we represent the forum environment as a type of transactional data such that each transaction summarizes the interaction of an asker with a specific set of authoritative users. Then, to group askers on the basis of their interactions with authoritative users, we propose a parameter-free transaction data clustering algorithm which is based on a novel criterion function. The identified clusters correspond to the communities that we aim to discover. To evaluate the suitability of our clustering algorithm, we conduct a series of experiments on both synthetic data and public real-life data. Finally, we put our approach to work using data from Yahoo! Answers which represent users' activities over one full year.	[Bouguessa, Mohamed] Univ Quebec Outaouais, Dept Informat & Ingn, Gatineau, PQ J8X 3X7, Canada; [Bouguessa, Mohamed; Dumoulin, Benoit] Yahoo Inc, Santa Clara, CA 95054 USA	Bouguessa, M (reprint author), Univ Quebec Outaouais, Dept Informat & Ingn, 101 St Jean Bosco, Gatineau, PQ J8X 3X7, Canada.	Mohamed.Bouguess@USherbrooke.ca; shengrui.wang@USherbrooke.ca; benoitd@yahoo-inc.com					Ackerman MS, 2003, SHARING EXPERTISE: BEYOND KNOWLEDGE MANAGEMENT, P159; Adamic L. A., 2008, P 17 INT C WORLD WID, P665, DOI 10.1145/1367497.1367587; Aggarwal CC, 2002, IEEE T KNOWL DATA EN, V14, P210, DOI 10.1109/69.991713; Agichtein E., 2008, P INT C WEB SEARCH W, P183, DOI DOI 10.1145/1341531.1341557; Agrawal R, 2005, DATA MIN KNOWL DISC, V11, P5, DOI 10.1007/s10618-005-1396-1; Agrawal R., 1994, P 20 INT C VER LARG, P487; Balakrishnan H, 2006, P ACM SE REG C, P280, DOI 10.1145/1185448.1185512; Balakrishnan N., 2003, PRIMER STAT DISTRIBU; Bezdek J., 1981, PATTERN RECOGNITION; Bouguessa M, 2009, IEEE T KNOWL DATA EN, V21, P507, DOI 10.1109/TKDE.2008.162; Bouguessa M., 2008, P 14 ACM SIGKDD INT, p866 874, DOI 10.1145/1401890.1401994; Bouguessa M, 2006, PATTERN RECOGN LETT, V27, P1419, DOI 10.1016/j.patrec.2006.01.015; CALDARELLI G., 2007, P INT WORKSH C NETW; Campbell C., 2003, P 12 INT C INF KNOWL, P528, DOI DOI 10.1145/956863.956965; CESARIO E., 2007, IEEE T KNOWL DATA EN, V12, P1607; CHEN K., 2006, P ACM C INF KNOWL MG, P367, DOI 10.1145/1183614.1183668; CHUANG K.-T., 2004, INFORM SYST, V31, P170; Danon L, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/09/P09008; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dom B., 2003, P 8 ACM SIGMOD WORKS, P42; Douribsboure Y., 2007, P 16 ACM INT C WORLD, P461, DOI 10.1145/1242572.1242635; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Giannotti F., 2002, Proceedings International Conference on Information Technology: Coding and Computing, DOI 10.1109/ITCC.2002.1000408; Gibson D., 1998, P 9 ACM C HYP HYP, P225, DOI 10.1145/276627.276652; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Gyongyi Z., 2008, P 1 WWW WORKSH QUEST; Han J, 2006, DATA MINING CONCEPTS; Hogg R. V., 2005, INTRO MATH STAT; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kautz H, 1997, COMMUN ACM, V40, P63, DOI 10.1145/245108.245123; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Kumar R, 1999, COMPUT NETW, V31, P1481, DOI 10.1016/S1389-1286(99)00040-7; Lawless J. F., 1982, STAT MODELS METHODS; Lesser EL, 2001, IBM SYST J, V40, P831; LI T., 2005, P 11 ACM SIGKDD INT, P188, DOI 10.1145/1081870.1081894; Liu XM, 2005, INFORM PROCESS MANAG, V41, P1462, DOI 10.1016/j.ipm.2005.03.012; Mattox D, 1999, P 8 INT C HUM COMP I, P303; MAYBURY M, 2006, 06B000040 MTR MITRE; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; Oliver J., 1996, P 13 INT C MACH LEAR, P364; Page L., 1998, PAGERANK CITATION RA; PRESCOTT L., 2006, YAHOO ANSWERS CAPTUR; Radicchi F, 2004, P NATL ACAD SCI USA, V101, P2658, DOI 10.1073/pnas.0400054101; Salvetti F, 2005, LECT NOTES COMPUT SC, V3828, P531; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Sihn W., 2001, P EUR C, P279; Wang K, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P483, DOI 10.1145/319950.320054; Welser H., 2007, J SOC STRUCT, V8; Wenger E., 2002, CULTIVATING COMMUNIT; XIAO Y., 2001, LECT NOTES COMPUTER, V2114, P121; Yang Y., 2002, P 8 ACM SIGKDD INT C, P682; Yang YH, 2005, IEEE T KNOWL DATA EN, V17, P1300, DOI 10.1109/TKDE.2005.145; Yang ZH, 1996, TRENDS ECOL EVOL, V11, P367, DOI 10.1016/0169-5347(96)10041-0; Yimam-Seid D, 2003, J ORG COMP ELECT COM, V13, P1, DOI 10.1207/S15327744JOCE1301_1; Zaki MJ, 2007, DATA KNOWL ENG, V60, P51, DOI 10.1016/j.datak.2006.01.005; Zhang HB, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE & ENGINEERING (14TH) VOLS 1-3, P663; Zhang J., 2007, P 16 INT C WORLD WID, P221, DOI DOI 10.1145/1242572.1242603; Zhou D, 2006, P 15 INT C WORLD WID, P173, DOI 10.1145/1135777.1135807	60	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2010	5	1							3	10.1145/1870096.1870099		49	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WP	WOS:000208170400003	
J	Liu, K; Terzi, E				Liu, Kun; Terzi, Evimaria			A Framework for Computing the Privacy Scores of Users in Online Social Networks	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Social networks; item-response theory; expectation maximization; maximum-likelihood estimation; information propagation		A large body of work has been devoted to address corporate-scale privacy concerns related to social networks. Most of this work focuses on how to share social networks owned by organizations without revealing the identities or the sensitive relationships of the users involved. Not much attention has been given to the privacy risk of users posed by their daily information-sharing activities. In this article, we approach the privacy issues raised in online social networks from the individual users' viewpoint: we propose a framework to compute the privacy score of a user. This score indicates the user's potential risk caused by his or her participation in the network. Our definition of privacy score satisfies the following intuitive properties: the more sensitive information a user discloses, the higher his or her privacy risk. Also, the more visible the disclosed information becomes in the network, the higher the privacy risk. We develop mathematical models to estimate both sensitivity and visibility of the information. We apply our methods to synthetic and real-world data and demonstrate their efficacy and practical utility.	[Terzi, Evimaria] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA; [Liu, Kun] Yahoo Labs, Santa Clara, CA 95054 USA	Terzi, E (reprint author), Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.	kyn@yahoo-inc.com; evimaria@cs.bu.edu					AHMAD O., 2006, ACM T KNOWLEDGE DISC, Patent No. U.S. 2006/0047605; BAKER F., 2004, ITEM RESPONSE THEORY; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Birnbaum A., 1968, STAT THEORIES MENTAL, P397; FANG L., 2010, P INT C WORLD WID WE; Gross R., 2005, P 2005 ACM WORKSH PR, P71, DOI 10.1145/1102199.1102214; Hay M., 2008, P VLDB ENDOWMENT, V1, P102; Kempe D, 2003, P 9 ACM SIGKDD INT C, P137; Kleinberg J., 2007, P 16 INT C WORLD WID, P181, DOI 10.1145/1242572.1242598; LEONARD A., 2004, YOU ARE WHO YOU KNOW; Liu K., 2008, P ACM SIGMOD INT C M, P93, DOI 10.1145/1376616.1376629; MAES P., 2005, P PERS WORKSH; Mislevy R. J., 1986, PC BILOG ITEM ANAL T; Owyang J, 2008, SOCIAL NETWORK STATS; Richardson M., 2003, P 2 INT SEM WEB C, P351; Ying X., 2008, P SIAM INT C DAT MIN, P739; Ypma TJ, 1995, SIAM REV, V37, P531, DOI 10.1137/1037125; Zhou B, 2008, PROC INT CONF DATA, P506, DOI 10.1109/ICDE.2008.4497459; [Anonymous], 2010, ACM Transactions on Knowledge Discovery from Data, V5, Patent No. 20060047605	19	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2010	5	1							6	10.1145/1870096.1870102		30	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WP	WOS:000208170400006	
J	Plangprasopchok, A; Lerman, K				Plangprasopchok, Anon; Lerman, Kristina			Modeling Social Annotation: A Bayesian Approach	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Collaborative tagging; probabilistic model; resource discovery; social annotation; social information processing		Collaborative tagging systems, such as Delicious, CiteULike, and others, allow users to annotate resources, for example, Web pages or scientific papers, with descriptive labels called tags. The social annotations contributed by thousands of users can potentially be used to infer categorical knowledge, classify documents, or recommend new relevant information. Traditional text inference methods do not make the best use of social annotation, since they do not take into account variations in individual users' perspectives and vocabulary. In a previous work, we introduced a simple probabilistic model that takes the interests of individual annotators into account in order to find hidden topics of annotated resources. Unfortunately, that approach had one major shortcoming: the number of topics and interests must be specified a priori. To address this drawback, we extend the model to a fully Bayesian framework, which offers a way to automatically estimate these numbers. In particular, the model allows the number of interests and topics to change as suggested by the structure of the data. We evaluate the proposed model in detail on the synthetic and real-world data by comparing its performance to Latent Dirichlet Allocation on the topic extraction task. For the latter evaluation, we apply the model to infer topics of Web resources from social annotations obtained from Delicious in order to discover new resources similar to a specified one. Our empirical results demonstrate that the proposed model is a promising method for exploiting social knowledge contained in user-generated annotations.	[Plangprasopchok, Anon] Natl Elect & Comp Technol Ctr, Klongluang 12120, Pathumthani, Thailand; [Lerman, Kristina] Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA	Plangprasopchok, A (reprint author), Natl Elect & Comp Technol Ctr, 112 Phahon Yothin Rd,Klong 1, Klongluang 12120, Pathumthani, Thailand.	anon.plangprasopchok@nectec.or.th; lerman@isi.edu			National Science Foundation [CMMI-0753124, IIS-0812677]	This material is based in part on work supported by the National Science Foundation under Grant Numbers CMMI-0753124 and IIS-0812677. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.	AMBITE J. L., 2009, P INT SEM WEB C, P17; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BUNTINE W., 2004, P ECML WORKSH STAT A; Buntine W., 1994, J ARTIFICIAL INTELLI, V2, P159; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; Giles C.L., 2008, P 17 INT C WORLD WID, P715, DOI DOI 10.1145/1367497.1367594; Gilks W., 1996, MARKOV CHAIN MONTE C; Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Hofmann T., 1999, P 15 C UNC ART INT U, P289; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Jin R, 2006, INFORM RETRIEVAL, V9, P357, DOI 10.1007/s10791-006-4651-1; LERMAN K., 2007, P AAAI WORKSH INT WE; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; MARLIN B., 2004, THESIS U TORONTO TOR; McCallum A, 2007, J ARTIF INTELL RES, V30, P249; Mika P, 2007, J WEB SEMANT, V5, P5, DOI 10.1016/j.websem.2006.11.002; Minka T. P., 2001, P 17 C UNC ART INT, P362; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Plangprasopchok A., 2007, P AAAI WORKSH INF IN; Popescul A, 2001, P 17 C UNC ART INT U, P437; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; Rattenbury T., 2007, P 30 ANN INT ACM SIG, P103, DOI 10.1145/1277741.1277762; RITTER C, 1992, J AM STAT ASSOC, V87, P861, DOI 10.2307/2290225; SAHU S. K., 1999, STAT COMPUT, V9, P9; SCHMITZ P., 2006, P WWW WORKSH COLL WE; Scott JP, 2000, P 20 C UNC ART INT; Steyvers Mark, 2006, LATENT SEMANTIC ANAL; Su Z, 2007, P 16 INT C WORLD WID, P943, DOI 10.1145/1242572.1242700; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Wu X., 2006, P 15 INT C WORLD WID, P417, DOI 10.1145/1135777.1135839	31	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2010	5	1							4	10.1145/1870096.1870100		32	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WP	WOS:000208170400004	
J	Sakurai, Y; Faloutsos, C; Papadimitriou, S				Sakurai, Yasushi; Faloutsos, Christos; Papadimitriou, Spiros			Fast Discovery of Group Lag Correlations in Streams	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Time-series; cross-correlation; data streams		The study of data streams has received considerable attention in various communities (theory, databases, data mining, networking), due to several important applications, such as network analysis, sensor monitoring, financial data analysis, and moving object tracking. Our goal in this article is to monitor multiple numerical streams and determine which pairs are correlated with lags, as well as the value of each such lag. Lag correlations and anticorrelations are frequent and very interesting in practice. For example, a decrease in interest rates typically precedes an increase in house sales by a few months; higher amounts of fluoride in drinking water may lead to fewer dental cavities some years later. Other lag settings include network analysis, sensor monitoring, financial data analysis, and tracking of moving objects. Such data streams are often correlated or anticorrelated, but with unknown lag. We propose BRAID, a method of detecting lag correlations among data streams. BRAID can handle data streams of semi-infinite length incrementally, quickly, and with small resource consumption. However, BRAID requires space and time quadratic on a number of streams k. We also propose ThinBRAID, which is even faster than BRAID, requiring O(k) space and time per time tick. Our theoretical analysis shows that BRAID/ThinBRAID can estimate lag correlations with little or, often, with no error. Our experiments on real and realistic data show that BRAID and ThinBRAID detect the correct lag perfectly most of the time (the largest relative error was about 1%), while they are significantly faster (up to 40,000 times) than the naive implementation.	[Sakurai, Yasushi] NTT Commun Sci Labs, Soura Ku, Kyoto 6190237, Japan; [Faloutsos, Christos] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Papadimitriou, Spiros] IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Sakurai, Y (reprint author), NTT Commun Sci Labs, Soura Ku, 2-4 Hikaridai, Kyoto 6190237, Japan.	yasushi.sakurai@acm.org; christos@cs.cmu.edu; spapadim@us.ibm.com			National Science Foundation [IIS-0083148, IIS-0113089, IIS-0209107, IIS-0205224, INT-0318547, SENSOR-0329549, EF-0331657, IIS-0326322, CNS-0433540]; Pennsylvania Infrastructure Technology Alliance (PTA) [22-901-001]; Intel; Northrop-Grumman Corporation	The work of C. Faloutsos was supported by the National Science Foundation under Grant Nos. IIS-0083148, IIS-0113089, IIS-0209107, IIS-0205224, INT-0318547, SENSOR-0329549, EF-0331657, IIS-0326322, and CNS-0433540, and by the Pennsylvania Infrastructure Technology Alliance (PTA) Grant No. 22-901-001. Additional funding was provided by Intel and Northrop-Grumman Corporation. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation, or other funding parties.	Abadi DJ, 2003, VLDB J, V12, P120, DOI 10.1007/s00778-003-0095-z; Achlioptas D., 2001, P ACM S PRINC DAT SY, P274, DOI 10.1145/375551.375608; Arasu A., 2002, P 21 ACM SIGACT SIGM, P221; Babcock B., 2003, P 2003 ACM SIGMOD IN, P253, DOI DOI 10.1145/872757.872789; Box G.E.P, 1994, TIME SERIES ANAL FOR; BRENT R. P., 2002, ALGORITHM MINIMIZATI; Cai Y., 2004, P ACM SIGMOD INT C M, P599, DOI 10.1145/1007568.1007636; Carney D., 2003, P INT C VER LARG DAT, P838, DOI 10.1016/B978-012722442-8/50079-3; Chandrasekaran S., 2003, P C INN DAT SYST RES; Chandrasekaran S., 2004, P 30 INT C VER LARG, P348, DOI 10.1016/B978-012088469-8/50033-4; Cole R., 2005, P 11 ACM SIGKDD INT, P743, DOI 10.1145/1081870.1081966; Considine J, 2004, PROC INT CONF DATA, P449, DOI 10.1109/ICDE.2004.1320018; Cormode G., 2008, P ACM SIGACT SIGMOD, P89, DOI 10.1145/1376916.1376930; Cranor Chuck, 2003, P 2003 ACM SIGMOD IN, P647; Das A., 2003, P 2003 ACM SIGMOD IN, P40; David BL., 1993, P 4 INT C FDN DAT OR, P69; Dobra A., 2002, P 2002 ACM SIGMOD IN, P61; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347107; ELFEKY M. G., 2005, P IEEE INT C DAT MIN, P138; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; Ganti V, 2002, SIGKDD EXPLORATIONS, V3, P1, DOI [10.1145/507515.507517, DOI 10.1145/507515.507517]; GEHRKE J., 2001, P 2001 ACM SIGMOD IN, P13, DOI 10.1145/375663.375665; Gilbert A. C., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Gilbert A. C., 2002, P 34 ACM S THEOR COM, P152; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; Han J., 2000, DATA MINING CONCEPTS; Hulten G., 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; Indyk P., 2000, P 26 INT C VER LARG, P363; Johnson W., 1984, CONT MATH, V26, P189; Koper K.D., 2001, EOS, V82, P45; Guha S, 2002, PROC INT CONF DATA, P567, DOI 10.1109/ICDE.2002.994775; Lathi BP, 1998, SIGNAL PROCESSING LI; Madden S., 2002, Proceedings Fourth IEEE Workshop on Mobile Computing Systems and Applications, DOI 10.1109/MCSA.2002.1017485; MATIAS Y., 2000, P 26 INT C VER LARG, P101; Moler C. B., 1977, COMPUTER METHODS MAT; Moon Y., 2002, P INT C MAN DAT ACM, P382; MOTWANI R., 2003, P C INN DAT SYST RES; Papadimitriou S., 2003, P INT C VER LARG DAT, P560, DOI 10.1016/B978-012722442-8/50056-2; Papadimitriou S., 2005, P 31 INT C VER LARG, P697; Patel P., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183925; Sakurai Y., 2005, P ACM SIGMOD BALT MA, P599, DOI DOI 10.1145/1066157.1066226; Sakurai Y., 2005, PODS, P326, DOI 10.1145/1065167.1065210; Sakurai Y., 2000, P 26 INT C VER LARG, P516; Tao Y., 2004, P ACM SIGMOD INT C M, P611, DOI 10.1145/1007568.1007637; Tatbul N, 2003, P 29 INT C VER LARG, P309, DOI 10.1016/B978-012722442-8/50035-5; VLACHOS M., 2006, P INT C EXT DAT TECH; Wang MZ, 2002, PROC INT CONF DATA, P507; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Yi B.-K., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839383; Zhu Y., 2002, P 28 INT C VER LARG, P358, DOI DOI 10.1016/B978-155860869-6/50039-1; Zhu Y., 2003, P 9 ACM SIGKDD INT C, P336; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680	52	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2010	5	1							5	10.1145/1870096.1870101		43	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WP	WOS:000208170400005	
J	Tang, J; Yao, LM; Zhang, D; Zhang, J				Tang, Jie; Yao, Limin; Zhang, Duo; Zhang, Jing			A Combination Approach to Web User Profiling	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						User profiling; information extraction; name disambiguation; topic modeling; social network; text mining		In this article, we study the problem of Web user profiling, which is aimed at finding, extracting, and fusing the "semantic"-based user profile from the Web. Previously, Web user profiling was often undertaken by creating a list of keywords for the user, which is (sometimes even highly) insufficient for main applications. This article formalizes the profiling problem as several subtasks: profile extraction, profile integration, and user interest discovery. We propose a combination approach to deal with the profiling tasks. Specifically, we employ a classification model to identify relevant documents for a user from the Web and propose a Tree-Structured Conditional Random Fields (TCRF) to extract the profile information from the identified documents; we propose a unified probabilistic model to deal with the name ambiguity problem (several users with the same name) when integrating the profile information extracted from different sources; finally, we use a probabilistic topic model to model the extracted user profiles, and construct the user interest model. Experimental results on an online system show that the combination approach to different profiling tasks clearly outperforms several baseline methods. The extracted profiles have been applied to expert finding, an important application on the Web. Experiments show that the accuracy of expert finding can be improved (ranging from +6% to +26% in terms of MAP) by taking advantage of the profiles.	[Tang, Jie; Zhang, Jing] Tsinghua Univ, Beijing 100084, Peoples R China; [Yao, Limin] Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA; [Zhang, Duo] Univ Illinois, Siebel Ctr Comp Sci 1125, Urbana, IL 61801 USA	Tang, J (reprint author), Tsinghua Univ, Room 1-308,FIT Bldg, Beijing 100084, Peoples R China.	jietang@tsinghua.edu.cn; lmyao@cs.umass.edu; dzhang22@illinois.edu; zhangjing@keg.cs.tsinghua.edu.cn			Natural Science Foundation of China [60703059, 60973102]; Chinese National Key Foundation Research [60933013]; National High-Tech RD Program [2009AA01Z138]; Chinese Young Faculty [20070003093]	This work is supported by the Natural Science Foundation of China (No. 60703059, No. 60973102), Chinese National Key Foundation Research (No. 60933013), National High-Tech R&D Program (No. 2009AA01Z138), and Chinese Young Faculty Research Fund (No. 20070003093).	Alani H, 2003, IEEE INTELL SYST, V18, P14, DOI 10.1109/MIS.2003.1179189; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Baeza-Yates R. A., 1999, MODERN INFORM RETRIE; Balog K., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148181; Basu S., 2004, P 10 ACM SIGKDD INT, P59, DOI 10.1145/1014052.1014062; Bekkerman R., 2005, P 14 INT C WORLD WID, P463, DOI 10.1145/1060745.1060813; BHATTACHARYA I., 2007, ACM T KNOWL DISCOV D, V1, P1; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BRICKLEY D., 2004, NAMESPACE DOCUMENT; Buckley C., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009000; Cai D., 2007, UIUCDCSR20072856; CAO Y., 2003, MSRTR200333; CHAN P. K., 1999, P WORKSH WEB US AN U; CIRAVEGNA F., 2001, P IJCAI WORKSH AD TE; Cohn D., 2003, TR20031892 CORN U; Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CRASWELL N., 2005, TREC 2005 C NOT, P199; Cunningham H, 2002, P 40 ANN M ASS COMP; Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; GUAN G., 2005, P 43 ANN M ASS COMP, P499, DOI 10.3115/1219840.1219902; Hammersley J. M., 1971, MARKOV FIELD F UNPUB; Han H., 2004, Proceedings of the Fourth ACM/IEEE Joint Conference on Digital Libraries (IEEE Cat. No.04TH8766), DOI 10.1145/996350.996419; Han H, 2005, PROCEEDINGS OF THE 5TH ACM/IEEE JOINT CONFERENCE ON DIGITAL LIBRARIES, PROCEEDINGS, P334, DOI 10.1145/1065385.1065462; Hofmann T., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312649; HUANG C., 2000, P 38 ANN M ASS COMP, P3; JORDAN M. I., 2004, 653 U CAL DEP STAT; KRISTJANSSON T., 2004, P AAAI; Lafferty J, 2001, P 18 INT C MACH LEAR, P282; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; McCallum A., 2000, P 17 INT C MACH LEAR, P591; MCCALLUM A., 1999, P AAAI WORKSH TEXT L; McCallum A, 2007, J ARTIF INTELL RES, V30, P249; Michelson M, 2007, INT J DOC ANAL RECOG, V10, P211, DOI 10.1007/s10032-007-0052-2; Mimno D., 2007, P 13 ACM SIGKDD INT, P500, DOI 10.1145/1281192.1281247; Minka T., 2003, ESTIMATING DIRICHLET; NEWMAN D., 2007, P 19 NEUR INF PROC S; On B, 2007, P SIAM INT C DAT MIN; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Radev DR, 2009, P 10 ACM SIGKDD INT, DOI DOI 10.1145/1014052.1014087; Sarawagi S., 2004, P 17 NEUR INF PROC S, P1185; Scott JP, 2000, P 20 C UNC ART INT; Sha F., 2003, P C N AM CHAPT ASS C, P134; Soltysiak SJ, 1998, BT TECHNOL J, V16, P110, DOI 10.1023/A:1009690117684; Sproat R., 2001, Computer Speech and Language, V15, DOI 10.1006/csla.2001.0169; Tan Y., 2006, P ACM IEEE JOINT C D, P314, DOI 10.1145/1141753.1141826; Tang J., 2008, P 14 ACM SIGKDD INT, P990, DOI 10.1145/1401890.1402008; TANG J., 2006, P 5 INT SEM WEB C IS, P640; TANG J, 2008, P IEEE INT C DAT MIN, P1055; TANG J., 2007, P 45 ANN M ASS COMP, P689; TANG J., 2007, EMERGING TECHNOLOGIE; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Wainwright M. J., 2001, P 13 NEUR INF PROC S, P1001; Yedidia JS, 2001, ADV NEUR IN, V13, P689; Yin X., 2007, P IEEE 23 INT C DAT, P1242; Zhai C., 2001, P 24 ANN INT ACM SIG, P334, DOI [10.1145/383952.384019, DOI 10.1145/383952.384019]; Zhang D., 2007, P 16 C INF KNOWL MAN, P1019, DOI 10.1145/1321440.1321600; Zhang J., 2007, P 12 DAT SYST C ADV, P1066; Zhu J., 2006, P 12 ACM SIGKDD INT, P494, DOI 10.1145/1150402.1150457	60	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2010	5	1							2	10.1145/1870096.1870098		44	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WP	WOS:000208170400002	
J	Zhong, N; Piatetsky-Shapiro, G; Yao, YY; Yu, PS				Zhong, Ning; Piatetsky-Shapiro, Gregory; Yao, Yiyu; Yu, Philip S.			ACM TKDD Special Issue on Knowledge Discovery for Web Intelligence	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Editorial Material																	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	DEC	2010	5	1							1	10.1145/1870096.1870097		1	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WP	WOS:000208170400001	
J	Ruiz, C; Spiliopoulou, M; Menasalvas, E				Ruiz, Carlos; Spiliopoulou, Myra; Menasalvas, Ernestina			Density-based semi-supervised clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Constraint-based clustering; Semi-supervised clustering; Density-based clustering; Instance level constraints; Constraints		Semi-supervised clustering methods guide the data partitioning and grouping process by exploiting background knowledge, among else in the form of constraints. In this study, we propose a semi-supervised density-based clustering method. Density-based algorithms are traditionally used in applications, where the anticipated groups are expected to assume non-spherical shapes and/or differ in cardinality or density. Many such applications, among else those on GIS, lend themselves to constraint-based clustering, because there is a priori knowledge on the group membership of some records. In fact, constraints might be the only way to prevent the formation of clusters that do not conform to the applications' semantics. For example, geographical objects, e.g. houses, separated by a borderline or a river may not be assigned to the same cluster, independently of their physical proximity. We first provide an overview of constraint-based clustering for different families of clustering algorithms. Then, we concentrate on the density-based algorithms' family and select the algorithm DBSCAN, which we enhance with Must-Link and Cannot-Link constraints. Our enhancement is seamless: we allow DBSCAN to build temporary clusters, which we then split or merge according to the constraints. Our experiments on synthetic and real datasets show that our approach improves the performance of the algorithm.	[Spiliopoulou, Myra] Otto VonGuericke Univ Magdegurg, Fac Comp Sci, D-39016 Magdeburg, Germany; [Ruiz, Carlos; Menasalvas, Ernestina] Univ Politecn Madrid, Fac Informat, Madrid, Spain	Spiliopoulou, M (reprint author), Otto VonGuericke Univ Magdegurg, Fac Comp Sci, D-39016 Magdeburg, Germany.	cruiz@cettico.fi.upm.es; myra@iti.cs.uni-magdeburg.de; emenasalvas@fi.upm.es			Spanish ministry [TIN2008-05924]	Part of Ernestina Menasalvas work was funded by the Spanish ministry under project grant TIN2008-05924.	Agrawal R., 1998, SIGMOD 98, P94; ANAND SS, 1995, C INF KNOWL MAN CIKM, P37; Angiulli F, 2004, LECT NOTES COMPUT SC, V3177, P203; Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; BASU S, 2004, SDM 04; Basu S., 2006, P 10 EUR C PRINC PRA, P115; Basu S, 2004, ICML 04, P11, DOI [10.1145/1015330.1015360, DOI 10.1145/1015330.1015360]; Basu S., 2004, KDD 04, P59; Basu S., 2002, INT C MACH LEARN, P19; Bennett K.P., 2000, MSRTR200065; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bilenko M., 2003, KDD 03, P39; Cohn D., 2003, TR20031892 CORN U; DAVIDSON I, 2005, SIAM 05; DAVIDSON I, 2006, KDD 06; DAVIDSON I, 2005, ICDM 05; Davidson I., 2005, P 9 EUR C PRINC PRAC, P59, DOI DOI 10.1007/11564126_11; Davis Ian D, 2007, Cancer Immun, V7, P13; Demiriz A., 1999, ARTIFICIAL NEURAL NE, P809; ESTER M, 1996, KDD 96; Guha S, 1998, SIGMOD, P73; GUNOPULOS D, 2006, SIAM 06; HALKIDI M, 2005, ICDM 2005, P637; Han JW, 1999, COMPUTER, V32, P46; Hinneburg A., 1998, KNOWLEDGE DISCOVERY, P58; KARYPIS G, 1999, IEEE COMPUT, V32, P68, DOI DOI 10.1109/2.781637; Klein D., 2002, ICML, P307; KOPANAS I, 2002, LECT NOTES COMPUTER, V2308; Newman D.J., 1998, UCI REPOSITORY MACHI; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; RUIZ C, 2007, AWIC 07; RUIZ C, 2006, IWKDDS 06, P117; RUIZ C, 2007, RSFDGRC 07; RUIZ C, 2009, DS 0R97 IN PRESS; SHEIKHOLESLAMI G, 1998, VLDB 98, P428; VAZIRGIANNIS M, 2003, LNAI SERIES; Wagstaff K, 2000, ICML, P1103; WAGSTAFF K, 2002, THESIS U CORNELL; Wagstaff K., 2001, ICML, P577; Wang WL, 1997, ELEC SOC S, V97, P186; Xing E. P., 2002, ADV NEURAL INFORMATI, V15, P505; Zaiane OR, 2002, IDEAS 2002: INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P214; ZAIANE OR, 2002, IEEE INT C DAT MIN, P737	43	4	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2010	21	3					345	370		10.1007/s10618-009-0157-y		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	640HG	WOS:000281039800001	
J	Wu, TY; Chen, YG; Han, JW				Wu, Tianyi; Chen, Yuguo; Han, Jiawei			Re-examination of interestingness measures in pattern mining: a unified framework	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Association rules; Frequent pattern; Interestingness measure; Null-invariant measure; Generalized mean	ASSOCIATIONS	Numerous interestingness measures have been proposed in statistics and data mining to assess object relationships. This is especially important in recent studies of association or correlation pattern mining. However, it is still not clear whether there is any intrinsic relationship among many proposed measures, and which one is truly effective at gauging object relationships in large data sets. Recent studies have identified a critical property, null-(transaction) invariance, for measuring associations among events in large data sets, but many measures do not have this property. In this study, we re-examine a set of null-invariant interestingness measures and find that they can be expressed as the generalized mathematical mean, leading to a total ordering of them. Such a unified framework provides insights into the underlying philosophy of the measures and helps us understand and select the proper measure for different applications. Moreover, we propose a new measure called Imbalance Ratio to gauge the degree of skewness of a data set. We also discuss the efficient computation of interesting patterns of different null-invariant interestingness measures by proposing an algorithm, GAMiner, which complements previous studies. Experimental evaluation verifies the effectiveness of the unified framework and shows that GAMiner speeds up the state-of-the-art algorithm by an order of magnitude.	[Wu, Tianyi; Han, Jiawei] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Chen, Yuguo] Univ Illinois, Dept Stat, Champaign, IL 61820 USA	Wu, TY (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	twu5@uiuc.edu; yuguo@uiuc.edu; hanj@cs.uiuc.edu			U.S. National Science Foundation [NSF IIS-08-42769, NSF IIS-09-05215, NSF DMS-05-03981, NSF DMS-08-06175]	The work was supported in part by the U.S. National Science Foundation NSF IIS-08-42769, NSF IIS-09-05215, NSF DMS-05-03981, and NSF DMS-08-06175. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding agencies. This paper is a major-value added extension of the paper: Tianyi Wu, Yuguo Chen and Jiawei Han, Association Mining in Large Databases: A Re-Examination of Its Measures", Proc. 2007 Int. Conf. on Principles and Practice of Knowledge Discovery in Databases (PKDD'07), Warsaw, Poland, Sept. 2007, pp. 621-628.	Agrawal R., 1994, P 20 INT C VER LARG, P487; BRADSHAW J, 2001, YAMS YET ANOTHER MEA; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Grahne G., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839450; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1; He B., 2004, P 10 ACM SIGKDD INT, P148, DOI 10.1145/1014052.1014071; Hilderman R., 2001, KNOWLEDGE DISCOVERY; KACHIGAN SK, 1991, MULTIVARIATE STAT AN; Kulczynski S., 1927, B INT ACAD POL SC SB, VII, P57; Lee Y.-K., 2003, P 2003 INT C DAT MIN, P581, DOI DOI 10.1109/ICDM.2003.1250982; Omiecinski ER, 2003, IEEE T KNOWL DATA EN, V15, P57, DOI 10.1109/TKDE.2003.1161582; POLYA G, 1988, INEQUALITIES; Savasere A, 1998, PROC INT CONF DATA, P494, DOI 10.1109/ICDE.1998.655812; Tan P., 2002, P 8 ACM SIGKDD INT C, P32, DOI DOI 10.1145/775047.775053; Wu T., 2007, P 11 EUR C PRINC PRA, P621; Xiong H., 2004, P 10 ACM SIGKDD INT, P334, DOI 10.1145/1014052.1014090	17	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2010	21	3					371	397		10.1007/s10618-009-0161-2		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	640HG	WOS:000281039800002	
J	Baruque, B; Corchado, E				Baruque, Bruno; Corchado, Emilio			A weighted voting summarization of SOM ensembles	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Data visualization; Topology preservation; Ensemble learning; Self-organizing maps	NEURAL-NETWORKS; VISUALIZATION	Weighted Voting Superposition is a novel summarization algorithm for the results of an ensemble of Self-Organizing Maps. Its principal aim is to achieve the lowest topographic error in the map in order to obtain the best possible visualization of the internal structure of the data sets under study. This is done by means of a weighted voting process between the neurons of the ensemble maps in order to determine the characteristics of the neurons in the resulting map. The algorithm is applied in this case to the most widely known topology preserving mapping architecture: the Self- Organizing Map. A comparison is made between the novel fusion algorithm presented in this work and other previously devised fusion algorithms, along with a new variation of those algorithms, called Ordered Similarity. Although a practical example of the new algorithm was introduced in an earlier work, a rigorous description and analysis is presented here for the first time by comparing the performance of the aforementioned algorithms in relation to three well-known data sets (Iris, Wisconsin Breast Cancer and Wine) obtained from Internet repositories. The results show how this novel fusion algorithm outperforms the other fusion algorithms, yielding better visualization results for ensemble summarization of maps.	[Corchado, Emilio] Univ Salamanca, Dept Informat & Automat, E-37008 Salamanca, Spain; [Baruque, Bruno] Univ Burgos, Dept Civil Engn, Burgos, Spain	Corchado, E (reprint author), Univ Salamanca, Dept Informat & Automat, Plaza Merced S-N, E-37008 Salamanca, Spain.	bbaruque@ubu.es; escorchado@ubu.es			Junta of Castilla and Leon [BU006A08]	This research has been partially supported through projects of the Junta of Castilla and Leon BU006A08; Business intelligent for production within the framework of the technological Institute of astilla y Leon and investment and services agency (ADE); project of the Spanish Ministry of Education and Innovation CIT-020000-2008-2. The authors would also like to thank the vehicle interior manufacturer, Grupo Antolin Ingenieria S. A., within the framework of the project MAGNO2008 - 1028.-CENIT Project funded by the Spanish Ministry.	ASUNCION A., 2007, UCI MACHINE LEARNING; AURENHAMMER F, 2000, HDB COMPUTATIONAL GE, V5, P201; Baruque B, 2008, LECT NOTES COMPUT SC, V5326, P491, DOI 10.1007/978-3-540-88906-9_62; Baruque B, 2007, LECT NOTES COMPUT SC, V4507, P235; Blackmore J., 1993, P IEEE INT C NEUR NE, V1, P450; BRASSARD G, 1995, FUNDAMENTALS ALGORIT, P524; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Corchado E, 2007, LECT NOTES COMPUT SC, V4668, P339; Freund Y., 1996, INT C MACH LEARN, P148; Ruta D., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.008; GEORGAKIS A, 2005, INT C AD KNOWL REPR, P6; Gianniotis N, 2008, IEEE T NEURAL NETWOR, V19, P1468, DOI 10.1109/TNN.2008.2001000; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; JOHANSSON U, 2006, INT C COMP INT MOD C, V2, P103; Kaski S., 1996, LECT NOTES COMPUTER, V1112, P809; Kiviluoto K., 1996, IEEE INT C NEUR NETW, V1, P294; KOHONEN T, 1977, NEUROSCIENCE, V2, P1065, DOI 10.1016/0306-4522(77)90129-4; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; Kohonen T, 1995, SERIES INFORM SCI, V30; Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105; Kuncheva L. I., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00093-3; Kuncheva LI, 2004, COMBINING PATTERN CL; Lampinen J., 1992, Journal of Mathematical Imaging and Vision, V2, DOI 10.1007/BF00118594; LING CX, 1995, NEUROCOMPUTING, V8, P341, DOI 10.1016/0925-2312(95)00050-G; Heskes T, 1997, ADV NEUR IN, V9, P466; Patra JC, 2006, IEEE IJCNN, P4429; PETRAKIEVA L, 2003, COMPUTING INFORM SYS, P1352; POLANI D, 2003, SELF ORGANIZING NEUR, V16, P13; POZLBAUER G, 2004, 5 WORKSH DAT AN WDA, P67; SAAVEDRA C, 2007, LECT NOTES COMPUTER, P227; Schwenk H, 2000, NEURAL COMPUT, V12, P1869, DOI 10.1162/089976600300015178; Vesanto J, 2003, P WORKSH SELF ORG MA, P11; Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7	33	19	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2010	21	3					398	426		10.1007/s10618-009-0160-3		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	640HG	WOS:000281039800003	
J	Bae, E; Bailey, J; Dong, GZ				Bae, Eric; Bailey, James; Dong, Guozhu			A clustering comparison measure using density profiles and its application to the discovery of alternate clusterings	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Clustering; Cluster analysis; Clustering comparison; Clustering similarity; Alternate clusterings; Alternate clustering algorithms	DISSIMILARITY; PARTITIONS	Data clustering is a fundamental and very popular method of data analysis. Its subjective nature, however, means that different clustering algorithms or different parameter settings can produce widely varying and sometimes conflicting results. This has led to the use of clustering comparison measures to quantify the degree of similarity between alternative clusterings. Existing measures, though, can be limited in their ability to assess similarity and sometimes generate unintuitive results. They also cannot be applied to compare clusterings which contain different data points, an activity which is important for scenarios such as data stream analysis. In this paper, we introduce a new clustering similarity measure, known as ADCO, which aims to address some limitations of existing measures, by allowing greater flexibility of comparison via the use of density profiles to characterize a clustering. In particular, it adopts a 'data mining style' philosophy to clustering comparison, whereby two clusterings are considered to be more similar, if they are likely to give rise to similar types of prediction models. Furthermore, we show that this new measure can be applied as a highly effective objective function within a new algorithm, known as MAXIMUS, for generating alternate clusterings.	[Bae, Eric; Bailey, James] Univ Melbourne, Dept Comp Sci & Software Engn, NICTA Victoria Lab, Melbourne, Vic, Australia; [Dong, Guozhu] Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA	Bailey, J (reprint author), Univ Melbourne, Dept Comp Sci & Software Engn, NICTA Victoria Lab, Melbourne, Vic, Australia.	kheb@csse.unimelb.edu.au; jbailey@csse.unimelb.edu.au; guozhu.dong@wright.edu			National ICT Australia (NICTA); Australian Government, Department of Broadband, Communications	This work was partially supported by National ICT Australia (NICTA). NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program.	Aggarwal C., 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1; Aggarwal C.C., 2003, P 2003 ACM SIGMOD IN, P575; BACARDIT J, 2004, GECCO, V2, P726; Bae E, 2006, IEEE DATA MINING, P53; Bae E, 2006, LECT NOTES COMPUT SC, V4304, P342; Caruana R, 2006, IEEE DATA MINING, P107; Chmielewski M. R., 1996, INT J APPROX REASON, P294; DAVIDSON I, 2005, SIAM INT C DAT MIN; Davidson I., 2005, P 9 EUR C PRINC PRAC, P59, DOI DOI 10.1007/11564126_11; DAVIDSON I, 2006, C ART INT; Dunn J. C., 1973, Journal of Cybernetics, V3; EKMAN G, 1963, PSYCHOMETRIKA, V28, P33, DOI 10.1007/BF02289545; Estivill-Castro V., 2002, SIGKDD EXPLORATIONS, V4, P65; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Fred ALN, 2003, PROC CVPR IEEE, P128; GONDEK D, 2003, IEEE INT C DAT MIN W, P36; Gondek D. ., 2004, ICDM 04, P75; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; Gregson R., 1975, PSYCHOMETRICS SIMILA; Groenen P., 1997, MODERN MULTIDIMENSIO; HAMERS L, 1989, INFORM PROCESS MANAG, V25, P315, DOI 10.1016/0306-4573(89)90048-4; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Karypis G, 1997, DES AUT CON, P526; Kendall K., 1999, THESIS MIT; Kuhn H., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109; Larsen B, 1999, P 5 ACM SIGKDD INT C, DOI 10.1145/312129.312186; Meil M., 2005, P 22 INT C MACH LEAR, P577, DOI 10.1145/1102351.1102424; MEILA M, 2003, COMP CLUSTERINGS TEC; MEILA M, 2002, COMP CLUSTERINGS; Meila M., 2005, INT C MACH LEARN; Mirkin B., 2005, CLUSTERING DATA MINI; Rand W.M., 1971, J AM STAT ASSOC, V66, P622; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; RATANAMAHATANA C, 2003, DATA MINING; Richeldi M., 1995, P 8 EUR C MACH LEARN, P335; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Streilein WW, 2001, P WORKSH STAT MACH L; Sung A. H., 2003, Proceedings 2003 Symposium on Applications and the Internet, DOI 10.1109/SAINT.2003.1183050; Theodoridis S., 1999, PATTERN RECOGNITION; TISHBY N, 1999, ALL C COMM CONTR COM, P368; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237; Topchy A. P., 2004, P 4 IEEE INT C DAT M, P225; Topchy AP, 2004, INT C DAT MIN, P225; TORGO L, 1998, P 6 IB AM C AI, P160; WALLACE DL, 1983, J AM STAT ASSOC, V78, P569, DOI 10.2307/2288118; Yang Y, 2009, MACH LEARN, V74, P39, DOI 10.1007/s10994-008-5083-5; Zhou D., 2005, P 22 INT C MACH LEAR, P1028, DOI 10.1145/1102351.1102481; 2007, MIXED INTEGER LINEAR	49	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2010	21	3					427	471		10.1007/s10618-009-0164-z		45	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	640HG	WOS:000281039800004	
J	Horvath, T; Ramon, J; Wrobel, S				Horvath, Tamas; Ramon, Jan; Wrobel, Stefan			Frequent subgraph mining in outerplanar graphs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph mining; Frequent pattern mining; Algorithms; Complexity; Applications	ISOMORPHISM	In recent years there has been an increased interest in frequent pattern discovery in large databases of graph structured objects. While the frequent connected subgraph mining problem for tree datasets can be solved in incremental polynomial time, it becomes intractable for arbitrary graph databases. Existing approaches have therefore resorted to various heuristic strategies and restrictions of the search space, but have not identified a practically relevant tractable graph class beyond trees. In this paper, we consider the class of outerplanar graphs, a strict generalization of trees, develop a frequent subgraph mining algorithm for outerplanar graphs, and show that it works in incremental polynomial time for the practically relevant subclass of well-behaved outerplanar graphs, i.e., which have only polynomially many simple cycles. We evaluate the algorithm empirically on chemo- and bioinformatics applications.	[Horvath, Tamas; Wrobel, Stefan] Univ Bonn, Dept Comp Sci 3, D-5300 Bonn, Germany; [Ramon, Jan] Katholieke Univ Leuven, Dept Comp Sci, Leuven, Belgium; [Horvath, Tamas; Wrobel, Stefan] Fraunhofer Inst IAIS, Schloss Birlinghoven, Sankt Augustin, Germany	Horvath, T (reprint author), Univ Bonn, Dept Comp Sci 3, D-5300 Bonn, Germany.	tamas.horvath@iais.fraunhofer.de; jan.ramon@cs.kuleuven.be; stefan.wrobel@iais.fraunhofer.de	Ramon, Jan/E-8956-2010	Ramon, Jan/0000-0002-0558-7176	Fund for Scientific Research Flanders (FWO); German Science Foundation (DFG) [GA 1615/1-1]	This work was partially supported by the Fund for Scientific Research Flanders (FWO), the K.U. Leuven and ERC Starting Grant 240186 'MiGraNT', and by the German Science Foundation (DFG) under the reference number 'GA 1615/1-1'.	Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bodlaender HL, 1998, THEOR COMPUT SCI, V209, P1, DOI 10.1016/S0304-3975(97)00228-4; Borgelt C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183885; CALDERS T, 2008, P 2008 IEEE INT C DA, P73; CHARTRAN.G, 1967, ANN I H POINCARE B, V3, P433; Chi Y, 2005, KNOWL INF SYST, V8, P203, DOI 10.1007/s10115-004-0180-7; Chi Y, 2005, FUND INFORM, V66, P161; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Deshpande M, 2005, IEEE T KNOWL DATA EN, V17, P1036, DOI 10.1109/TKDE.2005.127; DIESTEL R, 2005, GRAPH THEORY, V3; Feder T, 1998, J COMB THEORY B, V72, P236, DOI 10.1006/jctb.1997.1812; Garey M. R., 1979, COMPUTERS INTRACTABI; HARARY F., 1971, GRAPH THEORY; HE H, 2007, P 2007 INT C DAT MIN, P163; HEDETNIEMI S, 1971, J COMB THEORY, V10, P12; HOPCROFT JE, 1974, P 6 ANN ACM S THEOR, P172, DOI 10.1145/800119.803896; Horvath T, 2007, LECT NOTES ARTIF INT, V4455, P244; Horvath T, 2001, MACH LEARN, V43, P53, DOI 10.1023/A:1007668716498; Horvath T, 2005, LECT NOTES ARTIF INT, V3518, P791; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; JOHNSON DS, 1988, INFORM PROCESS LETT, V27, P119, DOI 10.1016/0020-0190(88)90065-8; KOONTZ WLG, 1980, AT&T TECH J, V59, P277; Kramer S., 2001, P 7 ACM SIGKDD INT C, P136, DOI 10.1145/502512.502533; Kuramochi M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989534; LEYDOLD J, 1998, ELECT J COMB, V5; LINGAS A, 1989, THEOR COMPUT SCI, V63, P295, DOI 10.1016/0304-3975(89)90011-X; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Matula D, 1978, ANN DISCRETE MATH, V2, P91, DOI 10.1016/S0167-5060(08)70324-8; Maunz A, 2009, P 15 ACM SIGKDD INT, P617, DOI 10.1145/1557019.1557089; MITCHELL SL, 1979, INFORM PROCESS LETT, V9, P229, DOI 10.1016/0020-0190(79)90075-9; Nijssen S, 2004, P 10 ACM SIGKDD INT, P647, DOI 10.1145/1014052.1014134; NISHI T, 1986, IEEE T CIRCUITS SYST, V33, P381, DOI 10.1109/TCS.1986.1085934; Ramon J, 2009, J MACH LEARN RES, V10, P907; Schietgat L, 2008, LECT NOTES COMPUT SC, V5255, P197, DOI 10.1007/978-3-540-88411-8_20; SCHIETGAT L, 2009, P 7 INT WORKSH MIN L, P1; Shamir R, 1999, J ALGORITHM, V33, P267, DOI 10.1006/jagm.1999.1044; SYSLO MM, 1982, THEOR COMPUT SCI, V17, P91, DOI 10.1016/0304-3975(82)90133-5; Read R. C., 1975, Networks, V5; Tarjan R., 1972, SIAM Journal on Computing, V1, DOI 10.1137/0201010; TONG H, 2007, P 13 ACM SIGKDD INT, P737, DOI 10.1145/1281192.1281271; Yan X., 2002, P 2002 IEEE INT C DA, P721	41	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2010	21	3					472	508		10.1007/s10618-009-0162-1		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	640HG	WOS:000281039800005	
J	Niennattrakul, V; Ruengronghirunya, P; Ratanamahatana, CA				Niennattrakul, Vit; Ruengronghirunya, Pongsakorn; Ratanamahatana, Chotirat Ann			Exact indexing for massive time series databases under time warping distance	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Time series; Indexing; Dynamic time warping	REPRESENTATION; RECOGNITION; SIMILARITY; ALGORITHM	Among many existing distance measures for time series data, Dynamic Time Warping (DTW) distance has been recognized as one of the most accurate and suitable distance measures due to its flexibility in sequence alignment. However, DTW distance calculation is computationally intensive. Especially in very large time series databases, sequential scan through the entire database is definitely impractical, even with random access that exploits some index structures since high dimensionality of time series data incurs extremely high I/O cost. More specifically, a sequential structure consumes high CPU but low I/O costs, while an index structure requires low CPU but high I/O costs. In this work, we therefore propose a novel indexed sequential structure called TWIST (Time Warping in Indexed Sequential sTructure) which benefits from both sequential access and index structure. When a query sequence is issued, TWIST calculates lower bounding distances between a group of candidate sequences and the query sequence, and then identifies the data access order in advance, hence reducing a great number of both sequential and random accesses. Impressively, our indexed sequential structure achieves significant speedup in a querying process. In addition, our method shows superiority over existing rival methods in terms of query processing time, number of page accesses, and storage requirement with no false dismissal guaranteed.	[Niennattrakul, Vit; Ruengronghirunya, Pongsakorn; Ratanamahatana, Chotirat Ann] Chulalongkorn Univ, Dept Comp Engn, Bangkok, Thailand	Ratanamahatana, CA (reprint author), Chulalongkorn Univ, Dept Comp Engn, Bangkok, Thailand.	g49vnn@cp.eng.chula.ac.th; g51prn@cp.eng.chula.ac.th; ann@cp.eng.chula.ac.th			Thailand Research Fund [MRG5080246]; Thailand Research Fund given through the Royal Golden Jubilee Ph.D. Program [PHD/0141/2549]; Chulalongkorn University Graduate Scholarship; 90th Anniversary of Chulalongkorn University Fund (Ratchadaphiseksomphot Endowment Fund)	This research is partially supported by the Thailand Research Fund (Grant No. MRG5080246), the Thailand Research Fund given through the Royal Golden Jubilee Ph.D. Program (PHD/0141/2549 to V. Niennattrakul and C. A. Ratanamahatana), the Chulalongkorn University Graduate Scholarship to Commemorate the 72nd Anniversary of His Majesty King Bhumibol Adulyadej, and the 90th Anniversary of Chulalongkorn University Fund (Ratchadaphiseksomphot Endowment Fund).	ASSENT I, 2008, P 11 INT C EXT DAT B, P252; Bagnall A, 2006, DATA MIN KNOWL DISC, V13, P11, DOI 10.1007/s10618-005-0028-0; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; BERNDT DJ, 1994, 1994 AAAI WORKSH KNO, P359; Chu S., 2002, P 2 SIAM INT C DAT M; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; DING H, 2008, P 34 INT C VER LARG; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; Faloutsos C., 2007, P IEEE 23 INT C DAT, P1046, DOI DOI 10.1109/ICDE.2007.368963; Guttman A., 1984, P ACM SIGMOD INT C M, P47; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; Keogh E., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011669; Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9; Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347153; Kim SW, 2001, PROC INT CONF DATA, P607; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Loh WK, 2004, DATA MIN KNOWL DISC, V9, P5, DOI 10.1023/B:DAMI.0000026902.89522.a3; MacQueen J.B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Moody G. B., 1983, COMPUT CARDIOL, V10, P227; Ratanamahatana CA, 2004, SIAM PROC S, P11; Ratanamahatana CA, 2005, SIAM PROC S, P506; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Sakurai Y., 2005, PODS, P326, DOI 10.1145/1065167.1065210; Vlachos M, 2006, DATA MIN KNOWL DISC, V12, P1, DOI 10.1007/s10618-005-0016-4; Wang XZ, 2006, DATA MIN KNOWL DISC, V13, P335, DOI 10.1007/s10618-005-0039-x; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Yi BK, 1998, PROC INT CONF DATA, P201; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Zhu Y., 2003, P ACM SIGMOD INT C M, P181	31	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2010	21	3					509	541		10.1007/s10618-010-0165-y		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	640HG	WOS:000281039800006	
J	Creamer, G; Stolfo, S				Creamer, German; Stolfo, Sal			A link mining algorithm for earnings forecast and trading (vol 18, pg 419, 2009)	DATA MINING AND KNOWLEDGE DISCOVERY			English	Correction									[Creamer, German; Stolfo, Sal] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; [Creamer, German] Pontificia Univ Catolica Peru, Ctr Catolica, Lima, Peru	Creamer, G (reprint author), Columbia Univ, Dept Comp Sci, 500 W 120 St, New York, NY 10027 USA.	ggc14@columbia.edu; sal@cs.columbia.edu	Creamer, German/B-8794-2012				Creamer G, 2009, DATA MIN KNOWL DISC, V18, P419, DOI 10.1007/s10618-008-0124-z	1	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2010	21	3					542	542		10.1007/s10618-010-0166-x		1	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	640HG	WOS:000281039800007	
J	Becchetti, L; Boldi, P; Castillo, C; Gionis, A				Becchetti, Luca; Boldi, Paolo; Castillo, Carlos; Gionis, Aristides			Efficient Algorithms for Large-Scale Local Triangle Counting	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Clustering coefficient; massive-graph computing; Web computing; social networks		In this article, we study the problem of approximate local triangle counting in large graphs. Namely, given a large graph G = (V, E) we want to estimate as accurately as possible the number of triangles incident to every node v. V in the graph. We consider the question both for undirected and directed graphs. The problem of computing the global number of triangles in a graph has been considered before, but to our knowledge this is the first contribution that addresses the problem of approximate local triangle counting with a focus on the efficiency issues arising in massive graphs and that also considers the directed case. The distribution of the local number of triangles and the related local clustering coefficient can be used in many interesting applications. For example, we show that the measures we compute can help detect the presence of spamming activity in large-scale Web graphs, as well as to provide useful features for content quality assessment in social networks. For computing the local number of triangles (undirected and directed), we propose two approximation algorithms, which are based on the idea of min-wise independent permutations [Broder et al. 1998]. Our algorithms operate in a semi-streaming fashion, using O(|V|) space in main memory and performing O(log |V|) sequential scans over the edges of the graph. The first algorithm we describe in this article also uses O(|E|) space of external memory during computation, while the second algorithm uses only main memory. We present the theoretical analysis as well as experimental results on large graphs, demonstrating the practical efficiency of our approach.	[Becchetti, Luca] Sapienza Univ Roma, Rome, Italy; [Boldi, Paolo] Univ Milan, Milan, Italy; [Castillo, Carlos; Gionis, Aristides] Yahoo Res, Barcelona, Spain	Becchetti, L (reprint author), Sapienza Univ Roma, Rome, Italy.	Luca.Becchetti@dis.uniroma1.it; boldi@dsi.unimi.it; chato@chato.cl; gionis@yahoo-inc.com	Gionis, Aristides/G-2225-2013	Gionis, Aristides/0000-0002-5211-112X	EU; MIUR FIRB [N. RBIN047MH9]; PRIN; MIUR; Yahoo! Faculty Grant	L. Becchetti was partially supported by EU Integrated Project AEOLUS, by MIUR FIRB project N. RBIN047MH9, and by PRIN 2008 research Project COGENT. P. Boldi was partially supported by the MIUR PRIN projects "Mathematical aspects and forthcoming applications of automata and formal languages", by the EU Integrated Project DELIS, and by a Yahoo! Faculty Grant.	Alon N, 1997, ALGORITHMICA, V17, P209, DOI 10.1007/BF02523189; Bar-Yossef Z, 2002, SIAM PROC S, P623; Batagelj V, 2001, SOC NETWORKS, V23, P237, DOI 10.1016/S0378-8733(01)00035-1; Becchetti L., 2008, P 14 ACM SIGKDD INT, P16, DOI 10.1145/1401890.1401898; BOHMAN T., 2000, ELECT J COMBINAT, P7; Boldi P., 2004, P 13 INT WORLD WID W, P595, DOI 10.1145/988672.988752; BORDINO I., 2008, P IEEE INT C DAT MIN, P737; Boykin PO, 2005, COMPUTER, V38, P61, DOI 10.1109/MC.2005.132; Broder A. Z., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276781; BRODER A. Z., 1997, P 6 INT WORLD WID WE, P1157; Broder A. Z., 1998, Proceedings. Compression and Complexity of SEQUENCES 1997 (Cat. No.97TB100171), DOI 10.1109/SEQUEN.1997.666900; BRODER A. Z., 2000, P 11 ANN S COMB PATT, P1; BURIOL L. S., 2007, P 15 ANN EUR S ALG, P618; Castillo C., 2006, SIGIR Forum, V40, DOI 10.1145/1189702.1189703; Castillo C., 2007, P 30 ANN INT ACM SIG, P423, DOI 10.1145/1277741.1277814; COPPERSMITH D, 1990, J SYMB COMPUT, V9, P251, DOI 10.1016/S0747-7171(08)80013-2; DEGRAAF M, 1992, DISCRETE MATH, V110, P279, DOI 10.1016/0012-365X(92)90719-V; Demetrescu C, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P714, DOI 10.1145/1109557.1109635; Eckmann JP, 2002, P NATL ACAD SCI USA, V99, P5825, DOI 10.1073/pnas.032093399; FEIGENBAUM J., 2004, P 31 INT C AUT LANG, P207; Fetterly D., 2004, P 7 INT WORKSH WEB D, P1, DOI 10.1145/1017074.1017077; Fogaras D., 2005, P 14 INT C WORLD WID, P641, DOI 10.1145/1060745.1060839; Gibson D., 2005, P 31 INT C VER LARG, P721; Gulli A., 2005, P 14 INT C WORLD WID, P902; Haveliwala T., 1999, EFFICIENT COMPUTATIO; HENZINGER M. R., 1999, DIMACS SERIES DISCRE, P107; Holme P, 2004, SOC NETWORKS, V26, P155, DOI 10.1016/j.socnet.2004.01.077; Indyk P, 1999, PROCEEDINGS OF THE TENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P454; ITAI A, 1978, SIAM J COMPUT, V7, P413, DOI 10.1137/0207033; Jeh G., 2002, KDD 02, P538, DOI DOI 10.1145/775047.775126; KUMAR R, 1999, COMPUTER NETWORKS, V31, P11; KUMAR R., 2004, P 15 ANN ACM SIAM S, P151; LATAPY M, 2006, ARXIVCS0609115V2; Latapy M, 2008, THEOR COMPUT SCI, V407, P458, DOI 10.1016/j.tcs.2008.07.017; Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI 10.1145/1081870.1081893; MITZENMACHER M., 2005, PROBABILITY COMPUTIN; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; SCHANK T., 2005, P 4 INT WORKSH EXP E; SOHLER C., 2006, PODS 06, P253, DOI 10.1145/1142351.1142388; Tsourakakis CE, 2008, IEEE DATA MINING, P608, DOI 10.1109/ICDM.2008.72; Vitter JS, 2001, ACM COMPUT SURV, V33, P209, DOI 10.1145/384192.384193; Welser H., 2007, J SOC STRUCT, V8	42	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	3							13	10.1145/1839490.1839494		28	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WF	WOS:000208169400004	
J	Chen, JL; Xiao, KL				Chen, Jinlin; Xiao, Keli			BISC: A Bitmap Itemset Support Counting Approach for Efficient Frequent Itemset Mining	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Data mining algorithms; frequent itemset mining; association rule mining		The performance of a depth-first frequent itemset (FI) miming algorithm is closely related to the total number of recursions. In previous approaches this is mainly decided by the total number of FIs, which results in poor performance when a large number of FIs are involved. To solve this problem, a three-strategy adaptive algorithm, bitmap itemset support counting (BISC), is presented. The core strategy, BISC1, is used in the innermost steps of the recursion. For a database D with only s frequent items, a depth-first approach need up to s levels of recursions to detect all the FIs (up to 2(s)). BISC1 completely replaces these recursions with a special summation that directly calculates the supports of all the possible 2s candidate itemsets. With BISC1 the run-time is entirely independent of the database after one database scan, and the per-candidate cost is only s. To offset the exponential growth of cost (both time and space) with BISC1 as s increases, a second strategy, BISC2, is introduced to effectively double the acceptable range of s. BISC2 divides an itemset into prefix and suffix and improves the performance by pruning all the itemsets with infrequent prefixes. If the total number of frequent items in D is high, the classic database projection strategy is used. In this case for the first s items a single run of BISC (1 or 2) is applied. For each of the remaining items, a projected database is created and the mining process proceeds recursively. To achieve optimal performance, BISC adaptively decides which strategy to use based on the dataset and minimum support. Experiments show that BISC outperforms previous approaches in all the datasets tested. Even though this does not guarantee that BISC will always perform the best, the result is impressive given the fact that most existing algorithms are only efficient in some types of datasets. The memory usage of BISC is also comparable to those of other algorithms.	[Chen, Jinlin] CUNY Queens Coll, Dept Comp Sci, Flushing, NY 11367 USA; [Xiao, Keli] Rutgers State Univ, Rutgers Business Sch, Newark, NJ 07102 USA	Chen, JL (reprint author), CUNY Queens Coll, Dept Comp Sci, Flushing, NY 11367 USA.	jchen@cs.qc.edu; kelixiao@pegasus.rutgers.edu			PSC-CUNY [62274-40]; Queens College	This research was supported in part by a PSC-CUNY Research Grant (62274-40) and a Queens College Research Enhancement Grant.	AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; ASAI T., 2003, P ICDM WORKSH FREQ I; Bodon F., 2003, P IEEE ICDM WORKSH F; Bodon F., 2006, SURVEY FREQUENT ITEM; BORGELT C., 2004, P IEEE ICDM WORKSH F; Brin S., 1997, SIGMOD Record, V26; Ceglar A., 2006, ACM COMPUT SURV, V38, P2; Gouda K., 2003, P 9 ACM SIGKDD INT C, P326; Grahne G., 2003, P ICDM WORKSH FREQ I; Grahne G, 2005, IEEE T KNOWL DATA EN, V17, P1347, DOI 10.1109/TKDE.2005.166; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Liu G., 2003, P ICDM WORKSH FREQ I; ORLANDO S., 2003, P IEEE ICDM WORKSH F; ORLANDO S., 2001, P INT C DAT WAR KNOW, P71; Orlando S., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183921; OZEL S. A, 2001, P 10 TURK S ART INT, P257; Park JS, 1997, IEEE T KNOWL DATA EN, V9, P813; Pei J, 2001, P IEEE INT C DAT MIN, P441; PIETRACAPRINA A, 2003, P ICDM WORKSH FREQ I; RACZ B, 2004, P IEEE ICDM WORKSH F; Racz Balazs, 2005, P ACM SIGKDD WORSKH, P36, DOI 10.1145/1133905.1133911; SCHMIDT-THIEME L, 2004, P IEEE ICDM WORKSH F; Song MJ, 2006, IEEE T KNOWL DATA EN, V18, P472, DOI 10.1109/TKDE.2006.1599386; Uno T., 2005, P 1 INT WORKSH OP SO, P77, DOI 10.1145/1133905.1133916; Uno T., 2004, P IEEE ICDM WORKSH F; Wang K, 2002, P 6 PAC AR C KNOWL D, P334; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	29	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	3							12	10.1145/1839490.1839493		37	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WF	WOS:000208169400003	
J	Chen, Y; Pavlov, D; Canny, JF				Chen, Ye; Pavlov, Dmitry; Canny, John F.			Behavioral Targeting: The Art of Scaling Up Simple Algorithms	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Design; Experimentation; Performance; Distributed data mining; high-performance and terascale computing; parallel data mining; statistical methods; user modeling; behavioral targeting; generalized linear model; nonnegative matrix factorization; large-scale; grid computing; Hadoop; MapReduce		Behavioral targeting (BT) leverages historical user behavior to select the ads most relevant to users to display. The state-of-the-art of BT derives a linear Poisson regression model from fine-grained user behavioral data and predicts click-through rate (CTR) from user history. We designed and implemented a highly scalable and efficient solution to BT using Hadoop MapReduce framework. With our parallel algorithm and the resulting system, we can build above 450 BT-category models from the entire Yahoo's user base within one day, the scale that one can not even imagine with prior systems. Moreover, our approach has yielded 20% CTR lift over the existing production system by leveraging the well-grounded probabilistic model fitted from a much larger training dataset. Specifically, our major contributions include: (1) A MapReduce statistical learning algorithm and implementation that achieve optimal data parallelism, task parallelism, and load balance in spite of the typically skewed distribution of domain data. (2) An in-place feature vector generation algorithm with strict linear-time complexity O(n) regardless of the granularity of sliding target window. (3) An in-memory caching scheme that significantly reduces the number of disk IOs to make large-scale learning practical. (4) Highly efficient data structures and sparse representations of models and data to enable fast model updates. We believe that our work makes significant contributions to solving large-scale machine learning problems of industrial relevance in general. Finally, we report comprehensive experimental results, using industrial proprietary codebase and datasets.	[Chen, Ye] Microsoft Corp, Mountain View, CA 94043 USA; [Canny, John F.] Univ Calif Berkeley, Berkeley, CA 94720 USA	Chen, Y (reprint author), Microsoft Corp, 1065 Ave, Mountain View, CA 94043 USA.	yec@microsoft.com					AGARWAL S., 2004, VU.S. Patent, Patent No. [10/818,925, 11394374]; ANDERSEN D., 2008, P NIPS WORKSH PAR IM; Broder A., 2007, P 30 ANN INT ACM SIG, P559, DOI 10.1145/1277741.1277837; Cameron A.C., 1998, REGRESSION ANAL COUN; CANNY J., 2007, VU.S. Patent Application, Patent No. [11/770,413, 12351749]; Canny J., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009016; CHANG E., 2008, P NIPS WORKSH SEARCH; CHEN Y., 2009, P C ADV NEUR INF PRO; Chen Y., 2009, P 15 ACM SIGKDD INT, P209, DOI DOI 10.1109/ICEC.2009.13; CHEN Y., 2009, P ACM C INF KNOWL MA, P1047, DOI 10.1145/1645953.1646087; CHEN Y., 2009, TORQUE, VU.S. Patent Application, Patent No. 12/351,749; CHUNG C. Y., 2006, U.S. Patent, Patent No. [111894,374, 11770413]; Ciaramita M, 2008, P 17 INT C WORLD WID, P227, DOI 10.1145/1367497.1367529; Dean J, 2008, COMMUN ACM, V51, P107, DOI 10.1145/1327452.1327492; Gibbs N. E., 1976, ACM Transactions on Mathematical Software, V2, DOI 10.1145/355705.355707; Lee DD, 2001, ADV NEUR IN, V13, P556; McCulloch CE, 2000, J AM STAT ASSOC, V95, P1320, DOI 10.2307/2669780; SPIELMAN D. A, 2004, J ACM, V51, P3; TORQUE, 2009, [No title captured], Patent No. 10813925	19	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	4							17	10.1145/1857947.1857949		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WK	WOS:000208169900002	
J	Cui, Y; Fern, XZ; Dy, JG				Cui, Ying; Fern, Xiaoli Z.; Dy, Jennifer G.			Learning Multiple Nonredundant Clusterings	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Nonredundant clustering; disparate clustering; diverse clustering; orthogonalization		Real-world applications often involve complex data that can be interpreted in many different ways. When clustering such data, there may exist multiple groupings that are reasonable and interesting from different perspectives. This is especially true for high-dimensional data, where different feature subspaces may reveal different structures of the data. However, traditional clustering is restricted to finding only one single clustering of the data. In this article, we propose a new clustering paradigm for exploratory data analysis: find all non-redundant clustering solutions of the data, where data points in the same cluster in one solution can belong to different clusters in other partitioning solutions. We present a framework to solve this problem and suggest two approaches within this framework: (1) orthogonal clustering, and (2) clustering in orthogonal subspaces. In essence, both approaches find alternative ways to partition the data by projecting it to a space that is orthogonal to the current solution. The first approach seeks orthogonality in the cluster space, while the second approach seeks orthogonality in the feature space. We study the relationship between the two approaches. We also combine our framework with techniques for automatically finding the number of clusters in the different solutions, and study stopping criteria for determining when all meaningful solutions are discovered. We test our framework on both synthetic and high-dimensional benchmark data sets, and the results show that indeed our approaches were able to discover varied clustering solutions that are interesting and meaningful.	[Cui, Ying] Yahoo Inc, Yahoo Labs, Sunnyvale, CA USA; [Fern, Xiaoli Z.] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA; [Dy, Jennifer G.] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA	Cui, Y (reprint author), Yahoo Inc, Yahoo Labs, Sunnyvale, CA USA.	ycui06@yahoo.com; xfern@eecs.oregonstate.edu; jdy@ece.neu.edu					Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BAE E, 2006, P 6 IEEE INT C DAT M, P53; BAY S. D, 1999, UCI KDD ACRH; Blake C, 1998, UCI REPOSITORY MACHI; CARUANA R., 2006, P 6 IEEE INT C DAT M, P107; CHECHIK G., 2003, P ADV NEUR INF PROC, P15; CMU, 1997, CMU 4 U WEBKB DAT; Ding C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183897; Domeniconi C, 2009, ACM T KNOWL DISCOV D, V2, P1; Domeniconi C, 2007, DATA MIN KNOWL DISC, V14, P63, DOI 10.1007/s10618-006-0060-8; Duda R., 1973, PATTERN CLASSIFICATI; Dy JG, 2004, J MACH LEARN RES, V5, P845; FERN X, 2007, P ICDM 2007, P133; FERN X. Z., 2004, P INT C MACH LEARN; Fern XZ, 2003, P 20 INT C MACH LEAR, P186; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; FORGY EW, 1965, BIOMETRICS, V21, P768; FRED A. L. N., 2006, P INT C PATT REC ICP, V1, P925; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Fukunaga K., 1990, STAT PATTERN RECOGNI; GONDEK D., 2005, P SIAM INT C DAT MIN; GONDEK D., 2005, THESIS BROWN U; GONDEK D., 2003, P 3 IEEE INT C DAT M; Gondek D., 2005, P 11 ACM SIGKDD INT, P70, DOI 10.1145/1081870.1081882; Gondek D, 2004, P 4 IEEE INT C DAT M; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jain P., 2008, P SIAM INT C DAT MIN, P858; Jolliffe I., 1986, PRINCIPAL COMPONENT; KOHONEN T., 1979, P IEEE INT C AC SPEE, P97; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; MacQueen J.B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487; OJA E, 1983, PATTERN RECOGN, V16, P421, DOI 10.1016/0031-3203(83)90064-X; Parsons L., 2004, SIGKDD EXPLORATIONS, V6, P90, DOI DOI 10.1145/1007730.1007731; PELLEG D, 2000, ICML, V17, P727; Roth V, 2002, P INT C COMP STAT, P123; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; STREHL, 2002, J MACHINE LEARNING R, V3, P583; STREHL A, 2002, J MACH LEARN RES, P583; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; WATANABE L, 1973, P 1 INT JOINT C PATT, P25	42	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	3							15	10.1145/1839490.1839496		32	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WF	WOS:000208169400006	
J	Deodhar, M; Ghosh, J				Deodhar, Meghana; Ghosh, Joydeep			SCOAL: A Framework for Simultaneous Co-Clustering and Learning from Complex Data	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Predictive modeling; co-clustering; classification; regression; dyadic data; multimodal data		For difficult classification or regression problems, practitioners often segment the data into relatively homogeneous groups and then build a predictive model for each group. This two-step procedure usually results in simpler, more interpretable and actionable models without any loss in accuracy. In this work, we consider problems such as predicting customer behavior across products, where the independent variables can be naturally partitioned into two sets, that is, the data is dyadic in nature. A pivoting operation now results in the dependent variable showing up as entries in a "customer by product" data matrix. We present the Simultaneous CO-clustering And Learning (SCOAL) framework, based on the key idea of interleaving co-clustering and construction of prediction models to iteratively improve both cluster assignment and fit of the models. This algorithm provably converges to a local minimum of a suitable cost function. The framework not only generalizes co-clustering and collaborative filtering to model-based co-clustering, but can also be viewed as simultaneous co-segmentation and classification or regression, which is typically better than independently clustering the data first and then building models. Moreover, it applies to a wide range of bi-modal or multimodal data, and can be easily specialized to address classification and regression problems. We demonstrate the effectiveness of our approach on both these problems through experimentation on a variety of datasets.	[Deodhar, Meghana; Ghosh, Joydeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA	Deodhar, M (reprint author), Univ Texas Austin, Dept Elect & Comp Engn, 1 Univ Stn, Austin, TX 78712 USA.	meghana@lans.ece.utexas.edu; ghosh@ece.utexas.edu			NSF [IIS-0713142, IIS-1016614]	This research was supported by NSF grants IIS-0713142 and IIS-1016614.	AGARWAL D, 2009, P 15 ACM SIGKDD INT, P19, DOI 10.1145/1557019.1557029; AGARWAL D, 2007, P INT C KNOWL DISC D, P26, DOI 10.1145/1281192.1281199; Banerjee A, 2007, J MACH LEARN RES, V8, P1919; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Baumann T., 1993, P 2 INT FOR APPL NEU, P407; Breiman L, 1984, CLASSIFICATION REGRE; Cheng Y., 2000, P 8 INT C INT SYST M, P93; DEODHAR M, 2007, IDEAL200708 DEP EL C; DEODHAR M., 2009, P INT C KNOWL DISC D, P249, DOI 10.1145/1557019.1557052; DHILLON I. S., 2004, P SIAM C DAT MIN SDM; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; DJUKANOVIC M, 1993, IEE PROC-C, V140, P311; Friedman J.H., 2008, FAST SPARSE REGRESSI; George T., 2005, P 5 IEEE INT C DAT M, P625, DOI DOI 10.1109/ICDM.2005.14; Gill P.E., 1981, PRACTICAL OPTIMIZATI; GROVER R, 1987, J MARKETING RES, V24, P139, DOI 10.2307/3151504; HAN I, 2001, P IT INT C SYST SCI, P3011; Hastie T., 2001, ELEMENTS STAT LEARNI; Herlocker J. L., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312682; Huber P.J., 1981, ROBUST STAT; JORDAN M., 1991, NEURAL COMPUT, V3, P79; Jornsten R, 2003, BIOINFORMATICS, V19, P1100, DOI 10.1093/bioinformatics/btg039; Lee W., 2003, P 20 INT C MACH LEAR; Liu X., 2005, BMC BIOINFORMATICS, V6, P76; LOKMIC L., 2000, P IEEE INNS ENNS INT, P6343; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; MCCULLAGH P, 1983, GEN LINEAR MODELS; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; RAMAMURTI V., 1998, P SPIE C APPL SCI CO, P24; ROSSI P, 1994, MARKET LETT, P57; SEETHARAMAN P., 1999, J MARKETING RES, P488; Sfetsos A, 2004, IEEE T SYST MAN CY A, V34, P399, DOI 10.1109/TSMCA.2003.822270; SHARKEY A., 1996, CONNECT SCI, V8, P299; WEDEL M, 1991, J MARKETING RES, V28, P385, DOI 10.2307/3172779; SULLIVAN M., 1998, MARKET LETT, P181; Wang Y., 1997, P 9 EUR C MACH LEARN, P128; ZHANG S., 2005, P INT NAT COMP ICNC, P1300	38	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	3							11	10.1145/1839490.1839492		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WF	WOS:000208169400002	
J	Liu, C; Guo, F; Faloutsos, C				Liu, Chao; Guo, Fan; Faloutsos, Christos			Bayesian Browsing Model: Exact Inference of Document Relevance from Petabyte-Scale Data	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Experimentation; Performance; Bayesian models; click log analysis; Web search		A fundamental challenge in utilizing Web search click data is to infer user-perceived relevance from the search log. Not only is the inference a difficult problem involving statistical reasonings but the bulky size, together with the ever-increasing nature, of the log data imposes extra requirements on scalability. In this paper, we propose the Bayesian Browsing Model (BBM), which performs exact inference of the document relevance, only requires a single pass of the data (i.e., the optimal scalability), and is shown effective. We present two sets of experiments to evaluate the model effectiveness and scalability. On the first set of over 50 million search instances of 1.1 million distinct queries, BBM outperforms the state-of-the-art competitor by 29.2% in log-likelihood while being 57 times faster. On the second click log set, spanning a quarter of petabyte, we showcase the scalability of BBM: we implemented it on a commercial MapReduce cluster, and it took only 3 hours to compute the relevance for 1.15 billion distinct query-URL pairs.	[Liu, Chao] Microsoft Res, Redmond, WA 98052 USA; [Guo, Fan; Faloutsos, Christos] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Liu, C (reprint author), Microsoft Res, Redmond, WA 98052 USA.	chaoliu@microsoft.com			National Science Foundation [DBI-0640543]	F. Guo and C. Faloutsos are supported in part by the National Science Foundation under Grant No. DBI-0640543. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	AGGARWAL G, 2008, P 4 INT WORKSH INT N, P621; Agichtein E., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148177; Agichtein E., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148175; Babcock B., 2002, P 21 ACM SIGACT SIGM, P1; Baeza-Yates R, 2005, LECT NOTES COMPUT SC, V3408, P7; Baeza-Yates R.A., 2004, P EDBT WORKSH CLUST, P588; Bilenko M., 2008, P 17 INT WORLD WID W, P51, DOI 10.1145/1367497.1367505; Bishop C. M., 2006, PATTERN RECOGNITION; Burges C., 2005, P 22 INT C MACH LEAR, P89, DOI 10.1145/1102351.1102363; Chapelle O., 2009, P 18 ACM C INF KNOWL, P621, DOI 10.1145/1645953.1646033; Chapelle O., 2009, P 18 INT C WORLD WID, P1, DOI 10.1145/1526709.1526711; CHENG H, 2010, P 3 ACM INT C WEB SE; Craswell N, 2008, P INT C WEB SEARCH W, P87, DOI 10.1145/1341531.1341545; Dean J., 2004, P 6 C S OP SYST DES, P10; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347107; Dupret G E, 2008, P 31 ANN INT ACM SIG, P331, DOI 10.1145/1390334.1390392; Gaber MM, 2005, SIGMOD RECORD, V34, P18, DOI 10.1145/1083784.1083789; Gao JF, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/1571941.1572003; GIANNELLA C, 2003, DATA MINING NEXT GEN; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; GUO F, 2009, P WORKSH WEB SEARCH, P88, DOI 10.1145/1507509.1507523; Guo F., 2009, P 18 INT C WORLD WID, P11, DOI 10.1145/1526709.1526712; Guo F., 2009, P 2 ACM INT C WEB SE, P124, DOI 10.1145/1498759.1498818; Joachims T., 2005, P 28 ANN INT ACM SIG, P154, DOI DOI 10.1145/1076034.1076063; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI DOI 10.1145/775047.775067; Joachims T, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1229179.1229181; KEMPE D, 2008, P 4 INT WORKSH INT N, P585; LIU C, 2009, P 18 ACM C INF KNOWL, P641, DOI 10.1145/1645953.1646035; Liu T. Y., 2009, FDN TRENDS INFORM RE, V3, P225, DOI [10.1561/1500000016, DOI 10.1561/1500000016]; Minka T. P., 2001, P 17 C UNC ART INT, P362; Murphy K., 2001, INTRO GRAPHICAL MODE; Radlinski F., 2005, P 11 ACM SIGKDD INT, P239, DOI 10.1145/1081870.1081899; RAGNO R AND, 2007, P 16 INT C WORLD WID, P521, DOI 10.1145/1242572.1242643; REUND Y, 2003, J MACH LEARN RES, V4, P933; SHOKOUHI M, 2008, P 30 EUR C INF RETR, P591; Silverstein C., 1999, SIGIR Forum, V33; Tsai M., 2007, P 30 ANN INT ACM SIG, P383, DOI 10.1145/1277741.1277808; Wainwright Martin J, 2008, Foundations and Trends in Machine Learning, V1, DOI 10.1561/2200000001; WANG K., 2009, P 15 ACM SIGKDD INT, P1355, DOI 10.1145/1557019.1557164; WEDIG S, 2006, P 12 ACM SIGKDD INT, P742, DOI 10.1145/1150402.1150497; Xue G, 2004, P 13 ACM INT C INF K, P118, DOI 10.1145/1031171.1031192; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085; Zhang Z., 2006, P 15 INT C WORLD WID, P1039, DOI 10.1145/1135777.1136004; ZHU ZA, 2010, P 3 ACM INT C WEB SE	44	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	4							19	10.1145/1857947.1857951		26	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WK	WOS:000208169900004	
J	Mohammed, N; Fung, BCM; Hung, PCK; Lee, CK				Mohammed, Noman; Fung, Benjamin C. M.; Hung, Patrick C. K.; Lee, Cheuk-Kwong			Centralized and Distributed Anonymization for High-Dimensional Healthcare Data	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Performance; Security; Privacy; anonymity; classification; healthcare		Sharing healthcare data has become a vital requirement in healthcare system management; however, inappropriate sharing and usage of healthcare data could threaten patients' privacy. In this article, we study the privacy concerns of sharing patient information between the Hong Kong Red Cross Blood Transfusion Service (BTS) and the public hospitals. We generalize their information and privacy requirements to the problems of centralized anonymization and distributed anonymization, and identify the major challenges that make traditional data anonymization methods not applicable. Furthermore, we propose a new privacy model called LKC-privacy to overcome the challenges and present two anonymization algorithms to achieve LKC-privacy in both the centralized and the distributed scenarios. Experiments on real-life data demonstrate that our anonymization algorithms can effectively retain the essential information in anonymous data for data analysis and is scalable for anonymizing large datasets.	[Mohammed, Noman; Fung, Benjamin C. M.] Concordia Univ, Montreal, PQ H3G 1M8, Canada; [Hung, Patrick C. K.] Univ Ontario Inst Technol, Oshawa, ON, Canada; [Lee, Cheuk-Kwong] Hong Kong Red Cross Blood Transfus Serv, Hong Kong, Hong Kong, Peoples R China	Mohammed, N (reprint author), Concordia Univ, Montreal, PQ H3G 1M8, Canada.	no_moham@cse.concordia.ca			Natural Sciences and Engineering Research Council of Canada [356065-2008]	The research is supported in part by Discovery Grants (356065-2008) and Canada Graduate Scholarship from the Natural Sciences and Engineering Research Council of Canada.	ADAM NR, 1989, ACM COMPUT SURV, V21, P515, DOI 10.1145/76894.76895; Aggarwal CC, 2008, ADV DATABASE SYST, V34, P1, DOI 10.1007/978-0-387-70992-5; AGGARWAL CC, 2005, P INT C VER LARG DAT; Agrawal R., 2000, P ACM SIGMOD INT C M; BAYARDO RJ, 2005, P INT C DAT ENG; BLUM A, 2005, P ACM SIGACT SIGMOD; CARLISLE DM, 2007, CALIFORNIA INPATIENT; CLIFTON C, 2002, P ACM SIGKDD INT C K, V4, P28; DINUR I, 2003, P ACM SIGACT SIGMOD; DU W, 2004, P SIAM INT C DAT MIN; DU W, 2001, THESIS PURDUE U W LA; DU W, 2002, P IEEE ICDM WORKSH P; Dwork C., 2006, P INT C AUT LANG PRO; DWORK C, 2006, P THEOR CRYPT C; FULLER WA, 1993, OFFICIAL STAT; Fung BCM, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1749603.1749605; Fung BCM, 2007, IEEE T KNOWL DATA EN, V19, P711, DOI 10.1109/TKDE.2007.1015; GARDNER J, 2009, DATA KNOWL ENG; GHINITA G, 2008, P INT C DAT ENG; IYENGAR VS, 2002, P ACM SIGKDD INT C K; JIANG W, 2006, J VLDB, V15, P316; JIANG W, 2005, P WORK C DAT APPL SE; JURCZYK P, 2009, P WORK C DAT APPL SE; JURCZYK P, 2008, P PHD WORKSH INF KNO; KIM J, 1995, P ASA SECT SURV RES; LeFevre K., 2006, P INT C DAT ENG; LEFEVRE K, 2008, ACM T DATAB SYST; MACHANAVAJJHALA A, 2007, ACM T KNOWL DISCOV D; MOHAMMED N, 2009, P ACM SIGKDD INT C K; MOHAMMED N., 2009, P INT C EXT DAT TECH; Newman D.J., 1998, UCI REPOSITORY MACHI; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SAMARATI P, 2001, IEEE T KNOWL DATA EN; Schneier B., 1995, APPL CRYPTOGRAPHY; Skowron A., 1992, HDB APPL ADV ROUGH S; SWEENEY L, 2002, INT J UNCERT FUZZ KN; TERROVITIS M, 2008, P INT C VER LARG DAT; Vaidya J., 2003, P ACM SIGKDD INT C K; Vaidya J., 2002, P ACM SIGKDD INT C K; Wang K, 2007, KNOWL INF SYST, V11, P345, DOI 10.1007/s10115-006-0035-5; WONG RCW, 2006, P ACM SIGKDD INT C K; Xiao X., 2006, P ACM SIGMOD INT C M; XIAO X., 2006, P INT C VER LARG DAT; XU Y, 2008, P ACM SIGKDD INT C K; YANG Z, 2005, P SIAM INT C DAT MIN; ZHAO K, 2005, P IEEE ICDM IEEE INT	46	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	4							18	10.1145/1857947.1857950		33	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WK	WOS:000208169900003	
J	Thomas, LT; Valluri, SR; Karlapalem, K				Thomas, Lini T.; Valluri, Satyanarayana R.; Karlapalem, Kamalakar			MARGIN: Maximal Frequent Subgraph Mining	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Graph mining; maximal frequent subgraph mining		The exponential number of possible subgraphs makes the problem of frequent subgraph mining a challenge. The set of maximal frequent subgraphs is much smaller to that of the set of frequent subgraphs providing ample scope for pruning. MARGIN is a maximal subgraph mining algorithm that moves among promising nodes of the search space along the "border" of the infrequent and frequent subgraphs. This drastically reduces the number of candidate patterns in the search space. The proof of correctness of the algorithm is presented. Experimental results validate the efficiency and utility of the technique proposed.	[Thomas, Lini T.; Valluri, Satyanarayana R.; Karlapalem, Kamalakar] Int Inst Informat Technol, Hyderabad 500032, Andhra Pradesh, India	Thomas, LT (reprint author), Int Inst Informat Technol, Hyderabad 500032, Andhra Pradesh, India.	lini@research.iiit.ac.in; satya@iiit.ac.in; kamal@iiit.ac.in					Borgelt C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183885; BUEHRER G., 2006, P IEEE INT C DAT MIN, P97; Burdick D, 2001, PROC INT CONF DATA, P443, DOI 10.1109/ICDE.2001.914857; CHENG J., 2007, P 13 ACM SIGKDD INT, P390, DOI 10.1145/1281192.1281236; Chi Y, 2005, IEEE T KNOWL DATA EN, V17, P190; Chi Y, 2004, P 16 INT C SCI STAT, P11, DOI DOI 10.1109/SSDBM.2004.41; Chi Y, 2005, FUND INFORM, V66, P161; COHEN M, 2004, P 9 INT WORKSH DAT M, P51, DOI 10.1145/1008694.1008702; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Dehaspe L, 1999, DATA MIN KNOWL DISC, V3, P7, DOI 10.1023/A:1009863704807; Gouda K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989514; GSPAN, GSPAN SOFTWARE; Gunopulos D, 2003, ACM T DATABASE SYST, V28, P140, DOI 10.1145/777943.777945; HASAN M., 2007, P 7 IEEE INT C DAT M, P153; He H., 2006, P 22 INT C DAT ENG I, P38; Huan J, 2003, P 3 IEEE INT C DAT M, P549; Huan J, 2004, P 10 ACM SIGKDD INT, P581, DOI 10.1145/1014052.1014123; INOKUCHI A., 2000, APRIORI BASED ALGORI, P13; Jiang H., 2007, P 23 INT C DAT ENG I, P566; Kaushik R, 2002, PROC INT CONF DATA, P129, DOI 10.1109/ICDE.2002.994703; KOYUTURK M., 2004, EFFICIENT ALGORITHM, P200; Kuramochi M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989534; Kuramochi M, 2005, DATA MIN KNOWL DISC, V11, P243, DOI 10.1007/s10618-005-0003-9; Kuramochi M., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183911; LIBGTOP, UN LIBGT UT; NIJSSEN S., 2004, P INT WORKSH GRAPH B; Pei J., 2000, P ACM SIGMOD WORKSH, P21; Pei J., 2002, P 2002 IEEE INT C DA, P378; SHEN X., 2002, MINING PROTEIN CONTA, P3; SRINIVASA S, 2004, FILTRATION BASED TEC; THOMAS L. T., 2006, P 6 INT C DAT MIN, P1097; TONG H, 2007, P 13 ACM SIGKDD INT, P737, DOI 10.1145/1281192.1281271; Vanetik N., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183988; WANG J, 2006, P IEEE INT C DAT MIN, P74; Wang J., 2006, P IEEE INT C DAT ENG, P73; Washio T., 2003, SIGKDD EXPLORATIONS, V5, P59; Williams D.W., 2007, P INT C DAT ENG, P976; YAHOO FINANCE, YAH FIN STOCK DAT; Yan X., 2002, P 2002 IEEE INT C DA, P721; YAN X, 2003, P 9 ACM SIGKDD INT C, P286; Yan X., 2004, GRAPH INDEXING FREQU, P335; Yang G., 2004, P 10 ACM SIGKDD INT, P344, DOI 10.1145/1014052.1014091; YOSHIDA K, 1994, APPL INTELL, V4, P297, DOI 10.1007/BF00872095; Zaki M. J., 2002, CHARM EFFICIENT ALGO; Zaki M. J., 2002, P 8 ACM SIGKDD INT C, P71, DOI DOI 10.1145/775047.775058; Zeng Z, 2006, P 12 ACM SIGKDD INT, P797, DOI [10.1145/1150402.1150506, DOI 10.1145/1150402.1150506]; Zhang S., 2007, P 23 INT C DAT ENG I, P966	47	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	3							10	10.1145/1839490.1839491		42	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WF	WOS:000208169400001	
J	Wang, W				Wang, Wei			TKDD Special Issue SIGKDD 2009	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Editorial Material									Univ N Carolina, Chapel Hill, NC 27515 USA	Wang, W (reprint author), Univ N Carolina, Chapel Hill, NC 27515 USA.	weiwang@cs.unc.edu						0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	4							16	10.1145/1857947.1857948		1	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WK	WOS:000208169900001	
J	Wu, MX; Jermaine, C; Ranka, S; Song, XY; Gums, J				Wu, Mingxi; Jermaine, Chris; Ranka, Sanjay; Song, Xiuyao; Gums, John			A Model-Agnostic Framework for Fast Spatial Anomaly Detection	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Performance; Anomaly detection; antibiotic resistance; likelihood ratio test; spatial anomaly		Given a spatial dataset placed on an n x n grid, our goal is to find the rectangular regions within which subsets of the dataset exhibit anomalous behavior. We develop algorithms that, given any user-supplied arbitrary likelihood function, conduct a likelihood ratio hypothesis test (LRT) over each rectangular region in the grid, rank all of the rectangles based on the computed LRT statistics, and return the top few most interesting rectangles. To speed this process, we develop methods to prune rectangles without computing their associated LRT statistics.	[Jermaine, Chris] Rice Univ, Houston, TX 77251 USA; [Ranka, Sanjay; Gums, John] Univ Florida, Gainesville, FL 32611 USA; [Song, Xiuyao] Yahoo Inc, Sunnyvale, CA USA		send2mingxiwu@gmail.com			National Science Foundation [0612170]	This work was performed primarily when M. Wu was a Ph.D. student at the University of Florida. This work was supported in part by the National Science Foundation under Grant No. 0612170.	Agarwal D, 2006, P 12 ACM SIGKDD INT, P24, DOI 10.1145/1150402.1150410; Agarwal D, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1137, DOI 10.1145/1109557.1109683; BRADLEY E, 2004, J AM STAT ASSOC, V99, P96; BRADLEY E, 2007, J AM STAT ASSOC, V102, P93; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dudoit S, 2003, STAT SCI, V18, P71, DOI 10.1214/ss/1056397487; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Kulldorff M, 1999, STAT IND TECHNOL, P303; Kulldorff M, 1997, COMMUN STAT-THEOR M, V26, P1481, DOI 10.1080/03610929708831995; LOLL JM, 2007, ANN APPL STAT, V1, P560; NEILL DB, 2003, P C NEUR INF PROC SY, P256; Neill D.B., 2004, P 10 ACM SIGKDD C KN, P256, DOI 10.1145/1014052.1014082; Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770; Wang W, 1997, P INT C VER LARG DAT, P186; Wilks SS, 1938, ANN MATH STAT, V9, P60, DOI 10.1214/aoms/1177732360; WU M, 2009, P ACM SIGKDD C KNOWL, P887, DOI 10.1145/1557019.1557116	16	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	4							20	10.1145/1857947.1857952		30	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WK	WOS:000208169900005	
J	Zhang, Y; Zhou, ZH				Zhang, Yin; Zhou, Zhi-Hua			Multilabel Dimensionality Reduction via Dependence Maximization	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Dimensionality reduction; multilabel learning		Multilabel learning deals with data associated with multiple labels simultaneously. Like other data mining and machine learning tasks, multilabel learning also suffers from the curse of dimensionality. Dimensionality reduction has been studied for many years, however, multilabel dimensionality reduction remains almost untouched. In this article, we propose amultilabel dimensionality reduction method, MDDM, with two kinds of projection strategies, attempting to project the original data into a lower-dimensional feature space maximizing the dependence between the original feature description and the associated class labels. Based on the Hilbert-Schmidt Independence Criterion, we derive a eigen-decomposition problem which enables the dimensionality reduction process to be efficient. Experiments validate the performance of MDDM.	[Zhang, Yin; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhang, Y (reprint author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhangyin@lamda.nju.edu.cn; zhouzh@lamda.nju.edu.cn			National Science Foundation of China [60635030, 60721002]; Jiangsu Science Foundation [BK2008018]; National Fundamental Research Program of China [2010CB327903]; Jiangsu 333 High-Level Talent Cultivation Program	This research was supported by the National Science Foundation of China (60635030, 60721002), the Jiangsu Science Foundation (BK2008018), the National Fundamental Research Program of China (2010CB327903), and the Jiangsu 333 High-Level Talent Cultivation Program.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Bach F. R., 2002, J MACHINE LEARNING R, V3, P1; Bakker B., 2003, J MACH LEARN RES, V4, P83; Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; Belkin M, 2002, ADV NEUR IN, V14, P585; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; CHEN J, 2008, P 14 ACM SIGKDD INT, P106, DOI 10.1145/1401890.1401908; Davis J. V., 2007, P 24 INT C MACH LEAR, P209, DOI DOI 10.1145/1273496.127352; Duygulu P., 2002, P EUR C COMP VIS, P97, DOI DOI 10.1007/3-540-47979-1_7; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Fisher RA, 1936, ANN EUGENIC, V7, P179; Ghamrawi N, 2005, P 14 ACM INT C INF K, P195, DOI 10.1145/1099554.1099591; Gretton A., 2005, P 16 INT C ALG LEARN, P63; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; He X., 2004, ADV NEURAL INFORM PR, V16; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Jolliffe I., 1986, PRINCIPAL COMPONENT; Kang F, 2006, P IEEE COMP SOC C CO, P1719; Kazawa H., 2005, ADV NEURAL INFORM PR, V17, P649; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Liu J., 2009, P 25 C UNC ART INT; Liu Y., 2006, P 21 NAT C ART INT, P421; Mccallum A., 1999, AAAI 99 WORKSH TEXT; Obozinski G., 2006, MULTITASK FEATURE SE; Qi G.-J., 2007, P 15 ACM INT C MULT, P17, DOI DOI 10.1145/1291233.1291245; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SONG L., 2008, ADV NEURAL INFORM PR, V20, P1385; Song L., 2007, P 24 INT C MACH LEAR, P823, DOI DOI 10.1145/1273496.1273600; Sun L., 2008, P 14 ACM SIGKDD INT, P668, DOI DOI 10.1145/1401890.1401971; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Thabtah F, 2004, P 4 IEEE INT C DAT M, P217; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Ueda N., 2003, ADV NEURAL INFORMATI, V15, P721; Wold H., 1985, ENCY STATISTICAL SCI, V6, P581; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; Yu K, 2005, P 28 ANN INT ACM SIG, P258, DOI 10.1145/1076034.1076080; Yu SP, 2006, IEEE T KNOWL DATA EN, V18, P1600, DOI 10.1109/TKDE.2006.194; Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang Y., 2008, P 23 AAAI C ART INT, P1503; Zhou Z.-H., 2007, ADV NEURAL INFORM PR, V19, P1609; Zhu S., 2005, P 28 ANN INT ACM SIG, P274, DOI 10.1145/1076034.1076082; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651	45	5	6	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	OCT	2010	4	3							14	10.1145/1839490.1839495		21	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20WF	WOS:000208169400005	
J	Balcazar, J; Bonchi, F; Gionis, A; Sebag, M				Balcazar, Jose L.; Bonchi, Francesco; Gionis, Aristides; Sebag, Michele			Guest editors' introduction: special issue of selected papers from ECML PKDD 2010	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Bonchi, Francesco; Gionis, Aristides] Yahoo Res Barcelona, Barcelona 08018, Spain; [Balcazar, Jose L.] Univ Cantabria Santander, Dept Matemat Estadist & Computac, Santander, Spain; [Sebag, Michele] Univ Paris 11, CNRS, LRI, TAO,INRIA, F-91405 Orsay, France	Bonchi, F (reprint author), Yahoo Res Barcelona, Avinguda Diagonal 177, Barcelona 08018, Spain.	joseluis.balcazar@unican.es; bonchi@yahoo-inc.com; gionis@yahoo-inc.corp; sebag@lri.fr	Gionis, Aristides/G-2225-2013	Gionis, Aristides/0000-0002-5211-112X				0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		221	223		10.1007/s10618-010-0192-8		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900001	
J	Chen, W; Liu, ZM; Sun, XR; Wang, YJ				Chen, Wei; Liu, Zhenming; Sun, Xiaorui; Wang, Yajun			Maximal exceptions with minimal descriptions	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 20-24, 2010	Barcelona, SPAIN	French Natl Inst Res Comp Sci & Control (INRIA), Pascal2 European Network Excellence, Nokia, Yahoo Labs, Google, KNIME, Aster data, Microsoft Res, HP, MODAP (Mobil, Data Min, & Privacy)		Overlapping communities; Community discovery; Social network analysis	COMMUNITY STRUCTURE; COAUTHORSHIP NETWORKS; SOCIETY	We introduce a new approach to Exceptional Model Mining. Our algorithm, called EMDM, is an iterative method that alternates between Exception Maximisation and Description Minimisation. As a result, it finds maximally exceptional models with minimal descriptions. Exceptional Model Mining was recently introduced by Leman et al. (Exceptional model mining 1-16, 2008) as a generalisation of Subgroup Discovery. Instead of considering a single target attribute, it allows for multiple 'model' attributes on which models are fitted. If the model for a subgroup is substantially different from the model for the complete database, it is regarded as an exceptional model. To measure exceptionality, we propose two information-theoretic measures. One is based on the Kullback-Leibler divergence, the other on Krimp. We show how compression can be used for exception maximisation with these measures, and how classification can be used for description minimisation. Experiments show that our approach efficiently identifies subgroups that are both exceptional and interesting.	[Chen, Wei; Wang, Yajun] Microsoft Res Asia, Beijing, Peoples R China; [Liu, Zhenming] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Sun, Xiaorui] Shanghai Jiao Tong Univ, Dept Comp Sci, Shanghai 200030, Peoples R China	Chen, W (reprint author), Microsoft Res Asia, Beijing, Peoples R China.	weic@microsoft.com; zliu@fas.harvard.edu; sunsirius@sjtu.edu.cn; yajunw@microsoft.com					Alos-Ferrer C, 2001, ECON LETT, V70, P165, DOI 10.1016/S0165-1765(00)00371-2; ATHEY S, 2006, THEORY COMMUNITY FOR; Brandes U., 2005, NETWORK ANAL METHODO; Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111; COPIC J, 2009, BE J THEOR EC, V9; Fjallstrom P.-O., 1998, LINKOPING ELECT ARTI, V3; Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104; GREGORY S, 2008, ECML PKDD; KASARDA JD, 1974, AM SOCIOL REV, V39, P328, DOI 10.2307/2094293; KOTLER P, 1971, J MARKETING, V35, P3, DOI 10.2307/1249783; Lancichinetti A, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.016118; Lusseau D, 2003, P ROY SOC B-BIOL SCI, V270, pS186, DOI 10.1098/rsbl.2003.0057; McKenzie-Mohr D., 1999, FOSTERING SUSTAINABL; MOLLOY M, 1995, RANDOM STRUCT ALGOR, V6, P161, DOI 10.1002/rsa.3240060204; Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103; Newman MEJ, 2004, LECT NOTES PHYS, V650, P337; Newman MEJ, 2004, P NATL ACAD SCI USA, V101, P5200, DOI 10.1073/pnas.0307545100; Nicosia V, 2009, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2009/03/P03024; Nisan N, 2007, ALGORITHMIC GAME THEORY, P1, DOI 10.1017/CBO9780511800481; Osborne M., 1994, COURSE GAME THEORY; Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607; SAMPSON RJ, 1989, AM J SOCIOL, V94, P774, DOI 10.1086/229068; Sarason S. B., 1974, PSYCHOL SENSE COMMUN; WHITE HC, 1976, AM J SOCIOL, V81, P730, DOI 10.1086/226141; ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452	25	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		224	240		10.1007/s10618-010-0187-5		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900002	
J	Mavroeidis, D				Mavroeidis, Dimitrios			Accelerating spectral clustering with partial supervision	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 20-24, 2010	Barcelona, SPAIN					Spectral Clustering is a popular learning paradigm that employs the eigenvectors and eigenvalues of an appropriate input matrix for approximating the clustering objective. Albeit its empirical success in diverse application areas, spectral clustering has been criticized for its inefficiency when dealing with large-size datasets. This is mainly due to the fact that the complexity of most eigenvector algorithms is cubic with respect to the number of instances and even memory efficient iterative eigensolvers (such as the Power Method) may converge very slowly to the desired eigenvector solutions. In this paper, inspired from the relevant work on Pagerank we propose a semi-supervised framework for spectral clustering that provably improves the efficiency of the Power Method for computing the Spectral Clustering solution. The proposed method is extremely suitable for large and sparse matrices, where it is demonstrated to converge to the eigenvector solution with just a few Power Method iterations. The proposed framework reveals a novel perspective of semi-supervised spectral methods and demonstrates that the efficiency of spectral clustering can be enhanced not only by data compression but also by introducing the appropriate supervised bias to the input Laplacian matrix. Apart from the efficiency gains, the proposed framework is also demonstrated to improve the quality of the derived cluster models.	Commiss European Communities, Joint Res Ctr, I-21020 Ispra, Italy	Mavroeidis, D (reprint author), Commiss European Communities, Joint Res Ctr, I-21020 Ispra, Italy.	dimitrios.mavroeidis@jrc.ec.europa.eu					Alzate C, 2009, IEEE IJCNN, P1338; BIE TD, 2004, LECT NOTES COMPUTER, P671; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Golub G.H., 1996, MATRIX COMPUTATIONS; Haveliwala T., 2003, 200320 STANF U; Kamvar SD, 2003, IJCAI, P561; KULIS B, 2005, ACM INT C P SERIES, V119, P457; Li ZG, 2009, PROC CVPR IEEE, P421; Lu Z., 2008, CVPR; Mavroeidis D, 2008, IEEE DATA MINING, P462, DOI 10.1109/ICDM.2008.120; Mavroeidis D, 2010, KNOWL INF SYST, V23, P243, DOI 10.1007/s10115-009-0215-1; Meila M., 2005, P 10 INT WORKSH ART; Stewart G. W., 1990, MATRIX PERTURBATION; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Yan DH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907; ZHOU D, 2003, SCHOLKOPF BNIPS	16	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		241	258		10.1007/s10618-010-0191-9		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900003	
J	van Leeuwen, M				van Leeuwen, Matthijs			A game-theoretic framework to identify overlapping communities in social networks	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 20-24, 2010	Barcelona, SPAIN			Exceptional Model Mining; Subgroup Discovery; Information theory		In this paper, we introduce a game-theoretic framework to address the community detection problem based on the structures of social networks. We formulate the dynamics of community formation as a strategic game called community formation game: Given an underlying social graph, we assume that each node is a selfish agent who selects communities to join or leave based on her own utility measurement. A community structure can be interpreted as an equilibrium of this game. We formulate the agents' utility by the combination of a gain function and a loss function. We allow each agent to select multiple communities, which naturally captures the concept of "overlapping communities". We propose a gain function based on the modularity concept introduced by Newman (Proc Natl Acad Sci 103(23):8577-8582, 2006), and a simple loss function that reflects the intrinsic costs incurred when people join the communities. We conduct extensive experiments under this framework, and our results show that our algorithm is effective in identifying overlapping communities, and are often better then other algorithms we evaluated especially when many people belong to multiple communities. To the best of our knowledge, this is the first time the community detection problem is addressed by a game-theoretic framework that considers community formation as the result of individual agents' rational behaviors.	Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands	van Leeuwen, M (reprint author), Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.	mleeuwen@cs.uu.nl					ANDRITSOS P, 2004, P EDBT 04, P124; ASUNCION A., 2007, UCI MACHINE LEARNING; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Garriga G. C., 2007, P ICDM 07, P481; Heikinheimo H, 2007, J BIOGEOGR, V34, P1053, DOI 10.1111/j.1365-2699.2006.01664.x; KLOSGEN W, 2002, SUBGROUP DISCOVERY; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LEEUWEN M, 2006, P ECML PKDD 06, P585; LEEUWEN M, 2009, P CIKM 09, P1147; LEMAN D, 2008, P ECML PKDD 08, V2, P1; Mitchell-Jones A.J., 1999, ATLAS EUROPEAN MAMMA; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Siebes A, 2006, P SIAM C DAT MIN, P393; Slonim N., 1999, P ADV NEUR INF PROC, P617; TSOUMAKAS G, 2010, MULAN JAVA LIB FORMU; UMEK L, 2009, P AIME 09, P265; WARNER HR, 1961, JAMA-J AM MED ASSOC, V177, P177; Witten IH, 2005, DATA MINING PRACTICA	18	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		259	276		10.1007/s10618-010-0186-6		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900004	
J	Calders, T; Verwer, S				Calders, Toon; Verwer, Sicco			Three naive Bayes approaches for discrimination-free classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 20-24, 2010	Barcelona, SPAIN			Discrimination-aware classification; Naive Bayes; Expectation maximization		In this paper, we investigate how to modify the naive Bayes classifier in order to perform classification that is restricted to be independent with respect to a given sensitive attribute. Such independency restrictions occur naturally when the decision process leading to the labels in the data-set was biased; e.g., due to gender or racial discrimination. This setting is motivated by many cases in which there exist laws that disallow a decision that is partly based on discrimination. Naive application of machine learning techniques would result in huge fines for companies. We present three approaches for making the naive Bayes classifier discrimination-free: (i) modifying the probability of the decision being positive, (ii) training one model for every sensitive attribute value and balancing them, and (iii) adding a latent variable to the Bayesian model that represents the unbiased label and optimizing the model parameters for likelihood using expectation maximization. We present experiments for the three approaches on both artificial and real-life data.	[Calders, Toon; Verwer, Sicco] Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands	Verwer, S (reprint author), Eindhoven Univ Technol, POB 513, NL-5600 MB Eindhoven, Netherlands.	s.verwer@tue.nl	Verwer, Sicco/D-1544-2012				CALDERS T, 2010, CONSTRUCTING DECISIO; CALDERS T, 2009, IEEE ICDM WORKSH DOM; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DUIVESTEIJN W, 2008, P ECML PKDD 08, P301; Elkan C, 2001, P 17 INT JOINT C ART, P973; KAMIRAN F, 2010, P BEN; KAMIRAN F, 2009, P IC409, pIC409; KOTLOWSKI W, 2007, P ECML PKDD 07; MARGINEANTU D, 1999, LEARNING DECISION TR; NIJSSEN S, 2007, P ACM SIGKDD; PEDRESCHI D, 2009, P SIAM DM; PEDRESCHI D, 2008, P ACM SIGKDD	12	15	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		277	292		10.1007/s10618-010-0190-x		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900005	
J	Tatti, N; Mampaey, M				Tatti, Nikolaj; Mampaey, Michael			Using background knowledge to rank itemsets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 20-24, 2010	Barcelona, SPAIN					Assessing the quality of discovered results is an important open problem in data mining. Such assessment is particularly vital when mining itemsets, since commonly many of the discovered patterns can be easily explained by background knowledge. The simplest approach to screen uninteresting patterns is to compare the observed frequency against the independence model. Since the parameters for the independence model are the column margins, we can view such screening as a way of using the column margins as background knowledge. In this paper we study techniques for more flexible approaches for infusing background knowledge. Namely, we show that we can efficiently use additional knowledge such as row margins, lazarus counts, and bounds of ones. We demonstrate that these statistics describe forms of data that occur in practice and have been studied in data mining. To infuse the information efficiently we use a maximum entropy approach. In its general setting, solving a maximum entropy model is infeasible, but we demonstrate that for our setting it can be solved in polynomial time. Experiments show that more sophisticated models fit the data better and that using more information improves the frequency prediction of itemsets.	[Tatti, Nikolaj; Mampaey, Michael] Univ Antwerp, Antwerp, Belgium	Tatti, N (reprint author), Univ Antwerp, Antwerp, Belgium.	nikolaj.tatti@ua.ac.be; michael.mampaey@ua.ac.be					AGGARWAL CC, 1998, PODS 98; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Brijs T., 1999, KNOWLEDGE DISCOVERY, P254; Brin S, 1997, SIGMOD, P265; Cowell R. G., 1999, PROBABILISTIC NETWOR; CSISZAR I, 1975, ANN PROBAB, V3, P146, DOI 10.1214/aop/1176996454; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Garriga G.C., 2008, P 14 ACM SIGKDD INT, P292, DOI 10.1145/1401890.1401929; Gionis A., 2007, TKDD, V1; Hanhijarvi S., 2009, P 15 ACM SIGKDD INT, P379, DOI 10.1145/1557019.1557065; JAROSZEWICZ S, 2005, KDD 05, P118; JAROSZEWICZ S, 2004, KDD 2004, P178; KOHAVI R, 2000, KDD CUP 2000 ORGANIZ; Mannila H, 2007, P 13 ACM SIGKDD INT, P489; Meo R, 2000, ACM T DATABASE SYST, V25, P380, DOI 10.1145/363951.363956; Myllykangas S, 2006, ONCOGENE, V25, P7324, DOI 10.1038/sj.onc.1209717; Rasch G., 1960, PROBABILISTIC MODELS; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Tatti N, 2008, KNOWL INF SYST, V17, P57, DOI 10.1007/s10115-008-0128-4; Tatti N, 2006, ACTA INFORM, V42, P617, DOI 10.1007/s00236-006-0009-9; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291	21	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		293	309		10.1007/s10618-010-0188-4		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900006	
J	Pietracaprina, A; Riondato, M; Upfal, E; Vandin, F				Pietracaprina, Andrea; Riondato, Matteo; Upfal, Eli; Vandin, Fabio			Mining top-K frequent itemsets through progressive sampling	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 20-24, 2010	Barcelona, SPAIN			Sampling; Top-K frequent itemsets; Frequent itemsets mining; Bloom filters; Progressive sampling	DATA STREAMS	We study the use of sampling for efficiently mining the top-K frequent itemsets of cardinality at most w. To this purpose, we define an approximation to the top-K frequent itemsets to be a family of itemsets which includes (resp., excludes) all very frequent (resp., very infrequent) itemsets, together with an estimate of these itemsets' frequencies with a bounded error. Our first result is an upper bound on the sample size which guarantees that the top-K frequent itemsets mined from a random sample of that size approximate the actual top-K frequent itemsets, with probability larger than a specified value. We show that the upper bound is asymptotically tight when w is constant. Our main algorithmic contribution is a progressive sampling approach, combined with suitable stopping conditions, which on appropriate inputs is able to extract approximate top-K frequent itemsets from samples whose sizes are smaller than the general upper bound. In order to test the stopping conditions, this approach maintains the frequency of all itemsets encountered, which is practical only for small w. However, we show how this problem can be mitigated by using a variation of Bloom filters. A number of experiments conducted on both synthetic and real benchmark datasets show that using samples substantially smaller than the original dataset (i.e., of size defined by the upper bound or reached through the progressive sampling approach) enable to approximate the actual top-K frequent itemsets with accuracy much higher than what analytically proved.	[Riondato, Matteo; Upfal, Eli; Vandin, Fabio] Brown Univ, Dept Comp Sci, Providence, RI 02912 USA; [Pietracaprina, Andrea] Univ Padua, Dipartimento Ingn Informaz, Padua, Italy	Riondato, M (reprint author), Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.	capri@dei.unipd.it; matteo@cs.brown.edu; eli@cs.brown.edu; vandinfa@cs.brown.edu					Charikar M, 2004, THEOR COMPUT SCI, V312, P3, DOI 10.1016/S0304-3975(03)00400-6; Chen B., 2002, P 8 ACM SIGKDD INT C, P462; Cohen E, 2008, COMPUT NETW, V52, P2605, DOI 10.1016/j.comnet.2008.04.021; Fayyad U, 1996, P 2 INT C KNOWL DISC, P367; LI Y, 2004, P 17 AUSTR JOINT C A, P391; Manku GS, 2002, P 28 INT C VER LARG, P346; Matias Y., 1998, P ACM SIGMOD INT C M, P331, DOI 10.1145/276304.276334; METWALLY A, 2005, P 10 INT C DAT THEOR, P398; MITZENMACHER M., 2005, PROBABILITY COMPUTIN; Pandit V., 2009, P 12 INT C DAT THEOR, P276, DOI 10.1145/1514894.1514927; Parthasarathy S., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183923; PIETRACAPRINA A, 2007, P 10 INT C DISC SCI, P275; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Vasudevan D., 2009, RANKING RANDOM UNPUB; Wang JY, 2005, IEEE T KNOWL DATA EN, V17, P652; Wong RCW, 2006, DATA MIN KNOWL DISC, V13, P193, DOI 10.1007/s10618-006-0042-x; Zaki M. J., 1997, Proceedings. Seventh International Workshop on Research Issues in Data Engineering. High Performance Database Management for Large-Scale Applications (Cat. No.97TB100122), DOI 10.1109/RIDE.1997.583696	17	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		310	326		10.1007/s10618-010-0185-7		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900007	
J	Menon, A; Elkan, C				Menon, Aditya Krishna; Elkan, Charles			Predicting labels for dyadic data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 20-24, 2010	Barcelona, SPAIN			Dyadic prediction; Collaborative filtering; Link prediction; Social networks; Within-network classification; Relational learning		In dyadic prediction, the input consists of a pair of items (a dyad), and the goal is to predict the value of an observation related to the dyad. Special cases of dyadic prediction include collaborative filtering, where the goal is to predict ratings associated with (user, movie) pairs, and link prediction, where the goal is to predict the presence or absence of an edge between two nodes in a graph. In this paper, we study the problem of predicting labels associated with dyad members. Special cases of this problem include predicting characteristics of users in a collaborative filtering scenario, and predicting the label of a node in a graph, which is a task sometimes called within-network classification or relational learning. This paper shows how to extend a recent dyadic prediction method to predict labels for nodes and labels for edges simultaneously. The new method learns latent features within a log-linear model in a supervised way, to maximize predictive accuracy for both dyad observations and item labels. We compare the new approach to existing methods for within-network classification, both experimentally and analytically. The experiments show, surprisingly, that learning latent features in an unsupervised way is superior for some applications to learning them in a supervised way.	[Menon, Aditya Krishna; Elkan, Charles] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92037 USA	Menon, A (reprint author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92037 USA.	akmenon@cs.ucsd.edu; elkan@cs.ucsd.edu					Blei D., 2010, SUPERVISED TOPIC MOD; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Huang Z, 2005, Proceedings of the 5th ACM/IEEE Joint Conference on Digital Libraries, Proceedings, P141, DOI 10.1145/1065385.1065415; Macskassy S. A., 2003, P 2 WORKSH MULT DAT, P64; MENON AK, 2010, DYADIC PREDICTION US; MENON AK, 2010, ACM T KNOWL DISCOV D; SARKAR P, 2008, P BIOSECURE INT WORK, P56; TANG L, 2009, ACM SIGKDD INT C KNO, P817; TANG L, 2010, SOCIAL DIMENSION APP; WEIMER M, 2008, EUR C MACH LEARN PRI, P263; YU K, 2005, ACM SIGIR C RES DEV, P258; YU S, 2006, ACM SIGKDD INT C KNO, P464; ZHU S, 2007, ACM SIGIR C RES DEV, P487; *USPS, 2010, USPS DAT	14	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		327	343		10.1007/s10618-010-0189-3		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900008	
J	Furnkranz, J; Knobbe, A				Fuernkranz, Johannes; Knobbe, Arno			Guest Editorial: Global modeling using local patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Fuernkranz, Johannes] Tech Univ Darmstadt, Darmstadt, Germany; [Knobbe, Arno] Leiden Univ, LIACS, Leiden, Netherlands	Furnkranz, J (reprint author), Tech Univ Darmstadt, Darmstadt, Germany.	juffi@ke.tu-darmstadt.de; knobbe@liacs.nl					Azevedo PJ, 2010, DATA MIN KNOWL DISC, V21, P91, DOI 10.1007/s10618-010-0173-y; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BRINGMANN B, 2006, P 10 EUR C PRINC PRA, P55; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); De Raedt L., 2007, P 7 SIAM INT C DAT M; Dembczynski K, 2010, DATA MIN KNOWL DISC, V21, P52, DOI 10.1007/s10618-010-0177-7; Fayyad U, 1996, AI MAG, V17, P37; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148; GIACOMETTI A, 2009, P 10 INT C INT DAT E; Goethals B, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P377, DOI 10.1007/0-387-25465-X_17; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hand D. J., 2002, Pattern Detection and Discovery. ESF Exploratory Workshop Proceedings (Lecture Notes in Artificial Intelligence Vol. 2447); Hofmann T., 1999, P 15 C UNC ART INT U, P289; Jaroszewicz S, 2010, DATA MIN KNOWL DISC, V21, P186, DOI 10.1007/s10618-010-0171-0; Knobbe A., 2006, PKDD, P577; Knobbe A., 2006, SAFARII MULTIRELATIO; Knobbe A., 2008, LOCAL PATTERNS GLOBA; Knobbe AJ, 2006, P 13 ACM SIGKDD INT, P237, DOI 10.1145/1150402.1150431; KRALJ NP, 2009, J MACH LEARN RES, V10, P377; Kramer S, 2001, RELATIONAL DATA MINING, P262; Liu H, 1998, ELEC SOC S, V98, P86; Malik HH, 2010, DATA MIN KNOWL DISC, V21, P153, DOI 10.1007/s10618-010-0172-z; MORIK K, 2005, LOCAL PATTERN DETECT; Nijssen S, 2010, DATA MIN KNOWL DISC, V21, P9, DOI 10.1007/s10618-010-0174-x; WEISS SM, 2000, P 17 INT C MACH LEAR, P1135; Wiswedel B, 2010, DATA MIN KNOWL DISC, V21, P130, DOI 10.1007/s10618-010-0170-1; ZIMMERMANN A, 2004, P 7 INT C DISC SCI D, P60; Zimmermann A, 2009, MACH LEARN, V77, P125, DOI 10.1007/s10994-009-5121-y	29	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2010	21	1			SI		1	8		10.1007/s10618-010-0169-7		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	612LK	WOS:000278899700001	
J	Nijssen, S; Fromont, E				Nijssen, Siegfried; Fromont, Elisa			Optimal constraint-based decision tree induction from itemset lattices	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Decision tree learning; Formal concepts; Frequent itemset mining; Constraint based mining	ASSOCIATION RULES; DISCOVERY; ALGORITHM; CONVERSION; MODEL	In this article we show that there is a strong connection between decision tree learning and local pattern mining. This connection allows us to solve the computationally hard problem of finding optimal decision trees in a wide range of applications by post-processing a set of patterns: we use local patterns to construct a global model. We exploit the connection between constraints in pattern mining and constraints in decision tree induction to develop a framework for categorizing decision tree mining constraints. This framework allows us to determine which model constraints can be pushed deeply into the pattern mining process, and allows us to improve the state-of-the-art of optimal decision tree induction.	[Nijssen, Siegfried] Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium; [Fromont, Elisa] Univ St Etienne Jean Monnet, Univ Lyon, CNRS UMR 5516, Lab Hubert Curien, F-42023 St Etienne, France	Nijssen, S (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Louvain, Belgium.	Siegfried.Nijssen@cs.kuleuven.be; Elisa.Fromont@univ-st-etienne.fr			EU [FP6-516169]; Research Foundation - Flanders; BINGO2 project [ANR-07-MDCO 014-02]; GOA project [2003/8]	Siegfried Nijssen was supported by the EU FET IST project "Inductive Querying", contract number FP6-516169, and is currently supported by the Research Foundation - Flanders. During this work, Elisa Fromont was working at the Katholieke Universteit Leuven. Elisa Fromont was partially supported by the BINGO2 project (ANR-07-MDCO 014-02) and the GOA project 2003/8 "Inductive Knowledge bases". The authors thank Luc De Raedt and Hendrik Blockeel for many interesting discussions; Ferenc Bodon and Bart Goethals for putting online their implementations of respectively Apriori and Eclat, which we used to implement DL8, and Takeaki Uno for providing LCM. We also wish to thank Daan Fierens for preprocessing the data that we used in our experiments.	Agrawal R., 1994, VLDB, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; ANGELOPOULOS N, 2005, IJCAI 05, P641; ASUNCION A., 2007, UCI MACHINE LEARNING; BAIXERIES J, 2009, ICFCA 09, P162; BAYARDO RJ, 2004, FIMI 04; Blanchard G, 2007, MACH LEARN, V66, P209, DOI 10.1007/s10994-007-0717-6; Bonchi F, 2007, DATA KNOWL ENG, V60, P377, DOI 10.1016/j.datak.2006.02.006; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Boulicaut J.-F., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Breiman L, 1984, CLASSIFICATION REGRE; BRINGMANN B, 2009, LEGO 09; Bucila C, 2003, DATA MIN KNOWL DISC, V7, P241, DOI 10.1023/A:1024076020895; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; Cremilleux A. Knobbe. B., 2008, LEGO 08, P1; DERAEDT L, 2007, SDM 07, P1; Dong GZ, 1999, LECT NOTES ARTIF INT, V1721, P30; Esmeir S, 2007, J MACH LEARN RES, V8, P891; ESMEIR S, 2007, NIPS 07, P425; FRIEDMAN A, 2006, P PKDD 06, P151; Ganter B., 1999, FORMAL CONCEPT ANAL; GAREY MR, 1972, SIAM J APPL MATH, V23, P173, DOI 10.1137/0123019; Garofalakis M, 2003, DATA MIN KNOWL DISC, V7, P187, DOI 10.1023/A:1022445500761; Han J, 2000, SIGMOD 00, P1, DOI DOI 10.1145/342009.335372; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Knobbe A.J., 2006, KDD, P237; LEW A, 1978, COMMUN ACM, V21, P269, DOI 10.1145/359460.359469; Li Wenmin, 2001, ICDM, P369; Liu H, 1998, ELEC SOC S, V98, P86; Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, P3, DOI 10.1145/1217299.1217302; Mannila H., 1994, KNOWLEDGE DISCOVERY, P181; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; Moore A, 1998, J ARTIF INTELL RES, V8, P67; MURPHY PM, 1997, COMPUTATIONAL LEARNI, V4, P171; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; PAYNE HJ, 1977, IEEE T COMPUT, V26, P905; PEI J, 2001, ICDE, P433; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193; SCHUMACHER H, 1976, COMMUN ACM, V19, P343, DOI 10.1145/360238.360245; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; UNO T, 2004, FIMI 04; Witten IH, 2005, DATA MINING PRACTICA; Yan X., 2005, KDD, P314; Zaki M.J., 1997, KDD, P283; Zaki MJ, 1997, DATA MIN KNOWL DISC, V1, P343, DOI 10.1023/A:1009773317876	50	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2010	21	1			SI		9	51		10.1007/s10618-010-0174-x		43	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	612LK	WOS:000278899700002	
J	Dembczynski, K; Kotowski, W; Slowinski, R				Dembczynski, Krzysztof; Kotowski, Wojciech; Slowinski, Roman			ENDER: a statistical framework for boosting decision rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Decision rules; Impurity measures; Ensemble; Boosting; Forward stagewise additive modeling	INDUCTION; CLASSIFICATION; CONFIRMATION; REGRESSION; ENSEMBLES; MARGIN; SETS	Induction of decision rules plays an important role in machine learning. The main advantage of decision rules is their simplicity and human-interpretable form. Moreover, they are capable of modeling complex interactions between attributes. In this paper, we thoroughly analyze a learning algorithm, called ENDER, which constructs an ensemble of decision rules. This algorithm is tailored for regression and binary classification problems. It uses the boosting approach for learning, which can be treated as generalization of sequential covering. Each new rule is fitted by focusing on examples which were the hardest to classify correctly by the rules already present in the ensemble. We consider different loss functions and minimization techniques often encountered in the boosting framework. The minimization techniques are used to derive impurity measures which control construction of single decision rules. Properties of four different impurity measures are analyzed with respect to the trade-off between misclassification (discrimination) and coverage (completeness) of the rule. Moreover, we consider regularization consisting of shrinking and sampling. Finally, we compare the ENDER algorithm with other well-known decision rule learners such as SLIPPER, LRI and RuleFit.	[Dembczynski, Krzysztof; Kotowski, Wojciech; Slowinski, Roman] Poznan Tech Univ, PL-60965 Poznan, Poland; [Slowinski, Roman] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland	Dembczynski, K (reprint author), Poznan Tech Univ, Piotrowo 2, PL-60965 Poznan, Poland.	kdembczynski@cs.put.poznan.pl; wkotlowski@cs.put.poznan.pl; rslowinski@cs.put.poznan.pl	Slowinski, Roman/A-5751-2013		Polish Ministry of Science and Higher Education [N N519 314435]	The authors wish to acknowledge financial support from the Polish Ministry of Science and Higher Education, grant no. N N519 314435.	ASUNCION A., 2007, UCI MACHINE LEARNING; BAZAN JG, 1998, LNCS, V1424, P521; Blaszczynski J., 2006, Foundations of Computing and Decision Sciences, V31; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brzezinska I, 2007, ENG APPL ARTIF INTEL, V20, P587, DOI 10.1016/j.engappai.2006.11.015; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Dembczynski K, 2008, LECT NOTES ARTIF INT, V5097, P533, DOI 10.1007/978-3-540-69731-2_52; Dembczynski Krzysztof, 2008, P 25 INT C MACH LEAR, P224, DOI 10.1145/1390156.1390185; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domingos P, 1996, MACH LEARN, V24, P141; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J., 2003, IMPORTANCE SAMPLED L; Friedman J., 2003, ELEMENTS STAT LEARNI; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148; FURNKRANZ J, 1996, AI REV, V13, P3; Gora G, 2002, LECT NOTES ARTIF INT, V2475, P405; Gora G, 2002, FUND INFORM, V51, P369; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; Greco S, 2004, ENG APPL ARTIF INTEL, V17, P345, DOI 10.1016/j.engappai.2004.04.008; Greco S., 2000, LECT NOTES ARTIF INT, V2005, P304; Grzymala-Busse J. W., 1992, HDB APPL ADV ROUGH S, P3; Hilderman R., 2001, KNOWLEDGE DISCOVERY; Janssen F, 2008, LECT NOTES COMPUT SC, V5255, P40, DOI 10.1007/978-3-540-88411-8_7; JOVANOSKI V, 2001, LECT NOTES ARTIF INT, V2258, P111; Kearns M. J., 1994, INTRO COMPUTATIONAL; KNOBBE A, 2008, P ECML PKDD 2008 WOR; Koltchinskii V, 2005, ANN STAT, V33, P1455, DOI 10.1214/009053605000000228; Marchand M., 2002, J MACHINE LEARNING R, V3, P723; Mason L, 1999, ADV LARGE MARGIN CLA, P33; Michalski R. S., 1983, MACHINE LEARNING ART, P83; Pawlak Z., 1991, ROUGH SETS THEORETIC; Ruckert U, 2008, MACH LEARN, V70, P189, DOI 10.1007/s10994-007-5034-6; Schapire RE, 1998, ANN STAT, V26, P1651; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SKOWRON A, 1995, COMPUT INTELL, V11, P371, DOI 10.1111/j.1467-8640.1995.tb00039.x; Slowinski R., 1992, HDB APPL ADV ROUGH S; Stefanowski J, 2001, INT J INTELL SYST, V16, P13, DOI 10.1002/1098-111X(200101)16:1<13::AID-INT3>3.3.CO;2-D; Stefanowski J., 1998, ROUGH SETS DATA MINI, P500; WEISS SM, 2000, P 17 INT C MACH LEAR, P1135	45	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2010	21	1			SI		52	90		10.1007/s10618-010-0177-7		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	612LK	WOS:000278899700003	
J	Azevedo, PJ; Jorge, AM				Azevedo, Paulo J.; Jorge, Alipio Mario			Ensembles of jittered association rule classifiers	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Ensembles; Associative classification; Model jittering	CLASSIFICATION	The ensembling of classifiers tends to improve predictive accuracy. To obtain an ensemble with N classifiers, one typically needs to run N learning processes. In this paper we introduce and explore Model Jittering Ensembling, where one single model is perturbed in order to obtain variants that can be used as an ensemble. We use as base classifiers sets of classification association rules. The two methods of jittering ensembling we propose are Iterative Reordering Ensembling (IRE) and Post Bagging (PB). Both methods start by learning one rule set over a single run, and then produce multiple rule sets without relearning. Empirical results on 36 data sets are positive and show that both strategies tend to reduce error with respect to the single model association rule classifier. A bias-variance analysis reveals that while both IRE and PB are able to reduce the variance component of the error, IRE is particularly effective in reducing the bias component. We show that Model Jittering Ensembling can represent a very good speed-up w.r.t. multiple model learning ensembling. We also compare Model Jittering with various state of the art classifiers in terms of predictive accuracy and computational efficiency.	[Azevedo, Paulo J.] Univ Minho, Dept Informat, CCTC, Braga, Portugal; [Jorge, Alipio Mario] Univ Porto, Fac Ciencias, DCC, P-4100 Oporto, Portugal; [Jorge, Alipio Mario] LIAAD INESC Porto LA, Oporto, Portugal	Azevedo, PJ (reprint author), Univ Minho, Dept Informat, CCTC, Braga, Portugal.	pja@di.uminho.pt; amjorge@fc.up.pt	FCUP, DCC/F-5042-2012; Jorge, Alipio/A-1721-2008		FCT [PTDC/EIA/81178/2006]; QREN; Fundo Europeu de Desenvolvimento Regional (FEDER)	This work was partially supported by FCT project Rank! (PTDC/EIA/81178/2006) and by AdI project Palco3.0 financed by QREN and Fundo Europeu de Desenvolvimento Regional (FEDER), and also supported by Fundacao Ciencia e Tecnologia, FEDER e Programa de Financiamento Plurianual de Unidades de I & D. Thanks are due to William Cohen for kindly providing the executable code for the SLIPPER implementation. Our gratitude goes also to our anonymous reviewers who have helped to significantly improve this paper by sharing their knowledge and their informed criticism with the authors.	Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Azevedo PJ, 2007, LECT NOTES ARTIF INT, V4701, P510; AZEVEDO PJ, 2008, CAREN CLASS PROJECT; AZEVEDO PJ, 2003, CAREN JAVA BASED APR; AZEVEDO PJ, 2005, DATA STRUCTURE REPRE; Azevedo PJ, 2007, LECT NOTES ARTIF INT, V4755, P56; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BAYARDO RJ, 1999, ICDE, P188; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brin S, 1997, SIGMOD 1997, P255; Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; COHEN WW, 1999, IAAI IAAI, P335; DEMBCZYNSKI K, 2008, ACM INT C P SERIES, V307, P224; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domingos P., 1997, KDD, P155; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; Frank E., 1998, ICML 98, P144; Frank E, 2006, LECT NOTES ARTIF INT, V3918, P97; Freund Y., 1996, INT C MACH LEARN, P148; Freund Y., 1995, LNCS, V904, P23, DOI DOI 10.1007/3-540-59119-2_166; Friedman J., 2005, PREDICTIVE LEARNING; Gama J, 2003, THEOR COMPUT SCI, V292, P417, DOI 10.1016/S0304-3975(02)00179-2; Hastie T., 2001, ELEMENTS STAT LEARNI; Jorge AM, 2005, LECT NOTES COMPUT SC, V3735, P137; Jovanoski V., 2001, LNCS LNAI, V2258, P44; Knobbe A., 2008, LOCAL PATTERNS GLOBA; Kohavi R., 1996, ICML, P275; Li Wenmin, 2001, ICDM, P369; Liu H, 1998, ELEC SOC S, V98, P86; MARTINEZMUNOZ G, 2006, ACM INT C P SERIES, V148, P609; MERETAKIS D, 1999, KNOWLEDGE DISCOVERY, P165; Merz C. J., 1996, UCI REPOSITORY MACHI; PFAHRINGER B, 2004, WORKSH ADV IND RUL L; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; R Development Core Team, 2004, R LANG ENV STAT COMP; RUCKERT U, 2006, ACM INT C P SERIES, V148, P785; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; WANG J, 2005, P 2005 SIAM INT DAT; Webb G. I., 2006, P 12 ACM SIGKDD INT, P434, DOI 10.1145/1150402.1150451; Webb G. I., 2003, P 9 ACM SIGKDD INT C, P256; Webb GI, 2008, MACH LEARN, V71, P307, DOI 10.1007/s10994-008-5046-x; Weiss SM, 2000, INT C MACH LEARN, P1135; WITTEN IH, 2005, M KAUFMANN SERIES DA, V2; Zimmermann A, 2004, LECT NOTES COMPUT SC, V3245, P60	45	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2010	21	1			SI		91	129		10.1007/s10618-010-0173-y		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	612LK	WOS:000278899700004	
J	Wiswedel, B; Hoppner, F; Berthold, MR				Wiswedel, Bernd; Hoeppner, Frank; Berthold, Michael R.			Learning in parallel universes	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Parallel universes; Descriptor space; Clustering	SIMILARITY	We discuss Learning in parallel universes as a learning concept that encompasses the simultaneous analysis from multiple descriptor spaces. In contrast to existing approaches, this approach constructs a global model that is based on only partially applicable, local models in each descriptor space. We present some application scenarios and compare this learning strategy to other approaches on learning in multiple descriptor spaces. As a representative for learning in parallel universes we introduce different extensions to a family of unsupervised fuzzy clustering algorithms and evaluate their performance on an artificial data set and a benchmark of 3D objects.	[Wiswedel, Bernd; Berthold, Michael R.] Univ Konstanz, Dept Comp & Informat Sci, Constance, Germany; [Hoeppner, Frank] Ostfalia Univ Appl Sci, Fac Business Informat Syst, Wolfenbuttel, Germany	Wiswedel, B (reprint author), Univ Konstanz, Dept Comp & Informat Sci, Constance, Germany.	Bernd.Wiswedel@uni-konstanz.de; f.hoeppner@ostfalia.de; Michael.Berthold@uni-konstanz.de			German Research Foundation (DFG) [BE 1740/12-1]	This work was supported by the German Research Foundation (DFG), BE 1740/12-1. We would also like to thank the reviewers and editors of this special issue for their constructive feedback.	Aggarwal C., 1999, P 1999 ACM SIGMOD IN, P61, DOI 10.1145/304182.304188; Aggarwal C. C., 2000, P ACM SIGMOD INT C M, P70, DOI 10.1145/342009.335383; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; ALQADAH F, 2008, CIKM 08, P1103; Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Bezdek J., 1981, PATTERN RECOGNITION; Bickel S., 2004, P 4 IEEE INT C DAT M, P19, DOI [10.1109/icdm.2004.10095, DOI 10.1109/ICDM.2004.10095]; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Bustos B., 2004, P IEEE INT C MULT EX, P1303; Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893; Bustos B, 2006, INT J DIGITAL LIB, V6, P39, DOI 10.1007/s00799-005-0122-3; Dasgupta S., 2001, NIPS, P375; Friedman JH, 2004, J ROY STAT SOC B, V66, P815, DOI 10.1111/j.1467-9868.2004.02059.x; Kailing K., 2004, P 8 PAC AS C KNOWL D, P394; Klawonn F., 2004, MATHWARE SOFT COMPUT, V11, P125; Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; Krishnapuram R, 1996, IEEE T FUZZY SYST, V4, P385, DOI 10.1109/91.531779; PATTERSON DE, 2001, IEEE C SYST MAN CYB; Ruping S., 2005, P ICML 2005 WORKSH L; Wiswedel B, 2007, INT J APPROX REASON, V45, P439, DOI 10.1016/j.ijar.2006.06.020; *3D BENCHM, 2008, KONST 3D MOD SEARCH	22	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2010	21	1			SI		130	152		10.1007/s10618-010-0170-1		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	612LK	WOS:000278899700005	
J	Malik, HH; Kender, JR; Fradkin, D; Moerchen, F				Malik, Hassan H.; Kender, John R.; Fradkin, Dmitriy; Moerchen, Fabian			Hierarchical document clustering using local patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Pattern based hierarchical clustering; Interestingness measures; Dimensionality reduction; Pattern selection; Global modeling using local patterns		The global pattern mining step in existing pattern-based hierarchical clustering algorithms may result in an unpredictable number of patterns. In this paper, we propose IDHC, a pattern-based hierarchical clustering algorithm that builds a cluster hierarchy without mining for globally significant patterns. IDHC first discovers locally promising patterns by allowing each instance to "vote" for its representative size-2 patterns in a way that ensures an effective balance between local pattern frequency and pattern significance in the dataset. The cluster hierarchy (i.e., the global model) is then directly constructed using these locally promising patterns as features. Each pattern forms an initial (possibly overlapping) cluster, and the rest of the cluster hierarchy is obtained by following a unique iterative cluster refinement process. By effectively utilizing instance-to-cluster relationships, this process directly identifies clusters for each level in the hierarchy, and efficiently prunes duplicate clusters. Furthermore, IDHC produces cluster labels that are more descriptive (patterns are not artificially restricted), and adapts a soft clustering scheme that allows instances to exist in suitable nodes at various levels in the cluster hierarchy. We present results of experiments performed on 16 standard text datasets, and show that IDHC outperforms state-of-the-art hierarchical clustering algorithms in terms of average entropy and FScore measures.	[Malik, Hassan H.] Thomson Reuters, New York, NY 10007 USA; [Kender, John R.] Columbia Univ, New York, NY 10027 USA; [Fradkin, Dmitriy; Moerchen, Fabian] Siemens Corp Res, Princeton, NJ 08540 USA	Malik, HH (reprint author), Thomson Reuters, 195 Broadway, New York, NY 10007 USA.	hassan.malik@thomsonreuters.com; jrk@cs.columbia.edu; dmitriy.fradkin@siemens.com; fabian.moerchen@siemens.com					Angiulli F., 2001, P NON CONV NAZ SIST, P177; Beil F., 2002, P 8 ACM SIGKDD INT C, P436; Brijs T., 2003, INT J INFORMATION TH, V10, P370; Carter CL, 1997, LECT NOTES ARTIF INT, V1263, P14; Clifton C, 2004, IEEE T KNOWL DATA EN, V16, P949, DOI 10.1109/TKDE.2004.32; Fung BCM, 2003, SIAM PROC S, P59; Geng L, 2006, ACM COMPUT SURV, V38; Gunopulos D, 2003, ACM T DATABASE SYST, V28, P140, DOI 10.1145/777943.777945; HAN EH, 1997, P RES ISS DAT MIN KN, P59; KARYPIS G, 2003, CLUTO SOFTWARE PACKA; Knobbe A, 2008, P LEGO 2008 ECML PKD, P1; LI Y, 2005, P 2005 ACM INT C INF, P293, DOI 10.1145/1099554.1099633; MALIK H, 2008, P LOC PATT GLOB MOD; MALIK H, 2007, P 7 IEEE INT C DAT M, P595; MALIK H. H., 2006, P ICDM 2006 IEEE COM, P991; MOERCHEN F, 2007, P DAT MIN CAS STUD W; Parsons L, 2004, ACM SIGKDD EXPLORATI, V6, P90, DOI 10.1145/1007730.1007731; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Tan P., 2002, P 8 ACM SIGKDD INT C, P32, DOI DOI 10.1145/775047.775053; WANG J, 2004, P 4 IEEE INT C DAT M, P241; WU C, 2006, P 10 PAC AS C KNOWL, P435; Xiong H, 2004, SIAM PROC S, P279; Yang Y, 1997, P 14 INT C MACH LEAR, P412; YU H, 2004, P IEEE INT C DAT MIN, P563; Zhao Y, 2005, DATA MIN KNOWL DISC, V10, P141, DOI 10.1007/s10618-005-0361-3	25	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2010	21	1			SI		153	185		10.1007/s10618-010-0172-z		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	612LK	WOS:000278899700006	
J	Jaroszewicz, S				Jaroszewicz, Szymon			Using interesting sequences to interactively build Hidden Markov Models	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Interesting pattern; Frequent sequence mining; Hidden Markov Model	SPEECH RECOGNITION	The paper presents a method of interactive construction of global Hidden Markov Models (HMMs) based on local sequence patterns discovered in data. The method is based on finding interesting sequences whose frequency in the database differs from that predicted by the model. The patterns are then presented to the user who updates the model using their intelligence and their understanding of the modelled domain. It is demonstrated that such an approach leads to more understandable models than automated approaches. Two variants of the problem are considered: mining patterns occurring only at the beginning of sequences and mining patterns occurring at any position; both practically meaningful. For each variant, algorithms have been developed allowing for efficient discovery of all sequences with given minimum interestingness. Applications to modelling webpage visitors behavior and to modelling protein secondary structure are presented, validating the proposed approach.	Inst Natl Telecommun, Warsaw, Poland	Jaroszewicz, S (reprint author), Inst Natl Telecommun, Warsaw, Poland.	s.jaroszewicz@itl.waw.pl					Agrawal R., 1993, ACM SIGMOD INT C MAN, P207; ASAI K, 1993, COMPUT APPL BIOSCI, V9, P141; BALASUBRAMANIAN V, 1993, 1370 AI MIT ART INT; BOUCHAFFRA D, 2006, INT C PATT REC LOS A, V3, P186; DUNHAM MH, 2003, DATA MINING INTRO 3; Golub G. H., 1996, MATRIX COMPUTATIONS; Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1; Hand D. J., 2002, Pattern Detection and Discovery. ESF Exploratory Workshop Proceedings (Lecture Notes in Artificial Intelligence Vol. 2447); Hunter L., 1993, ARTIF INTELL, P1; Huo Q, 1997, IEEE T SPEECH AUDI P, V5, P161; HUO Q, 1995, IEEE T SPEECH AUDI P, V3, P334; Inoue M, 2003, IEEE T PATTERN ANAL, V25, P1570, DOI 10.1109/TPAMI.2003.1251150; Jaroszewicz S, 2009, DATA MIN KNOWL DISC, V18, P56, DOI 10.1007/s10618-008-0102-5; JAROSZEWICZ S, 2004, 10 ACM SIGKDD INT C, P178; JAROSZEWICZ S, 2005, 11 ACM SIGKDD INT C, P118; Jaroszewicz S., 2008, P LOC PATT GLOB MOD, P82; Ji SH, 2009, IEEE T PATTERN ANAL, V31, P275, DOI 10.1109/TPAMI.2008.71; Laxman S, 2006, SADHANA-ACAD P ENG S, V31, P173, DOI 10.1007/BF02719780; Laxman S, 2005, IEEE T KNOWL DATA EN, V17, P1505; Lee CH, 1996, ACIAR PROC, P83; Li D.H., 2007, RR07027 LAB INF ROB; LOWKAM C, 2009, MINING UNEXPECTED SE; Meyer C. D., 2001, MATRIX ANAL APPL LIN; PRUM B, 1995, J ROY STAT SOC B MET, V57, P205; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROBBINS H, 1956, 3RD P BERK S MATH ST, V1, P157; SATSANGI A, 2007, 11 INT DAT ENG APPL; Spiliopoulou M, 1999, LECT NOTES ARTIF INT, V1704, P554; UHLIG F, 2001, TRANSFORM LINEAR ALG; Welch L. R., 2003, IEEE INFORM THEORY S, V53, p[1, 10]; Welch L. R., 2003, IEEE INFORM THEORY S, V53, P10; ZAIANE OR, 2007, TR0703 U ALB DEP COM	33	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2010	21	1			SI		186	220		10.1007/s10618-010-0171-0		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	612LK	WOS:000278899700007	
J	Ji, SW; Tang, L; Yu, SP; Ye, JP				Ji, Shuiwang; Tang, Lei; Yu, Shipeng; Ye, Jieping			A Shared-Subspace Learning Framework for Multi-Label Classification	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Multi-label classification; kernel methods; shared subspace; least squares loss; singular value decomposition; web page categorization; gene expression pattern image annotation		Multi-label problems arise in various domains such as multi-topic document categorization, protein function prediction, and automatic image annotation. One natural way to deal with such problems is to construct a binary classifier for each label, resulting in a set of independent binary classification problems. Since multiple labels share the same input space, and the semantics conveyed by different labels are usually correlated, it is essential to exploit the correlation information contained in different labels. In this paper, we consider a general framework for extracting shared structures in multi-label classification. In this framework, a common subspace is assumed to be shared among multiple labels. We show that the optimal solution to the proposed formulation can be obtained by solving a generalized eigenvalue problem, though the problem is nonconvex. For high-dimensional problems, direct computation of the solution is expensive, and we develop an efficient algorithm for this case. One appealing feature of the proposed framework is that it includes several well-known algorithms as special cases, thus elucidating their intrinsic relationships. We further show that the proposed framework can be extended to the kernel-induced feature space. We have conducted extensive experiments on multi-topic web page categorization and automatic gene expression pattern image annotation tasks, and results demonstrate the effectiveness of the proposed formulation in comparison with several representative algorithms.	[Ji, Shuiwang; Tang, Lei; Ye, Jieping] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA; [Yu, Shipeng] Siemens Med Solut, Comp Aided Diag Grp, Malvern, PA 19355 USA; [Ji, Shuiwang; Ye, Jieping] Arizona State Univ, Ctr Evolutionary Med, Tempe, AZ 85287 USA; [Ji, Shuiwang; Ye, Jieping] Arizona State Univ, Informat Biodesign Inst, Tempe, AZ 85287 USA	Ji, SW (reprint author), Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA.	shuiwang.ji@asu.edu; L.Tang@asu.edu; shipeng.yu@siemens.com; jieping.ye@asu.edu			NSF [IIS-0612069, IIS-0812551, CCF-0811790]; NIH [R01-HG002516]; NGA [HM1582-08-1-0016]	This work was supported by NSF IIS-0612069, IIS-0812551, CCF-0811790, NIH R01-HG002516, and NGA HM1582-08-1-0016.	Amit Y., 2007, P 24 INT C MACH LEAR, P17, DOI 10.1145/1273496.1273499; Andersen E. D., 2000, HIGH PERFORMANCE OPT, P197; Ando RK, 2005, J MACH LEARN RES, V6, P1817; ARENASGARCIA J, 2007, ADV NEURAL INFORM PR, V19, P33; ARGYRIOU A, 2008, P EUR C MACH LEARN K, P71; BAKKER B., 2003, J MACH LEARN RES, V4, P83, DOI DOI 10.1162/153244304322765658; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Fan R.-E, 2007, STUDY THRESHOLD SELE; Fukunaga K., 1990, INTRO STAT PATTERN R; Fung GM, 2005, MACH LEARN, V59, P77, DOI 10.1007/s10994-005-0463-6; Ghamrawi N, 2005, P 14 ACM INT C INF K, P195, DOI 10.1145/1099554.1099591; Golub G.H., 1996, MATRIX COMPUTATIONS; Grauman K, 2007, J MACH LEARN RES, V8, P725; GRAUMAN K, 2006, ADV NEURAL INFORM PR, V19, P505; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Jacob L., 2009, ADV NEURAL INFORM PR, V21, P745; Ji SW, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-119; JI S, 2009, P IJCAI, P1077; Ji S., 2009, P 15 ACM SIGKDD INT, P407, DOI 10.1145/1557019.1557068; Ji SW, 2008, BIOINFORMATICS, V24, P1881, DOI 10.1093/bioinformatics/btn347; Jin R, 2002, ADV NEURAL INFORM PR, V15, P897; JOACHIMS T., 2005, P 22 INT C MACH LEAR, P377, DOI 10.1145/1102351.1102399; Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI 10.1145/1150402.1150429; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kang F, 2006, P IEEE COMP SOC C CO, P1719; Kazawa H., 2005, ADV NEURAL INFORM PR, V17, P649; KIM S, 2008, CMUML08113; Kumar S, 2002, GENETICS, V162, P2037; Larsen R. M., 2000, COMPUTING SVD LARGE; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847; Li Y., 2009, P 21 INT JOINT C ART, P1445; MCCALLUM A., 1999, P AAAI WORKSH TEXT L; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; MONAY F, 2007, IEEE T PATTERN ANAL, V29, P10; Park H., 2003, BIT, V43, P1; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Roth V, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S2-S12; SCHOLKOPF S, 2002, LEARNING KERNELS SUP; Sun L., 2008, P 25 INT C MACH LEAR, P1024, DOI 10.1145/1390156.1390285; SUN L, 2009, P 21 INT JOINT C ART, P1230; SUN L, 2008, P 14 ACM SIGKDD INT; TANG L, 2009, P 18 INT WORLD WID W; TANG L, 2009, P 21 INT JOINT C ART; Tomancak P, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-7-r145; TOMANCAK P, 2002, GENOME BIOL, V3, P12; Ueda N., 2003, ADV NEURAL INFORMATI, V15, P721; Ueda N, 2002, P 8 ACM SIGKDD INT C, P626; Van R., 2007, P 13 ACM SIGKDD INT, P834, DOI 10.1145/1281192.1281281; Wold H., 1966, MULTIVARIATE ANAL, P391; Yang Y, 1997, P 14 INT C MACH LEAR, P412; Ye J, 2007, P 24 INT C MACH LEAR, P1087, DOI 10.1145/1273496.1273633; Ye JP, 2005, J MACH LEARN RES, V6, P483; Yu K, 2005, P 28 ANN INT ACM SIG, P258, DOI 10.1145/1076034.1076080; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhou Z.-H., 2007, ADV NEURAL INFORM PR, V19, P1609	63	10	10	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAY	2010	4	2								10.1145/1754428.1754431		29	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VZ	WOS:000208168800003	
J	Kandylas, V; Upham, SP; Ungar, LH				Kandylas, Vasileios; Upham, S. Phineas; Ungar, Lyle H.			Analyzing Knowledge Communities Using Foreground and Background Clusters	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Text mining; clustering; knowledge communities; community evolution; citation analysis		Insight into the growth (or shrinkage) of "knowledge communities" of authors that build on each other's work can be gained by studying the evolution over time of clusters of documents. We cluster documents based on the documents they cite in common using the Streemer clustering method, which finds cohesive foreground clusters (the knowledge communities) embedded in a diffuse background. We build predictive models with features based on the citation structure, the vocabulary of the papers, and the affiliations and prestige of the authors and use these models to study the drivers of community growth and the predictors of how widely a paper will be cited. We find that scientific knowledge communities tend to grow more rapidly if their publications build on diverse information and use narrow vocabulary and that papers that lie on the periphery of a community have the highest impact, while those not in any community have the lowest impact.	[Kandylas, Vasileios; Ungar, Lyle H.] Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA; [Upham, S. Phineas] Univ Penn, Whartom Sch, Philadelphia, PA 19104 USA	Kandylas, V (reprint author), Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA.	kandylas@seas.upenn.edu; uphams@wharton.upenn.edu; ungar@cis.upenn.edu			Greek State Scholarship Foundation (IKY)	V. Kandylas was supported in part by the Greek State Scholarship Foundation (IKY).	Allison PD, 2002, SOCIOL METHODOL, V32, P247, DOI 10.1111/1467-9531.00117; Banerjee A, 2004, P 10 ACM SIGKDD INT, P509, DOI 10.1145/1014052.1014111; Blei D, 2006, P 23 INT C MACH LEAR, P113, DOI DOI 10.1145/1143844.1143859; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BONACICH P, 1978, SOCIOL METHODOL, V9, P101, DOI 10.2307/270805; Borgatti SP, 1997, SOC NETWORKS, V19, P243, DOI 10.1016/S0378-8733(96)00301-2; BRAAM RR, 1991, J AM SOC INFORM SCI, V42, P252, DOI 10.1002/(SICI)1097-4571(199105)42:4<252::AID-ASI2>3.0.CO;2-G; Crane D, 1972, INVISIBLE COLL DIFFU; Dasgupta S., 2000, P 16 C UNC ART INT, P152; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dhillon I., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; Dhillon I. S, 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; DHILLON IS, 2003, P 2003 IEEE INT C DA, P517; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; DOREIAN P, 1979, CLASSIFYING SOCIAL D, P215; Ester M, 1996, P 2 INT C KNOWL DISC, P226; EVERETT M, 1993, SOC NETW, V15, P23; Fern XZ, 2003, P 20 INT C MACH LEAR, P186; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Freeman LC, 2003, DYNAMIC SOCIAL NETWORK MODELING AND ANALYSIS, P39; Frenken K, 2005, J ENG TECHNOL MANAGE, V22, P9, DOI [10.1016/j.jengtecman.2004.11.002, 10.1016/j.jengrtecman.2004.11.002]; Getoor L., 2001, P 18 INT C MACH LEAR, P170; Gibson D., 1998, INFERRING WEB COMMUN; GILES CL, 1998, P 3 ACM C DIG LIB, V1, P89; GREENE WH, 1994, WORKING PAPERS NEW Y, V9410; GRIFFITH BC, 1974, SCI STUD, V4, P339, DOI 10.1177/030631277400400402; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4; Hage J., 2006, INNOVATION SCI I CHA; Hage JT, 1999, ANNU REV SOCIOL, V25, P597, DOI 10.1146/annurev.soc.25.1.597; HANNAN MT, 1977, AM J SOCIOL, V82, P929, DOI 10.1086/226424; HAUSMAN J, 1984, ECONOMETRICA, V52, P909, DOI 10.2307/1911191; He YL, 2002, INFORM PROCESS MANAG, V38, P491, DOI 10.1016/S0306-4573(01)00046-2; Hopcroft J, 2003, P 9 ACM SIGKDD INT C, P541; HUANG Q, 1995, P INT C IM PROC WASH, V1, P246; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Janssens F, 2007, P 13 ACM SIGKDD INT, P360, DOI 10.1145/1281192.1281233; KANDYLAS V, 2007, P IEEE INT C DAT MIN, P203; Kearns M., 1997, P 13 C UNC ART INT, P282; Kostoff RN, 2001, J AM SOC INF SCI TEC, V52, P1148, DOI 10.1002/asi.1181; Larsen B, 1999, P 5 ACM SIGKDD INT C, DOI 10.1145/312129.312186; Lee JD, 2003, SCIENTOMETRICS, V56, P223, DOI 10.1023/A:1021967111530; Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI 10.1145/1081870.1081893; Ley M, 2002, P 9 INT S STRING PRO, P1; March JG, 1991, ORGAN SCI, V2, P71, DOI 10.1287/orsc.2.1.71; MATSUMURA N, 2001, LNCS, V2198, P473; McCullagh P, 1989, GEN LINEAR MODELS; McGann AJ, 2002, J THEOR POLIT, V14, P37, DOI 10.1177/095169280201400104; McGovern A., 2003, SIGKDD EXPLOR NEWSL, V5, P165; Moody J, 2001, SOC NETWORKS, V23, P261, DOI 10.1016/S0378-8733(01)00042-9; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pantel P., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; PERLICH C, 2003, SIGKDD EXPLOR, V5, P154; PFEFFER J, 1993, ACAD MANAGE REV, V18, P599, DOI 10.2307/258592; Popescul A., 2000, Proceedings IEEE Advances in Digital Libraries 2000, DOI 10.1109/ADL.2000.848380; SAVAKIS A, 1998, P INT C IM PROC ICIP; Shi JB, 1997, PROC CVPR IEEE, P731; SLONIM N, 2001, ADV NEUR INFORM PROC; SMALL H, 1985, SCIENTOMETRICS, V8, P321, DOI 10.1007/BF02018057; SMALL H, 1985, SCIENTOMETRICS, V7, P391, DOI 10.1007/BF02017157; Small H, 2003, J AM SOC INF SCI TEC, V54, P394, DOI 10.1002/asi.10225; SMALL HG, 1979, SCIENTOMETRICS, V1, P445, DOI 10.1007/BF02016661; Steinbach M., 2000, KDD WORKSH TEXT MIN, V34, P35; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; SULLIVAN D, 1977, SOC STUD SCI, V7, P223, DOI 10.1177/030631277700700205; Sun J., 2007, P 13 ACM SIGKDD INT, P687, DOI DOI 10.1145/1281192.1281266; Tantipathananandh C, 2007, P 13 ACM SIGKDD INT, P717, DOI 10.1145/1281192.1281269; UPHAM SP, 2006, THESIS U PENNSYLVANI; Wang PM, 2003, ECON LETT, V78, P373, DOI 10.1016/S0165-1765(02)00262-8; Wang X., 2006, P 12 ACM SIGKDD INT, P424, DOI 10.1145/1150402.1150450; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	73	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAY	2010	4	2								10.1145/1754428.1754430		35	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VZ	WOS:000208168800002	
J	Ruggieri, S; Pedreschi, D; Turini, F				Ruggieri, Salvatore; Pedreschi, Dino; Turini, Franco			Data Mining for Discrimination Discovery	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Discrimination; classification rules		In the context of civil rights law, discrimination refers to unfair or unequal treatment of people based on membership to a category or a minority, without regard to individual merit. Discrimination in credit, mortgage, insurance, labor market, and education has been investigated by researchers in economics and human sciences. With the advent of automatic decision support systems, such as credit scoring systems, the ease of data collection opens several challenges to data analysts for the fight against discrimination. In this article, we introduce the problem of discovering discrimination through data mining in a dataset of historical decision records, taken by humans or by automatic systems. We formalize the processes of direct and indirect discrimination discovery by modelling protected-by-law groups and contexts where discrimination occurs in a classification rule based syntax. Basically, classification rules extracted from the dataset allow for unveiling contexts of unlawful discrimination, where the degree of burden over protected-by-law groups is formalized by an extension of the lift measure of a classification rule. In direct discrimination, the extracted rules can be directly mined in search of discriminatory contexts. In indirect discrimination, the mining process needs some background knowledge as a further input, for example, census data, that combined with the extracted rules might allow for unveiling contexts of discriminatory decisions. A strategy adopted for combining extracted classification rules with background knowledge is called an inference model. In this article, we propose two inference models and provide automatic procedures for their implementation. An empirical assessment of our results is provided on the German credit dataset and on the PKDD Discovery Challenge 1999 financial dataset.	[Ruggieri, Salvatore] Univ Pisa, Dipartimento Informat, I-56127 Pisa, Italy	Ruggieri, S (reprint author), Univ Pisa, Dipartimento Informat, Lgo B Pontecorvo 3, I-56127 Pisa, Italy.	ruggieri@di.unipi.it					Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; Agrawal R., 1994, P 20 INT C VER LARG, P487; Baesens B, 2003, J OPER RES SOC, V54, P627, DOI 10.1057/palgrave.jors.2601545; Becker G., 1957, EC DISCRIMINATION; BERKA P, 1999, PKDD 1999 DISCOVERY; Chien CF, 2008, EXPERT SYST APPL, V34, P280, DOI 10.1016/j.eswa.2006.09.003; CLIFTON C, 2003, P ACM SIGKDD INT C K; GASTWIRTH JL, 1992, AM STAT, V46, P55, DOI 10.2307/2684414; GOETHALS B, 2009, FREQUENT ITEMSET MIN; Hand D. J., 2001, IMA Journal of Management Mathematics, V12, DOI 10.1093/imaman/12.2.139; Hand DJ, 1997, J R STAT SOC A STAT, V160, P523; HARFORD T, 2008, LOGIC LIFE; HINTOGLU AA, 2005, P 5 IEEE INT C DAT M, P645; Holzer HJ, 2006, J POLICY ANAL MANAG, V25, P463, DOI 10.1002/pam.20181; HUNTER R, 1992, INDIRECT DISCRIMINAT; KAMIRAN F, 2009, P IEEE INT C COMP CO; KAYE D, 1992, STAT METHODS DISCRIM; KNOPFF R, 1986, CAN PUBLIC POL, V12, P573, DOI 10.2307/3550667; Knuth D, 1997, FUNDAMENTAL ALGORITH; KUHN P, 1987, AM ECON REV, V77, P567; Lacour-Little M., 1999, J REAL ESTATE LIT, V7, P15, DOI 10.1023/A:1008616203852; Liu B, 1998, P 4 INT C KNOWL DISC, P80; LIU K, 2009, PRIVACY PRESERVING D; Makkonen T., 2007, MEASURING DISCRIMINA; Newman D.J., 1998, UCI REPOSITORY MACHI; Pedreschi D., 2008, P ACM SIGKDD INT C K, P560, DOI 10.1145/1401890.1401959; Pedreschi D., 2009, P SIAM INT C DAT MIN, P581; PIETTE MJ, 1999, J FORENSIC EC, V12, P43, DOI 10.5085/0898-5510-12.1.43; Rauch J, 2005, APPL INTELL, V22, P9, DOI 10.1023/B:APIN.0000047380.15356.7a; RAUCH J, 2001, P INT C APPL PROLOG, P285; RAUCH J, 2009, 4 FT MINER PROCEDURE; RIACH P., 2002, ECON J, V112, P480, DOI DOI 10.1111/1468-0297.00080; Squires GD, 2003, J URBAN AFF, V25, P391, DOI 10.1111/1467-9906.t01-1-00168; Srikant R., 1995, P 21 INT C VER LARG, P407; Stoll MA, 2004, IND LABOR RELAT REV, V57, P267, DOI 10.2307/4126620; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P571, DOI 10.1142/S021848850200165X; SWEENEY L. A., 2001, THESIS MIT CAMBRIDGE; Tan PN, 2004, INFORM SYST, V29, P293, DOI 10.1016/S0306-4379(03)00072-3; Thomas LC, 2000, INT J FORECASTING, V16, P149, DOI 10.1016/S0169-2070(00)00034-0; VAIDYA J., 2006, PRIVACY PRESERVING D; Verykios VS, 2004, IEEE T KNOWL DATA EN, V16, P434, DOI 10.1109/TKDE.2004.1269668; Viaene S, 2002, J RISK INSUR, V69, P373, DOI 10.1111/1539-6975.00023; Vojtek M, 2006, FINANC UVER, V56, P152; Wang K., 2005, P 5 IEEE INT C DAT M, P466; Wu XD, 2004, ACM T INFORM SYST, V22, P381, DOI 10.1145/1010614.1010616; Yin XX, 2003, SIAM PROC S, P331	46	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAY	2010	4	2								10.1145/1754428.1754432		40	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VZ	WOS:000208168800004	
J	Vadera, S				Vadera, Sunil			CSNL: A Cost-Sensitive Non-Linear Decision Tree Algorithm	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Decision tree learning; cost-sensitive learning		This article presents a new decision tree learning algorithm called CSNL that induces Cost-Sensitive Non-Linear decision trees. The algorithm is based on the hypothesis that nonlinear decision nodes provide a better basis than axis-parallel decision nodes and utilizes discriminant analysis to construct nonlinear decision trees that take account of costs of misclassification. The performance of the algorithm is evaluated by applying it to seventeen datasets and the results are compared with those obtained by two well known cost-sensitive algorithms, ICET and MetaCost, which generate multiple trees to obtain some of the best results to date. The results show that CSNL performs at least as well, if not better than these algorithms, in more than twelve of the datasets and is considerably faster. The use of bagging with CSNL further enhances its performance showing the significant benefits of using nonlinear decision nodes.	Univ Salford, Sch Comp Sci & Engn, Salford M5 4WK, Lancs, England	Vadera, S (reprint author), Univ Salford, Sch Comp Sci & Engn, Salford M5 4WK, Lancs, England.	S.Vadera@salford.ac.uk					Abe N., 2004, P 10 ACM SIGKDD INT, P3, DOI 10.1145/1014052.1014056; Allwein E.L., 2000, P 17 INT C MACH LEAR, P9; ALTHOFF K, 1995, REV IND CASE BASED R; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bennett KP, 1999, ADVANCES IN KERNEL METHODS, P307; Berry M. J. A., 2004, DATA MINING TECHNIQU; Blake C, 1998, UCI REPOSITORY MACHI; BRADFORD J, 1998, LECT NOTES COMPUTER, V398, P131; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRESLOW L, 1997, P 6 INT WORKSH ART I, P67; Breslow LA, 1997, KNOWL ENG REV, V12, P1, DOI 10.1017/S0269888997000015; BROWN G, 2009, P 5 UK S KNOWL DISC, P34; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; DRAPER BA, 1994, IEEE T PATTERN ANAL, V16, P888, DOI 10.1109/34.310684; Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5; Elkan C, 2001, P 17 INT JOINT C ART, P973; Esmeir S, 2008, J ARTIF INTELL RES, V33, P1; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Fan W., 1999, P 16 INT C MACH LEAR, P97; FISHER RA, 1936, ANN EUGEN, V8, P179; FRANK E., 1998, REDUCED ERROR PRUNIN; GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; Ji SH, 2007, PATTERN RECOGN, V40, P1474, DOI 10.1016/j.patcog.2006.11.008; Johnson R. A., 1998, APPL MULTIVARIATE ST; KANANI P, 2008, P WORKSH COST SENS L; KNOLL U, 1994, P 8 EUR C MACH LEARN, V2, P383; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Ling CX, 2006, IEEE T KNOWL DATA EN, V18, P1055, DOI 10.1109/TKDE.2006.131; MARGINEANTU D, 2001, THESIS OREGAN STATE; Martin A., 1997, P EUROSPEECH, P1895; MASNADISHIRAZI H, 2008, P NEUR INF PROC SYST, P1049; Masnadi-Shirazi H., 2007, P 24 INT C MACH LEAR, P609, DOI 10.1145/1273496.1273573; Merler S., 2003, Information Fusion, V4, DOI 10.1016/S1566-2535(02)00100-8; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; Murthy S, 1994, J ARTIFICIAL INTELLI, V2, P1; Nilsson Nils J., 1965, LEARNING MACHINES; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Pazzani MJ, 2000, IEEE INTELL SYST APP, V15, P10, DOI 10.1109/5254.850821; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SAVAGE LJ, 1971, J AM STAT ASSOC, V66, P783, DOI 10.2307/2284229; Swets J. A., 1964, SIGNAL DETECTION REC; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; Ting K., 2000, P 17 INT C MACH LEAR, P983; TING K. M., 1998, P 10 EUR C MACH LEAR, P190; Turney P., 2000, P WORKSH COST SENS L, P15; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; VADERA S, 2005, INDUCING COST SENSIT; VADERA S, 2001, P 2 EUR C INT MAN SY, P79; Vadera S, 2005, EXPERT SYST, V22, P206, DOI 10.1111/j.1468-0394.2005.00311.x; Zadrozny B., 2003, P 3 IEEE INT C DAT M, P435; ZHU X, 2007, P 20 INT JOINT C ART, P1168	59	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAY	2010	4	2								10.1145/1754428.1754429		25	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VZ	WOS:000208168800001	
J	Rosales, RE; Rao, RB				Rosales, Romer E.; Rao, R. Bharat			Guest Editorial: Special Issue on impacting patient care by mining medical data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Rosales, Romer E.; Rao, R. Bharat] Siemens Healthcare, Malvern, PA USA	Rosales, RE (reprint author), Siemens Healthcare, Malvern, PA USA.	romer.rosales@siemens.com					BILGIN CC, 2009, ECM AWARE CELL GRAPH; DAVIS DA, 2009, TIME CARE RECOMMENDA; JIANG X, 2009, REAL TIME TEMPORAL B; NOREN GN, 2009, TEMPORAL PATTERN DIS; ROSSET S, 2009, MED DATA MINING INSI	5	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2010	20	3			SI		325	327		10.1007/s10618-010-0167-9		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	578EK	WOS:000276276100001	
J	Jiang, X; Cooper, GF				Jiang, Xia; Cooper, Gregory F.			A real-time temporal Bayesian architecture for event surveillance and its application to patient-specific multiple disease outbreak detection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Temporal disease outbreak detection; Bayesian network; Patient-specific model; Mining ED chief complaint data; Uncertainty modeling; Biosurveillance	RECOGNITION; TUTORIAL	Reliable and accurate detection of disease outbreaks remains an important research topic in disease outbreak surveillance. A temporal surveillance system bases its analysis on data not only from the most recent time period, but also on data from previous time periods. A non-temporal system only looks at data from the most recent time period. There are two difficulties with a non-temporal system when it is used to monitor real data which often contain noise. First, it is prone to produce false positive signals during non-outbreak time periods. Second, during an outbreak, it tends to release false negative signals early in the outbreak, which can adversely affect the decision making process of the user of the system. We conjecture that by converting a non-temporal system to a temporal one, we may attenuate these difficulties inherent in a non-temporal system. In this paper, we propose a Bayesian network architecture for a class of temporal event surveillance models called BayesNet-T. Using this Bayesian network architecture, we can convert certain non-temporal surveillance systems to temporal ones. We apply this architecture to a previously developed non-temporal multiple-disease outbreak detection system called PC and create a temporal system called PCT. PCT takes Emergency Department (ED) patient chief complaint data as its input. The PCT system was constructed using both data (non-outbreak diseases) and expert assessments (outbreak diseases). We compare PCT to PC using a real influenza outbreak. Furthermore, we compare PCT to both PC and the classic statistical methods CUSUM and EWMA using a total of 240 influenza and Cryptosporidium disease outbreaks created by injecting stochastically simulated outbreak cases into real ED admission data. Our results indicate that PCT has a smaller mean time to detection than PC at low false alarm rates, and that PCT is more stable than PC in that once an outbreak is detected, PCT is better at maintaining the detection signal on future days.	[Jiang, Xia; Cooper, Gregory F.] Univ Pittsburgh, Sch Med, Dept Biomed Informat, Pittsburgh, PA 15260 USA	Jiang, X (reprint author), Univ Pittsburgh, Sch Med, Dept Biomed Informat, Pittsburgh, PA 15260 USA.	xij6@pitt.edu; gfc@pitt.edu					BARON MI, 2002, CASE STUDIES BAYESIA; BOS T, 1992, PACIFIC BASIN CAPITA; Box G.E.P, 1994, TIME SERIES ANAL FOR; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cooper G. F., 2004, P 20 C UNC ART INT, P94; COOPER GF, 2007, ADV DIS SURVEILLANCE, V2, P45; Fawcett T., 1999, P 5 ACM SIGKDD INT C, P53, DOI 10.1145/312129.312195; Hamilton JD, 1994, TIME SERIES ANAL; Hogan WR, 2007, STAT MED, V26, P5225, DOI 10.1002/sim.3093; Jiang PP, 2006, MOL ECOL NOTES, V6, P1160, DOI 10.1111/j.1471-8286.2006.01472.x; Jiang X, 2008, THESIS U PITTSBURGH; Jiang X, 2010, INT J APPROX REASON, V51, P224, DOI 10.1016/j.ijar.2009.01.001; JIANG X, 2007, ADV DIS SURVEILL, V2, P15; Kulldorff M, 1997, COMMUN STAT-THEOR M, V26, P1481, DOI 10.1080/03610929708831995; Kulldorff M, 2005, PLOS MED, V2, P216, DOI 10.1371/journal.pmed.0020059; Kulldorff M, 2007, STAT MED, V26, P1824, DOI 10.1002/sim.2818; KULLDORFF M, 2004, SATSCAN V 4 0 SOFTWA; Montgomery DC, 2001, INTRO STAT QUALITY C; MOORE A, 2006, HDB BIOSURVEILLANCE; MOORE A, 2001, POWERPOINT TUTORIAL; Neill D, 2005, ADV NEURAL INFORM PR, V18, P1003; Neill D., 2005, P 11 ACM SIGKDD INT, P218, DOI 10.1145/1081870.1081897; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Reis BY, 2003, P NATL ACAD SCI USA, V100, P1961, DOI 10.1073/pnas.0335026100; Reis Ben Y, 2003, BMC Med Inform Decis Mak, V3, P2, DOI 10.1186/1472-6947-3-2; SERFLING RE, 1963, PUBLIC HEALTH REP, V78, P494, DOI 10.2307/4591848; SHMUELI G, 2006, STAT METHODS COUNTER; Sonesson C, 2003, J ROY STAT SOC A STA, V166, P5, DOI 10.1111/1467-985X.00256; Stirling R, 2001, Can Commun Dis Rep, V27, P185; Sun LL, 2007, EUR J OPER RES, V180, P738, DOI 10.1016/j.ejor.2006.04.019; TSUI FC, 2001, S J AM MED INFORM AS, V9, P4; Wong W.K., 2006, HDB BIOSURVEILLANCE	32	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2010	20	3			SI		328	360		10.1007/s10618-009-0151-4		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	578EK	WOS:000276276100002	
J	Noren, GN; Hopstadius, J; Bate, A; Star, K; Edwards, IR				Noren, G. Niklas; Hopstadius, Johan; Bate, Andrew; Star, Kristina; Edwards, I. Ralph			Temporal pattern discovery in longitudinal electronic patient records	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Temporal pattern discovery; Longitudinal patient records; Electronic health records	DRUG REACTION SURVEILLANCE; CASE SERIES; SAFETY; ASSOCIATIONS; DATABASE; EVENTS	Large collections of electronic patient records provide a vast but still underutilised source of information on the real world use of medicines. They are maintained primarily for the purpose of patient administration, but contain a broad range of clinical information highly relevant for data analysis. While they are a standard resource for epidemiological confirmatory studies, their use in the context of exploratory data analysis is still limited. In this paper, we present a framework for open-ended pattern discovery in large patient records repositories. At the core is a graphical statistical approach to summarising and visualising the temporal association between the prescription of a drug and the occurrence of a medical event. The graphical overview contrasts the observed and expected number of occurrences of the medical event in different time periods both before and after the prescription of interest. In order to effectively screen for important temporal relationships, we introduce a new measure of temporal association, which contrasts the observed-to-expected ratio in a time period immediately after the prescription to the observed-to-expected ratio in a control period 2 years earlier. An important feature of both the observed-to-expected graph and the measure of temporal association is a statistical shrinkage towards the null hypothesis of no association, which provides protection against highlighting spurious associations. We demonstrate the usefulness of the proposed pattern discovery methodology by a set of examples from a collection of over two million patient records in the United Kingdom. The identified patterns include temporal relationships between drug prescriptions and medical events suggestive of persistent and transient risks of adverse events, possible beneficial effects of drugs, periodic co-occurrence, and systematic tendencies of patients to switch from one medication to another.	[Noren, G. Niklas; Hopstadius, Johan; Bate, Andrew; Star, Kristina; Edwards, I. Ralph] WHO Collaborating Ctr Int Drug Monitoring, Uppsala, Sweden; [Noren, G. Niklas] Stockholm Univ, Dept Math, S-10691 Stockholm, Sweden; [Bate, Andrew] Brunel Univ, Sch Informat Syst Comp & Math, London, England	Noren, GN (reprint author), WHO Collaborating Ctr Int Drug Monitoring, Uppsala, Sweden.	niklas.noren@who-umc.org	Noren, G. Niklas/D-4739-2012				Agrawal R., 1995, 11 INT C DAT ENG, P3; Bate A, 1998, EUR J CLIN PHARMACOL, V54, P315, DOI 10.1007/s002280050466; Brown JS, 2007, PHARMACOEPIDEM DR S, V16, P1275, DOI 10.1002/pds.1509; DuMouchel W, 1999, AM STAT, V53, P177, DOI 10.2307/2686093; FARRINGTON CP, 1995, BIOMETRICS, V51, P228, DOI 10.2307/2533328; Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1; Hocine MN, 2009, J ROY STAT SOC A STA, V172, P213, DOI 10.1111/j.1467-985X.2008.00555.x; Hopstadius J, 2008, DRUG SAFETY, V31, P1035, DOI 10.2165/00002018-200831110-00008; Jin HD, 2008, IEEE T INF TECHNOL B, V12, P488, DOI 10.1109/TITB.2007.900808; KEIM DA, 2007, SIGKDD EXPLOR, V9, P3; Lindquist M, 2000, DRUG SAFETY, V23, P533, DOI 10.2165/00002018-200023060-00004; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Noren G. N., 2008, P 14 ACM SIGKDD INT, P963, DOI 10.1145/1401890.1402005; Noren GN, 2007, DATA MIN KNOWL DISC, V14, P305, DOI 10.1007/s10618-006-0052-8; Noren GN, 2006, STAT MED, V25, P3740, DOI 10.1002/sim.2473; Noren GN, 2008, STAT MED, V27, P3057, DOI 10.1002/sim.3247; Pirmohamed M, 2004, BRIT MED J, V329, P15, DOI 10.1136/bmj.329.7456.15; Wadman M, 2007, NATURE, V446, P358, DOI 10.1038/446358b	18	16	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2010	20	3			SI		361	387		10.1007/s10618-009-0152-3		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	578EK	WOS:000276276100003	
J	Davis, DA; Chawla, NV; Christakis, NA; Barabasi, AL				Davis, Darcy A.; Chawla, Nitesh V.; Christakis, Nicholas A.; Barabasi, Albert-Laszlo			Time to CARE: a collaborative engine for practical disease prediction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Collaborative filtering; Prospective medicine; Disease prediction; Electronic healthcare record	MEDICINE; RISK; ASSOCIATION; PREVALENCE; SYSTEMS	The monumental cost of health care, especially for chronic disease treatment, is quickly becoming unmanageable. This crisis has motivated the drive towards preventative medicine, where the primary concern is recognizing disease risk and taking action at the earliest signs. However, universal testing is neither time nor cost efficient. We propose CARE, a Collaborative Assessment and Recommendation Engine, which relies only on patient's medical history using ICD-9-CM codes in order to predict future disease risks. CARE uses collaborative filtering methods to predict each patient's greatest disease risks based on their own medical history and that of similar patients. We also describe an Iterative version, ICARE, which incorporates ensemble concepts for improved performance. Also, we apply time-sensitive modifications which make the CARE framework practical for realistic long-term use. These novel systems require no specialized information and provide predictions for medical conditions of all kinds in a single run. We present experimental results on a large Medicare dataset, demonstrating that CARE and ICARE perform well at capturing future disease risks.	[Davis, Darcy A.; Chawla, Nitesh V.] Univ Notre Dame, Dept Comp Sci & Engn, Interdisciplinary Ctr Network Sci & Applicat, Notre Dame, IN 46556 USA; [Christakis, Nicholas A.] Harvard Univ, Sch Med, Boston, MA USA; [Barabasi, Albert-Laszlo] Northeastern Univ, Boston, MA 02115 USA	Chawla, NV (reprint author), Univ Notre Dame, Dept Comp Sci & Engn, Interdisciplinary Ctr Network Sci & Applicat, Notre Dame, IN 46556 USA.	ddavis4@nd.edu; nchawla@nd.edu; christak@hcp.med.harvard.edu; alb@neu.edu	Christakis, Nicholas/C-3205-2009		Arthur J. Schmitt Foundation	The work was supported in part by the Arthur J. Schmitt Foundation.	Barabasi AL, 2007, NEW ENGL J MED, V357, P404, DOI 10.1056/NEJMe078114; Breese John S., 1998, MSRTR9812; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHERRY DK, 2001, ADV DATA, V337, P1; Christakis NA, 2006, NEW ENGL J MED, V354, P719, DOI 10.1056/NEJMsa050196; CORDN O, 2002, P 8 IB C AI, P381; Coyle PK, 2002, MULT SCLER, V8, P2, DOI 10.1191/1352458502ms735oa; DAVIS D, 2008, P ACM C INF KNOWL MA; DAVIS D, 2008, P KDD 2008 WORKSH MI; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; Edelman D, 2006, J GEN INTERN MED, V21, P728, DOI 10.1111/j.1525-1497.2006.0495.x; Glasgow RE, 2001, MILBANK Q, V79, P579, DOI 10.1111/1468-0009.00222; GOLDBERG K, 2000, EIGENTASTE CONSTANT; GRCAR M, 2005, WEBKDD; HECKERMAN D, 2001, MSRTR200016; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Hofmann T., 1999, P 16 INT JOINT C ART, P688; Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774; HUNT JR, 1995, AM J PUBLIC HEALTH, V85, P722, DOI 10.2105/AJPH.85.5.722; Kahn CE, 2005, J DIGIT IMAGING, V18, P131, DOI 10.1007/s10278-004-1910-9; KANNEL WB, 1961, ANN INTERN MED, V55, P33; Koertge J, 2003, AM J CARDIOL, V91, P1316, DOI 10.1016/S0002-9149(03)00320-5; Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126; LAUDERDALE DS, 1993, EPIDEMIOL REV, V15, P319; LIU Y, 2007, 2007 IEEE INT S BIOM; LOSCALZO J, 2007, MOL SYST BIOL; Loscalzo J, 2007, CIRCULATION, V116, P1866, DOI 10.1161/CIRCULATIONAHA.107.741611; MITCHELL JB, 1994, MED CARE S, V32, P38; Mould RF, 2003, LANCET, V361, P262, DOI 10.1016/S0140-6736(03)12299-4; PATEREK A, 2007, KDDCUP; PENNOCK DM, 1999, P IJCAI WORKSH MACH; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Salton G., 1983, INTRO MODERN INFORM; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; SI L, 2003, P ICML; SNYDERMAN R, 2003, PROSPECTIVE MED NEXT; Starfield Barbara, 2003, Ann Fam Med, V1, P8, DOI 10.1370/afm.1; van den Akker M, 1998, J CLIN EPIDEMIOL, V51, P367, DOI 10.1016/S0895-4356(97)00306-5; Burton PR, 2007, NATURE, V447, P661, DOI 10.1038/nature05911; Weston AD, 2004, J PROTEOME RES, V3, P179, DOI 10.1021/pr0499693; WONG DT, 1991, CAN J ANAESTH, V38, P374; *NC HLTH STAT, 2007, INT CLASS DIS; *NC I, 2007, CANC TRENDS PROGR RE	43	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2010	20	3			SI		388	415		10.1007/s10618-009-0156-z		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	578EK	WOS:000276276100004	
J	Bilgin, CC; Bullough, P; Plopper, GE; Yener, B				Bilgin, Cemal Cagatay; Bullough, Peter; Plopper, George E.; Yener, Buelent			ECM-aware cell-graph mining for bone tissue modeling and classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Colored cell-graphs; Cancer diagnosis; Graph mining; Tissue classification	SUPPORT VECTOR MACHINES; BREAST-CANCER DIAGNOSIS; IDENTIFICATION; CARCINOMA; SELECTION; CYTOLOGY; TEXTURE	Pathological examination of a biopsy is the most reliable and widely used technique to diagnose bone cancer. However, it suffers from both inter- and intra- observer subjectivity. Techniques for automated tissue modeling and classification can reduce this subjectivity and increases the accuracy of bone cancer diagnosis. This paper presents a graph theoretical method, called extracellular matrix (ECM)-aware cell-graph mining, that combines the ECM formation with the distribution of cells in hematoxylin and eosin stained histopathological images of bone tissues samples. This method can identify different types of cells that coexist in the same tissue as a result of its functional state. Thus, it models the structure-function relationships more precisely and classifies bone tissue samples accurately for cancer diagnosis. The tissue images are segmented, using the eigenvalues of the Hessian matrix, to compute spatial coordinates of cell nuclei as the nodes of corresponding cell-graph. Upon segmentation a color code is assigned to each node based on the composition of its surrounding ECM. An edge is hypothesized (and established) between a pair of nodes if the corresponding cell membranes are in physical contact and if they share the same color. Hence, multiple colored-cell-graphs coexist in a tissue each modeling a different cell-type organization. Both topological and spectral features of ECM-aware cell-graphs are computed to quantify the structural properties of tissue samples and classify their different functional states as healthy, fractured, or cancerous using support vector machines. Classification accuracy comparison to related work shows that the ECM-aware cell-graph approach yields 90.0% whereas Delaunay triangulation and the simple cell-graph approach achieves 75.0 and 81.1% accuracy, respectively.	[Bilgin, Cemal Cagatay; Yener, Buelent] Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA; [Plopper, George E.] Rensselaer Polytech Inst, Dept Biol, Troy, NY 12180 USA; [Bullough, Peter] Hosp Special Surg, Dept Lab Med, New York, NY 10021 USA	Bilgin, CC (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.	bilgic@cs.rpi.edu; plopg@rpi.edu; yener@cs.rpi.edu					BECKER W., 2000, WORLD CELL; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; BILGIN C, 2007, ENG MED BIOL SOC 200, P5311; Byun H, 2002, LECT NOTES COMPUT SC, V2388, P213; Chen YW, 2006, STUD FUZZ SOFT COMP, V207, P315; Choi HK, 1997, ANAL CELL PATHOL, V15, P1; Chung F, 1997, SPECTRAL GRAPH THEOR; Demir C., 2005, AUTOMATED CANC DIAGN; DOYLE S, 2007, BIOM IM NAN MACR 200, P1284; Einstein AJ, 1998, J PATHOL, V185, P366; ERSOY I, 2008, 15 IEEE INT C IM PRO, P1804; Esgiar AN, 1998, ANAL QUANT CYTOL, V20, P297; Esgiar AN, 2002, IEEE T INF TECHNOL B, V6, P54, DOI 10.1109/4233.992163; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GANSTER H, 2001, MED IMAGING IEEE T, V20, P233; Glotsos D., 2003, Proceedings of the International Conference of Computational Methods in Sciences and Engineering 2003 (ICCMSE 2003); Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gunduz C, 2004, BIOINFORMATICS, V20, P145, DOI 10.1093/bioinformatics/bth933; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hamilton PW, 1997, J PATHOL, V182, P68; HAMILTON PW, 1987, HISTOPATHOLOGY, V11, P901, DOI 10.1111/j.1365-2559.1987.tb01897.x; Hladuvka J., 2001, 9th International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision 2001. in co-operation with EUROGRAPHICS and IFIP WG 5.10. WSCG'2001. Conference Proceedings; Hodneland E, 2009, INT J COMPUT VISION, V82, P264, DOI 10.1007/s11263-008-0199-4; Hsu C.W., 2003, PRACTICAL GUIDE SUPP; Ibanez L., 2005, ITK SOFTWARE GUIDE; Jain R., 2004, AUSTRALIASIAN PHYS E, V27, P147; Keenan SJ, 2000, J PATHOL, V192, P351, DOI 10.1002/1096-9896(2000)9999:9999<::AID-PATH708>3.0.CO;2-I; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Pena-Reyes CA, 1999, ARTIF INTELL MED, V17, P131, DOI 10.1016/S0933-3657(99)00019-6; Platt JC, 2000, ADV NEUR IN, P61; Schnorrenberg F, 1996, Technol Health Care, V4, P147; Siek J. G., 2002, BOOST GRAPH LIB USER; Tasoulis DK, 2003, LECT NOTES ARTIF INT, V2773, P199; TODMAN AG, 2001, EL COMP ENG 2001 CAN, V2; Weyn B, 1999, CYTOMETRY, V35, P23, DOI 10.1002/(SICI)1097-0320(19990101)35:1<23::AID-CYTO4>3.0.CO;2-P; WOLBERG WH, 1995, HUM PATHOL, V26, P792, DOI 10.1016/0046-8177(95)90229-5; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X; *TOC VIEW, 1998, INF TECHNOL BIOMED I, V2, P197	42	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2010	20	3			SI		416	438		10.1007/s10618-009-0153-2		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	578EK	WOS:000276276100005	
J	Rosset, S; Perlich, C; Swirszcz, G; Melville, P; Liu, Y				Rosset, Saharon; Perlich, Claudia; Swirszcz, Grzergorz; Melville, Prem; Liu, Yan			Medical data mining: insights from winning two competitions	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Medical data mining; Leakage; Model evaluation; Relational learning		Two major data mining competitions in 2008 presented challenges in medical domains: KDD Cup 2008, which concerned cancer detection from mammography data; and Informs Data Mining Challenge 2008, dealing with diagnosis of pneumonia based on patient information from hospital files. Our team won both of these competitions, and in this paper we share our lessons learned and insights. We emphasize the aspects that pertain to the general practice and methodology of medical data mining, rather than to the specifics of each modeling competition. We concentrate on three topics: information leakage, its effect on competitions and proof-of-concept projects; consideration of real-life model performance measures in model construction and evaluation; and relational learning approaches to medical data mining tasks.	[Perlich, Claudia; Swirszcz, Grzergorz; Melville, Prem; Liu, Yan] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA; [Rosset, Saharon] Tel Aviv Univ, Sch Math Sci, IL-69978 Tel Aviv, Israel	Perlich, C (reprint author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.	saharon@post.tau.ac.il; perlich@us.ibm.com; swirszcz@us.ibm.com; pmelvil@us.ibm.com; liuya@us.ibm.com			EU [MIRG-CT-2007-208019]	thank the organizers of both competitions, whose efforts made possible the enjoyable and instructive experiences we discuss here. Saharon Rosset's research is partially supported by EU grant MIRG-CT-2007-208019.	Bandos Al, 2008, BIOMETRICS, V65, P247; DELUCA PM, 2008, J ICRU, V8, P31; Domingos P., 2007, INTRO STAT RELATIONA; FERRI C, 2002, P INT C MACH LEARN; Getoor L, 2007, INTRO STAT RELATIONA; Glymour C, 1987, DISCOVERING CAUSAL S; INGER A, 2000, KDD CUP 2000 QUESTIO; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 2005, P INT C MACH LEARN; KOU Z, 2007, P INT C DAT MIN; KROGEL MA, 2003, P INT C IND LOG PROG; Lawrence R, 2007, IBM SYST J, V46, P797; MELVILLE P, 2008, P C KNOWL DISC DAT M; MUGGLETON S, 1994, J LOGIC PROGRAM, V20, P629; Perlich C, 2006, MACH LEARN, V62, P65, DOI 10.1007/s10994-006-6064-1; PERLICH C, 2005, P C IND LOG PROGR; PERLICH C, 2008, BREAST CANC IDENTIFI; Platt J. C., 1998, ADV LARGE MARGIN CLA; RAO RB, 2008, KDD CUP 2008 WORKSH; ROSSET S, 2007, MAKING MOST YOUR DAT; RUSS TA, 1989, P 13 ANN S COMP APPL; Saar-Tsechansky M, 2001, Top Health Inf Manage, V22, P24; Shahar Y, 2000, ANN INTERN MED, V132, P45; SIMON HA, 1954, J AM STAT ASSOC, V49, P467, DOI 10.2307/2281124; TURNEY P, 2000, P WORKSH COST SENS L; Valentini G., 2003, INT C MACH LEARN; WEISS GM, 2008, DATA MIN KNOWL DISCO, V17; WHITE K, 1997, HDB PSYCHOPHARMACOLO, P123; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; YAN R, 2004, P IEEE C COMP VIS PA; *NIST SEMATECH, 2006, E HDB STAT METH, pCH1	31	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2010	20	3			SI		439	468		10.1007/s10618-009-0158-x		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	578EK	WOS:000276276100006	
J	Chawla, S; Hand, D; Dhar, V				Chawla, Sanjay; Hand, David; Dhar, Vasant			Outlier detection special issue	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Chawla, Sanjay; Hand, David; Dhar, Vasant] Univ Sydney, Sydney, NSW 2006, Australia	Chawla, S (reprint author), Univ Sydney, Sydney, NSW 2006, Australia.	chawla@it.usyd.edu.au						0	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2010	20	2			SI		189	190		10.1007/s10618-009-0163-0		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	562XI	WOS:000275088800001	
J	Wu, JJ; Xiong, H; Chen, J				Wu, Junjie; Xiong, Hui; Chen, Jian			COG: local decomposition for rare class analysis	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Rare class analysis; Local clustering; Support vector machines (SVMs); K-means clustering		Given its importance, the problem of predicting rare classes in large-scale multi-labeled data sets has attracted great attention in the literature. However, rare class analysis remains a critical challenge, because there is no natural way developed for handling imbalanced class distributions. This paper thus fills this crucial void by developing a method for classification using local clustering (COG). Specifically, for a data set with an imbalanced class distribution, we perform clustering within each large class and produce sub-classes with relatively balanced sizes. Then, we apply traditional supervised learning algorithms, such as support vector machines (SVMs), for classification. Along this line, we explore key properties of local clustering for a better understanding of the effect of COG on rare class analysis. Also, we provide a systematic analysis of time and space complexity of the COG method. Indeed, the experimental results on various real-world data sets show that COG produces significantly higher prediction accuracies on rare classes than state-of-the-art methods and the COG scheme can greatly improve the computational performance of SVMs. Furthermore, we show that COG can also improve the performances of traditional supervised learning algorithms on data sets with balanced class distributions. Finally, as two case studies, we have applied COG for two real-world applications: credit card fraud detection and network intrusion detection.	[Xiong, Hui] Rutgers State Univ, Rutgers Business Sch, Dept Management Sci & Informat Syst, Newark, NJ 07102 USA; [Wu, Junjie] Beihang Univ, Sch Econ & Management, Dept Informat Syst, Beijing, Peoples R China; [Chen, Jian] Tsinghua Univ, Sch Econ & Management, Dept Management Sci & Engn, Beijing 100084, Peoples R China	Xiong, H (reprint author), Rutgers State Univ, Rutgers Business Sch, Dept Management Sci & Informat Syst, Newark, NJ 07102 USA.	wujj@buaa.edu.cn; hxiong@rutgers.edu; chenj@sem.tsinghua.edu.cn			National Natural Science Foundation of China (NSFC) [70901002, 70621061, 70890082]; National Science Foundation (NSF) [CNS 0831186]; Rutgers Seed Funding for Collaborative Computing Research; Ministry of Education of China [360285]; Beihang University [221531]	This research was partially supported by the National Natural Science Foundation of China (NSFC) (No. 70901002, 70621061, 70890082), National Science Foundation (NSF) via grant number CNS 0831186, and the Rutgers Seed Funding for Collaborative Computing Research. This work was also supported in part by the Doctoral Fund of Ministry of Education of China (No. 360285), and the Lan Tian Xin Xiu 2008 Seed Funding of Beihang University (No. 221531).	Boser B., 1992, P 5 ANN WORKSH COMP, V21, P144, DOI DOI 10.1145/130385.130401; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cristianini N., 2000, INTRO SUPPORT VECTOR; DeGroot M. H., 2001, PROBABILITY STAT; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; DRUMMOND C, 2003, P 20 INT C MACH LEAR; Duda R., 1973, PATTERN CLASSIFICATI; Duda R. O., 2000, PATTERN CLASSIFICATI; Elkan C, 2001, P 17 INT JOINT C ART, P973; Fan W., 1999, P 16 INT C MACH LEAR, P97; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; GENKIN A, 2005, BMR BAYESIAN MULTINO; HAN EH, 1998, P 2 INT C AUT AG; JAPKOWICZ N, 2002, P IASTED INT C ART I, P321; Joshi M. V., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989527; JOSHI MV, 2001, P ACM SIGMOD C SANT, P91, DOI 10.1145/375663.375673; KARYPIS G, 2003, CLUTO SOFTWARE CLUST; Kubat M, 1997, P 9 EUR C MACH LEARN, P146; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; MacQueen J.B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Maimon O., 2005, DATA MINING KNOWLEDG; MARGINEANTU D, 1999, LEARNING DECISION TR; Newman D.J., 1998, UCI REPOSITORY MACHI; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; QUINLAN R, 1992, C4 5 RELEASE 8; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; RIDDLE P, 1994, APPL ARTIF INTELL, V8, P125, DOI 10.1080/08839519408945435; Tan P.N, 2005, INTRO DATA MINING; Vapnik V.N., 1995, NATURE STAT LEARNING; Weiss G. M., 2004, ACM SIGKDD EXPLORATI, V6, P7, DOI 10.1145/1007730.1007734; Weiss G. M., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Witten IH, 2005, DATA MINING PRACTICA; Wu J, 2007, P 13 ACM SIGKDD INT, P814, DOI 10.1145/1281192.1281279; Xiong H., 2006, P 12 ACM SIGKDD INT, P779, DOI 10.1145/1150402.1150503; Zadrozny B., 2003, P 3 IEEE INT C DAT M, P435; ZURADA J, 2001, KNOWLEDGE DISCOVERY, P397	40	5	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2010	20	2			SI		191	220		10.1007/s10618-009-0146-1		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	562XI	WOS:000275088800002	
J	Janeja, VP; Adam, NR; Atluri, V; Vaidya, J				Janeja, Vandana P.; Adam, Nabil R.; Atluri, Vijayalakshmi; Vaidya, Jaideep			Spatial neighborhood based anomaly detection in sensor datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Outlier detection; Spatial neighborhood; Sensors	DATA SETS; OUTLIERS; PATTERNS; CLUSTER	Success of anomaly detection, similar to other spatial data mining techniques, relies on neighborhood definition. In this paper, we argue that the anomalous behavior of spatial objects in a neighborhood can be truly captured when both (a) spatial autocorrelation (similar behavior of nearby objects due to proximity) and (b) spatial heterogeneity (distinct behavior of nearby objects due to difference in the underlying processes in the region) are taken into consideration for the neighborhood definition. Our approach begins by generating micro neighborhoods around spatial objects encompassing all the information about a spatial object. We selectively merge these based on spatial relationships accounting for autocorrelation and inferential relationships accounting for heterogeneity, forming macro neighborhoods. In such neighborhoods, we then identify (i) spatio-temporal outliers, where individual sensor readings are anomalous, (ii) spatial outliers, where the entire sensor is an anomaly, and (iii) spatio-temporally coalesced outliers, where a group of spatio-temporal outliers in the macro neighborhood are separated by a small time lag indicating the traversal of the anomaly. We demonstrate the effectiveness of our approach in neighborhood formation and anomaly detection with experimental results in (i) water monitoring and (ii) highway traffic monitoring sensor datasets. We also compare the results of our approach with an existing approach for spatial anomaly detection.	[Adam, Nabil R.; Atluri, Vijayalakshmi; Vaidya, Jaideep] Rutgers State Univ, Newark, NJ 07102 USA; [Janeja, Vandana P.] Univ Maryland Baltimore Cty, ITE 429, Baltimore, MD 21250 USA	Vaidya, J (reprint author), Rutgers State Univ, 1 Washington Pk, Newark, NJ 07102 USA.	vjaneja@umbc.edu; adam@adam.rutgers.edu; atluri@business.rutgers.edu; jsvaidya@business.rutgers.edu					Aurenhammer F., 1991, ACM COMPUT SURV, V23, P345, DOI DOI 10.1145/116873.116880; Birant D., 2006, Journal of Computing and Information Technology - CIT, V14, DOI 10.2498/cit.2006.04.04; Chatfield C., 1983, STAT TECHNOLOGY COUR; DASGUPTA D, 1999, INT C INT SYST; ESTER M, 1996, KDD, P44; ESTER M, 1998, 4 INT C KDD; Ester M, 1999, LECT NOTES ARTIF INT, V1701, P61; ESTER M, 1997, 5 INT S ADV SPAT DAT, P47; ESTIVILLCASTRO V, 2000, 5 INT C GEOC; Griffith D, 1987, SPATIAL AUTOCORRELAT; Haining R., 2003, SPATIAL DATA ANAL TH; Huang Y, 2004, IEEE T KNOWL DATA EN, V16, P1472, DOI 10.1109/TKDE.2004.90; Huang Y, 2006, GEOINFORMATICA, V10, P239, DOI 10.1007/s10707-006-9827-8; KANG I, 1997, 5 ACM INT WORKSH ADV, P35, DOI DOI 10.1145/267825.267836; Kang JM, 2008, IEEE DATA MINING, P851, DOI 10.1109/ICDM.2008.117; Kaufman L., 1990, FINDING GROUPS DATA; Keogh E., 2002, 8 ACM SIGKDD INT C K, P550, DOI DOI 10.1145/775047.775128; Knorr E. M., 1998, 24 INT C VER LARG DA, P392; KOU YF, 2007, ICTAI 2007, V1, P281; Kulldorff M, 1997, COMMUN STAT-THEOR M, V26, P1481, DOI 10.1080/03610929708831995; Kulldorff M, 1998, AM J PUBLIC HEALTH, V88, P1377, DOI 10.2105/AJPH.88.9.1377; Lu CT, 2003, PROC INT C TOOLS ART, P122; Lu CT, 2007, INFORM SCIENCES, V177, P1609, DOI 10.1016/j.ins.2006.09.013; MCGUIRE MP, 2008, P 2 INT WORKSH KNOWL; Miller H. J., 2001, GEOGRAPHIC DATA MINI; MORAN P, 1948, J R STAT SOC B, V10, P51; NAUS JI, 1965, J AM STAT ASSOC, V60, P532, DOI 10.2307/2282688; Ng R., 1994, 20 INT C VER LARG DA, P144; Okabe A., 2000, SPATIAL TESSELLATION; SHAHABI C, 2000, 12 INT C SCI STAT DA; SHEKHAR S, 2001, 7 ACM INT C KNOWL DI, P371, DOI DOI 10.1145/502512.502567; Shekhar S, 2003, GEOINFORMATICA, V7, P139, DOI 10.1023/A:1023455925009; SHEKHAR S, 2002, IEEE TRANSACTION MUL; SHEWCHUK J. R., 1996, WORKSH APPL COMP GEO, P203; Sun P, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P209; UNWIN D, 1982, INTRO SPATIAL ANAL; *ARC, 2002, ARC IMS 4 0 ARCVIEW; *USGS, 2002, NASQAN	38	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2010	20	2			SI		221	258		10.1007/s10618-009-0147-0		38	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	562XI	WOS:000275088800003	
J	Koufakou, A; Georgiopoulos, M				Koufakou, Anna; Georgiopoulos, Michael			A fast outlier detection strategy for distributed high-dimensional data sets with mixed attributes	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Outlier detection; Anomaly detection; Data mining; Distributed data sets; Mixed attribute data sets; High-dimensional data sets	LOCAL OUTLIERS	Outlier detection has attracted substantial attention in many applications and research areas; some of the most prominent applications are network intrusion detection or credit card fraud detection. Many of the existing approaches are based on calculating distances among the points in the dataset. These approaches cannot easily adapt to current datasets that usually contain a mix of categorical and continuous attributes, and may be distributed among different geographical locations. In addition, current datasets usually have a large number of dimensions. These datasets tend to be sparse, and traditional concepts such as Euclidean distance or nearest neighbor become unsuitable. We propose a fast distributed outlier detection strategy intended for datasets containing mixed attributes. The proposed method takes into consideration the sparseness of the dataset, and is experimentally shown to be highly scalable with the number of points and the number of attributes in the dataset. Experimental results show that the proposed outlier detection method compares very favorably with other state-of-the art outlier detection strategies proposed in the literature and that the speedup achieved by its distributed version is very close to linear.	[Koufakou, Anna] Florida Gulf Coast Univ, UA Whitaker Sch Engn, Ft Myers, FL 33965 USA; [Koufakou, Anna; Georgiopoulos, Michael] Univ Cent Florida, Sch EECS, Orlando, FL 32816 USA	Koufakou, A (reprint author), Florida Gulf Coast Univ, UA Whitaker Sch Engn, Ft Myers, FL 33965 USA.	akoufakou@fgcu.edu; michaelg@mail.ucf.edu					ACUNA E, 2004, META ANAL STUDY OUTL; AGGARWAL CC, 2001, ACM SIGMOD RECORD, V30, P37, DOI 10.1145/376284.375668; Agrawal R., 1994, P 20 INT C VER LARG, P487; Aha D.W., 1994, P AAAI 94 WORKSH CAS, P106; Angiulli F, 2005, IEEE T KNOWL DATA EN, V17, P203, DOI 10.1109/TKDE.2005.31; BARNETT V., 1978, OUTLIERS STAT DATA; Bay SD, 2003, P 9 ACM SIGKDD INT C, P29; Beyer K., 1999, P 7 INT C DAT THEOR, P217; BIBA M, 2007, P 20 INT C AI HYDR I, P696; Blake C, 1998, UCI REPOSITORY MACHI; Bolton RJ, 2002, STAT SCI, V17, P235; BRANCH J, 2006, P 26 INT C DISTR COM; Breunig MM, 2000, SIGMOD REC, V29, P93; Calders T, 2004, LECT NOTES ARTIF INT, V3848, P64; Catlett J., 1991, THESIS U SYDNEY AUST; Dean J., 2004, USENIX S OP SYST DES; Dokas P., 2002, P NSF WORKSH NEXT GE, P21; Ertoz L, 2003, SIAM PROC S, P47; Geerts F, 2005, ACM T DATABASE SYST, V30, P333, DOI 10.1145/1071610.1071611; Hawkins D. M., 1980, IDENTIFICATION OUTLI; Hawkins S., 2002, P 4 INT C DAT WAR KN, P170; HAYS CL, 2004, NY TIMES        1114; He Z., 2006, P 10 PAC AS C KNOWL, P567; Hettich S., 1999, UCI KDD ARCH; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1007/s10462-004-4304-y; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Knuth D., 1968, ART COMPUTER PROGRAM, V<IT>1</IT>; KOUFAKOU A, 2007, IEEE INT C TOOLS ART, P210; Koufakou A, 2008, IEEE IJCNN, P3298, DOI 10.1109/IJCNN.2008.4634266; KOUFAKOU A, 2008, INT C DAT MIN DMIN, P427; Latecki LJ, 2007, LECT NOTES ARTIF INT, V4571, P61; Lazarevic A, 2003, SIAM PROC S, P25; Mehta S, 2005, IEEE T KNOWL DATA EN, V17, P1174, DOI 10.1109/TKDE.2005.153; Otey ME, 2006, DATA MIN KNOWL DISC, V12, P203, DOI 10.1007/s10618-005-0014-6; Papadimitriou S, 2003, PROC INT CONF DATA, P315, DOI 10.1109/ICDE.2003.1260802; PENNY KI, 2001, STATISTICIAN, V50, P295; Preparata FP, 1985, COMPUTATIONAL GEOMET; ROBERTS S, 1994, NEURAL COMPUT, V6, P270, DOI 10.1162/neco.1994.6.2.270; Rousseeuw P., 1985, MATH STAT APPL, V8, P283; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Tan P.N, 2005, INTRO DATA MINING; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Yu JX, 2006, KNOWL INF SYST, V9, P309, DOI 10.1007/s10115-005-0197-6	44	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2010	20	2			SI		259	289		10.1007/s10618-009-0148-z		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	562XI	WOS:000275088800004	
J	Angiulli, F; Fassetti, F				Angiulli, Fabrizio; Fassetti, Fabio			Distance-based outlier queries in data streams: the novel task and algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Data streams; Anomaly detection; Distance-based outliers		This work proposes a method for detecting distance-based outliers in data streams under the sliding window model. The novel notion of one-time outlier query is introduced in order to detect anomalies in the current window at arbitrary points-in-time. Three algorithms are presented. The first algorithm exactly answers to outlier queries, but has larger space requirements than the other two. The second algorithm is derived from the exact one, reduces memory requirements and returns an approximate answer based on estimations with a statistical guarantee. The third algorithm is a specialization of the approximate algorithm working with strictly fixed memory requirements. Accuracy properties and memory consumption of the algorithms have been theoretically assessed. Moreover experimental results have confirmed the effectiveness of the proposed approach and the good quality of the solutions.	[Angiulli, Fabrizio; Fassetti, Fabio] Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, DEIS, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.	f.angiulli@deis.unical.it; f.fassetti@deis.unical.it					AGGARWAL CC, 2001, P INT C MAN DAT SIGM; AGGARWAL CC, 2005, SIAM DATA MINING; Angiulli F, 2005, IEEE T KNOWL DATA EN, V17, P203, DOI 10.1109/TKDE.2005.31; Angiulli F, 2006, IEEE T KNOWL DATA EN, V18, P145, DOI 10.1109/TKDE.2006.29; ANGIULLI F, 2007, CIKM 07, P791; Angiulli F, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497581; Arning A., 1996, P 2 INT C KNOWL DISC, P164; Babcock B., 2002, P 21 ACM SIGACT SIGM, P1; Barnett V., 1994, OUTLIERS STAT DATA; BAY SD, 2003, P INT C KNOWL DISC D; BREUNIG MM, 2000, P INT C MAN DAT SIGM; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; DARPA DARPA Intrusion Detection Evaluation, 1998, INTR DET EV; Eskin E., 2002, APPL DATA MINING COM; GHOTING A, 2006, P SIAM INT C DAT MIN; Golab L, 2003, SIGMOD REC, V32, P5; JIN W, 2001, P ACM SIGKDD INT C K; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; KNUTHD, 1997, ART COMPUTER PROGRAM, V3; Lazarevic A., 2003, P SIAM INT C DAT MIN; Milne P., 2000, KNOWLEDGE DISCOVERY, P320; Mood A.M., 1974, INTRO THEORY STAT; PAPADIMITRIOU S, 2003, ICDE, P315; Papadimitriou S, 2003, PROC INT CONF DATA, P315, DOI 10.1109/ICDE.2003.1260802; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; SUBRAMANIAM S, 2006, INT C VER LARG DAT B; Tao Y., 2006, P 12 ACM SIGKDD INT, P394, DOI 10.1145/1150402.1150447; WATANABE O, 2000, TIEICE IEICE T COMMU	30	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2010	20	2			SI		290	324		10.1007/s10618-009-0159-9		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	562XI	WOS:000275088800005	
J	Yan, H; Chen, KK; Liu, L; Yi, Z				Yan, Hua; Chen, Keke; Liu, Ling; Yi, Zhang			SCALE: a scalable framework for efficiently clustering transactional data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Transactional data clustering; Cluster assessment; Cluster validation; Frequent itemset mining; Weighted coverage density	ALGORITHM	This paper presents SCALE, a fully automated transactional clustering framework. The SCALE design highlights three unique features. First, we introduce the concept of Weighted Coverage Density as a categorical similarity measure for efficient clustering of transactional datasets. The concept of weighted coverage density is intuitive and it allows the weight of each item in a cluster to be changed dynamically according to the occurrences of items. Second, we develop the weighted coverage density measure based clustering algorithm, a fast, memory-efficient, and scalable clustering algorithm for analyzing transactional data. Third, we introduce two clustering validation metrics and show that these domain specific clustering evaluation metrics are critical to capture the transactional semantics in clustering analysis. Our SCALE framework combines the weighted coverage density measure for clustering over a sample dataset with self-configuring methods. These self-configuring methods can automatically tune the two important parameters of our clustering algorithms: (1) the candidates of the best number K of clusters; and (2) the application of two domain-specific cluster validity measures to find the best result from the set of clustering results. We have conducted extensive experimental evaluation using both synthetic and real datasets and our results show that the weighted coverage density approach powered by the SCALE framework can efficiently generate high quality clustering results in a fully automated manner.	[Chen, Keke] Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA; [Yan, Hua] Univ Elect Sci & Technol China, Sch Engn & Comp Sci, Computat Intelligence Lab, Chengdu 610054, Peoples R China; [Liu, Ling] Georgia Inst Technol, Coll Comp, Atlanta, GA 30280 USA; [Yi, Zhang] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China	Chen, KK (reprint author), Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.	keke.chen@wright.edu; zhangyi@scu.edu.cn			Chinese 863 High-Tech Program [2008AA01Z132]; NSF CISE CyberTrust; IBM SUR; IBM	The first and last authors are partly supported by Chinese 863 High-Tech Program under Grant 2008AA01Z132. The third author thanks for the partial support from grants in NSF CISE CyberTrust program, IBM SUR grant, and IBM Faculty Award.	Abello J., 2002, P 5 LAT AM S THEOR I, P598; Aggarwal CC, 2002, IEEE T KNOWL DATA EN, V14, P51, DOI 10.1109/69.979972; Agrawal R., 1994, P 20 INT C VER LARG, P487; ANDRITSOS P., 2004, P INT C EXT DAT TECH, P123; Babcock B, 2003, P 22 ACM SIGMOD SIGA, P234, DOI 10.1145/773153.773176; Barbara D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Brijs T, 1999, P 5 INT C KNOWL DISC, P254, DOI 10.1145/312129.312241; Chakrabarti D, 2004, P 10 ACM SIGKDD INT, P79, DOI 10.1145/1014052.1014064; CHEN K, 2005, P INT C SCI STAT DAT, P253; CHEN K., 2006, P ACM C INF KNOWL MG, P367, DOI 10.1145/1183614.1183668; Chen K., 2004, Information Visualization, V3, DOI 10.1057/palgrave.ivs.9500076; Dhillon I. S, 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Ding C. H. Q., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989507; Ganti V., 1999, P 5 ACM SIGKDD INT C, P73, DOI 10.1145/312129.312201; Gibson D., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Guha S., 2000, Proceedings 41st Annual Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2000.892124; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Halkidi M, 2002, SIGMOD RECORD, V31, P40; Hastie T., 2001, ELEMENTS STAT LEARNI; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Li T., 2004, P INT C MACH LEARN I, P68; Li YR, 2006, LECT NOTES COMPUT SC, V4304, P1069; Meil M., 2005, P 22 INT C MACH LEAR, P577, DOI 10.1145/1102351.1102424; Mishra N., 2003, P 16 COLT, P448; ONG KL, 2004, P ZAR SPAIN, P209; Ordonez C, 2003, P 8 ACM SIGMOD WORKS, P12; Tishby N., 1999, P 37 ANN ALL C COMM, P368; Wang K, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P483, DOI 10.1145/319950.320054; YAN H, 2005, P INT C ADV DAT MIN, P248; Yang Y., 2002, P 8 ACM SIGKDD INT C, P682; Zha H., 2001, P 10 INT C INF KNOWL, P25	32	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN 10	2010	20	1					1	27		10.1007/s10618-009-0134-5		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	546LN	WOS:000273812400001	
J	Zhang, ZY; Li, T; Ding, C; Ren, XW; Zhang, XS				Zhang, Zhong-Yuan; Li, Tao; Ding, Chris; Ren, Xian-Wen; Zhang, Xiang-Sun			Binary matrix factorization for analyzing gene expression data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Biclustering; Non-negative matrix factorization; Boundedness property of NMF; Binary matrix	MICROARRAY DATA; ONTO-EXPRESS; ERROR; ORGANIZATION; ALGORITHMS; NETWORK; ARRAYS; MODEL; PARTS	The advent of microarray technology enables us to monitor an entire genome in a single chip using a systematic approach. Clustering, as a widely used data mining approach, has been used to discover phenotypes from the raw expression data. However traditional clustering algorithms have limitations since they can not identify the substructures of samples and features hidden behind the data. Different from clustering, biclustering is a new methodology for discovering genes that are highly related to a subset of samples. Several biclustering models/methods have been presented and used for tumor clinical diagnosis and pathological research. In this paper, we present a new biclustering model using Binary Matrix Factorization (BMF). BMF is a new variant rooted from non-negative matrix factorization (NMF). We begin by proving a new boundedness property of NMF. Two different algorithms to implement the model and their comparison are then presented. We show that the microarray data biclustering problem can be formulated as a BMF problem and can be solved effectively using our proposed algorithms. Unlike the greedy strategy-based algorithms, our proposed algorithms for BMF are more likely to find the global optima. Experimental results on synthetic and real datasets demonstrate the advantages of BMF over existing biclustering methods. Besides the attractive clustering performance, BMF can generate sparse results (i.e., the number of genes/features involved in each biclustering structure is very small related to the total number of genes/features) that are in accordance with the common practice in molecular biology.	[Li, Tao] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA; [Zhang, Zhong-Yuan] Cent Univ Finance & Econ, Sch Stat, Beijing, Peoples R China; [Ding, Chris] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA; [Ren, Xian-Wen; Zhang, Xiang-Sun] Chinese Acad Sci, Acad Math & Syst Sci, Beijing, Peoples R China	Li, T (reprint author), Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.	taoli@cis.fiu.edu					Ben-Dor A., 2002, RECOMB 02, P49; Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Carmona-Saez P, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-78; Chee M, 1996, SCIENCE, V274, P610, DOI 10.1126/science.274.5287.610; Cheng Y., 2000, P 8 INT C INT SYST M, P93; Cooper M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P25; Dhillon I., 2005, ADV NEURAL INFORM PR, V17; Ding C., 2005, P SIAM DAT MIN C; DING C, 2006, P NAT C ART INT AAAI; DING C, 2006, LBNL60428 U CAL; Draghici S, 2003, NUCLEIC ACIDS RES, V31, P3775, DOI 10.1093/nar/gkg624; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FODOR SPA, 1991, SCIENCE, V251, P767, DOI 10.1126/science.1990438; Gaussier E., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Gordon GJ, 2002, CANCER RES, V62, P4963; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Huber Wolfgang, 2002, Bioinformatics, V18 Suppl 1, pS96; Ideker T, 2000, J COMPUT BIOL, V7, P805, DOI 10.1089/10665270050514945; Ihmels J, 2004, BIOINFORMATICS, V20, P1993, DOI 10.1093/bioinformatics/bth166; Ihmels J, 2002, NAT GENET, V31, P370, DOI 10.1038/ng941; Khatri P, 2002, GENOMICS, V79, P266, DOI 10.1006/geno.2002.6698; Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134; Koyuturk M, 2006, ACM T MATH SOFTWARE, V32, P33, DOI 10.1145/1132973.1132976; LATORRE FD, 2006, P 23 INT C MACH LEAR; Lee D.D., 2001, ADV NEURAL INFORM PR, V13; Lee DD, 1999, NATURE, V401, P788; Li SZ, 2001, PROC CVPR IEEE, P207; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; LI T., 2005, P 11 ACM SIGKDD INT, P188, DOI 10.1145/1081870.1081894; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Pauca VP, 2004, SIAM PROC S, P452; Prelic A, 2006, BIOINFORMATICS, V22, P1122, DOI 10.1093/bioinformatics/btl060; Rocke DM, 2001, J COMPUT BIOL, V8, P557, DOI 10.1089/106652701753307485; Sha F, 2002, ADV NEURAL INFORM PR, V15, P1041; Sharan R, 2003, BIOINFORMATICS, V19, P1787, DOI 10.1093/bioinformatics/btg232; Srebro N., 2005, ADV NEURAL INFORM PR; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; TAMAYO P, 1999, P NATL ACAD SCI US, V96; Tanay Amos, 2002, Bioinformatics, V18 Suppl 1, pS136; Tanay A, 2004, P NATL ACAD SCI USA, V101, P2981, DOI 10.1073/pnas.0308661100; VAVASIS SA, 2007, COMPLEXITY NONNEGATI; Xie YL, 1998, J CHEMOMETR, V12, P357, DOI 10.1002/(SICI)1099-128X(199811/12)12:6<357::AID-CEM523>3.0.CO;2-S; Xu W, 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Zeimpekis D, 2005, SIAM PROC S, P631; Zhang Z., 2007, P 2007 IEEE INT C DA	47	6	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN 10	2010	20	1					28	52		10.1007/s10618-009-0145-2		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	546LN	WOS:000273812400002	
J	Wagstaff, KL; Kocurek, M; Mazzoni, D; Tang, BY				Wagstaff, Kiri L.; Kocurek, Michael; Mazzoni, Dominic; Tang, Benyang			Progressive refinement for support vector machines	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Support vector machines; Efficiency; Reclassification	MISR	Support vector machines (SVMs) have good accuracy and generalization properties, but they tend to be slow to classify new examples. In contrast to previous work that aims to reduce the time required to fully classify all examples, we present a method that provides the best-possible classification given a specific amount of computational time. We construct two SVMs: a "full" SVM that is optimized for high accuracy, and an approximation SVM (via reduced-set or subset methods) that provides extremely fast, but less accurate, classifications. We apply the approximate SVM to the full data set, estimate the posterior probability that each classification is correct, and then use the full SVM to reclassify items in order of their likelihood of misclassification. Our experimental results show that this method rapidly achieves high accuracy, by selectively devoting resources (reclassification) only where needed. It also provides the first such progressive SVM solution that can be applied to multiclass problems.	[Wagstaff, Kiri L.; Mazzoni, Dominic; Tang, Benyang] CALTECH, Jet Prop Lab, Pasadena, CA 91109 USA; [Kocurek, Michael] CALTECH, Pasadena, CA 91125 USA	Wagstaff, KL (reprint author), CALTECH, Jet Prop Lab, 4800 Oak Grove Dr, Pasadena, CA 91109 USA.	kiri.wagstaff@jpl.nasa.gov; mikekocurek@gmail.com; dmazzoni@google.com; benyang.tang@jpl.nasa.gov			National Aeronautics and Space Administration; NASA Advanced Information Systems Technology; National Science Foundation [IIS-0705681]	We wish to thank Dennis DeCoste, Robert Granat, and the anonymous reviewers for their helpful comments and suggestions. The research described in this paper was performed at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration. We gratefully acknowledge the support of a grant from the NASA Advanced Information Systems Technology program and grant #IIS-0705681 from the National Science Foundation. The MISR remote-sensing data was obtained from the Langley Atmospheric Science Data Center.	Burges C. J. C., 1996, P 13 INT C MACH LEAR, P71; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CASTANO R, 2007, P 13 INT C KNOWL DIS, P922, DOI 10.1145/1281192.1281291; Chien S., 2005, J AEROSPACE COMPUTIN, V2, P196, DOI 10.2514/1.12923; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DECOSTE D, 2002, P INT C MACH LEARN I, P99; DECOSTE D, 2003, P SIAM INT C DAT MIN; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DECOSTE D, 2003, P 20 INT C MACH LEAR, P115; Diner DJ, 1998, IEEE T GEOSCI REMOTE, V36, P1072, DOI 10.1109/36.700992; Duan Kai-Bo, 2005, P 6 INT WORKSH MULT, P278; Hastie T, 1998, ANN STAT, V26, P451; HT Lin, 2003, NOTE PLATTS PROBABIL; Mazzoni D, 2007, REMOTE SENS ENVIRON, V107, P149, DOI 10.1016/j.rse.2006.06.021; Newman D.J., 1998, UCI REPOSITORY MACHI; Platt J. C., 1999, ADV LARGE MARGIN CLA, P61; Ratsch M, 2004, LECT NOTES COMPUT SC, V3175, P62; Romdhani S., 2001, P 8 INT C COMP VIS, VII, P695, DOI 10.1109/ICCV.2001.937694; Tang B, 2006, P 23 INT C MACH LEAR, P921, DOI 10.1145/1143844.1143960	19	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN 10	2010	20	1					53	69		10.1007/s10618-009-0149-y		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	546LN	WOS:000273812400003	
J	Kimura, M; Saito, K; Nakano, R; Motoda, H				Kimura, Masahiro; Saito, Kazumi; Nakano, Ryohei; Motoda, Hiroshi			Extracting influential nodes on a social network for information diffusion	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Social network analysis; Information diffusion model; Influence maximization problem; Bond percolation	COMPLEX NETWORKS; PERCOLATION; MODEL	We address the combinatorial optimization problem of finding the most influential nodes on a large-scale social network for two widely-used fundamental stochastic diffusion models. The past study showed that a greedy strategy can give a good approximate solution to the problem. However, a conventional greedy method faces a computational problem. We propose a method of efficiently finding a good approximate solution to the problem under the greedy algorithm on the basis of bond percolation and graph theory, and compare the proposed method with the conventional method in terms of computational complexity in order to theoretically evaluate its effectiveness. The results show that the proposed method is expected to achieve a great reduction in computational cost. We further experimentally demonstrate that the proposed method is much more efficient than the conventional method using large-scale real-world networks including blog networks.	[Kimura, Masahiro] Ryukoku Univ, Dept Elect & Informat, Otsu, Shiga 5202194, Japan; [Saito, Kazumi] Univ Shizuoka, Sch Adm & Informat, Shizuoka 4228526, Japan; [Nakano, Ryohei] Chubu Univ, Dept Comp Sci, Aichi 4878501, Japan; [Motoda, Hiroshi] Osaka Univ, Inst Sci & Ind Res, Osaka 5670047, Japan	Kimura, M (reprint author), Ryukoku Univ, Dept Elect & Informat, Otsu, Shiga 5202194, Japan.	kimura@rins.ryukoku.ac.jp; k-saito@u-shizuoka-ken.ac.jp; nakano@cs.chubu.ac.jp; motoda@ar.sanken.osaka-u.ac.jp					Callaway DS, 2000, PHYS REV LETT, V85, P5468, DOI 10.1103/PhysRevLett.85.5468; Chung F., 2002, ANN COMB, V6, P125, DOI DOI 10.1007/PL00012580; Domingos P, 2005, IEEE INTELL SYST, V20, P80; Domingos P, 2001, P 7 ACM SIGKDD INT C, P57, DOI 10.1145/502512.502525; Even-Dar E, 2007, LECT NOTES COMPUT SC, V4858, P281; Goldenberg J, 2001, MARKET LETT, V12, P211, DOI 10.1023/A:1011122126881; GRASSBERGER P, 1983, MATH BIOSCI, V63, P157; Gruhl D., 2004, P 13 INT WORLD WID W, P107; Kempe D, 2005, LECT NOTES COMPUT SC, V3580, P1127; Kempe D, 2003, P 9 ACM SIGKDD INT C, P137; LESKOVEC J, 2007, P 13 ACM SIGKDD INT, P420, DOI 10.1145/1281192.1281239; LESKOVEC J, 2006, P 7 ACM C EL COMM EC, P228, DOI 10.1145/1134707.1134732; MCCALLUM A, 2005, P 19 INT JOINT C ART, P786; Molloy M, 1998, COMB PROBAB COMPUT, V7, P295, DOI 10.1017/S0963548398003526; Newman MEJ, 2001, P NATL ACAD SCI USA, V98, P404, DOI 10.1073/pnas.021544898; Newman MEJ, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.016128; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Newman MEJ, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.036122; Richardson M, 2002, P 8 ACM SIGKDD INT C, P61; Saito K, 2008, LECT NOTES ARTIF INT, V5212, P326, DOI 10.1007/978-3-540-87481-2_22; Watts DJ, 2002, P NATL ACAD SCI USA, V99, P5766, DOI 10.1073/pnas.082090499; Watts DJ, 2007, J CONSUM RES, V34, P441, DOI 10.1086/518527	22	18	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN 10	2010	20	1					70	97		10.1007/s10618-009-0150-5		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	546LN	WOS:000273812400004	
J	Bjelland, J; Burgess, M; Canright, G; Engo-Monsen, K				Bjelland, J.; Burgess, M.; Canright, G.; Engo-Monsen, K.			Eigenvectors of directed graphs and importance scores: dominance, T-Rank, and sink remedies	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph mining; Web searches; Node ranking; Link analysis		We study the properties of the principal eigenvector for the adjacency matrix (and related matrices) for a general directed graph. In particular-motivated by the use of the eigenvector for estimating the "importance" of the nodes in the graph-we focus on the distribution of positive weight in this eigenvector, and give a coherent picture which builds upon and unites earlier results. We also propose a simple method-"T-Rank"-for generating importance scores. T-Rank generates authority scores via a one-level, non-normalized matrix, and is thus distinct from known methods such as PageRank (normalized), HITS (two-level), and SALSA (two-level and normalized). We show, using our understanding of the principal eigenvector, that T-Rank has a much less severe "sink problem" than does PageRank. Also, we offer numerical results which quantify the "tightly-knit community" or TKC effect. We find that T-Rank has a stronger TKC effect than PageRank, and we offer a novel interpolation method which allows for continuous tuning of the strength of this TKC effect. Finally, we propose two new "sink remedies", i.e., methods for ensuring that the principal eigenvector is positive everywhere. One of our sink remedies (source pumping) is unique among sink remedies, in that it gives a positive eigenvector without rendering the graph strongly connected. We offer a preliminary evaluation of the effects and possible applications of these new sink remedies.	[Burgess, M.] Oslo Univ Coll, Oslo, Norway; [Bjelland, J.; Canright, G.; Engo-Monsen, K.] Telenor Res & Innovat, N-1331 Fornebu, Norway	Burgess, M (reprint author), Oslo Univ Coll, Oslo, Norway.	mark@iu.hio.no			EU [001907, P2P IR]	We would like to thank Gerhard Weikum for a critical reading of the manuscript. JB, GC, and KEM acknowledge partial support by the EU within the 6th Framework Programme under contract 001907 (DELIS) and by the European Commission Sixth Framework Programme project SAPIR: Search in Audio-visual content using P2P IR.	Adamic L. A., 2005, LINKKDD 05, P36; Arasu A, 2002, P 11 INT WORLD WID W; AVRACHENKOV K, 2007, WORKSH ALG MOD WEB G; BAEZAYATES R, 2002, LECT NOTES COMPUTER, V2476, P117; Berkhin P., 2005, INTERNET MATH, V2, P73, DOI 10.1080/15427951.2005.10129098; BERMAN A, 2009, ENCY COMPLEXITY SYST; Berman A., 1979, NONNEGATIVE MATRICES; Bianchini M., 2005, ACM Transactions on Internet Technology, V5, DOI 10.1145/1052934.1052938; BJELLAND J, 2008, TELEKTRONIKK, V1, P95; BJELLAND J, 2009, ENCY COMPLEXITY SYST; Boldi P., 2004, P 13 INT WORLD WID W, P595, DOI 10.1145/988672.988752; BOLDI P, 2005, WWW 05, P557; Broder A, 2000, P 9 INT WORLD WID WE, P247; DING CHQ, 2002, SIGIR, P353; DONATO D, 2005, P 8 INT WORKSH WEB D, P145; Ebel H, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.035103; Farkas IJ, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.026704; Gantmacher F. R., 1959, THEORY MATRICES, VII; GLEICH D, 2006, MATLABBGL; Goh KI, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.051903; Gospodnetic O., 2004, LUCENE ACTION; Harary F., 1965, STRUCTURAL MODELS IN; Hirai J, 2000, COMPUT NETW, V33, P277, DOI 10.1016/S1389-1286(00)00063-3; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Langville A. N, 2006, GOOGLES PAGERANK SCI; Langville A.N., 2004, INTERNET MATH, V1, P335, DOI 10.1080/15427951.2004.10129091; Langville AN, 2005, SIAM REV, V47, P135, DOI 10.1137/S0036144503424786; Lempel R, 2001, ACM T INFORM SYST, V19, P131, DOI 10.1145/382979.383041; Meila M., 2007, SDM; Motwani R., 1995, RANDOMIZED ALGORITHM; Ng A.Y., 2001, IJCAI, P903; Ng A. Y., 2001, SIGIR Forum; Page L., 1998, PAGERANK CITATION RA; ROTHBLUM UG, 1975, LINEAR ALGEBRA APPL, V12, P281, DOI 10.1016/0024-3795(75)90050-6; Tarjan R., 1972, SIAM Journal on Computing, V1, DOI 10.1137/0201010; VICTORY HD, 1985, SIAM J ALGEBRA DISCR, V6, P406; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z	37	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN 10	2010	20	1					98	151		10.1007/s10618-009-0154-1		54	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	546LN	WOS:000273812400005	
J	Costa, G; Manco, G; Ortale, R				Costa, Gianni; Manco, Giuseppe; Ortale, Riccardo			An incremental clustering scheme for data de-duplication	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Clustering-mining methods and algorithms; Record classification; Indexing methods and structures; Locality-sensitive hashing; Min-wise independent permutations; Approximated similarity measures; De-duplication	METRIC-SPACES	We propose an incremental technique for discovering duplicates in large databases of textual sequences, i.e., syntactically different tuples, that refer to the same real-world entity. The problem is approached from a clustering perspective: given a set of tuples, the objective is to partition them into groups of duplicate tuples. Each newly arrived tuple is assigned to an appropriate cluster via nearest-neighbor classification. This is achieved by means of a suitable hash-based index, that maps any tuple to a set of indexing keys and assigns tuples with high syntactic similarity to the same buckets. Hence, the neighbors of a query tuple can be efficiently identified by simply retrieving those tuples that appear in the same buckets associated to the query tuple itself, without completely scanning the original database. Two alternative schemes for computing indexing keys are discussed and compared. An extensive experimental evaluation on both synthetic and real data shows the effectiveness of our approach.	[Costa, Gianni; Manco, Giuseppe; Ortale, Riccardo] ICAR CNR, I-87036 Arcavacata Di Rende, CS, Italy	Manco, G (reprint author), ICAR CNR, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.	costa@icar.cnr.it; manco@icar.cnr.it; ortale@icar.cnr.it					Agichtein E., 2004, P 10 ACM SIGKDD INT, P20, DOI 10.1145/1014052.1014058; Ananthakrishna R., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; ARASU A., 2006, P 32 INT C VER LARG, P918; BAWA M., 2005, P 14 INT C WORLD WID, P651, DOI 10.1145/1060745.1060840; BAYARDO R. J., 2007, P 16 INT C WORLD WID, P131, DOI 10.1145/1242572.1242591; Bhattacharya I, 2004, P 9 ACM SIGMOD WORKS, P11, DOI 10.1145/1008694.1008697; Bilenko M., 2003, P KDD 2003 WORKSH DA, P7; Bilenko M., 2003, P 9 ACM SIGKDD INT C, P39; Broder A. Z., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276781; BRODER A. Z., 1997, P 6 INT WORLD WID WE, P1157; Cesario E, 2008, KNOWL INF SYST, V15, P285, DOI 10.1007/s10115-007-0085-3; Cesario E., 2005, Proceedings. 9th International Database Engineering and Applications Symposium (IDEAS 2005); Chaudhuri S, 2003, P ACM SIGMOD INT C M, P313; Chaudhuri S, 2005, PROC INT CONF DATA, P865; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; COCHINWALA M, 2005, RECORD MATCHING PRES; Cohen W., 2002, P 8 ACM SIGKDD INT C, P475; COHEN W, 2001, P ACM SIGIR WORKSH M, P13; Cohen W.W., 2003, P IJCAI 03 WORKSH IN, P73; Ester M, 1996, P 2 INT C KNOWL DISC, P226; FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061; Ganti V, 1999, PROC INT CONF DATA, P502, DOI 10.1109/ICDE.1999.754966; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gravano L., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Gu L., 2003, 0383 CSIRO MATH INF; Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3; Gunsfield D., 1997, ALGORITHMS STRINGS T; Hernandez M., 1995, P 1995 ACM SIGMOD IN, P127, DOI 10.1145/223784.223807; Hjatason G.R., 2003, ACM T DATABASE SYST, V28, P517; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; IPEIROTIS PG, 2007, IEEE T KNOWL DATA EN, V18, P1; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; KALASHNIKOV D, 2005, P SIAM C, P262; McCallum A., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347123; Monge A., 1996, P 2 INT C KNOWL DISC, P267; Monge A.E., 1997, P SIGMOD WORKSH RES, P23; MONGE AE, 2001, P ACM SIGMOD C MAN D; Neiling M., 2003, P KDD WORKSH DAT CLE, P37; Sarawagi S., 2002, P 8 ACM SIGKDD INT C, P269; SARAWAGI S., 2004, P ACM SIGMOD INT C M, P743, DOI 10.1145/1007568.1007652; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Tejada S., 2002, P 8 ACM SIGKDD INT C, P350; UKKONEN E, 1992, THEOR COMPUT SCI, V92, P191, DOI 10.1016/0304-3975(92)90143-4; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Winkler W., 1999, STATE RECORD LINKAGE; Winkler WE, 1990, P SECT SURV RES METH, P354	47	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN 10	2010	20	1					152	187		10.1007/s10618-009-0155-0		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	546LN	WOS:000273812400006	
J	Koren, Y				Koren, Yehuda			Factor in the Neighbors: Scalable and Accurate Collaborative Filtering	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Recommender systems; collaborative filtering; Netflix Prize		Recommender systems provide users with personalized suggestions for products or services. These systems often rely on collaborating filtering (CF), where past transactions are analyzed in order to establish connections between users and products. The most common approach to CF is based on neighborhood models, which originate from similarities between products or users. In this work we introduce a new neighborhood model with an improved prediction accuracy. Unlike previous approaches that are based on heuristic similarities, we model neighborhood relations by minimizing a global cost function. Further accuracy improvements are achieved by extending the model to exploit both explicit and implicit feedback by the users. Past models were limited by the need to compute all pairwise similarities between items or users, which grow quadratically with input size. In particular, this limitation vastly complicates adopting user similarity models, due to the typical large number of users. Our new model solves these limitations by factoring the neighborhood model, thus making both item-item and user-user implementations scale linearly with the size of the data. The methods are tested on the Netflix data, with encouraging results.	[Koren, Yehuda] Yahoo Res, IL-31905 Haifa, Israel	Koren, Y (reprint author), Yahoo Res, Matam Pk, IL-31905 Haifa, Israel.	Yehuda@yahoo-inc.com					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Ali K., 2004, P 10 ACM SIGKDD INT, P394, DOI 10.1145/1014052.1014097; BELL R., 2007, P 13 ACM SIGKDD INT, P95, DOI DOI 10.1145/1281192.1281206; Bell R. M., 2007, SIGKDD EXPLOR NEWSL, V9, P75, DOI DOI 10.1145/1345448.1345465; Bell Robert, 2007, P 7 IEEE INT C DAT M, P43; Bennett J, 2007, P KDD CUP WORKSH; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Canny J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/564376.564419; Das A., 2007, P 16 INT C WORLD WID, P271, DOI 10.1145/1242572.1242610; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Herlocker J. L., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312682; Herlocker JL, 2000, P 2000 ACM C COMP SU, P241, DOI DOI 10.1145/358916.358995; Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774; Kim D, 2005, EXPERT SYST APPL, V28, P823, DOI 10.1016/j.eswa.2004.12.037; Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI 10.1145/1401890.1401944; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; MARLIN B. M., 2007, P 23 C UNC ART INT U; Oard D.W, 1998, P 5 DELOS WORKSH FIL, P31; PARK S. T., 2007, P 13 ACM SIGKDD INT, P550, DOI 10.1145/1281192.1281252; Paterek A., 2007, P KDD CUP WORKSH; PIATETSKY G., 2007, SIGKDD EXPLOR NEWSL, V9, P38; Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Sarwar B, 2000, P ACM WEBKDD WORKSH; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; TAKACS G., 2007, SIGKDD EXPLORATIONS, V9, P80; TINTAREV N, 2007, P 23 INT C DAT ENG W, P801; Wang J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148257	28	10	12	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JAN	2010	4	1							1	10.1145/1644873.1644874		24	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VX	WOS:000208168600001	
J	Plantevit, M; Laurent, A; Laurent, D; Teisseire, M; Choong, YW				Plantevit, Marc; Laurent, Anne; Laurent, Dominique; Teisseire, Maguelonne; Choong, Yeow Wei			Mining Multidimensional and Multilevel Sequential Patterns	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Sequential patterns; frequent patterns; multidimensional databases; hierarchy; multilevel patterns		Multidimensional databases have been designed to provide decision makers with the necessary tools to help them understand their data. This framework is different from transactional data as the datasets contain huge volumes of historicized and aggregated data defined over a set of dimensions that can be arranged through multiple levels of granularities. Many tools have been proposed to query the data and navigate through the levels of granularity. However, automatic tools are still missing to mine this type of data in order to discover regular specific patterns. In this article, we present a method for mining sequential patterns from multidimensional databases, at the same time taking advantage of the different dimensions and levels of granularity, which is original compared to existing work. The necessary definitions and algorithms are extended from regular sequential patterns to this particular case. Experiments are reported, showing the significance of this approach.	[Plantevit, Marc] Univ Lyon 1, F-69622 Villeurbanne, France; [Laurent, Anne] Univ Montpellier 2, F-34095 Montpellier 5, France; [Laurent, Dominique] Univ Cergy Pontoise, Cergy Pontoise, France; [Teisseire, Maguelonne] CEMAGREF Montpellier, Montpellier, France	Plantevit, M (reprint author), Univ Lyon 1, F-69622 Villeurbanne, France.	marc.plantevit@liris.cnrs.fr; laurent@lirmm.fr; dlaurent@u-cergy.fr; teisseire@teledetection.fr; choongyw@help.edu.my					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Ayres J., 2002, P 8 ACM SIGKDD INT C, P429; BEYER K, 1999, P 1999 ACM SIGMOD IN, P359, DOI 10.1145/304182.304214; Bonchi F, 2006, KNOWL INF SYST, V9, P180, DOI 10.1007/s10115-005-0201-1; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Burdick D, 2001, PROC INT CONF DATA, P443, DOI 10.1109/ICDE.2001.914857; Calders T., 2006, LNCS, V3848, P64; Calders T., 2002, LECT NOTES ARTIF INT, V2431, P74; Pinto H., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management; Chiu DY, 2004, PROC INT CONF DATA, P375; DIETTERICH TG, 1985, ARTIF INTELL, V25, P187, DOI 10.1016/0004-3702(85)90003-7; FURTADO D. A., 2004, P S BRAS BANC DAD, P48; Han JW, 1999, IEEE T KNOWL DATA EN, V11, P798; Inmon W. H., 2003, BUILDING DATA WAREHO; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Mannila H., 1996, P 2 INT C KNOWL DISC, P189; Masseglia F, 1998, LECT NOTES ARTIF INT, V1510, P176; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; Pei J., 2000, P ACM SIGMOD WORKSH, P21; Pei J, 2004, IEEE T KNOWL DATA EN, V16, P1424; PLANTEVIT M., 2006, P INT WORKSH DAT WAR, P19, DOI 10.1145/1183512.1183518; Plantevit M, 2005, LECT NOTES ARTIF INT, V3721, P205; RASHAD S., 2007, P S COMP INT DAT MIN, P552; Srikant R.R., 1996, LNCS, V1057, P3; STEFANOWSKI J., 2007, FUNDAMENTA INFORM, V76, P495; Stefanowski J, 2005, LECT NOTES COMPUT SC, V3528, P401; YANG Z., 2006, P INT DAT ENG APPL S, P113; Yu CC, 2005, IEEE T KNOWL DATA EN, V17, P136; Zaki M. J., 2002, P SIAM INT C DAT MIN; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315; Zaki MJ, 2004, DATA MIN KNOWL DISC, V9, P223, DOI 10.1023/B:DAMI.0000040429.96086.c7; ZHANG C., 2007, P INT C FUZZ SYST KN, V2, P730	33	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JAN	2010	4	1							4	10.1145/1644873.1644877		37	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VX	WOS:000208168600004	
J	Syed, Z; Stultz, C; Kellis, M; Indyk, P; Guttag, J				Syed, Zeeshan; Stultz, Collin; Kellis, Manolis; Indyk, Piotr; Guttag, John			Motif Discovery in Physiological Datasets: A Methodology for Inferring Predictive Elements	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Gibbs sampling; knowledge discovery; data mining; motifs; physiological signals; inference	SYMBOLIC ANALYSIS; SIGNALS	In this article, we propose a methodology for identifying predictive physiological patterns in the absence of prior knowledge. We use the principle of conservation to identify activity that consistently precedes an outcome in patients, and describe a two-stage process that allows us to efficiently search for such patterns in large datasets. This involves first transforming continuous physiological signals from patients into symbolic sequences, and then searching for patterns in these reduced representations that are strongly associated with an outcome. Our strategy of identifying conserved activity that is unlikely to have occurred purely by chance in symbolic data is analogous to the discovery of regulatory motifs in genomic datasets. We build upon existing work in this area, generalizing the notion of a regulatory motif and enhancing current techniques to operate robustly on non-genomic data. We also address two significant considerations associated with motif discovery in general: computational efficiency and robustness in the presence of degeneracy and noise. To deal with these issues, we introduce the concept of active regions and new subset-based techniques such as a two-layer Gibbs sampling algorithm. These extensions allow for a framework for information inference, where precursors are identified as approximately conserved activity of arbitrary complexity preceding multiple occurrences of an event. We evaluated our solution on a population of patients who experienced sudden cardiac death and attempted to discover electrocardiographic activity that may be associated with the endpoint of death. To assess the predictive patterns discovered, we compared likelihood scores for motifs in the sudden death population against control populations of normal individuals and those with non-fatal supraventricular arrhythmias. Our results suggest that predictive motif discovery may be able to identify clinically relevant information even in the absence of significant prior knowledge.	[Syed, Zeeshan] Univ Michigan, Ann Arbor, MI 48109 USA; [Syed, Zeeshan; Stultz, Collin; Kellis, Manolis; Indyk, Piotr; Guttag, John] MIT, Cambridge, MA 02139 USA	Syed, Z (reprint author), Univ Michigan, Ann Arbor, MI 48109 USA.	zhs@umich.edu			Center for the Integration of Medicine and Innovative Technology (CIMIT); Harvard-MIT Division of Health Sciences and Technology (HST)	Z. Syed was previously affiliated with the Massachusetts Institute of Technology. This work was supported in part by the Center for the Integration of Medicine and Innovative Technology (CIMIT) and the Harvard-MIT Division of Health Sciences and Technology (HST).	Bailey T L, 1995, Proc Int Conf Intell Syst Mol Biol, V3, P21; Cesa-Bianchi N., 2006, PREDICTION LEARNING; CHIU B., 2003, P 9 ACM SIGKDD INT C; Crooks GE, 2004, GENOME RES, V14, P1188, DOI 10.1101/gr.849004; Daw CS, 2003, REV SCI INSTRUM, V74, P915, DOI 10.1063/1.1531823; Durbin R., 1998, BIOL SEQUENCE ANAL; FREITAS A., 2001, DATA MINING KNOWLEDG; GERT T., 2002, J COMPUT BIOL, V9, P447; Giles CL, 2001, MACH LEARN, V44, P161, DOI 10.1023/A:1010884214864; GIONIS A., 2006, P 12 ACM SIGKDD INT; Goldberger AL, 2000, CIRCULATION, V101, pE215; HARMS S., 2002, P 13 INT S FDN INT S; Helmbold DP, 1997, MACH LEARN, V27, P51, DOI 10.1023/A:1007396710653; JIN X., 2002, P 3 INT C INT DAT EN; Jones NC, 2004, INTRO BIOINFORMATICS; Kellis M, 2003, NATURE, V423, P241, DOI 10.1038/nature01644; KEOGH E., 2002, P 8 ACM SIGKDD INT C; Lin J., 2003, P 8 ACM SIGMOD WORKS; MANNILA H., 1999, P 5 ACM SIGKDD INT C; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; PATEL P., 2002, P INT C DAT MIN; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; STORMO GD, 1989, P NATL ACAD SCI USA, V86, P1183, DOI 10.1073/pnas.86.4.1183; Syed Z, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/67938	24	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JAN	2010	4	1							2	10.1145/1644873.1644875		23	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VX	WOS:000208168600002	
J	Webb, GI				Webb, Geoffrey I.			Self-Sufficient Itemsets: An Approach to Screening Potentially Interesting Associations Between Items	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Association discovery; association rules; itemset discovery; itemset screening; statistical evaluation		Self-sufficient itemsets are those whose frequency cannot be explained solely by the frequency of either their subsets or of their supersets. We argue that itemsets that are not self-sufficient will often be of little interest to the data analyst, as their frequency should be expected once that of the itemsets on which their frequency depends is known. We present tests for statistically sound discovery of self-sufficient itemsets, and computational techniques that allow those tests to be applied as a post-processing step for any itemset discovery algorithm. We also present a measure for assessing the degree of potential interest in an itemset that complements these statistical measures.	Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia	Webb, GI (reprint author), Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia.	webb@infotech.monash.edu.au			Australian Research Council [DP0772238]	This research has been supported by the Australian Research Council under grant DP0772238.	Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agresti A., 1992, STAT SCI, V7, P131, DOI DOI 10.1214/SS/1177011454; Agresti A., 2002, CATEGORICAL DATA ANA; Aumann Y., 1999, P 5 ACM SIGKDD INT C, P261, DOI 10.1145/312129.312243; Bastide Y., 2000, P 1 INT C COMP LOG, P972; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; Brijs T, 1999, P 5 INT C KNOWL DISC, P254, DOI 10.1145/312129.312241; Calders T., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Chan R, 2003, P 3 IEEE INT C DAT M, P19; CHENG J., 2006, P 6 IEEE INT C DAT M, P139; Cooley R., 1999, P INT WEBKDD 99 WORK, P163; DUMOUCHEL W., 2001, P 7 ACM SIGKDD INT C, P76; DuMouchel W, 1999, AM STAT, V53, P177, DOI 10.2307/2686093; GOETHALS B., 2007, NDI SOFTWARE; HETTICH S., 2006, UCI KDD ARCH; HOLM S, 1979, SCAND J STAT, V6, P65; Jaroszewicz S., 2004, P 10 ACM SIGKDD INT, P178, DOI 10.1145/1014052.1014074; Liu B, 2001, P 7 ACM SIGKDD INT C, P329, DOI 10.1145/502512.502560; MALIK H. H., 2006, P ICDM 2006 IEEE COM, P991; Megiddo N, 1998, P 4 INT C KNOWL DISC, P27; NEWMAN D. J., 2006, UCI REPOSITORY MACHI; Pei J., 2002, P 2002 IEEE INT C DA, P378; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; SHAFFER JP, 1995, ANNU REV PSYCHOL, V46, P561, DOI 10.1146/annurev.psych.46.1.561; Tabachnick B. G., 2001, USING MULTIVARIATE S; WEBB G. I., 2009, MAGNUM OPUS VERSION; Webb GI, 1995, J ARTIF INTELL RES, V3, P431; Webb G. I., 2001, P 7 ACM SIGKDD INT C, P383, DOI 10.1145/502512.502569; Webb GI, 2005, DATA MIN KNOWL DISC, V10, P39, DOI 10.1007/s10618-005-0255-4; Webb GI, 2007, MACH LEARN, V68, P1, DOI 10.1007/s10994-007-5006-x; Wu X., 2003, P ACM SIGKDD INT C K, P276; Xin D., 2005, P 31 INT C VER LARG, P709; Yao H, 2006, DATA KNOWL ENG, V59, P603, DOI 10.1016/j.datak.2005.10.004; Zaki M. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347101; Zaki MJ, 2002, SIAM PROC S, P457; Zaki MJ, 2004, DATA MIN KNOWL DISC, V9, P223, DOI 10.1023/B:DAMI.0000040429.96086.c7; ZHANG H., 2004, P 10 INT C KNOWL DIS, P374, DOI 10.1145/1014052.1014094; Zheng Z., 2001, P 7 ACM SIGKDD INT C, P401, DOI 10.1145/502512.502572	39	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JAN	2010	4	1							3	10.1145/1644873.1644876		20	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VX	WOS:000208168600003	
J	Zaki, MJ; Carothers, CD; Szymanski, BK				Zaki, Mohammed J.; Carothers, Christopher D.; Szymanski, Boleslaw K.			VOGUE: A Variable Order Hidden Markov Model with Duration Based on Frequent Sequence Mining	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Hidden Markov models; higher-order HMM; HMM with duration; sequence mining and modeling; variable-order HMM		We present VOGUE, a novel, variable order hidden Markov model with state durations, that combines two separate techniques for modeling complex patterns in sequential data: pattern mining and data modeling. VOGUE relies on a variable gap sequence mining method to extract frequent patterns with different lengths and gaps between elements. It then uses these mined sequences to build a variable order hidden Markov model (HMM), that explicitly models the gaps. The gaps implicitly model the order of the HMM, and they explicitly model the duration of each state. We apply VOGUE to a variety of real sequence data taken from domains such as protein sequence classification, Web usage logs, intrusion detection, and spelling correction. We show that VOGUE has superior classification accuracy compared to regular HMMs, higher-order HMMs, and even special purpose HMMs like HMMER, which is a state-of-the-art method for protein classification. The VOGUE implementation and the datasets used in this article are available as open-source.(1)	[Zaki, Mohammed J.; Carothers, Christopher D.; Szymanski, Boleslaw K.] Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Zaki, MJ (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.	zaki@cs.rpi.edu; chrisc@cs.rpi.edu; szymansk@cs.rpi.edu	Szymanski, Boleslaw/A-9121-2009	Szymanski, Boleslaw/0000-0002-0307-6743	NSF [EMT-0829835, CNS-0103708]; NIH [1R01EB0080161-01A1]	This work was supported in part by NSF Grants EMT-0829835 and CNS-0103708, and NIH Grant 1R01EB0080161-01A1.	Agrawal R., 1995, P INT C DAT ENG; Antunes C, 2003, LECT NOTES ARTIF INT, V2734, P239; BOUQATA B., 2006, P 10 EUR C PRINC PRA; Buhlmann P, 1999, ANN STAT, V27, P480; CHAN C., 1996, P INT C COMP LING; Chaoji V, 2008, Proceedings of the 5th International Conference on Soft Computing as Transdisciplinary Science and Technology 2008. In Memory of Professor Yasuhiko Dote, DOI 10.1145/1456223.1456270; DESHPANDE M., 2001, P SIAM INT C DAT MIN; Dong G., 2007, SEQUENCE DATA MINING; du Preez JA, 1998, COMPUT SPEECH LANG, V12, P23, DOI 10.1006/csla.1997.0037; Durbin R., 1998, BIOL SEQUENCE ANAL; Eddy SR, 1998, BIOINFORMATICS, V14, P755, DOI 10.1093/bioinformatics/14.9.755; Falquet L, 2002, NUCLEIC ACIDS RES, V30, P235, DOI 10.1093/nar/30.1.235; FELZENSZWALB P., 2003, ADV NEURAL INFORM PR; Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079; Francis W. N., 1967, COMPUTATIONAL ANAL P; Galassi U, 2007, FUND INFORM, V78, P487; Garofalakis M, 2002, IEEE T KNOWL DATA EN, V14, P530, DOI 10.1109/TKDE.2002.1000341; GOLDING A., 1996, P ML 96 13 INT C MAC, P180; Gusfield D., 1997, ALGORITHMS STRINGS T; Jensen KL, 2006, BIOINFORMATICS, V22, P21, DOI 10.1093/bioinformatics/bti745; KRIOUILE A., 1990, P INT C AC SPEECH SI; Lane T, 1999, ACM T INFORM SYST, V2, P295, DOI 10.1145/322510.322526; Laxman S, 2005, IEEE T KNOWL DATA EN, V17, P1505; Mannila H., 1995, P 1 INT C KNOWL DISC; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Nanopoulos A, 2003, IEEE T KNOWL DATA EN, V15, P1155, DOI 10.1109/TKDE.2003.1232270; Pei J., 2001, P INT C DAT ENG; Pitkow J., 1999, P 2 USENIX S INT TEC; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ron D, 1996, MACH LEARN, V25, P117, DOI 10.1023/A:1026490906255; Saul LK, 1999, MACH LEARN, V37, P75, DOI 10.1023/A:1007649326333; SCHWARDT L. C., 2000, P INT C SPOK LANG PR; Srikant R., 1996, P 5 INT C EXT DAT TE; Szymanski BK, 2004, PROCEEDINGS FROM THE FIFTH IEEE SYSTEMS, MAN AND CYBERNETICS INFORMATION ASSURANCE WORKSHOP, P424, DOI 10.1109/IAW.2004.1437848; WANG J., 2008, P SIAM INT C DAT MIN; WANG Y., 2006, P 6 IEEE INT C DAT M; WU X., 2007, P INT JOINT C AI; ZAKI M. J., 2000, P 9 INT C INF KNOWL; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315; ZHANG M., 2005, P ACM SIGMOD INT C M	40	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JAN	2010	4	1							5	10.1145/1644873.1644878		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VX	WOS:000208168600005	
J	Huhn, J; Hullermeier, E				Huehn, Jens; Huellermeier, Eyke			FURIA: an algorithm for unordered fuzzy rule induction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Classification; Rule learning; Fuzzy logic; Rule stretching	CLASSIFICATION SYSTEMS; DATA SETS; CLASSIFIERS; FRAMEWORK; WEIGHTS	This paper introduces a novel fuzzy rule-based classification method called FURIA, which is short for Fuzzy Unordered Rule Induction Algorithm. FURIA extends the well-known RIPPER algorithm, a state-of-the-art rule learner, while preserving its advantages, such as simple and comprehensible rule sets. In addition, it includes a number of modifications and extensions. In particular, FURIA learns fuzzy rules instead of conventional rules and unordered rule sets instead of rule lists. Moreover, to deal with uncovered examples, it makes use of an efficient rule stretching method. Experimental results show that FURIA significantly outperforms the original RIPPER, as well as other classifiers such as C4.5, in terms of classification accuracy.	[Huehn, Jens; Huellermeier, Eyke] Univ Marburg, Dept Math & Comp Sci, D-35043 Marburg, Germany	Hullermeier, E (reprint author), Univ Marburg, Dept Math & Comp Sci, Hans Meerwein Str, D-35043 Marburg, Germany.	huehnj@informatik.uni-marburg.de; eyke@informatik.uni-marburg.de			German Research Foundation (DFG); Konrad Adenauer Foundation (KAS)	This research was supported by the German Research Foundation (DFG) and the Konrad Adenauer Foundation (KAS). The CHI and SLAVE classifiers were made available to us by the developers of the KEEL software (Alberto Fernandez). We gratefully acknowledge this support. We also thank Johannes Furnkranz for insightful discussions about rule fuzzification and generalization.	AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ASUNCION A., 2007, UCI MACHINE LEARNING; BARKER D, 2007, DATASET PASTURE PROD; BOSTROM H, 2004, P WORKSH ADV RUL LEA, P17; BULLOCH B, 2007, DATASET EUCALYPTUS S; Chi Z., 1996, FUZZY ALGORITHMS APP; CHI ZR, 1995, PATTERN RECOGN, V28, P59, DOI 10.1016/0031-3203(94)00085-Z; Cloete I, 2006, IEEE T FUZZY SYST, V14, P93, DOI 10.1109/TFUZZ.2005.861616; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cordon O, 2004, FUZZY SET SYST, V141, P5, DOI 10.1016/S0165-0114(03)00111-8; Alcala-Fdez J, 2009, SOFT COMPUT, V13, P307, DOI 10.1007/s00500-008-0323-y; del Jesus MJ, 2004, IEEE T FUZZY SYST, V12, P296, DOI 10.1109/TFUZZ.2004.825972; Demsar J, 2006, J MACH LEARN RES, V7, P1; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; Drobics M, 2003, INT J APPROX REASON, V32, P131, DOI 10.1016/S0888-613X(02)00080-4; Eineborg M., 2001, Inductive Logic Programming. 11th International Conference, ILP 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2157); Fawcett T, 2008, DATA MIN KNOWL DISC, V17, P207, DOI 10.1007/s10618-008-0089-y; Fernandez A, 2007, LECT NOTES ARTIF INT, V4578, P170; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Gonzalez A, 2001, IEEE T SYST MAN CY B, V31, P417, DOI 10.1109/3477.931534; Gonzalez A, 1999, IEEE T FUZZY SYST, V7, P176, DOI 10.1109/91.755399; Guillaume S, 2001, IEEE T FUZZY SYST, V9, P426, DOI 10.1109/91.928739; HARVEY W, 2007, DATASET SQUASH HARVE; HENDRICKX I, 2005, P 16 EUR C MACH LEAR, P158; Huhn JC, 2009, IEEE T FUZZY SYST, V17, P138, DOI 10.1109/TFUZZ.2008.2005490; Hullermeier E, 2005, FUZZY SET SYST, V156, P387, DOI 10.1016/j.fss.2005.05.036; IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904; Ishibuchi H, 2001, IEEE T FUZZY SYST, V9, P506, DOI 10.1109/91.940964; Ishibuchi H, 2005, IEEE T FUZZY SYST, V13, P428, DOI 10.1109/TFUZZ.2004.841738; ISHIBUCHI H, 2003, 12 IEEE INT C FUZZ S, V1, P149; Juang CF, 2007, IEEE T FUZZY SYST, V15, P998, DOI 10.1109/TFUZZ.2007.894980; KAMAL M, 1993, P 13 INT JOINT C ART, P1064; Kearns M., 1988, THOUGHTS HYPOTHESIS; MEYER M, 2007, STATLIB; Mitra S, 2000, IEEE T NEURAL NETWOR, V11, P748, DOI 10.1109/72.846746; Nauck D., 1997, FDN NEUROFUZZY SYSTE; Nemenyi PB, 1963, THESIS PRINCETON U; Newman D, 1939, BIOMETRIKA, V31, P20, DOI 10.2307/2334973; PRADE H, 2003, P PKDD 03 LNCS 2838, P399; Press W, 1992, NUMERICAL RECIPES FO; Quinlan J. R., 1993, P EUR C MACH LEARN, P3; Quinlan J. R., 1995, P 12 INT C MACH LEAR, P464; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Serrurier M, 2007, ARTIF INTELL, V171, P939, DOI 10.1016/j.artint.2007.04.016; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; WANG T, 2007, ADV SOFT COMPUTING, V40; Witten IH, 2005, DATA MINING PRACTICA; Zolghadri MJ, 2007, INFORM SCIENCES, V177, P2296, DOI 10.1016/j.ins.2006.12.009	52	19	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2009	19	3					293	319		10.1007/s10618-009-0131-8		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	500SE	WOS:000270324200001	
J	Lipets, V; Vanetik, N; Gudes, E				Lipets, V.; Vanetik, N.; Gudes, E.			Subsea: an efficient heuristic algorithm for subgraph isomorphism	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Graph algorithms; Subgraph isomorphism; Heuristic; Bisection	PATTERNS	We present a novel approach to the problem of finding all subgraphs and induced subgraphs of a (target) graph which are isomorphic to another (pattern) graph. To attain efficiency we use a special representation of the pattern graph. We also combine our search algorithm with some known bisection algorithms. Experimental comparison with other algorithms was performed on several types of graphs. The comparison results suggest that the approach provided here is most effective when all instances of a subgraph need to be found.	[Lipets, V.; Vanetik, N.; Gudes, E.] Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel	Vanetik, N (reprint author), Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel.	lipets@cs.bgu.ac.il; orlovn@cs.bgu.ac.il; ehud@cs.bgu.ac.il	GUDES, EHUD/F-1168-2012		Fraenkel Center for Computer Science and Paul Ivanier Center for Robotics and Production Management	We thank anonymous reviewers for their useful comments on our paper. We thank Lior Becker and Arie Ohana for doing extraordinary job implementing the Subsea algorithm and making it even more efficient than we anticipated. We also thank Rosa Shlayzer for conducting the experiments. We thank Fraenkel Center for Computer Science and Paul Ivanier Center for Robotics and Production Management for partially supporting this work.	AKINNIYI FA, 1986, T SYSTEMS MAN CYBERN, V16, P740; Alon N., 1995, J ACM, V42, P44; AMBAUEN R, 2003, LNCS, V2726, P259; BATZ GV, 2006, 20062007 U KARL FAC; BERRETTI S, 2004, P CIVR2004, P464; BOERES M, 2004, P WEA 2004, P100; Cai D., 2005, P 3 INT WORKSH LINK, P58, DOI 10.1145/1134271.1134280; Champin P., 2003, C CAS BAS REAS ICCBR, P100; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; CHENG JK, 1981, PATTERN RECOGN, V13, P371, DOI 10.1016/0031-3203(81)90093-5; Cordella L. P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, DOI 10.1109/ICIAP.1999.797762; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; CORTADELLA J, 2000, P 5 INT SEM REL METH, P45; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Dessmark A, 2000, ALGORITHMICA, V27, P337, DOI 10.1007/s004530010023; Eppstein D., 1999, J GRAPH ALGORITHMS A, V3, P1; Erdos P, 1959, PUBL MATH-DEBRECEN, V6, P290; FOGGIA P, 2001, 3 IAPR TC15 WORKSH G; Garey M. R., 1979, COMPUTERS INTRACTABI; Gudes E, 2006, IEEE T KNOWL DATA EN, V18, P1441, DOI 10.1109/TKDE.2006.173; Krissinel EB, 2004, SOFTWARE PRACT EXPER, V34, P591, DOI 10.1002/spe.588; KURAMOCHI M, 2004, P SDM 2004; Kuramochi M., 2001, P ICDM 2001; LARROSA J, 2000, P JOINT APPLIGRAPH G, P189; LIN X, 1998, P 31 INT C TECHN OBJ; LINGAS A, 1989, LITHIDAR8905 LINK U; Matula D, 1978, ANN DISCRETE MATH, V2, P91, DOI 10.1016/S0167-5060(08)70324-8; Messmer BT, 2000, IEEE T KNOWL DATA EN, V12, P307, DOI 10.1109/69.842269; MESSMER BT, 1996, P 2 AS C COMP VIS, P373; NIJSSEN S, 2004, P IEEE INT C SYST MA; Nijssen S, 2004, P 10 ACM SIGKDD INT, P647, DOI 10.1145/1014052.1014134; Pennec X, 1998, BIOINFORMATICS, V14, P516, DOI 10.1093/bioinformatics/14.6.516; SAMMOUD O, 2005, P EVOCOP 2005, P213; SANSONE C, 2001, GRAPH DATABASE LIB S; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; Vanetik N., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183988; Wang K., 1998, P SIGIR, P146, DOI 10.1145/290941.290982; Yan X., 2002, P 2002 IEEE INT C DA, P721; ZHANG S, 2009, P EDBT C 2009; *NCI, 2008, DAT INT PROT; *SIVALAB U NAPL, 2003, ARG GRAPH DAT	41	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2009	19	3					320	350		10.1007/s10618-009-0132-7		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	500SE	WOS:000270324200002	
J	Hansen, P; Brimberg, J; Urosevic, D; Mladenovic, N				Hansen, Pierre; Brimberg, Jack; Urosevic, Dragan; Mladenovic, Nenad			Solving large p-median clustering problems by primal-dual variable neighborhood search	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Data clustering; Variable neighborhood search	LOCATION-PROBLEMS; ALGORITHM	Data clustering methods are used extensively in the data mining literature to detect important patterns in large datasets in the form of densely populated regions in a multi-dimensional Euclidean space. Due to the complexity of the problem and the size of the dataset, obtaining quality solutions within reasonable CPU time and memory requirements becomes the central challenge. In this paper, we solve the clustering problem as a large scale p-median model, using a new approach based on the variable neighborhood search (VNS) metaheuristic. Using a highly efficient data structure and local updating procedure taken from the OR literature, our VNS procedure is able to tackle large datasets directly without the need for data reduction or sampling as employed in certain popular methods. Computational results demonstrate that our VNS heuristic outperforms other local search based methods such as CLARA and CLARANS even after upgrading these procedures with the same efficient data structures and local search. We also obtain a bound on the quality of the solutions by solving heuristically a dual relaxation of the problem, thus introducing an important capability to the solution process.	[Urosevic, Dragan] Math Inst SANU, Belgrade, Serbia; [Hansen, Pierre] Ecole Hautes Etud Commerciales, Gerad, Montreal, PQ, Canada; [Hansen, Pierre] CRT, Montreal, PQ, Canada; [Brimberg, Jack] Royal Mil Coll Canada, Kingston, ON, Canada; [Mladenovic, Nenad] Brunel Univ, London, England	Urosevic, D (reprint author), Math Inst SANU, Belgrade, Serbia.	pierre.hansen@gerad.ca; Jack.Brimberg@rmc.ca; draganu@mi.sanu.ac.rs; Nenad.Mladenovic@brunel.ac.uk					ERLENKOTTER D, 1978, OPER RES, V26, P992, DOI 10.1287/opre.26.6.992; Hansen P, 2001, EUR J OPER RES, V130, P449, DOI 10.1016/S0377-2217(00)00100-4; HANSEN P, 2007, CAHIERS GERAD; Hansen P, 2001, J HEURISTICS, V7, P335, DOI 10.1023/A:1011336210885; Hansen P, 2007, INFORMS J COMPUT, V19, P552, DOI 10.1287/ijoc.1060.0196; Hansen P., 1997, Location Science, V5, DOI 10.1016/S0966-8349(98)00030-8; KAUFMAN L, 1990, SERIES APPL PROBABIL; KLOSE A, 1995, OP RES P 1994 SPRING, P335; KOCHETOV Y, 2005, OPERATIONS RES COMPU, P351; Mladenovic N, 2007, EUR J OPER RES, V179, P927, DOI 10.1016/j.ejor.2005.05.034; Mladenovic N, 1997, COMPUT OPER RES, V24, P1097, DOI 10.1016/S0305-0548(97)00031-2; Ng R, 1994, P 20 INT C VER LARG, P144; Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770; Reinelt G., 1991, ORSA Journal on Computing, V3; Resende MGC, 2007, ANN OPER RES, V150, P205, DOI 10.1007/s10479-006-0154-0; Resende MGC, 2004, J HEURISTICS, V10, P59, DOI 10.1023/B:HEUR.0000019986.96257.50; TEITZ MB, 1968, OPER RES, V16, P955, DOI 10.1287/opre.16.5.955; WHITAKER RA, 1983, INFOR, V21, P95; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	20	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2009	19	3					351	375		10.1007/s10618-009-0135-4		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	500SE	WOS:000270324200003	
J	Ezeife, CI; Liu, Y				Ezeife, C. I.; Liu, Yi			Fast incremental mining of web sequential patterns with PLWAP tree	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Incremental mining; Sequential mining; Frequent patterns; Data streams; PLWAP tree; Scalability	EFFICIENT ALGORITHMS; FREQUENT SEQUENCES	Point and click at web pages generate continuous data sequences, which flow into the web log data, causing the need to update previously mined web sequential patterns. Algorithms for mining web sequential patterns from scratch include WAP, PLWAP and Apriori-based GSP. Reusing old patterns with only recent additional data sequences in an incremental fashion, when updating patterns, would achieve fast response time with reasonable memory space usage. This paper proposes two algorithms, RePL4UP (Revised PLWAP For UPdate), and PL4UP (PLWAP For UPdate), which use the PLWAP tree structure to incrementally update web sequential patterns efficiently without scanning the whole database even when previous small items become frequent. The RePL4UP concisely stores the position codes of small items in the database sequences in its metadata during tree construction. During mining, RePL4UP scans only the new additional database sequences, revises the old PLWAP tree to restore information on previous small items that have become frequent, while it deletes previous frequent items that have become small using the small item position codes. PL4UP initially builds a bigger PLWAP tree that includes all sequences in the database using a tolerance support, t, that is lower than the regular minimum support, s. The position code features of the PLWAP tree are used to efficiently mine these trees to extract current frequent patterns when the database is updated. These approaches more quickly update old frequent patterns without the need to re-scan the entire updated database.	[Ezeife, C. I.; Liu, Yi] Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada	Ezeife, CI (reprint author), Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.	cezeife@uwindsor.ca; woddlab@uwindsor.ca			Natural Science and Engineering Research Council (NSERC) of Canada [OGP-0194134]; University of Windsor	This research was supported by the Natural Science and Engineering Research Council (NSERC) of Canada under an operating grant (OGP-0194134) and a University of Windsor grant.	AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Berendt B, 2000, VLDB J, V9, P56, DOI 10.1007/s007780050083; CHEUNG D, 1996, P 12 INT C DAT ENG N; CHEUNG D, 1997, P 1 PAC AS C KNOWL D; Cheung H., 2004, P ACM SIGKDD INT C K, P527; Ezeife C. I., 2005, P OP SOURC DAT MIN W, P26, DOI 10.1145/1133905.1133910; Ezeife C. I., 2004, Proceedings. International Database Engineering and Applications Symposium, DOI 10.1109/IDEAS.2004.1319823; Ezeife CI, 2005, DATA MIN KNOWL DISC, V10, P5, DOI 10.1007/s10618-005-0248-3; EZEIFE CI, 2004, P INT C WEB AG INF M, P539; Han J., 2001, DATA MINING CONCEPTS; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Kao B, 2005, DATA MIN KNOWL DISC, V10, P87, DOI 10.1007/s10618-005-0268-z; Lee YS, 2008, INFORM SCIENCES, V178, P287, DOI 10.1016/j.ins.2007.08.020; LIU JW, 2003, SPRINGER LECT NOTES, V3614, P462; LU Y, 2003, P 7 PAC AS C KNOWL D; Masseglia F, 2003, DATA KNOWL ENG, V46, P97, DOI 10.1016/S0169-023X(02)00209-4; Masseglia F., 1999, NETWORKING INFORMATI, V2, P571; Nanopoulos A, 2001, DATA KNOWL ENG, V37, P243, DOI 10.1016/S0169-023X(01)00008-8; NGUYEN S, 2005, P 2000 PAC AS C KNOW, P442; Ou JC, 2008, VLDB J, V17, P827, DOI 10.1007/s00778-006-0043-9; Parthasarathy S, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P251, DOI 10.1145/319950.320010; Pei J., 2000, P PAC AS C KNOWL DIS, P396; Pei J, 2001, PROC INT CONF DATA, P215; RUIZ C., 2004, P 6 ANN ACM INT WORK, P128, DOI 10.1145/1031453.1031477; SPILIOPOULOU M, 1999, J COMPUTER SYSTEMS S, V14, P113; Srikant R., 1995, P 21 INT C VER LARG; TANG P, 2007, 45 ACM ANN SE REG C, P226; Wang K., 1996, P ACM WORKSH RES ISS; WANG K., 1997, J INTELL INF SYST, V9, P33, DOI DOI 10.1023/A:1008689103430; Yen S.-J., 2006, INT J BUS INTELL DAT, V1, P288; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315; Zhang M, 2002, P 2 IEEE INT C DAT M, P554; Zhang M., 2002, P 6 PAC AS C KNOWL D, P186	33	1	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2009	19	3					376	416		10.1007/s10618-009-0133-6		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	500SE	WOS:000270324200004	
J	Asur, S; Parthasarathy, S; Ucar, D				Asur, Sitaram; Parthasarathy, Srinivasan; Ucar, Duygu			An Event-Based Framework for Characterizing the Evolutionary Behavior of Interaction Graphs	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Measurement; Dynamic interaction networks; evolutionary analysis; diffusion of innovations		Interaction graphs are ubiquitous in many fields such as bioinformatics, sociology and physical sciences. There have been many studies in the literature targeted at studying and mining these graphs. However, almost all of them have studied these graphs from a static point of view. The study of the evolution of these graphs over time can provide tremendous insight on the behavior of entities, communities and the flow of information among them. In this work, we present an event-based characterization of critical behavioral patterns for temporally varying interaction graphs. We use nonoverlapping snapshots of interaction graphs and develop a framework for capturing and identifying interesting events from them. We use these events to characterize complex behavioral patterns of individuals and communities over time. We show how semantic information can be incorporated to reason about community-behavior events. We also demonstrate the application of behavioral patterns for the purposes of modeling evolution, link prediction and influence maximization. Finally, we present a diffusion model for evolving networks, based on our framework.	[Asur, Sitaram; Parthasarathy, Srinivasan; Ucar, Duygu] Ohio State Univ, Dept Comp Sci, Dreese Labs 395, Columbus, OH 43210 USA	Asur, S (reprint author), Ohio State Univ, Dept Comp Sci, Dreese Labs 395, 2015 Neil Ave, Columbus, OH 43210 USA.	srini@cse.ohio-state.edu			DOE [DE-FG02-04ER25611]; NSF [IIS-0347662]; NSF SGER [IIS-0742999]	This work was supported in part by the DOE Early Career Principal Investigator Award No. DE-FG02-04ER25611, NSF CAREER Grant IIS-0347662 and NSF SGER Grant IIS-0742999.	ALKEMADE F., 2005, COMPUTAT EC, V25, P1; ASUR S., 2007, OSUCISRC207TR16; Asur S, 2007, BIOINFORMATICS, V23, pI29, DOI 10.1093/bioinformatics/btm212; BACKSTORM L., 2006, P SIGKDD INT C KNOWL; Barabasi AL, 2003, SCI AM, V288, P60; Barabasi AL, 2002, PHYSICA A, V311, P590, DOI 10.1016/S0378-4371(02)00736-7; CHAKRABARTI D., 2006, P SIGKDD INT C KNOWL; CHI Y, 2007, P 13 ACM SIGKDD INT, P153, DOI 10.1145/1281192.1281212; Clauset A., 2004, PHYS REV E, V70; Cowan R, 2004, J ECON DYN CONTROL, V28, P1557, DOI 10.1016/j.jedc.2003.04.002; FALKOWSKI T., 2006, P IEEE WIC ACM INT C; Ferlez J, 2008, PROC INT CONF DATA, P1328, DOI 10.1109/ICDE.2008.4497545; FLAKE GW, 2002, IEEE COMPUT, V35, P66; GABRILOVICH E., 2007, P INT JOINT C ART IN; GANESAN P., 2003, ACM T INFORM SYST, V21, P1; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Hopcroft J, 2004, P NATL ACAD SCI USA, V101, P5249, DOI 10.1073/pnas.0307750100; KEMPE D., 2003, P SIGKDD INT C KNOWL; Kempe D., 2005, P INT C AUT LANG PRO; LAD A. A., 2003, SOC NETWORKS, V25, P211; LESKOVEC J., 2005, P SIGKDD INT C KNOWL; Leskovec J., 2008, WWW 08, P695, DOI DOI 10.1145/1367497.1367591; LIBEN-NOWELL D., 2008, P ACM CIKM INT C INF; Lin D, 1998, P 15 INT C MACH LEAR; Lord P W, 2003, Pac Symp Biocomput, P601; Newman M. E. J., 2001, PHYS REV E, V64; Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103; OTEY M. E., 2006, P SIAM INT C DAT MIN; Palla G, 2007, NATURE, V446, P664, DOI 10.1038/nature05670; Resnik P, 1999, J ARTIF INTELL RES, V11, P95; RICHARDSON R., 1994, P ART INT COGN SCI A; SAMTANEY R, 1994, COMPUTER, V27, P20, DOI 10.1109/2.299407; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; TADEPALLI S., 2008, P 6 AS PAC BIOINF C, P297, DOI 10.1142/9781848161092_0031; Tantipathananandh C, 2007, P 13 ACM SIGKDD INT, P717, DOI 10.1145/1281192.1281269; Wasserman S, 1994, SOCIAL NETWORK ANAL; YANG H., 2005, P SIGKDD INT C KNOWL; YANG X., 2008, P SIGKDD INT C KNOWL	38	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	NOV	2009	3	4								10.1145/1631162.1631164		36	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VT	WOS:000208168200002	
J	Bilgic, M; Getoor, L				Bilgic, Mustafa; Getoor, Lise			Reflect and Correct: A Misclassification Prediction Approach to Active Inference	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Active inference; label acquisition; collective classification; viral marketing; information diffusion		Information diffusion, viral marketing, graph-based semi-supervised learning, and collective classification all attempt to model and exploit the relationships among nodes in a network to improve the performance of node labeling algorithms. However, sometimes the advantage of exploiting the relationships can become a disadvantage. Simple models like label propagation and iterative classification can aggravate a misclassification by propagating mistakes in the network, while more complex models that define and optimize a global objective function, such as Markov random fields and graph mincuts, can misclassify a set of nodes jointly. This problem can be mitigated if the classification system is allowed to ask for the correct labels for a few of the nodes during inference. However, determining the optimal set of labels to acquire is intractable under relatively general assumptions, which forces us to resort to approximate and heuristic techniques. We describe three such techniques in this article. The first one is based on directly approximating the value of the objective function of label acquisition and greedily acquiring the label that provides the most improvement. The second technique is a simple technique based on the analogy we draw between viral marketing and label acquisition. Finally, we propose a method, which we refer to as reflect and correct, that can learn and predict when the classification system is likely to make mistakes and suggests acquisitions to correct those mistakes. We empirically show on a variety of synthetic and real-world datasets that the reflect and correct method significantly outperforms the other two techniques, as well as other approaches based on network structural measures such as node degree and network clustering.	[Bilgic, Mustafa; Getoor, Lise] Univ Maryland, College Pk, MD 20742 USA	Bilgic, M (reprint author), Univ Maryland, AV Williams Bldg, College Pk, MD 20742 USA.	mbilgic@cs.umd.edu; getoor@cs.umd.edu			National Science Foundation, NSF [0746930, 0438866]	This work was supported by the National Science Foundation, NSF #0746930 and NSF #0438866, with additional support from ARO #W911NF0710428.	BILGIC M., 2008, P 14 ACM SIGKDD INT, P43, DOI 10.1145/1401890.1401901; Bilgic M., 2007, P AAAI C ART INT, P1225; Blum A., 2001, P 18 INT C MACH LEAR, P19; Chakrabarti S., 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; Chapelle O, 2006, SEMISUPERVISED LEARN; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Getoor L., 2002, J MACHINE LEARNING R, V3, P679; Giles C. L., 1998, P 3 ACM C DIG LIB, P89, DOI 10.1145/276675.276685; Gilks W., 1996, MARKOV CHAIN MONTE C; HOWARD RA, 1966, IEEE T SYST SCI CYB, VSSC2, P22, DOI 10.1109/TSSC.1966.300074; IU Q., 2003, P ICML WORKSH CONT L; Jensen D., 2004, P 10 ACM SIGKDD INT, P593, DOI 10.1145/1014052.1014125; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kempe D, 2003, P 9 ACM SIGKDD INT C, P137; Koller D., 2001, P IJCAI WORKSH TEXT, P24; KRALTSE A., 2005, P INT JOINT C ART IN, P1339; Lafferty J, 2001, P 18 INT C MACH LEAR, P282; Leskovec J, 2007, ACM T WEB, V1, DOI 10.1145/1232722.1232727; LESKOVEC J., 2007, ACM T KNOWL DISCOV D, V1, P177; Lewis DD, 1994, P 17 ANN INT ACM SIG, P3; Lu Q., 2003, P 20 INT C MACH LEAR, P496; MACSKASSY S., 2003, P ACM WORKSH MULT DA; Macskassy SA, 2007, J MACH LEARN RES, V8, P935; McCallum A., 1998, P 15 INT C MACH LEAR, P350; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; McDOWELL L., 2007, P 22 C ART INT, P596; Melville P, 2004, P 21 INT C MACH LEAR, P584; Namata G, 2008, AI MAG, V29, P3; NEVILLE J., 2000, P SRL WORKSH AAAI; Newman MEJ, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.026126; PROVOST F., 2007, P ACM INT C EL COMM, P389; RATTIGAN M. J., 2007, P ICDM WORKSH MIN GR, P429; Richardson M, 2002, P 8 ACM SIGKDD INT C, P61; Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1; Roy N., 2001, P 18 INT C MACH LEAR, P441; Saar-Tsechansky M, 2004, MACH LEARN, V54, P153, DOI 10.1023/B:MACH.0000011806.12374.c3; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; SHENG V. S., 2006, P 23 INT C MACH LEAR, P809, DOI 10.1145/1143844.1143946; Tasker B., 2002, P 18 C UNC ART INT U, P485; Tong S, 2002, J MACH LEARN RES, V2, P45; XIANG R., 2008, P IEEE INT C DAT MIN, P1103; Yedidia J. S., 2000, NIPS, P689; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540; Zhu X, 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663; ZHU X., 2002, CMUCALD02107	47	1	2	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	NOV	2009	3	4							20	10.1145/1631162.1631168		32	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VT	WOS:000208168200006	
J	Chi, Y; Song, XD; Zhou, DY; Hino, K; Tseng, BL				Chi, Yun; Song, Xiaodan; Zhou, Dengyong; Hino, Koji; Tseng, Belle L.			On Evolutionary Spectral Clustering	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Experimentation; Measurement; Theory		Evolutionary clustering is an emerging research area essential to important applications such as clustering dynamic Web and blog contents and clustering data streams. In evolutionary clustering, a good clustering result should fit the current data well, while simultaneously not deviate too dramatically from the recent history. To fulfill this dual purpose, a measure of temporal smoothness is integrated in the overall measure of clustering quality. In this article, we propose two frameworks that incorporate temporal smoothness in evolutionary spectral clustering. For both frameworks, we start with intuitions gained from the well-known k-means clustering problem, and then propose and solve corresponding cost functions for the evolutionary spectral clustering problems. Our solutions to the evolutionary spectral clustering problems provide more stable and consistent clustering results that are less sensitive to short-term noises while at the same time are adaptive to long-term cluster drifts. Furthermore, we demonstrate that our methods provide the optimal solutions to the relaxed versions of the corresponding evolutionary k-means clustering problems. Performance experiments over a number of real and synthetic data sets illustrate our evolutionary spectral clustering methods provide more robust clustering results that are not sensitive to noise and can adapt to data drifts.	[Chi, Yun; Hino, Koji] NEC Labs Amer, Cupertino, CA 95014 USA; [Song, Xiaodan] Google Inc, Mountain View, CA 94043 USA; [Zhou, Dengyong] Microsoft Res, Redmond, WA 98052 USA; [Tseng, Belle L.] YAHOO Inc, Santa Clara, CA 95054 USA	Chi, Y (reprint author), NEC Labs Amer, 10080 NorthWolfe Rd,SW3-350, Cupertino, CA 95014 USA.	ychi@sc.nec-labs.com					AGGARWAL C. C., 2003, P 12 VLDB C; ARABIE P., 1985, J CLASSIF, V2; ASUR S., 2007, P 13 ACM SIGKDD C; Chakrabarti D., 2006, P 12 ACM SIGKDD C; Charikar M., 1997, P 29 STOC C; Chatfield C., 2003, ANAL TIME SERIES INT; Chung F, 1997, SPECTRAL GRAPH THEOR; DE LATHAUWER L., 2000, SIAM J MATRIX ANAL A, V21, P4; DHILLON I. S., 2004, P 10 ACM SIGKDD C; FALOUTSOS C., 2007, P 13 ACM SIGKDD C; FAN K., 1949, P NATL ACAD SCI; Golub G.H., 1996, MATRIX COMPUTATIONS; GONG Y., 2003, P 26 SIGIR C; GROSSMAN R., 2004, P SIAM INT C DAT MIN; Guha S., 2000, P IEEE S FDN COMP SC; HE X., 2004, P 21 ICML C; JORDAN M. I., 2006, J MACH LEARN RES, V7; Li Y., 2004, P 10 ACM SIGKDD C; Lie X., 2002, 2002L011 NEC LAB AM; MOORE A. W., 2005, SIGKDD EXPLOR NEWSL, V7, P2; Newman M, 2004, PHYS REV E; Ng A., 2001, NIPS; NING H., 2007, P SIAM INT C DAT MIN; Palla G., 2007, NATURE, V446; SHI J., 2000, IEEE T PATTERN ANAL, V22, P8, DOI DOI 10.1109/34.868688; SIMON H. D., 2001, NIPS; SONG X., 2007, P 13 ACM SIGKDD C; SPILIOPOULOU M., 2006, P 12 ACM SIGKDD C; Toyoda M., 2003, HYPERTEXT 03; WAGSTAFF K., 2001, P 18 ICML C; WEISS Y., 1999, ICCV 99, V2; XU W., 2006, P SIGIR; ZHAI C., 2005, P 11 ACM SIGKDD C; ZHOU D., 2005, P 22 ICML C	34	5	7	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	NOV	2009	3	4								10.1145/1631162.1631165		30	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VT	WOS:000208168200003	
J	Fujiwara, Y; Sakurai, Y; Kitsuregawa, M				Fujiwara, Yasuhiro; Sakurai, Yasushi; Kitsuregawa, Masaru			Fast Likelihood Search for Hidden Markov Models	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Theory; Hidden Markov model; likelihood; upper bound		Hidden Markov models (HMMs) are receiving considerable attention in various communities and many applications that use HMMs have emerged such as mental task classification, biological analysis, traffic monitoring, and anomaly detection. This article has two goals; The first goal is exact and efficient identification of the model whose state sequence has the highest likelihood for the given query sequence (more precisely, no HMM that actually has a high-probability path for the given sequence is missed by the algorithm), and the second goal is exact and efficient monitoring of streaming data sequences to find the best model. We propose SPIRAL, a fast search method for HMM datasets. SPIRAL is based on three ideas; (1) it clusters states of models to compute approximate likelihood, (2) it uses several granularities and approximates likelihood values in search processing, and (3) it focuses on just the promising likelihood computations by pruning out low-likelihood state sequences. Experiments verify the effectiveness of SPIRAL and show that it is more than 490 times faster than the naive method.	[Fujiwara, Yasuhiro] NTT Cyber Space Labs, Yokosuka, Kanagawa 2390847, Japan; [Sakurai, Yasushi] NTT Commun Sci Labs, Sora Ku, Kyoto 6190237, Japan; [Kitsuregawa, Masaru] Univ Tokyo, Inst Ind Sci, Meguro Ku, Tokyo 1538505, Japan	Fujiwara, Y (reprint author), NTT Cyber Space Labs, 1-1 Hikari Nooka, Yokosuka, Kanagawa 2390847, Japan.	fujiwara.yasuhiro@lab.ntt.co.jp; yasushi.sakurai@acm.org; kitsure@tkl.iis.u-tokyo.ac.jp					Abadi DJ, 2003, VLDB J, V12, P120, DOI 10.1007/s00778-003-0095-z; Agrawal R., 1993, LNCS, V730, P69, DOI 10.1007/3-540-57301-1_5; Agrawal R., 1995, P 21 INT C VER LARG, P490; Arasu A., 2002, P 21 ACM SIGACT SIGM, P221; Babcock B., 2003, P 2003 ACM SIGMOD IN, P253, DOI DOI 10.1145/872757.872789; BALDI P, 1994, P NATL ACAD SCI USA, V91, P1059, DOI 10.1073/pnas.91.3.1059; Barbara D, 2001, SIGMOD RECORD, V30, P15; BICKEL P., 2001, P WORKSH NONL EST CL; Bishop C. M., 2007, PATTERN RECOGNITION; BISWAS G., 1999, P SPIE 99 C DAT MIN, P14; Bocchieri E., 1993, P ICASSP, P692; Chandrasekaran S., 2003, P C INN DAT SYST RES; Cheng R., 2004, P 30 INT C VER LARG, P876, DOI 10.1016/B978-012088469-8/50077-2; Cheng R, 2003, P ACM SIGMOD INT C M, P551; Cranor Chuck, 2003, P 2003 ACM SIGMOD IN, P647; Das G, 1997, LECT NOTES ARTIF INT, V1263, P88; DENNING D. E., 1998, CYBERSPACE ATTACKS C; Deshpande A, 2005, PROC INT CONF DATA, P143; Eickeler S, 1998, INT C PATT RECOG, P1206; ESPOSITO R., 2007, ICML, P257; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; FUJIWARA Y., 2008, KDD, P247; GALES M., 1999, TSAP, P152; GANTI V., 2000, ICDE, P439; Gao LK, 2005, IEEE T KNOWL DATA EN, V17, P1320, DOI 10.1109/TKDE.2005.161; GEHRKE J., 2001, P 2001 ACM SIGMOD IN, P13, DOI 10.1145/375663.375665; HAUSSLER D., 1993, HICSS, P792; Helbing D., 2000, TRAFFIC GRANULAR FLO; Hu JY, 1996, IEEE T PATTERN ANAL, V18, P1039; Huang JC, 2005, IEEE T MULTIMEDIA, V7, P538, DOI 10.1109/TMM.2005.843346; Hunt M., 1989, P ICASSP, P262; Jelinek F., 1999, STAT METHODS SPEECH; Kahn Joseph, 1999, P 5 ANN ACM IEEE INT, P271, DOI 10.1145/313451.313558; Kaufman L., 2005, FINDING GROUPS DATA; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; KWOK J. T., 2000, ICPR, P2195; Kwon J., 2000, MODELING FREEWAY TRA; Lane T., 1999, P IJCAI 99 WORKSH LE, P35; LEVINSON SE, 1983, AT&T TECH J, V62, P1035; Li C, 2000, INT C MACH LEARN, P543; Mitchison G., 1999, BIOL SEQUENCE ANAL P; Moon Y., 2002, P INT C MAN DAT ACM, P382; MOORE A. W., 2005, ICML, P800; MOTWANI R., 2003, P C INN DAT SYST RES; MOUNT D. W., 2001, BIOINFORMATICS SEQUE; NEY H, 1992, IEEE T SIGNAL PROCES, V40, P272, DOI 10.1109/78.124938; NOVAK D., 2004, EUROSIM; PFURTSCHELLER G, 1994, ELECTROEN CLIN NEURO, V90, P456, DOI 10.1016/0013-4694(94)90137-6; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; SAGAYAMA S., 1995, P IEEE INT C AC SPEE, P213; SINGH S. P., 1994, NIPS, P361; SMYTH P., 1996, NIPS, P648; Tao Y, 2005, P 31 INT C VER LARG, P922; Tatbul N, 2003, P 29 INT C VER LARG, P309, DOI 10.1016/B978-012722442-8/50035-5; Warrender C, 1999, P IEEE S SECUR PRIV, P133, DOI 10.1109/SECPRI.1999.766910; Yi BK, 1998, PROC INT CONF DATA, P201; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324; Zhong S, 2002, IEEE IJCNN, P1154, DOI 10.1109/IJCNN.2002.1007657; Zhu Y., 2002, P 28 INT C VER LARG, P358, DOI DOI 10.1016/B978-155860869-6/50039-1	59	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	NOV	2009	3	4								10.1145/1631162.1631166		37	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VT	WOS:000208168200004	
J	Kiernan, J; Terzi, E				Kiernan, Jerry; Terzi, Evimaria			Constructing Comprehensive Summaries of Large Event Sequences	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithms; Experimentation; Theory; Event sequences; summarization; log mining		Event sequences capture system and user activity over time. Prior research on sequence mining has mostly focused on discovering local patterns appearing in a sequence. While interesting, these patterns do not give a comprehensive summary of the entire event sequence. Moreover, the number of patterns discovered can be large. In this article, we take an alternative approach and build short summaries that describe an entire sequence, and discover local dependencies between event types. We formally define the summarization problem as an optimization problem that balances shortness of the summary with accuracy of the data description. We show that this problem can be solved optimally in polynomial time by using a combination of two dynamic-programming algorithms. We also explore more efficient greedy alternatives and demonstrate that they work well on large datasets. Experiments on both synthetic and real datasets illustrate that our algorithms are efficient and produce high-quality results, and reveal interesting local structures in the data.	[Terzi, Evimaria] Boston Univ, Dept Comp Sci, Boston, MA USA	Terzi, E (reprint author), Boston Univ, Dept Comp Sci, 115 Cummington St, Boston, MA USA.	jkiernan@us.ibm.com; evimaria@cs.bu.edu					Agrawal R., 1995, P 11 INT C DAT ENG; Allan J., 2001, SIGIR Forum; BELLMAN R., 1961, COMMUN ACM, V1, P6; Bettini C, 1998, DATA ENG B, V21, P32; Brants T, 2003, P 26 ANN INT ACM SIG, P330; CHUDOVA D., 2002, P INT C KNOWL DISC D, P153; Elfeky M.G., 2004, P 9 INT C EXT DAT TE; Gionis A, 2003, P 7 INT C RES COMP M, P123, DOI 10.1145/640075.640091; Guha S., 2001, P 33 ANN ACM S THEOR, P471, DOI 10.1145/380752.380841; Han J, 1998, P 4 INT C KNOWL DISC, P214; Han J., 1999, P 15 INT C DAT ENG; Karras P., 2007, P ACM SIGKDD INT C K, P380, DOI 10.1145/1281192.1281235; Keogh E., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989531; KIERNAN J., 2009, P INT C EXT IN PRESS; KILPELAINEN P., 1995, P 2 EUR C EUR, P252; Kleinberg J, 2003, DATA MIN KNOWL DISC, V7, P373, DOI 10.1023/A:1024940629314; Koivisto M, 2003, Pac Symp Biocomput, P502; Li W., 2001, P 5 ANN INT C COMP B, P204, DOI 10.1145/369133.369202; Li WT, 2001, PHYS REV LETT, V86, P5815, DOI 10.1103/PhysRevLett.86.5815; MA S., 2001, P 17 INT C DAT ENG; Mannila H., 2001, P 7 ACM SIGKDD INT C, P341, DOI 10.1145/502512.502562; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Mehta M., 1995, P 1 INT C KNOWL DISC, P216; PAPADIMITRIOU S., 2006, P 2006 ACM SIGMOD IN, P647, DOI DOI 10.1145/1142473.1142545; Pei J, 2007, J INTELL INF SYST, V28, P133, DOI 10.1007/s10844-006-0006-z; Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rissanen J, 1989, STOCHASTIC COMPLEXIT; Ruzzo W L, 1999, Proc Int Conf Intell Syst Mol Biol, P234; Sakurai Y., 2005, P ACM SIGMOD BALT MA, P599, DOI DOI 10.1145/1066157.1066226; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; SWAN R, 2000, P 23 ANN INT ACM SIG, P49, DOI 10.1145/345508.345546; Terzi E., 2006, P SIAM INT C DAT MIN; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; Yang J., 2002, P 2002 ACM SIGMOD IN, P406; Yang Yiming, 2000, P 23 ANN INT ACM SIG, P65, DOI 10.1145/345508.345550; Zhu Y., 2002, P 28 INT C VER LARG, P358, DOI DOI 10.1016/B978-155860869-6/50039-1	37	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	NOV	2009	3	4							21	10.1145/1631162.1631169		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VT	WOS:000208168200007	
J	Mannila, H; Gunopulos, D				Mannila, Heikki; Gunopulos, Dimitrios			ACM TKDD Special Issue ACM SIGKDD 2007 and ACM SIGKDD 2008	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Editorial Material									[Mannila, Heikki] Helsinki Univ Technol, FIN-02150 Espoo, Finland; [Mannila, Heikki] Univ Helsinki, FIN-00014 Helsinki, Finland; [Gunopulos, Dimitrios] Univ Athens, Athens, Greece; [Gunopulos, Dimitrios] Univ Calif Riverside, Riverside, CA 92521 USA	Mannila, H (reprint author), Helsinki Univ Technol, FIN-02150 Espoo, Finland.	mannila@cs.helsinki.fi; dgunopulos@gmail.com						0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	NOV	2009	3	4								10.1145/1631162.1631163		2	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VT	WOS:000208168200001	
J	Zhang, X; Zou, F; Wang, W				Zhang, Xiang; Zou, Fei; Wang, Wei			Efficient Algorithms for Genome-Wide Association Study	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Algorithm; Performance; Association study; ANOVA test; permutation test		Studying the association between quantitative phenotype (such as height or weight) and single nucleotide polymorphisms (SNPs) is an important problem in biology. To understand underlying mechanisms of complex phenotypes, it is often necessary to consider joint genetic effects across multiple SNPs. ANOVA (analysis of variance) test is routinely used in association study. Important findings from studying gene-gene (SNP-pair) interactions are appearing in the literature. However, the number of SNPs can be up to millions. Evaluating joint effects of SNPs is a challenging task even for SNP-pairs. Moreover, with large number of SNPs correlated, permutation procedure is preferred over simple Bonferroni correction for properly controlling family-wise error rate and retaining mapping power, which dramatically increases the computational cost of association study. In this article, we study the problem of finding SNP-pairs that have significant associations with a given quantitative phenotype. We propose an efficient algorithm, FastANOVA, for performing ANOVA tests on SNP-pairs in a batch mode, which also supports large permutation test. We derive an upper bound of SNP-pair ANOVA test, which can be expressed as the sum of two terms. The first term is based on single-SNP ANOVA test. The second term is based on the SNPs and independent of any phenotype permutation. Furthermore, SNP-pairs can be organized into groups, each of which shares a common upper bound. This allows for maximum reuse of intermediate computation, efficient upper bound estimation, and effective SNP-pair pruning. Consequently, FastANOVA only needs to perform the ANOVA test on a small number of candidate SNP-pairs without the risk of missing any significant ones. Extensive experiments demonstrate that FastANOVA is orders of magnitude faster than the brute-force implementation of ANOVA tests on all SNP pairs. The principles used in FastANOVA can be applied to categorical phenotypes and other statistics such as Chi-square test.	[Zhang, Xiang; Zou, Fei; Wang, Wei] Univ N Carolina, Chapel Hill, NC 27599 USA	Zhang, X (reprint author), Univ N Carolina, Chapel Hill, NC 27599 USA.	xiang@cs.unc.edu; fzou@bios.unc.edu; weiwang@cs.unc.edu			NSF [IIS-0448392, CCF-0523875, IIS-0812464]; Micosoft New Faculty	This research was partially supported by NSF grant IIS-0448392, NSF grant CCF-0523875, NSF grant IIS-0812464, and a Micosoft New Faculty Fellowship.	Balding DJ, 2006, NAT REV GENET, V7, P781, DOI 10.1038/nrg1916; Boyd S., 2004, CONVEX OPTIMIZATION; Breiman L, 1984, CLASSIFICATION REGRE; Carlborg O, 2000, GENETICS, V155, P2003; Carlson CS, 2004, NATURE, V429, P446, DOI 10.1038/nature02623; Chi PB, 2006, GENET EPIDEMIOL, V30, P609, DOI 10.1002/gepi.20172; Curtis D, 2001, ANN HUM GENET, V65, P95, DOI 10.1046/j.1469-1809.2001.6510095.x; Saxena R, 2007, SCIENCE, V316, P1331, DOI 10.1126/science.1142358; Doerge RW, 2002, NAT REV GENET, V3, P43, DOI 10.1038/nrg703; Dudoit S, 2008, SPRINGER SER STAT, P1; Evans DM, 2006, PLOS GENET, V2, P1424, DOI 10.1371/journal.pgen.0020157; HALPERIN E., 2005, P ISMB; Hoh J, 2000, ANN HUM GENET, V64, P413, DOI 10.1046/j.1469-1809.2000.6450413.x; Hoh J, 2003, NAT REV GENET, V4, P701, DOI 10.1038/nrg1155; Ideraabdullah FY, 2004, GENOME RES, V14, P1880, DOI 10.1101/gr.2519704; Liu H., 1998, FEATURE SELECTION KN; Miller R.G.J., 1981, SIMULTANEOUS STAT IN; Moore JH, 2006, J THEOR BIOL, V241, P252, DOI 10.1016/j.jtbi.2005.11.036; Nakamichi R, 2001, GENETICS, V158, P463; Nelson MR, 2001, GENOME RES, V11, P458, DOI 10.1101/gr.172901; Ohno Y, 2000, GENETICS, V155, P785; Pagano M, 2000, PRINCIPLES BIOSTATIS; Province MA, 2001, ADV GENET, V42, P273, DOI 10.1016/S0065-2660(01)42028-1; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; ROBERTS A., 2007, P ISMB; Scuteri A, 2007, PLOS GENET, V3, P1200, DOI 10.1371/journal.pgen.0030115; Sebastiani P, 2003, P NATL ACAD SCI USA, V100, P9900, DOI 10.1073/pnas.1633613100; Segre D, 2005, NAT GENET, V37, P77, DOI 10.1038/ng1489; Sherriff A, 2001, ADV GENET, V42, P287, DOI 10.1016/S0065-2660(01)42029-3; Shimomura K, 2001, GENOME RES, V11, P959, DOI 10.1101/gr.171601; Weedon MN, 2007, NAT GENET, V39, P1245, DOI 10.1038/ng2121; WESTFALL P. H., 1998, RESAMPLING BASED MUL; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5; ZHANG X., 2009, P PAC S BIOC; ZHANG X., 2009, LECT NOTES COMPUTER, V5541	35	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	NOV	2009	3	4								10.1145/1631162.1631167		28	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VT	WOS:000208168200005	
J	Kolcz, A; Mladenic, D; Buntine, W; Grobelnik, M; Shawe-Taylor, J				Kolcz, Aleksander; Mladenic, Dunja; Buntine, Wray; Grobelnik, Marko; Shawe-Taylor, John			Guest editors' introduction: special issue of selected papers from ECML PKDD 2009	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Kolcz, Aleksander] Microsoft Corp, Redmond, WA 98052 USA; [Mladenic, Dunja; Grobelnik, Marko] Jozef Stefan Inst, Ljubljana, Slovenia; [Buntine, Wray] Helsinki Inst IT, Helsinki, Finland; [Buntine, Wray] NICTA, Sydney, NSW, Australia; [Shawe-Taylor, John] UCL, London, England	Kolcz, A (reprint author), Microsoft Corp, Redmond, WA 98052 USA.	alek@ir.iit.edu					Akoglu L, 2009, DATA MIN KNOWL DISC, V19, P194, DOI 10.1007/s10618-009-0140-7; Bonchi F, 2009, DATA MIN KNOWL DISC, V19, P227, DOI 10.1007/s10618-009-0141-6; Cheng WW, 2009, MACH LEARN, V76, P211, DOI 10.1007/s10994-009-5127-5; Gartner T, 2009, MACH LEARN, V76, P227, DOI 10.1007/s10994-009-5129-3; Johns J, 2009, MACH LEARN, V76, P243, DOI 10.1007/s10994-009-5128-4; Grosskreutz H, 2009, DATA MIN KNOWL DISC, V19, P210, DOI 10.1007/s10618-009-0136-3; Huopaniemi I, 2009, DATA MIN KNOWL DISC, V19, P261, DOI 10.1007/s10618-009-0142-5; Joachims T, 2009, MACH LEARN, V76, P179, DOI 10.1007/s10994-009-5126-6; Kranen P, 2009, DATA MIN KNOWL DISC, V19, P245, DOI 10.1007/s10618-009-0139-0; Liu A, 2009, MACH LEARN, V76, P257, DOI 10.1007/s10994-009-5131-9; Roth D, 2009, MACH LEARN, V76, P195, DOI 10.1007/s10994-009-5130-x; Santos-Rodriguez R, 2009, MACH LEARN, V76, P271, DOI 10.1007/s10994-009-5132-8; van Leeuwen M, 2009, DATA MIN KNOWL DISC, V19, P176, DOI 10.1007/s10618-009-0137-2; Zhao QL, 2009, DATA MIN KNOWL DISC, V19, P277, DOI 10.1007/s10618-009-0138-1	14	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2009	19	2					173	175		10.1007/s10618-009-0143-4		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	478FJ	WOS:000268572900001	
J	van Leeuwen, M; Vreeken, J; Siebes, A				van Leeuwen, Matthijs; Vreeken, Jilles; Siebes, Arno			Identifying the components	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia		MDL; Database components; Clusters	COMPRESSION	Most, if not all, databases are mixtures of samples from different distributions. Transactional data is no exception. For the prototypical example, supermarket basket analysis, one also expects a mixture of different buying patterns. Households of retired people buy different collections of items than households with young children. Models that take such underlying distributions into account are in general superior to those that do not. In this paper we introduce two MDL-based algorithms that follow orthogonal approaches to identify the components in a transaction database. The first follows a model-based approach, while the second is data-driven. Both are parameter-free: the number of components and the components themselves are chosen such that the combined complexity of data and models is minimised. Further, neither prior knowledge on the distributions nor a distance metric on the data is required. Experiments with both methods show that highly characteristic components are identified.	[van Leeuwen, Matthijs; Vreeken, Jilles; Siebes, Arno] Univ Utrecht, Dept Comp Sci, NL-3508 TB Utrecht, Netherlands	van Leeuwen, M (reprint author), Univ Utrecht, Dept Comp Sci, POB 80089, NL-3508 TB Utrecht, Netherlands.	mleeuwen@cs.uu.nl; jillesv@cs.uu.nl; arno@cs.uu.nl					Aggarwal CC, 2002, IEEE T KNOWL DATA EN, V14, P51, DOI 10.1109/69.979972; ANDRITSOS P, 2004, P EDBT 04, P124; Bischof H, 1999, PATTERN ANAL APPL, V2, P59, DOI 10.1007/s100440050015; Bohm C., 2006, P 12 ACM SIGKDD INT, P65, DOI 10.1145/1150402.1150414; Brijs T, 1999, P 5 INT C KNOWL DISC, P254, DOI 10.1145/312129.312241; Cadez I., 2001, P 7 ACM SIGKDD INT C, P37, DOI 10.1145/502512.502523; Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059; Coenen F., 2003, LUCS KDD DISCRETISED; Faloutsos C, 2007, DATA MIN KNOWL DISC, V15, P3, DOI 10.1007/s10618-006-0057-3; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gokcay E, 2002, IEEE T PATTERN ANAL, V24, P158, DOI 10.1109/34.982897; Grunwald P. D., 2005, ADV MINIMUM DESCRIPT; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Heikinheimo H, 2007, J BIOGEOGR, V34, P1053, DOI 10.1111/j.1365-2699.2006.01664.x; KONTKANEN P, 2004, 200406 HIIT; KOYOTURK M, 2005, IEEE T KNOWL DATA EN, V17, P447; Li M., 1993, INTRO KOLMOGOROV COM; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Mitchell-Jones A.J., 1999, ATLAS EUROPEAN MAMMA; Pensa R, 2005, P 9 EUR C PRINC PRAC, P643; Siebes A, 2006, P SIAM C DAT MIN, P393; Tishby N., 1999, P 37 ANN ALL C COMM, P368; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; VANLEEUWEN M, 2006, P ECML PKDD 06, P585; VREEKEN J, 2007, P KDD 07, P765, DOI 10.1145/1281192.1281274; Wang K, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P483, DOI 10.1145/319950.320054	26	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2009	19	2					176	193		10.1007/s10618-009-0137-2		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	478FJ	WOS:000268572900002	
J	Akoglu, L; Faloutsos, C				Akoglu, Leman; Faloutsos, Christos			RTG: a recursive realistic graph generator using random typing	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia		Simulation and modeling; Model validation and analysis; Graph generators	NETWORKS; WEB	We propose a new, recursive model to generate realistic graphs, evolving over time. Our model has the following properties: it is (a) flexible, capable of generating the cross product of weighted/unweighted, directed/undirected, uni/bipartite graphs; (b) realistic, giving graphs that obey eleven static and dynamic laws that real graphs follow (we formally prove that for several of the (power) laws and we estimate their exponents as a function of the model parameters); (c) parsimonious, requiring only four parameters. (d) fast, being linear on the number of edges; (e) simple, intuitively leading to the generation of macroscopic patterns. We empirically show that our model mimics two real-world graphs very well: Blognet (unipartite, undirected, unweighted) with 27 K nodes and 125 K edges; and Committee-to-Candidate campaign donations (bipartite, directed, weighted) with 23 K nodes and 880 K edges. We also show how to handle time so that edge/weight additions are bursty and self-similar.	[Akoglu, Leman; Faloutsos, Christos] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Akoglu, L (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.	lakoglu@cs.cmu.edu; christos@cs.cmu.edu					AKOGLU L, 2008, ICDM; Albert R, 1999, NATURE, V401, P130; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; CHAKRABARTI D, 2006, ACM COMPUT SURV, V38, P1; Chakrabarti D., 2004, 4 SIAM INT C DAT MIN; Conrad B, 2004, IEEE T INFORM THEORY, V50, P1403, DOI 10.1109/TIT.2004.830752; CROVELLA M, 1996, SIGMETRICS, P160; Erdos P., 1960, PUBL MATH I HUNG, V5, P17; EVENBAR E, 2007, SODA; Fabrikant A., 2003, PODC; Faloutsos M., 1999, SIGCOMM, P251; FLAKE GW, 2002, IEEE COMPUT, V35, P66; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; GOMEZ ME, 1998, WWC; GRIBBLE SD, 1998, SIGMETRICS 98; Kleinberg J. M., 1999, LECT NOTES COMPUTER, V1627, P1, DOI DOI 10.1007/3-540-48686-0_1; KRAETZL MSE, 2005, PRELIMINARY MANUSCRI; LAOUTARIS N, 2008, PODC; Leskovec J., 2005, ACM SIGKDD; Leskovec J., 2005, PKDD; MANDELBROT B, 1953, COMMUN THEORY; MCGLOHON M, 2008, ACM SIGKDD; MILLER GA, 1957, AM J PSYCHOL, V70, P311, DOI 10.2307/1419346; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; NEWMAN MEJ, 2004, POWER LAWS PARETO DI; Pennock DM, 2002, P NATL ACAD SCI USA, V99, P5207, DOI 10.1073/pnas.032085699; SCHWARTZ MF, 1993, COMMUN ACM, V36, P78, DOI 10.1145/163381.163402; SIGANOS G, 2003, POWER LAWS AS LEVEL; STROGATZ S. H., 1998, NATURE, V393, P6684; Tsourakakis C, 2008, ICDM; WANG M, 2002, ICDE, P507; YOUNG SJ, 2007, WAW 07, P138; Zipf G., 1932, SELECTIVE STUDIES PR	33	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2009	19	2					194	209		10.1007/s10618-009-0140-7		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	478FJ	WOS:000268572900003	
J	Grosskreutz, H; Ruping, S				Grosskreutz, Henrik; Rueping, Stefan			On subgroup discovery in numerical domains	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia		Pattern mining; Subgroup discovery; Performance; Pruning		Subgroup discovery is a Knowledge Discovery task that aims at finding subgroups of a population with high generality and distributional unusualness. While several subgroup discovery algorithms have been presented in the past, they focus on databases with nominal attributes or make use of discretization to get rid of the numerical attributes. In this paper, we illustrate why the replacement of numerical attributes by nominal attributes can result in suboptimal results. Thereafter, we present a new subgroup discovery algorithm that prunes large parts of the search space by exploiting bounds between related numerical subgroup descriptions. The same algorithm can also be applied to ordinal attributes. In an experimental section, we show that the use of our new pruning scheme results in a huge performance gain when more that just a few split-points are considered for the numerical attributes.	[Grosskreutz, Henrik; Rueping, Stefan] Fraunhofer IAIS, Schloss Birlinghoven, St Augustin, Germany	Grosskreutz, H (reprint author), Fraunhofer IAIS, Schloss Birlinghoven, St Augustin, Germany.	henrik.grosskreutz@iais.fraunhofer.de; stefan.rueping@iais.fraunhofer.de					ASUNCION A., 2007, UCI MACHINE LEARNING; Atzmueller M, 2006, LECT NOTES ARTIF INT, V4213, P6; Atzmueller M, 2005, J UNIVERS COMPUT SCI, V11, P1752; Demsar J., 2004, ORANGE EXPT MACHINE; DOUGHERTY J, 1995, SUPERVISED UNSUPERVI, P194; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; Grosskreutz H, 2008, LECT NOTES ARTIF INT, V5211, P440, DOI 10.1007/978-3-540-87479-9_47; HAPFELMEIER A, 2008, P 8 IEEE INT C DAT M; Klosgen W., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Klosgen W., 1996, ADV KNOWLEDGE DISCOV, P249; KRALJ P, 2005, P 8 INT MULT INF SOC, P220; Lavrac N., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183912; Lavrac N, 2004, MACH LEARN, V57, P115, DOI 10.1023/B:MACH.0000035474.48771.cd; Lavrac N, 2004, LECT NOTES ARTIF INT, V3848, P243; Srikant R, 1996, ACM SIGMOD RECORD, V25, P1, DOI 10.1145/235968.233311; Webb G. I., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Wrobel S, 1997, LECT NOTES ARTIF INT, V1263, P78	17	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2009	19	2					210	226		10.1007/s10618-009-0136-3		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	478FJ	WOS:000268572900004	
J	Bonchi, F; Castillo, C; Donato, D; Gionis, A				Bonchi, Francesco; Castillo, Carlos; Donato, Debora; Gionis, Aristides			Taxonomy-driven lumping for sequence mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia		Data mining; Sequence analysis; Markov models; Query-log analysis; Spatial-data analysis	SYSTEMS	Given a taxonomy of events and a dataset of sequences of these events, we study the problem of finding efficient and effective ways to produce a compact representation of the sequences. We model sequences with Markov models whose states correspond to nodes in the provided taxonomy, and each state represents the events in the subtree under the corresponding node. By lumping observed events to states that correspond to internal nodes in the taxonomy, we allow more compact models that are easier to understand and visualize, at the expense of a decrease in the data likelihood. We formally define and characterize our problem, and we propose a scalable search method for finding a good trade-off between two conflicting goals: maximizing the data likelihood, and minimizing the model complexity. We implement these ideas in Taxomo, a taxonomy-driven modeler, which we apply in two different domains, query-log mining and mining of moving-object trajectories. The empirical evaluation confirms the feasibility and usefulness of our approach.	[Bonchi, Francesco; Castillo, Carlos; Donato, Debora; Gionis, Aristides] Yahoo Res, Barcelona 080018, Spain	Gionis, A (reprint author), Yahoo Res, Diagonal 177, Barcelona 080018, Spain.	bonchi@yahoo-inc.com; chato@yahoo-inc.com; debora@yahoo-inc.com; gionis@yahoo-inc.com	Gionis, Aristides/G-2225-2013	Gionis, Aristides/0000-0002-5211-112X			Bicego M, 2001, LECT NOTES COMPUT SC, V2134, P75; BICEGO M, 2003, MACH LEARN DATA MIN, P95; BORGES J, 2004, ARXIVCS0406032; Brinkhoff T., 2003, IEEE DATA ENG B, V26, P19; CAKMAK A, 2008, P 11 INT C EXT DAT T; CAO H, 2008, P 14 ACM SIGKDD INT; Cover T. M., 1991, ELEMENTS INFORM THEO; FELZENSZWALB PF, 2004, ADV NEURAL INFORM PR; GIROLAMI M, 2003, ADV NEURAL INFORM PR; GURALNIK V, 2001, BIOKDD; KEMENY JG, 1959, FINITE MARKOV CHAINS; LAW MH, 2000, PATT REC INT C 2; Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961; LEE JG, 2007, P 2007 ACM SIGMOD IN; LEE JG, 2008, P 34 INT C VER LARG; LI X, 2007, P 10 INT S ADV SPAT; MANAVOGLU E, 2003, P 3 IEEE INT C DAT M; MANNING AM, 1997, PKDD; MEYER CD, 1989, SIAM REV, V31, P240, DOI 10.1137/1031050; Nanni M, 2006, J INTELL INF SYST, V27, P267, DOI 10.1007/s10844-006-9953-7; Schwarz G.E., 1978, ANN STAT, V6; SIMON HA, 1961, ECONOMETRICA, V29, P111, DOI 10.2307/1909285; Smyth P, 1997, ADV NEUR IN, V9, P648; Srikant R., 1995, P 21 INT C VER LARG; Srikant R., 1996, P 5 INT C EXT DAT TE; STOLCKE A, 1994, BEST 1 MODEL MERGING; Tijms HC, 1986, STOCHASTIC MODELLING; WANG J, 2007, SDM; WELCH LR, 2003, IEEE INF THEORY SOC, V53; WHITE LB, 2000, IEEE T AUTOMAT CONTR, V45	30	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2009	19	2					227	244		10.1007/s10618-009-0141-6		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	478FJ	WOS:000268572900005	
J	Kranen, P; Seidl, T				Kranen, Philipp; Seidl, Thomas			Harnessing the strengths of anytime algorithms for constant data streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia		Anytime algorithms; Stream data mining; Classification confidence		Anytime algorithms have been proposed for many different applications, e.g., in data mining. Their strengths are the ability to first provide a result after a very short initialization and second to improve their result with additional time. Therefore, anytime algorithms have so far been used when the available processing time varies, e.g., on varying data streams. In this paper we propose to employ anytime algorithms on constant data streams, i.e., for tasks with constant time allowance. We introduce two approaches that harness the strengths of anytime algorithms on constant data streams and thereby improve the over all quality of the result with respect to the corresponding budget algorithm. We derive formulas for the expected performance gain and demonstrate the effectiveness of our novel approaches using existing anytime algorithms on benchmark data sets.	[Kranen, Philipp; Seidl, Thomas] Rhein Westfal TH Aachen, Data Management & Data Explorat Grp, D-52056 Aachen, Germany	Kranen, P (reprint author), Rhein Westfal TH Aachen, Data Management & Data Explorat Grp, D-52056 Aachen, Germany.	kranen@cs.rwth-aachen.de; seidl@cs.rwth-aachen.de					Aggarwal C., 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1; AGGARWAL CC, 2004, P 30 INT C VER LARG, P852, DOI 10.1016/B978-012088469-8/50075-9; Aggarwal CC, 2004, P 10 ACM SIGKDD INT, P503, DOI 10.1145/1014052.1014110; Arai B., 2007, P 33 INT C VER LARG, P914; Charikar M., 2003, P 35 ANN ACM S THEOR, P30, DOI DOI 10.1145/780542.780548; Cheetham W., 2000, LNCS LNAI, V1898, P15; Cormode G, 2003, P ACM PRINC DAT SYST, P296, DOI 10.1145/773153.773182; Crammer K., 2003, NIPS; DECOSTE D, 2002, P INT C MACH LEARN I, P99; DECOSTE D, 2003, P 3 SIAM SDM; Delany SJ, 2005, LECT NOTES ARTIF INT, V3620, P177; Dredze M., 2008, P 25 INT C MACH LEAR, P264, DOI 10.1145/1390156.1390190; ESMEIR S, 2006, P 21 AAAI; Grass J., 1996, SIGART Bulletin, V7; Hettich S., 1999, UCI KDD ARCH; Hulten G., 2002, P 8 ACM SIGKDD INT C, P525; LIU CL, 1996, SIGART B, V7, P50; Manku GS, 2002, P 28 INT C VER LARG, P346; Myers K., 2000, P ICML 00 17 INT C M, P655; SEIDL T, 2009, ACM INT C P SERIES, V360, P311; Silberstein A., 2007, P 33 INT C VER LARG, P842; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; Ueno Ken, 2006, Proceedings Sixth International Conference on Data Mining (ICDM'06); VLACHOS M, 2003, WORKSH CLUST HIGH DI; Wan E A, 1990, IEEE Trans Neural Netw, V1, P303, DOI 10.1109/72.80269; Wang H., 2003, P 9 ACM SIGKDD INT C, P226, DOI DOI 10.1145/956750.956778; Yang Y, 2007, MACH LEARN, V69, P35, DOI 10.1007/s10994-007-5020-z; Zilberstein S, 1996, AI MAG, V17, P73	28	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2009	19	2					245	260		10.1007/s10618-009-0139-0		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	478FJ	WOS:000268572900006	
J	Huopaniemi, I; Suvitaival, T; Nikkila, J; Oresic, M; Kaski, S				Huopaniemi, Ilkka; Suvitaival, Tommi; Nikkila, Janne; Oresic, Matej; Kaski, Samuel			Two-way analysis of high-dimensional collinear data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia		ANOVA; Factor analysis; Hierarchical model; Metabolomics; Multi-way analysis; Small sample-size	GENE-EXPRESSION PROFILES; VALIDATION; MIXTURE; MODELS; ASCA; TOOL	We present a Bayesian model for two-way ANOVA-type analysis of high-dimensional, small sample-size datasets with highly correlated groups of variables. Modern cellular measurement methods are a main application area; typically the task is differential analysis between diseased and healthy samples, complicated by additional covariates requiring a multi-way analysis. The main complication is the combination of high dimensionality and low sample size, which renders classical multivariate techniques useless. We introduce a hierarchical model which does dimensionality reduction by assuming that the input variables come in similarly-behaving groups, and performs an ANOVA-type decomposition for the set of reduced-dimensional latent variables. We apply the methods to study lipidomic profiles of a recent large-cohort human diabetes study.	[Huopaniemi, Ilkka; Suvitaival, Tommi; Nikkila, Janne; Kaski, Samuel] Helsinki Univ Technol, Dept Informat & Comp Sci, TKK, Espoo 02015, Finland; [Nikkila, Janne] Univ Helsinki, Dept Vet Basic Sci, Div Microbiol & Epidemiol, Fac Vet Med, FIN-00014 Helsinki, Finland; [Oresic, Matej] VTT Tech Res Ctr Finland, Espoo 02044, Finland	Huopaniemi, I (reprint author), Helsinki Univ Technol, Dept Informat & Comp Sci, TKK, POB 5400, Espoo 02015, Finland.	ilkka.huopaniemi@tkk.fi; tommi.suvitaival@tkk.fi; janne.nikkila@tkk.fi; matej.oresic@vtt.com; samuel.kaski@tkk.fi					Archambeau Cedric, 2009, ADV NEURAL INFORM PR, V21, P73; BEAL M, 2006, P 22 ANN C UNC ART I; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BISHOP CM, 1999, P 1998 C ADV NEUR IN, P382; Cao G., 2009, ADV NEURAL INFORM PR, V21, P225; Celeux G, 2005, STAT MODEL, V5, P243, DOI 10.1191/1471082X05st096oa; Gelman A., 2003, BAYESIAN DATA ANAL; Ghahramani Z, 2000, ADV NEUR IN, V12, P449; Langsrud O, 2002, J ROY STAT SOC D-STA, V51, P305, DOI 10.1111/1467-9884.00320; Ng SK, 2006, BIOINFORMATICS, V22, P1745, DOI 10.1093/bioinformatics/btl165; NIKKILA J, 2008, MOL SYST BIOL, V4, DOI 10.1038/msb.2008.34; Oresic M, 2008, J EXP MED, V205, P2975, DOI 10.1084/jem.20081800; ROWE DB, 2000, 1096 DIV HUM SOC SCI; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Sanguinetti G, 2008, BIOINFORMATICS, V24, P1078, DOI 10.1093/bioinformatics/btn066; Seo DM, 2007, ANN APPL STAT, V1, P152, DOI 10.1214/07-AOAS110; Smilde AK, 2005, BIOINFORMATICS, V21, P3043, DOI 10.1093/bioinformatics/bti476; Steuer R, 2006, BRIEF BIOINFORM, V7, P151, DOI 10.1093/bib/bbl009; Tai F, 2007, BIOINFORMATICS, V23, P3170, DOI 10.1093/bioinformatics/btm488; Vis DJ, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-322; Wang L, 2008, PLOS GENET, V4, DOI 10.1371/journal.pgen.1000115; West M., 2003, BAYESIAN STAT, V7, P723; Westerhuis JA, 2008, METABOLOMICS, V4, P81, DOI 10.1007/s11306-007-0099-6	23	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2009	19	2					261	276		10.1007/s10618-009-0142-5		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	478FJ	WOS:000268572900007	
J	Zhao, QL; Jiang, YH; Xu, M				Zhao, Qiang-Li; Jiang, Yan-Huang; Xu, Ming			A fast ensemble pruning algorithm based on pattern mining process	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia		Pattern mining based ensemble pruning; FP-Tree; Bagging; Back-propagation neural network	CLASSIFIERS; RECOGNITION	Ensemble pruning deals with the reduction of base classifiers prior to combination in order to improve generalization and prediction efficiency. Existing ensemble pruning algorithms require much pruning time. This paper presents a fast pruning approach: pattern mining based ensemble pruning (PMEP). In this algorithm, the prediction results of all base classifiers are organized as a transaction database, and FP-Tree structure is used to compact the prediction results. Then a greedy pattern mining method is explored to find the ensemble of size k. After obtaining the ensembles of all possible sizes, the one with the best accuracy is outputted. Compared with Bagging, GASEN, and Forward Selection, experimental results show that PMEP achieves the best prediction accuracy and keeps the size of the final ensemble small, more importantly, its pruning time is much less than other ensemble pruning algorithms.	[Zhao, Qiang-Li; Jiang, Yan-Huang; Xu, Ming] Natl Univ Def Technol, Sch Comp Sci, Changsha, Hunan, Peoples R China	Zhao, QL (reprint author), Natl Univ Def Technol, Sch Comp Sci, Changsha, Hunan, Peoples R China.	zhao-qiangli@163.com; yhjiang@nudt.edu.cn					Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Allwein E.L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Asuncion D.N.A., 2007, UCI MACHINE LEARNING; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Caruana R., 2004, P 21 INT C MACH LEAR; Demsar J, 2006, J MACH LEARN RES, V7, P1; Ruta D., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.008; Han J., 2000, SIGKDD EXPLORATIONS, V2, P14; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Martinez-Munoz G, 2007, PATTERN RECOGN LETT, V28, P156, DOI 10.1016/j.patrec.2006.06.018; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; Parmanto B, 1996, ADV NEUR IN, V8, P882; PARTALAS I, 2009, NEUROCOMPUT IN PRESS; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; SCHAPIRE RE, 1999, P 16 INT JOINT C ART, P1401; SEWELL M, 2008, ENSEMBLE LEARNING; Tsoumakas G, 2005, INTELL DATA ANAL, V9, P511; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Zhang Y, 2006, J MACH LEARN RES, V7, P1315; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	21	5	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2009	19	2					277	292		10.1007/s10618-009-0138-1		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	478FJ	WOS:000268572900008	
J	Alvarez, D; Hidalgo, H				Alvarez, Dora; Hidalgo, Hugo			Document analysis and visualization with zero-inflated poisson	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Document visualization; Zero-inflated Poisson; Generative model	LATENT CLASS; REGRESSION; PROJECTION; ALGORITHM; MODEL; GTM	Data visualization is aimed at obtaining a graphic representation of high dimensional information. A data projection over a lower dimensional space is pursued, looking for some structure on the projections. Among the several data projection based methods available, the Generative Topographic Mapping (GTM) has become an important probabilistic framework to model data. The application to document data requires a change in the original (Gaussian) model in order to consider binary or multinomial variables. There have been several modifications on GTM to consider this kind of data, but the resulting latent projections are all scattered on the visualization plane. A document visualization method is proposed in this paper, based on a generative probabilistic model consisting of a mixture of Zero-inflated Poisson distributions. The performance of the method is evaluated in terms of cluster forming for the latent projections with an index based on Fisher's classifier, and the topology preservation capability is measured with the Sammon's stress error. A comparison with the GTM implementation with Gaussian, multinomial and Poisson distributions and with a Latent Dirichlet model is presented, observing a greater performance for the proposed method. A graphic presentation of the projections is also provided, showing the advantage of the developed method in terms of visualization and class separation. A detailed analysis of some documents projected on the latent representation showed that most of the documents appearing away from the corresponding cluster could be identified as outliers.	[Alvarez, Dora; Hidalgo, Hugo] CICESE, Ensenada 22860, Baja California, Mexico	Hidalgo, H (reprint author), CICESE, Km 107 Carr Tijuana Eda, Ensenada 22860, Baja California, Mexico.	dalvarez@cicese.mx; hugo@cicese.mx			CONACyT	The authors would like to thank to the reviewers for their suggestions. The first author was financed by CONACyT.	ALVAREZ D, 2006, P WORKSH TEXT MIN 6; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dobson AJ, 2002, INTRO GEN LINEAR MOD; Duda R.O., 2001, PATTERN CLASSIFICATI; Girolami M, 2001, IEEE T NEURAL NETWOR, V12, P1367, DOI 10.1109/72.963773; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; HONKELA T, 1996, P INT C NEUR NETW IC, P56; Kaban A, 2001, IEEE T PATTERN ANAL, V23, P859, DOI 10.1109/34.946989; KASKI S, 1996, P WCNN 96 WORLD C NE, P814; Kohonen T., 1989, SELF ORG ASS MEMORY; Kohonen T., 1996, LECT NOTES COMPUTER, V1112, P269; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; LAGUS K, 1996, P 2 INT C KNOWL DISC, P238; LAMBERT D, 1992, TECHNOMETRICS, V34, P1, DOI 10.2307/1269547; Li J., 2006, COMPUTATIONAL STAT D, V50, P163, DOI 10.1016/j.csda.2004.07.013; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; Miikkulainen R., 1993, SUBSYMBOLIC NATURAL; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171; Salton G., 1983, INTRO MODERN INFORM; SAMMON JW, 1969, IEEE T COMPUT, V18, P404; Tino P, 2002, IEEE T PATTERN ANAL, V24, P639, DOI 10.1109/34.1000238; Vellido A, 2006, COMPUT BIOL MED, V36, P1049, DOI 10.1016/j.compbiomed.2005.09.004; WEDEL M, 1993, J APPL ECONOM, V8, P397, DOI 10.1002/jae.3950080407; YANG J, 2001, LECT NOTES ARTIF INT, V2168, P55	27	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2009	19	1					1	23		10.1007/s10618-009-0127-4		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	448ML	WOS:000266266600001	
J	Shieh, J; Keogh, E				Shieh, Jin; Keogh, Eamonn			iSAX: disk-aware mining and indexing of massive time series datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Time series; Data mining; Representations; Indexing	REPRESENTATION; COMPRESSION	Current research in indexing and mining time series data has produced many interesting algorithms and representations. However, the algorithms and the size of data considered have generally not been representative of the increasingly massive datasets encountered in science, engineering, and business domains. In this work, we introduce a novel multi-resolution symbolic representation which can be used to index datasets which are several orders of magnitude larger than anything else considered in the literature. To demonstrate the utility of this representation, we constructed a simple tree-based index structure which facilitates fast exact search and orders of magnitude faster, approximate search. For example, with a database of one-hundred million time series, the approximate search can retrieve high quality nearest neighbors in slightly over a second, whereas a sequential scan would take tens of minutes. Our experimental evaluation demonstrates that our representation allows index performance to scale well with increasing dataset sizes. Additionally, we provide analysis concerning parameter sensitivity, approximate search effectiveness, and lower bound comparisons between time series representations in a bit constrained environment. We further show how to exploit the combination of both exact and approximate search as sub-routines in data mining algorithms, allowing for the exact mining of truly massive real world datasets, containing tens of millions of time series.	[Shieh, Jin; Keogh, Eamonn] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA	Shieh, J (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	shiehj@cs.ucr.edu; eamonn@cs.ucr.edu					Andre-Jonsson H, 1997, LECT NOTES ARTIF INT, V1263, P211; ASSENT I, 2008, P 11 EDBT; Bagnall A, 2006, DATA MIN KNOWL DISC, V13, P11, DOI 10.1007/s10618-005-0028-0; Batista LV, 2001, MED ENG PHYS, V23, P127, DOI 10.1016/S1350-4533(01)00030-3; Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI 10.1145/502512.502546; Cai Y., 2004, P ACM SIGMOD INT C M, P599, DOI 10.1145/1007568.1007636; Chan KP, 1999, PROC INT CONF DATA, P126; Chen J, 1998, IEEE T BIO-MED ENG, V45, P1414, DOI 10.1109/10.730435; CHEN Q, 2007, P 33 INT C VER LARG; Ding H., 2008, P VLDB ENDOWMENT, V1, P1542, DOI DOI 10.1145/1454159.1454226; DING H, 2008, P VLDB END AUG 2008, V2, P1542; Faloutsos C., 1994, P ACM SIGMOD; FUGLEDE B, 2004, P INT S INF THEOR; Guttman A, 1984, ACM SIGMOD, V14, P47, DOI [10.1145/971697.602266, DOI 10.1145/971697.602266], DOI 10.1145/971697.602266]; Huang YW, 1999, P 5 INT C KNOWL DISC, P282, DOI 10.1145/312129.318357; IJDO JW, 1991, P NATL ACAD SCI USA, V88, P9051, DOI 10.1073/pnas.88.20.9051; KAFFKA S, 2000, PROTECTING HIGH YIEL; Keogh E., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011669; Kumar N., 2005, P SIAM INT C DAT MIN; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; MEGALOOIKONOMOU V, 2005, P 21 ICDE; MORINAKA Y, 2001, P PAC AS C KNOWL DIS; PORTET F, 2007, P AIME 2007; Ratanamahatana CA, 2005, SIAM PROC S, P506; Rogers J, 2006, GENOMICS, V87, P30, DOI 10.1016/j.ygeno.2005.10.004; Scholle S., 1999, SOMNOLOGIE, V3, P163, DOI 10.1007/s11818-999-0029-0; Shatkay H, 1996, PROC INT CONF DATA, P536, DOI 10.1109/ICDE.1996.492204; Steinbach MS, 2003, P 9 ACM SIGKDD INT C, P446; WEI L, 2005, P 5 IEEE INT C DAT M, P490; Xi X., 2006, P 23 INT C MACH LEAR, P1033, DOI 10.1145/1143844.1143974; ZILBERSTEIN S, 1995, IMPRECISE APPROXIMAT; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680	32	5	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2009	19	1					24	57		10.1007/s10618-009-0125-6		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	448ML	WOS:000266266600002	
J	Huang, HS; Yang, BH; Chang, YM; Hsu, CN				Huang, Han-Shen; Yang, Bo-Hou; Chang, Yu-Ming; Hsu, Chun-Nan			Global and componentwise extrapolations for accelerating training of Bayesian networks and conditional random fields	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Bayesian networks; Conditional random fields; Expectation maximization (EM) algorithm; Generalized iterative scaling; Aitken's extrapolation	EM ALGORITHM; PROBABILISTIC NETWORKS; CONVERGENCE; INFORMATION; INDUCTION	The triple jump extrapolation method is an effective approximation of Aitken's acceleration that can accelerate the convergence of many algorithms for data mining, including EM and generalized iterative scaling (GIS). It has two options-global and componentwise extrapolation. Empirical studies showed that neither can dominate the other and it is not known which one is better under what condition. In this paper, we investigate this problem and conclude that, when the Jacobian is (block) diagonal, componentwise extrapolation will be more effective. We derive two hints to determine the block diagonality. The first hint is that when we have a highly sparse data set, the Jacobian of the EM mapping for training a Bayesian network will be block diagonal. The second is that the block diagonality of the Jacobian of the GIS mapping for training CRF is negatively correlated with the strength of feature dependencies. We empirically verify these hints with controlled and real-world data sets and show that our hints can accurately predict which method will be superior. We also show that both global and componentwise extrapolation can provide substantial acceleration. In particular, when applied to train large-scale CRF models, the GIS variant accelerated by componentwise extrapolation not only outperforms its global extrapolation counterpart, as our hint predicts, but can also compete with limited-memory BFGS (L-BFGS), the de facto standard for CRF training, in terms of both computational efficiency and F-scores. Though none of the above methods are as fast as stochastic gradient descent (SGD), careful tuning is required for SGD and the results given in this paper provide a useful foundation for automatic tuning.	[Huang, Han-Shen; Yang, Bo-Hou; Chang, Yu-Ming; Hsu, Chun-Nan] Acad Sinica, Inst Informat Sci, Taipei, Taiwan; [Yang, Bo-Hou] Chang Gung Univ, Dept Elect Engn, Tao Yuan, Taiwan	Hsu, CN (reprint author), Acad Sinica, Inst Informat Sci, Taipei, Taiwan.	hanshen@iis.sinica.edu.tw; ericyang@iis.sinica.edu.tw; porter@iis.sinica.edu.tw; chunnan@iis.sinica.edu.tw					Bauer E, 1997, P 13 ANN C UNC ART I, P3; Berlinet A, 2007, COMPUT STAT DATA AN, V51, P3689, DOI 10.1016/j.csda.2006.12.013; Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Bottou L, 2007, STOCHASTIC GRADIENT; Burden R. L., 1988, NUMERICAL ANAL; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Fraley C, 1999, COMPUT STAT DATA AN, V31, P13, DOI 10.1016/S0167-9473(99)00003-1; Golub G.H., 1996, MATRIX COMPUTATIONS; Hammerlin G., 1991, NUMERICAL MATH; HESTERBERG T, 2005, P STAT COMP SECT AM; Hsu CN, 2008, BIOINFORMATICS, V24, pi286; HUANG HS, 2005, P 5 IEEE INT C DAT M, P649; HUANG HS, 2007, P 7 IEEE INT C DAT M, P511; HUANG HS, 2007, TRIIS07012 AC SIN; Jamshidian M, 1997, J ROY STAT SOC B MET, V59, P569, DOI 10.1111/1467-9868.00083; KAPETANIOS G, 2004, TESTING DIAGONALITY; Kim J.-D., 2004, P INT WORKSH NAT LAN, P70, DOI 10.3115/1567594.1567610; KUDO T, 2006, CRF YET ANOTHER CRF; Kuroda M, 2006, COMPUT STAT DATA AN, V51, P1549, DOI 10.1016/j.csda.2006.05.004; Lafferty J, 2001, P 18 INT C MACH LEAR, P282; LOUIS TA, 1982, J ROY STAT SOC B MET, V44, P226; Malouf R., 2002, P 6 C NAT LANG LEARN, P49; McLachlan G., 1997, WILEY SERIES PROBABI; MENG XL, 1994, LINEAR ALGEBRA APPL, V199, P413, DOI 10.1016/0024-3795(94)90363-8; Nocedal J, 1999, NUMERICAL OPTIMIZATI; Pearl J., 1988, PROBABILISTIC REASON; Russell S., 1995, P 14 INT JOINT C ART, P1146; SALAKHUTDINOV R, 2003, C UNC ART INT UAI 03, P509; Salama AD, 2003, AM J TRANSPLANT, V3, P509, DOI 10.1034/j.1600-6143.2003.00114.x; Schafer J.L., 1997, ANAL INCOMPLETE MULT; Settles B., 2004, P INT JOINT WORKSH N, P104, DOI 10.3115/1567594.1567618; Sha Fei, 2003, P HLT NAACL, P213; Thiesson B, 2001, MACH LEARN, V45, P279, DOI 10.1023/A:1017986506241; TJONG EF, 2000, P CONLL 2000 LLL 200, P127; VARADHAN R, 2004, 63 J HOPK U DEP BIOS; Wilbur J., 2007, P 2 BIOCREATIVE CHAL, P7	39	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2009	19	1					58	94		10.1007/s10618-009-0128-3		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	448ML	WOS:000266266600003	
J	Hashemi, S; Yang, Y				Hashemi, Sattar; Yang, Ying			Flexible decision tree for data stream classification in the presence of concept change, noise and missing values	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Classification learning; Data stream classification; Decision tree learning; Fuzzy learning	NETWORK	In recent years, classification learning for data streams has become an important and active research topic. A major challenge posed by data streams is that their underlying concepts can change over time, which requires current classifiers to be revised accordingly and timely. To detect concept change, a common methodology is to observe the online classification accuracy. If accuracy drops below some threshold value, a concept change is deemed to have taken place. An implicit assumption behind this methodology is that any drop in classification accuracy can be interpreted as a symptom of concept change. Unfortunately however, this assumption is often violated in the real world where data streams carry noise that can also introduce a significant reduction in classification accuracy. To compound this problem, traditional noise cleansing methods are incompetent for data streams. Those methods normally need to scan data multiple times whereas learning for data streams can only afford one-pass scan because of data's high speed and huge volume. Another open problem in data stream classification is how to deal with missing values. When new instances containing missing values arrive, how a learning model classifies them and how the learning model updates itself according to them is an issue whose solution is far from being explored. To solve these problems, this paper proposes a novel classification algorithm, flexible decision tree (FlexDT), which extends fuzzy logic to data stream classification. The advantages are three-fold. First, FlexDT offers a flexible structure to effectively and efficiently handle concept change. Second, FlexDT is robust to noise. Hence it can prevent noise from interfering with classification accuracy, and accuracy drop can be safely attributed to concept change. Third, it deals with missing values in an elegant way. Extensive evaluations are conducted to compare FlexDT with representative existing data stream classification algorithms using a large suite of data streams and various statistical tests. Experimental results suggest that FlexDT offers a significant benefit to data stream classification in real-world scenarios where concept change, noise and missing values coexist.	[Yang, Ying] Australian Taxat Off, Melbourne, Vic, Australia; [Hashemi, Sattar] Shiraz Univ, Sch Elect Engn & Comp Sci, Shiraz, Iran	Yang, Y (reprint author), Australian Taxat Off, Melbourne, Vic, Australia.	s_hashemi@shirazu.ac.ir; ying.yang@ato.gov.au					Basak J, 2006, NEURAL COMPUT, V18, P2062, DOI 10.1162/neco.2006.18.9.2062; Bhatt RB, 2006, INT J NEURAL SYST, V16, P63, DOI 10.1142/S0129065706000470; CHAN P, 1972, J AM STAT ASSOC, V6, P473; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347107; Fan W., 2004, P 10 ACM SIGKDD INT, P128, DOI 10.1145/1014052.1014069; Fayyad U. M., 1993, 13 INT JOINT C ART I, P1022; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Hashemi S, 2007, LECT NOTES COMPUT SC, V4830, P669; Haykin S., 1994, NEURAL NETWORKS COMP; Ho S.-S., 2005, P 22 INT C MACH LEAR, P321, DOI 10.1145/1102351.1102392; Hulten G., 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Janikow C. Z., 2005, ANN M N AM FUZZ INF, P379; Janikow CZ, 1998, IEEE T SYST MAN CY B, V28, P1, DOI 10.1109/3477.658573; KOLTER JZ, 2003, P 3 IEEE INT C DAT M, P123; MAHER PE, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P7, DOI 10.1109/FUZZY.1993.327472; Mitchell T. M, 1997, MACHINE LEARNING; Mitra S, 2002, IEEE T SYST MAN CY C, V32, P328, DOI 10.1109/TSMCC.2002.806060; Mundfrom D. J., 1998, MULTIPLE LINEAR REGR, V25, P13; Newman D.J., 1998, UCI REPOSITORY MACHI; Olaru C, 2003, FUZZY SET SYST, V138, P221, DOI 10.1016/S0165-0114(03)00089-7; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1993, INDUCTION DECISION T, P349; Saar-Tsechansky M, 2007, J MACH LEARN RES, V8, P1625; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; Tsymbal A., 2004, TCDCS200415; Umanol M., 1994, IEEE INT C FUZZ SYST, P2113; Wang H., 2003, P 9 ACM SIGKDD INT C, P226, DOI DOI 10.1145/956750.956778; Wang P., 2005, P 5 IEEE INT C DAT M, P474; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280; Yang Y., 2005, P 11 ACM SIGKDD INT, P710, DOI 10.1145/1081870.1081961; Yang Y, 2006, DATA MIN KNOWL DISC, V13, P261, DOI 10.1007/s10618-006-0050-x; Zhu X., 2003, P 20 INT C MACH LEAR, P920; Zhu X., 2004, P 4 IEEE INT C DAT M, P305; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8; Zhu XQ, 2006, KNOWL INF SYST, V9, P339, DOI 10.1007/s10115-005-0212-y; Zimmermann H. -J, 2001, FUZZY SET THEORY ITS	40	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2009	19	1					95	131		10.1007/s10618-009-0130-9		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	448ML	WOS:000266266600004	
J	Wang, ET; Chen, ALP				Wang, En Tzu; Chen, Arbee L. P.			A novel hash-based approach for mining frequent itemsets over data streams requiring less memory space	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Data stream; Data mining; Frequent itemset; Hash-based approach; False positive		In recent times, data are generated as a form of continuous data streams in many applications. Since handling data streams is necessary and discovering knowledge behind data streams can often yield substantial benefits, mining over data streams has become one of the most important issues. Many approaches for mining frequent itemsets over data streams have been proposed. These approaches often consist of two procedures including continuously maintaining synopses for data streams and finding frequent itemsets from the synopses. However, most of the approaches assume that the synopses of data streams can be saved in memory and ignore the fact that the information of the non-frequent itemsets kept in the synopses may cause memory utilization to be significantly degraded. In this paper, we consider compressing the information of all the itemsets into a structure with a fixed size using a hash-based technique. This hash-based approach skillfully summarizes the information of the whole data stream by using a hash table, provides a novel technique to estimate the support counts of the non-frequent itemsets, and keeps only the frequent itemsets for speeding up the mining process. Therefore, the goal of optimizing memory space utilization can be achieved. The correctness guarantee, error analysis, and parameter setting of this approach are presented and a series of experiments is performed to show the effectiveness and the efficiency of this approach.	[Chen, Arbee L. P.] Natl Chengchi Univ, Dept Comp Sci, Taipei 11623, Taiwan; [Wang, En Tzu] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30043, Taiwan	Chen, ALP (reprint author), Natl Chengchi Univ, Dept Comp Sci, 64 Chihnan Rd,Sec 2 Wenshan, Taipei 11623, Taiwan.	m9221009@em92.ndhu.edu.tw; alpchen@cs.nccu.edu.tw					Agrawal R., 1994, P 20 INT C VER LARG, P487; Arlitt M. F., 1996, Performance Evaluation Review, V24; CALDERS T, 2007, P INT C DAT MIN 2007, P83; CALDERS T, 2006, P ECML PKDD 2006 WOR, P87; CHANG JH, 2003, P 9 ACM SIGKDD INT C, P487; Charikar M., 2002, P 29 INT C AUT LANG, P693; Cheng J., 2006, P 10 PAC AS C KNOWL, P462; Chi Y, 2004, P 4 IEEE INT C DAT M, P59; Cormode G, 2003, P ACM PRINC DAT SYST, P296, DOI 10.1145/773153.773182; Dang XH, 2008, KNOWL INF SYST, V16, P245, DOI 10.1007/s10115-007-0106-2; Demaine E. D., 2002, P 10 ANN EUR S ALG, P348; FISCHER MJ, 1982, J ALGORITHMS, V3, P362; Giannella C, 2004, DATA MINING NEXT GEN, P191; Golab L, 2003, P INT MEAS C, P173; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Jiang N., 2006, P 12 ACM SIGKDD INT, P592, DOI 10.1145/1150402.1150473; Jin C, 2003, P 12 INT C INF KNOWL, P287; Jin R., 2005, P 5 IEEE INT C DAT M, P210; Karp RM, 2003, ACM T DATABASE SYST, V28, P51, DOI 10.1145/762471.762473; Lee D., 2005, P 5 IEEE INT C DAT M, P266; Lee L., 2006, P 25 ACM SIGMOD SIGA, P290, DOI 10.1145/1142351.1142393; Leung C K S, 2006, P IEEE ICDM, P928; Li H., 2006, P IWMESD 06 HONG KON, P672; Li H, 2004, 1 INT WORKSH KNOWL D; LIN CH, 2005, 2005 SIAM INT C DAT; Manku GS, 2002, P 28 INT C VER LARG, P346; Mozafari B, 2008, PROC INT CONF DATA, P179, DOI 10.1109/ICDE.2008.4497426; WANG SY, 2007, P 2007 INT WORKSH HI, P244; WANG SY, 2007, P 8 ACIS INT C SOFTW, P682; Yu JX, 2004, P 30 INT C VER LARG, P204, DOI 10.1016/B978-012088469-8/50021-8	30	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2009	19	1					132	172		10.1007/s10618-009-0129-2		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	448ML	WOS:000266266600005	
J	Torvik, VI; Smalheiser, NR				Torvik, Vetle I.; Smalheiser, Neil R.			Author Name Disambiguation in MEDLINE	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Name disambiguation; bibliographic databases		Background: We recently described "Author-ity," a model for estimating the probability that two articles in MEDLINE, sharing the same author name, were written by the same individual. Features include shared title words, journal name, coauthors, medical subject headings, language, affiliations, and author name features (middle initial, suffix, and prevalence in MEDLINE). Here we test the hypothesis that the Author-ity model will suffice to disambiguate author names for the vast majority of articles in MEDLINE. Methods: Enhancements include: (a) incorporating first names and their variants, email addresses, and correlations between specific last names and affiliation words; (b) new methods of generating large unbiased training sets; (c) new methods for estimating the prior probability; (d) a weighted least squares algorithm for correcting transitivity violations; and (e) a maximum likelihood based agglomerative algorithm for computing clusters of articles that represent inferred author-individuals. Results: Pairwise comparisons were computed for all author names on all 15.3 million articles in MEDLINE (2006 baseline), that share last name and first initial, to create Author-ity 2006, a database that has each name on each article assigned to one of 6.7 million inferred author-individual clusters. Recall is estimated at similar to 98.8%. Lumping (putting two different individuals into the same cluster) affects similar to 0.5% of clusters, whereas splitting (assigning articles written by the same individual to >1 cluster) affects similar to 2% of articles. Impact: The Author-ity model can be applied generally to other bibliographic databases. Author name disambiguation allows information retrieval and data integration to become person-centered, not just document-centered, setting the stage for new data mining and social network tools that will facilitate the analysis of scholarly publishing and collaboration behavior. Availability: The Author-ity 2006 database is available for nonprofit academic research, and can be freely queried via http://arrowsmith.psych.uic.edu.	[Smalheiser, Neil R.] Univ Illinois, Dept Psychiat MC912, Chicago, IL 60612 USA	Torvik, VI (reprint author), Univ Illinois, Grad Sch Lib & Informat Sci, 501 E Daniel St, Champaign, IL 61820 USA.	vtorvik@illinois.edu; neils@uic.edu			US National Institutes of Health (NIH) [LM008364]	This research was supported by the US National Institutes of Health (NIH) grant LM008364.	Bhattacharya I, 2006, SIAM PROC S, P47; BHATTACHARYA I., 2007, ACM T KNOWL DISCOV D, V1, P1; BILENKO M, 2006, P IEEE COMP SOC 6 IN, P87; CULOTTA A., 2007, P 6 AAAI INT WORKSH; CULOTTA A., 2006, P ICML WORKSH OP PRO; Dominguez J, 2006, NUMER ALGORITHMS, V42, P1, DOI 10.1007/s11075-006-9019-5; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; French JC, 2000, J AM SOC INFORM SCI, V51, P774, DOI 10.1002/(SICI)1097-4571(2000)51:8<774::AID-ASI90>3.3.CO;2-G; Galvez C, 2007, J AM SOC INF SCI TEC, V58, P1960, DOI 10.1002/asi.20671; GARFIELD E, 1969, NATURE, V223, P763, DOI 10.1038/223763b0; Han H., 2004, Proceedings of the Fourth ACM/IEEE Joint Conference on Digital Libraries (IEEE Cat. No.04TH8766), DOI 10.1145/996350.996419; Han H, 2005, PROCEEDINGS OF THE 5TH ACM/IEEE JOINT CONFERENCE ON DIGITAL LIBRARIES, PROCEEDINGS, P334, DOI 10.1145/1065385.1065462; Herskovic JR, 2007, J AM MED INFORM ASSN, V14, P212, DOI 10.1197/jamia.M2191; Holmes DI, 2001, COMPUT HUMANITIES, V35, P315, DOI 10.1023/A:1017549100097; Huang J., 2006, P 10 EUR C PRINC PRA, P536; JARO MA, 1995, STAT MED, V14, P491, DOI 10.1002/sim.4780140510; Kalashnikov DV, 2006, ACM T DATABASE SYST, V31, P716, DOI 10.1145/1138394.1138401; KANANI P, 2007, P 20 INT JOINT C ART, P429; MADIGAN D., 2005, ANN M CLASS SOC N AM; Mann G., 2003, P 7 C NAT LANG LEARN, P33; On BW, 2005, Proceedings of the 5th ACM/IEEE Joint Conference on Digital Libraries, Proceedings, P344, DOI 10.1145/1065385.1065463; Qiu J, 2008, NATURE, V451, P766, DOI 10.1038/451766a; Reuther P., 2006, International Journal of Metadata, Semantics and Ontologies, V1, DOI 10.1504/IJMSO.2006.011006; Scoville Caryn L, 2003, Med Ref Serv Q, V22, P1, DOI 10.1300/J115v22n04_01; Smalheiser Neil R, 2008, J Biomed Discov Collab, V3, P2, DOI 10.1186/1747-5333-3-2; Smalheiser NR, 2009, COMPUT METH PROG BIO, V94, P190, DOI 10.1016/j.cmpb.2008.12.006; Smalheiser NR, 2009, ANNU REV INFORM SCI, V43, P287; Soler JM, 2007, SCIENTOMETRICS, V72, P281, DOI 10.1007/s11192-007-1730-z; Song Y, 2007, PROCEEDINGS OF THE 7TH ACM/IEE JOINT CONFERENCE ON DIGITAL LIBRARIES, P342, DOI 10.1145/1255175.1255243; SRIVASTAVA D., 2006, P ACM SIGMOD INT C M, P802, DOI 10.1145/1142473.1142599; Tan Y., 2006, P ACM IEEE JOINT C D, P314, DOI 10.1145/1141753.1141826; Torvik VI, 2007, BIOINFORMATICS, V23, P1658, DOI 10.1093/bioinformatics/btm161; Torvik VI, 2005, J AM SOC INF SCI TEC, V56, P140, DOI [10.1002/asi.20105, 10.1002/asi/20105]; Wilbur WJ, 1996, COMPUT BIOL MED, V26, P209, DOI 10.1016/0010-4825(95)00055-0; WINKLER WE, 1995, WILEY S PRO, P355; Yin X., 2007, P IEEE 23 INT C DAT, P1242	36	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2009	3	3								10.1145/1552303.1552304		29	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VR	WOS:000208168000001	
J	Tu, L; Chen, YX				Tu, Li; Chen, Yixin			Stream Data Clustering Based on Grid Density and Attraction	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Stream data; data mining; clustering; density-based algorithms		Clustering real-time stream data is an important and challenging problem. Existing algorithms such as CluStream are based on the k-means algorithm. These clustering algorithms have difficulties finding clusters of arbitrary shapes and handling outliers. Further, they require the knowledge of k and user-specified time window. To address these issues, this article proposes D-Stream, a framework for clustering stream data using a density-based approach. Our algorithm uses an online component that maps each input data record into a grid and an offline component that computes the grid density and clusters the grids based on the density. The algorithm adopts a density decaying technique to capture the dynamic changes of a data stream and a attraction-based mechanism to accurately generate cluster boundaries. Exploiting the intricate relationships among the decay factor, attraction, data density, and cluster structure, our algorithm can efficiently and effectively generate and adjust the clusters in real time. Further, a theoretically sound technique is developed to detect and remove sporadic grids mapped by outliers in order to dramatically improve the space and time efficiency of the system. The technique makes high-speed data stream clustering feasible without degrading the clustering quality. The experimental results show that our algorithm has superior quality and efficiency, can find clusters of arbitrary shapes, and can accurately recognize the evolving behaviors of real-time data streams.	[Tu, Li] Nanjing Univ Aeronaut & Astronaut, Inst Informat Sci & Technol, Nanjing 210016, Peoples R China; [Chen, Yixin] Washington Univ, St Louis, MO 63130 USA	Tu, L (reprint author), Nanjing Univ Aeronaut & Astronaut, Inst Informat Sci & Technol, Nanjing 210016, Peoples R China.	chen@cse.wustl.edu			Microsoft Research New Faculty; NSF [IIS-0713109]; Department of Energy [ER25737]; Chinese National Natural Science Foundation [60673060]; Natural Science Foundation of Jiangsu Province [BK2008206]	This work is partly supported by a Microsoft Research New Faculty Fellowship, NSF grant IIS-0713109, Department of Energy grant ER25737, Chinese National Natural Science Foundation grant No. 60673060, and Natural Science Foundation of Jiangsu Province grant No. BK2008206.	Aggarwal C., 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1; Bandyopadhyay S, 2006, INFORM SCIENCES, V176, P1952, DOI 10.1016/j.ins.2005.11.007; Barbara D, 2002, SIGKDD EXPLORATIONS, V3, P23; Beringer J, 2006, DATA KNOWL ENG, V58, P180, DOI 10.1016/j.datak.2005.05.009; CHEN Y, 2007, P INT C KNOWL DISC D; CHEN Y, 2002, P WORKSH RES ISS DAT, P53; GILBERT A., 2001, P INT C VER LARG DAT; Golab L, 2003, SIGMOD REC, V32, P5; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; GUHA S., 2000, P ANN IEEE S FDN COM; HUANG J., 2006, IEEE T KNOWL DATA EN, V18, P9; KANG J., 2005, P 3 ACIS INT C SOFTW; LEE W, 2005, P IEEE INT C DAT MIN; Nasraoui O, 2006, COMPUT NETW, V50, P1488, DOI 10.1016/j.comnet.2005.10.021; O'CALLAGHAN L., 2002, P INT C DAT ENG ICDE; Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419; Subramaniam S., 2006, P INT C VER LARG DAT; WANG H, 2006, P INT C KNOWL DISC D; Wang Z, 2004, LECT NOTES COMPUT SC, V3007, P416; Yesha Y., 2003, NEXT GENERATION DATA, P191; ZHAO F, 2005, P 15 INT WORKSH RES; Zhong S, 2005, NEURAL NETWORKS, V18, P790, DOI 10.1016/j.neunet.2005.06.008	22	3	4	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2009	3	3								10.1145/1552303.1552305		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VR	WOS:000208168000002	
J	Wan, L; Ng, WK; Dang, XH; Yu, PS; Zhang, K				Wan, Li; Ng, Wee Keong; Dang, Xuan Hong; Yu, Philip S.; Zhang, Kuan			Density-Based Clustering of Data Streams at Multiple Resolutions	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Data mining algorithms; density based clustering; evolving data streams		In data stream clustering, it is desirable to have algorithms that are able to detect clusters of arbitrary shape, clusters that evolve over time, and clusters with noise. Existing stream data clustering algorithms are generally based on an online-offline approach: The online component captures synopsis information from the data stream (thus, overcoming real-time and memory constraints) and the offline component generates clusters using the stored synopsis. The online-offline approach affects the overall performance of stream data clustering in various ways: the ease of deriving synopsis from streaming data; the complexity of data structure for storing and managing synopsis; and the frequency at which the offline component is used to generate clusters. In this article, we propose an algorithm that (1) computes and updates synopsis information in constant time; (2) allows users to discover clusters at multiple resolutions; (3) determines the right time for users to generate clusters from the synopsis information; (4) generates clusters of higher purity than existing algorithms; and (5) determines the right threshold function for density-based clustering based on the fading model of stream data. To the best of our knowledge, no existing data stream algorithms has all of these features. Experimental results show that our algorithm is able to detect arbitrarily shaped, evolving clusters with high quality.	[Wan, Li; Ng, Wee Keong] Nanyang Technol Univ, Singapore 639798, Singapore; [Dang, Xuan Hong] Inst Infocomm Res, Singapore, Singapore; [Yu, Philip S.] Univ Illinois, Chicago, IL USA; [Zhang, Kuan] Singapore Management Univ, Singapore, Singapore	Wan, L (reprint author), Nanyang Technol Univ, Singapore 639798, Singapore.	Wanli@pmail.ntu.edu.sg					Aggarwal C., 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1; Babcock B, 2003, P 22 ACM SIGMOD SIGA, P234, DOI 10.1145/773153.773176; Cao F., 2006, P SIAM C DAT MIN; Charikar M., 2003, P 35 ANN ACM S THEOR, P30, DOI DOI 10.1145/780542.780548; CHEN Y, 2007, P ACM SIGKDD INT C K; Duan L, 2007, INFORM SYST, V32, P978, DOI 10.1016/j.is.2006.10.006; El-Sonbaty Y, 2004, PROC INT C TOOLS ART, P673; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; HINNEBURG E, 1998, P ACM SIGKDD INT C K, P58; HUANG J.-W, 2004, P ICDM, P367; Kriegel H.-P., 2005, P 11 ACM SIGKDD INT, P672, DOI 10.1145/1081870.1081955; Manku GS, 2002, P 28 INT C VER LARG, P346; MISHRA N., 2002, P IEEE INT C DAT ENG, P685; Wang H., 2006, P 12 ACM SIGKDD INT, P736, DOI 10.1145/1150402.1150496; WANG W, 1997, P 23 INT C VER LARG, P186; Yang J, 2003, PROC INT CONF DATA, P695, DOI 10.1109/ICDE.2003.1260838	17	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2009	3	3								10.1145/1552303.1552307		28	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VR	WOS:000208168000004	
J	Zhou, B; Pei, J				Zhou, Bin; Pei, Jian			Link Spam Target Detection Using Page Farms	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						PageRank; Page Farm; Link Spam		Currently, most popular Web search engines adopt some link-based ranking methods such as PageRank. Driven by the huge potential benefit of improving rankings of Web pages, many tricks have been attempted to boost page rankings. The most common way, which is known as link spam, is to make up some artificially designed link structures. Detecting link spam effectively is a big challenge. In this article, we develop novel and effective detection methods for link spam target pages using page farms. The essential idea is intuitive: whether a page is the beneficiary of link spam is reflected by how it collects its PageRank score. Technically, how a target page collects its PageRank score is modeled by a page farm, which consists of pages contributing a major portion of the PageRank score of the target page. We propose two spamicity measures based on page farms. They can be used as an effective measure to check whether the pages are link spam target pages. An empirical study using a newly available real dataset strongly suggests that our method is effective. It outperforms the state-of-the-art methods like SpamRank and SpamMass in both precision and recall.	[Zhou, Bin; Pei, Jian] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Zhou, B (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	bzhou@cs.sfu.ca; jpei@cs.sfu.ca			NSERC; Microsoft Research Grant	This research is supported in part by an NSERC Discovery Grant, an NSERC Discovery Accelerator Supplements Grant, and a Microsoft Research Grant. All opinions, findings, conclusions and recommendations in this article are those of the authors and do not necessarily reflect the views of the funding agencies.	ABOU-ASSALEH T, 2007, P 3 INT WORKSH ADV I; ADAMIC L. A, 1999, P ECDL, P443; Albert R, 1999, NATURE, V401, P130; Baeza-Yates R., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148225; Becchetti L., 2006, P WORKSH WEB MIN WEB; BENCZUR A., 2007, P 3 INT WORKSH ADV I, P89, DOI 10.1145/1244408.1244424; Benczur A.A., 2005, P 1 INT WORKSH ADV I; Bianchini M., 2005, ACM Transactions on Internet Technology, V5, DOI 10.1145/1052934.1052938; Brinkmeier M., 2006, ACM Transactions on Internet Technology, V6, DOI 10.1145/1151087.1151090; BRODER A., 2000, P 9 INT WORLD WID WE, P309; Castillo C., 2006, SIGIR Forum, V40, DOI 10.1145/1189702.1189703; Castillo C., 2007, P 30 ANN INT ACM SIG, P423, DOI 10.1145/1277741.1277814; CHIEN S., 2007, P 3 INT WORKSH ADV I; Cormack G. V., 2007, P 3 INT WORKSH ADV I; Cormen T. H., 2001, INTRO ALGORITHMS; Du Y., 2007, P 3 INT WORKSH ADV I; Fetterly D., 2004, P 7 INT WORKSH WEB D, P1, DOI 10.1145/1017074.1017077; Fetterly D., 2005, P 28 ANN INT ACM SIG, P170, DOI 10.1145/1076034.1076066; GOEL V., 2006, P INT WORLD WID WEB, P63, DOI 10.1145/1135777.1135792; Gyongyi Z., 2006, P 32 INT C VER LARG, P439; Gyongyi Z., 2004, P 30 INT C VER LARG, P576, DOI 10.1016/B978-012088469-8/50052-8; Gyongyi Z., 2005, P 31 INT C VER LARG, P517; Gyongyi Z., 2005, P 1 INT WORKSH ADV I; Henzinger M.R., 2003, P 18 INT JOINT C ART, P1573; Karp R. M., 1972, COMPLEXITY COMPUTER; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Langville A.N., 2004, INTERNET MATH, V1, P335, DOI 10.1080/15427951.2004.10129091; Ntoulas A., 2006, P 15 INT C WORLD WID, P83, DOI 10.1145/1135777.1135794; Page L., 1998, PAGERANK CITATION RA; Scott J., 2000, SOCIAL NETWORK ANAL; Thompson A.C., 1996, MINKOWSKI GEOMETRY; Wasserman S, 1994, SOCIAL NETWORK ANAL; Wu B., 2005, P 14 INT WORLD WID W, P820; ZHANG H., 2004, P 3 WORKSH ALG MOD W, V3243, P92	34	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2009	3	3								10.1145/1552303.1552306		38	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VR	WOS:000208168000003	
J	Pei, T; Jasra, A; Hand, DJ; Zhu, AX; Zhou, CH				Pei, Tao; Jasra, Ajay; Hand, David J.; Zhu, A-Xing; Zhou, Chenghu			DECODE: a new method for discovering clusters of different densities in spatial data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Data mining; MCMC; Point process; Reversible jump; Nearest neighbor; Earthquake	CHAIN MONTE-CARLO; POINT-PROCESSES; NEIGHBOR; FEATURES; EARTHQUAKES; FORESHOCK; ALGORITHM; SEQUENCE	When clusters with different densities and noise lie in a spatial point set, the major obstacle to classifying these data is the determination of the thresholds for classification, which may form a series of bins for allocating each point to different clusters. Much of the previous work has adopted a model-based approach, but is either incapable of estimating the thresholds in an automatic way, or limited to only two point processes, i.e. noise and clusters with the same density. In this paper, we present a new density-based cluster method (DECODE), in which a spatial data set is presumed to consist of different point processes and clusters with different densities belong to different point processes. DECODE is based upon a reversible jump Markov Chain Monte Carlo (MCMC) strategy and divided into three steps. The first step is to map each point in the data to its mth nearest distance, which is referred to as the distance between a point and its mth nearest neighbor. In the second step, classification thresholds are determined via a reversible jump MCMC strategy. In the third step, clusters are formed by spatially connecting the points whose mth nearest distances fall into a particular bin defined by the thresholds. Four experiments, including two simulated data sets and two seismic data sets, are used to evaluate the algorithm. Results on simulated data show that our approach is capable of discovering the clusters automatically. Results on seismic data suggest that the clustered earthquakes, identified by DECODE, either imply the epicenters of forthcoming strong earthquakes or indicate the areas with the most intensive seismicity, this is consistent with the tectonic states and estimated stress distribution in the associated areas. The comparison between DECODE and other state-of-the-art methods, such as DBSCAN, OPTICS and Wavelet Cluster, illustrates the contribution of our approach: although DECODE can be computationally expensive, it is capable of identifying the number of point processes and simultaneously estimating the classification thresholds with little prior knowledge.	[Pei, Tao; Zhu, A-Xing; Zhou, Chenghu] Inst Geog Sci & Nat Resources Res, Beijing 100101, Peoples R China; [Pei, Tao] Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, London SW7 2PG, England; [Jasra, Ajay; Hand, David J.] Univ London Imperial Coll Sci Technol & Med, Dept Math, London, England; [Hand, David J.] Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, London, England; [Zhu, A-Xing] Univ Wisconsin, Dept Geog, Madison, WI 53706 USA	Zhou, CH (reprint author), Inst Geog Sci & Nat Resources Res, 11A,Datun Rd Anwai, Beijing 100101, Peoples R China.	peit@lreis.ac.cn; ajay.jasra@imperial.ac.uk; d.j.hand@imperial.ac.uk; axing@geography.wisc.edu; zhouch@lreis.ac.cn			National Key Basic Research and Development Program of China [2006CB701305]; State Key Laboratory of Resource and Environment Information System [088RA400SA]; Chinese Academy of Sciences	This study was funded through support from the National Key Basic Research and Development Program of China (Project Number: 2006CB701305), a grant from the State Key Laboratory of Resource and Environment Information System (Project Number: 088RA400SA) and the 'one Hundred Talents' Program of Chinese Academy of Sciences. Ajay Jasra was supported by a Chapman Fellowship, and David Hand was partially supported by a Royal Society Wolfson Research Merit Award.	Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Allard D, 1997, J AM STAT ASSOC, V92, P1485, DOI 10.2307/2965419; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Ankerst M, 1999, P ACM SIGMOD 99 INT, P46; Byers S, 1998, J AM STAT ASSOC, V93, P577, DOI 10.2307/2670109; [郑魁香 Cheng Kueihsiang], 2002, [地震地质, Seismology and Geology], V24, P400; Cressie NAC, 1991, STAT SPATIAL DATA; Daszykowski M, 2001, CHEMOMETR INTELL LAB, V56, P83, DOI 10.1016/S0169-7439(01)00111-3; DIGGLE P, 1985, APPL STAT-J ROY ST C, V34, P138, DOI 10.2307/2347366; Ester M, 1996, P 2 INT C KNOWL DISC, P226; FENG H, 1989, EARTHQUAKE CATALOGUE; FENG H, 1980, EARTHQUAKE CATALOGUE; Fu Z X, 1997, EARTHQ RES CHINA, V13, P1; Ghosh SC, 2002, SEDIMENT GEOL, V147, P155, DOI 10.1016/S0037-0738(01)00195-6; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; GU GX, 1983, CHIN SEISMIC CATALOG; Han J., 2001, GEOGRAPHIC DATA MINI, P188, DOI 10.4324/9780203468029_chapter_8; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jasra A, 2006, MATH GEOL, V38, P269, DOI 10.1007/s11004-005-9019-3; Jiao M R, 1999, ACTA SEISMOLOGICA SI, V12, P137, DOI DOI 10.1007/S11589-999-0018-1; Kagan YY, 2005, GEOPHYS J INT, V163, P1039, DOI 10.1111/j.1365-246X.2005.02772.x; Kaufman L., 1990, FINDING GROUPS DATA; Lin CY, 2005, FUND INFORM, V68, P315; Liu B, 2007, J UNCERTAIN SYSTEMS, V1, P4; MARKUS MB, 2000, P ACM SIGMOD 2000 IN, V29, P93; Matsu'ura RS, 2005, PURE APPL GEOPHYS, V162, P1319, DOI 10.1007/s00024-005-2672-0; Murtagh F, 1998, PATTERN RECOGN, V31, P847, DOI 10.1016/S0031-3203(97)00115-5; Neill DB, 2005, P KDD 2005 WORKSH DA, P41; Neill DB, 2006, THESIS U S CAROLINA; PASCUAL D, 2006, P INT DAT ENG AUT LE, P671; PEI T, 2003, ACTA SEISMOLOGICA SI, V3, P292, DOI 10.1007/s11589-003-0033-6; Pei T, 2006, INT J GEOGR INF SCI, V20, P153, DOI 10.1080/13658810500399654; Reasenberg PA, 1999, PURE APPL GEOPHYS, V155, P355, DOI 10.1007/s000240050269; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Robert C., 2004, MONTE CARLO STAT MET; Roy S, 2005, LECT NOTES COMPUT SC, V3816, P523; Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; THOMPSON HR, 1956, ECOLOGY, V37, P391, DOI 10.2307/1933159; Tran TN, 2006, COMPUT STAT DATA AN, V51, P513, DOI 10.1016/j.csda.2005.10.001; Umino N, 2002, B SEISMOL SOC AM, V92, P2465, DOI 10.1785/0120010140; Wyss M, 2000, B SEISMOL SOC AM, V90, P1174, DOI 10.1785/0119990158; Zhang GM, 2005, CHINESE J GEOPHYS-CH, V48, P602; ZHOU CH, 2006, DATABASE INTEGRATED; Zhuang JC, 2005, J GEOPHYS RES-SOL EA, V110, DOI 10.1029/2004JB003157	46	8	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2009	18	3					337	369		10.1007/s10618-008-0120-3		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RP	WOS:000265081200001	
J	Mahdavi, M; Abolhassani, H				Mahdavi, Mehrdad; Abolhassani, Hassan			Harmony K-means algorithm for document clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Document clustering; Markov chain; Harmony search; Global optimization; K-means algorithm	OPTIMIZATION; SEARCH	Fast and high quality document clustering is a crucial task in organizing information, search engine results, enhancing web crawling, and information retrieval or filtering. Recent studies have shown that the most commonly used partition-based clustering algorithm, the K-means algorithm, is more suitable for large datasets. However, the K-means algorithm can generate a local optimal solution. In this paper we propose a novel Harmony K-means Algorithm (HKA) that deals with document clustering based on Harmony Search (HS) optimization method. It is proved by means of finite Markov chain theory that the HKA converges to the global optimum. To demonstrate the effectiveness and speed of HKA, we have applied HKA algorithms on some standard datasets. We also compare the HKA with other meta-heuristic and model-based document clustering approaches. Experimental results reveal that the HKA algorithm converges to the best known optimum faster than other methods and the quality of clusters are comparable.	[Mahdavi, Mehrdad; Abolhassani, Hassan] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran; [Abolhassani, Hassan] Sch Comp Sci, Inst Studies Theoret Phys & Math IPM, Tehran, Iran	Mahdavi, M (reprint author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.	mahdavi@ce.sharif.edu; abolhassani@sharif.edu	Mahdavi, Mehrdad/A-2975-2013				Aggarwal C., 1999, P 5 ACM SIGKDD INT C, P352, DOI 10.1145/312129.312279; Anderberg M.R., 1973, CLUSTER ANAL APPL; Boley D, 1999, DECIS SUPPORT SYST, V27, P329, DOI 10.1016/S0167-9236(99)00055-X; Cios K., 1998, DATA MINING METHODS; Coello CAC, 2000, CIV ENG ENVIRON SYST, V17, P319, DOI 10.1080/02630250008970288; Cui X., 2005, IEEE SWARM INT S PAS, P185; CUTTING DR, 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; EVERITT B., 1980, CLUSTER ANAL; Geem Z. W., 2002, International Journal of Modelling and Simulation, V22; Geem ZW, 2005, LECT NOTES COMPUT SC, V3612, P741; Grira N., 2005, 7 ACM SIGMM INT WORK, P9; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jones J.P., 1995, J MARK COMMUN, V1, P1, DOI 10.1080/13527269500000001; Kennedy JF, 2001, SWARM INTELLIGENCE; KLEIN RW, 1989, PATTERN RECOGN, V22, P213, DOI 10.1016/0031-3203(89)90067-8; Labroche N, 2003, LECT NOTES COMPUT SC, V2723, P25; Larsen B, 1999, P 5 ACM SIGKDD INT C, DOI 10.1145/312129.312186; Lee KS, 2005, COMPUT METHOD APPL M, V194, P3902, DOI 10.1016/j.cma.2004.09.007; Mahdavi M, 2007, APPL MATH COMPUT, V188, P1567, DOI 10.1016/j.amc.2006.11.033; McQueen J., 1967, P 5 BERK S MATH STAT, P281; Merwe V. D., 2003, P IEEE C EV COMP CEC, P215; Omran M. G., 2002, P 4 AS PAC C SIM EV, P370; Quinlan R.J., 1993, C4 5 PROGRAMS MACHIN; Raghavan V.V., 1979, P 2 INT C INF STOR R, P10, DOI 10.1145/511706.511709; RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964; Salton G., 1989, AUTOMATIC TEXT PROCE; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; Steinbach M, 2000, KDD WORKSH TEXT MIN; Steinbach M., 2000, COMP DOCUMENT CLUSTE; Stumme G., 2001, 12 EUR C MACH LEARN; Stumme G, 2006, J WEB SEMANT, V4, P124, DOI 10.1016/j.websem.2006.02.001; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6; Zhao Y, 2005, DATA MIN KNOWL DISC, V10, P141, DOI 10.1007/s10618-005-0361-3; Zhong S, 2003, J MACHINE LEARNING R, V4, P1001, DOI 10.1162/jmlr.2003.4.6.1001; Zhong S, 2005, KNOWL INF SYST, V8, P374, DOI 10.1007/s10115-004-0194-1; ZHONG S, 2006, MACH LEARN, V65; *TREC, 1999, TEXT RETRIEVAL C; *TRECQ, 1999, TEXT RETRIEVAL C REL	40	9	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2009	18	3					370	391		10.1007/s10618-008-0123-0		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RP	WOS:000265081200002	
J	de Haro-Garcia, A; Garcia-Pedrajas, N				de Haro-Garcia, Aida; Garcia-Pedrajas, Nicolas			A divide-and-conquer recursive approach for scaling up instance selection algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Instance selection; Instance based learning; Divide-and-conquer; Scalability	LEARNING ALGORITHMS; PROTOTYPE SELECTION; DATA REDUCTION; CLASSIFIERS; CLASSIFICATION; ENSEMBLES; DESIGN	Instance selection is becoming more and more relevant due to the huge amount of data that is being constantly produced. However, although current algorithms are useful for fairly large datasets, scaling problems are found when the number of instances is of hundreds of thousands or millions. In the best case, these algorithms are of efficiency O(n (2)), n being the number of instances. When we face huge problems, scalability is an issue, and most algorithms are not applicable. This paper presents a divide-and-conquer recursive approach to the problem of instance selection for instance based learning for very large problems. Our method divides the original training set into small subsets where the instance selection algorithm is applied. Then the selected instances are rejoined in a new training set and the same procedure, partitioning and application of an instance selection algorithm, is repeated. In this way, our approach is based on the philosophy of divide-and-conquer applied in a recursive manner. The proposed method is able to match, and even improve, for the case of storage reduction, the results of well-known standard algorithms with a very significant reduction of execution time. An extensive comparison in 30 datasets form the UCI Machine Learning Repository shows the usefulness of our method. Additionally, the method is applied to 5 huge datasets with from 300,000 to more than a million instances, with very good results and fast execution time.	[de Haro-Garcia, Aida; Garcia-Pedrajas, Nicolas] Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain	Garcia-Pedrajas, N (reprint author), Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.	i22hagaa@uco.es; npedrajas@uco.es			Spanish Comision Interministerial de Ciencia y Tecnologia [TIN2008-03151]	This work was supported in part by the Project TIN2008-03151 of the Spanish Comision Interministerial de Ciencia y Tecnologia.	Anderson TW, 1984, WILEY SERIES PROBABI; Baluja S., 1994, CMUCS94163; Banfield RE, 2005, LECT NOTES COMPUT SC, V3541, P196; Barandela R, 2005, INT J PATTERN RECOGN, V19, P787, DOI 10.1142/S0218001405004332; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; Cano JR, 2005, PATTERN RECOGN LETT, V26, P953, DOI 10.1016/j.patrec.2004.09.043; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Chaudhuri S., 1998, P ACM SIGMOD INT C M, P436, DOI 10.1145/276304.276343; Chawla NV, 2004, J MACH LEARN RES, V5, P421; Chen JH, 2005, INT J APPROX REASON, V40, P3, DOI 10.1016/j.ijar.2004.11.009; Cochran W.G., 1977, SAMPLING TECHNIQUES; Cover T. M., 1991, WILEY SERIES TELECOM; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Eshelman L., 1990, CHC ADAPTIVE SEARCH; GARCIAPEDRAJAS N, 2008, MACH LEARN IN PRESS; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Hettich S., 1998, UCI REPOSITORY MACHI; HOLLAND JH, 1975, ADAPTATION NATURAL A; Hussain F., 1999, TRC699 NAT U SING SC; Ishibuchi H., 2000, J ADV COMPUT INTELL, V4, P138; Keogh E., 1997, P 14 INT C MACH LEAR, P406; Kivinen J., 1994, Proceedings of the Thirteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1994, DOI 10.1145/182591.182601; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Li J, 2005, INT J ARTIF INTELL T, V14, P261, DOI 10.1142/S0218213005002090; Liu H., 1998, FEATURE SELECTION KN; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Michalewicz Z., 1994, GENETIC ALGORITHMS D; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Reeves C. R., 2001, INSTANCE SELECTION C, P339; SMITH P, 1998, INTO STAT; Smyth B., 1995, P INTL JOINT C ART I, V1, P377; Son SH, 2006, LECT NOTES COMPUT SC, V3982, P590; Whitley D, 1989, P ICGA, V3, P116; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZHU X, 2006, P 18 INT C PATT REC, V3, P352	40	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2009	18	3					392	418		10.1007/s10618-008-0121-2		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RP	WOS:000265081200003	
J	Creamer, G; Stolfo, S				Creamer, German; Stolfo, Sal			A link mining algorithm for earnings forecast and trading	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Link mining; Social network; Machine learning; Computational finance; Trading strategies; Data mining applications	LOGISTIC-REGRESSION; SOCIAL NETWORKS; ANALYSTS; INFORMATION; STOCK; RECOMMENDATIONS; CENTRALITY	The objective of this paper is to present and discuss a link mining algorithm called CorpInterlock and its application to the financial domain. This algorithm selects the largest strongly connected component of a social network and ranks its vertices using several indicators of distance and centrality. These indicators are merged with other relevant indicators in order to forecast new variables using a boosting algorithm. We applied the algorithm CorpInterlock to integrate the metrics of an extended corporate interlock (social network of directors and financial analysts) with corporate fundamental variables and analysts' predictions (consensus). CorpInterlock used these metrics to forecast the trend of the cumulative abnormal return and earnings surprise of S&P 500 companies. The rationality behind this approach is that the corporate interlock has a direct effect on future earnings and returns because these variables affect directors and managers' compensation. The financial analysts engage in what the agency theory calls the "earnings game": Managers want to meet the financial forecasts of the analysts and analysts want to increase their compensation or business of the company that they follow. Following the CorpInterlock algorithm, we calculated a group of well-known social network metrics and integrated with economic variables using Logitboost. We used the results of the CorpInterlock algorithm to evaluate several trading strategies. We observed an improvement of the Sharpe ratio (risk-adjustment return) when we used "long only" trading strategies with the extended corporate interlock instead of the basic corporate interlock before the regulation Fair Disclosure (FD) was adopted (1998-2001). There was no major difference among the trading strategies after 2001. Additionally, the CorpInterlock algorithm implemented with Logitboost showed a significantly lower test error than when the CorpInterlock algorithm was implemented with logistic regression. We conclude that the CorpInterlock algorithm showed to be an effective forecasting algorithm and supported profitable trading strategies.	[Creamer, German; Stolfo, Sal] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Creamer, G (reprint author), Columbia Univ, Dept Comp Sci, 500 W 120 St, New York, NY 10027 USA.	ggc14@columbia.edu; sal@cs.columbia.edu	Creamer, German/B-8794-2012				ABARBANELL JS, 1991, J ACCOUNT ECON, V14, P147, DOI 10.1016/0165-4101(91)90003-7; ABARBANELL JS, 1992, J FINANC, V47, P1181, DOI 10.2307/2328982; Asquith P, 2005, J FINANC ECON, V75, P245, DOI 10.1016/j.jfineco.2004.01.002; Barabasi Albert-Laszlo, 2002, LINKED NEW SCI NETWO; Barber B, 2001, J FINANC, V56, P531, DOI 10.1111/0022-1082.00336; Beckers S, 2004, FINANC ANAL J, V60, P74, DOI 10.2469/faj.v60.n2.2611; BERNARD VL, 1990, J ACCOUNT EC, V13; Borgatti SP, 2006, SOC NETWORKS, V28, P466, DOI 10.1016/j.socnet.2005.11.005; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREUSCH TS, 1979, ECONOMETRICA, V47, P1287, DOI 10.2307/1911963; BROWN LD, 2000, IBES RES BIBLIO; Brown LD, 2001, FINANC ANAL J, V57, P44, DOI 10.2469/faj.v57.n6.2492; BROWN LJC, 1996, J INVESTING, V5, P17, DOI 10.3905/joi.5.1.17; CESSIE SL, 1992, APPL STAT, V41, P191, DOI 10.2307/2347628; CLEMENT M, 2005, J FINANC, V40, P307; COHEN L, 2008, SELL SIDE SCH TIES; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; CREAMER G, 2004, 1 P FIN ENG APPL C M; CREAMER G, 2005, MACH LEARN FIN WORKS; CREAMER G, 2006, P LINK AN DYN STAT L; CREAMER G, 2007, J TRADING        SUM, P84; DAVIS CE, 1986, MODERN STAT METHODS; DAVIS GF, 1991, ADM SCI Q, V36, P586; Davis G. F., 2003, Strategic Organization, V1, DOI 10.1177/14761270030013002; de Nooy W., 2005, EXPLORATORY SOCIAL N; Dhar V, 2001, IEEE T NEURAL NETWOR, V12, P907, DOI 10.1109/72.935099; Domingos P., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; ELTON EJ, 1986, J FINANC, V41, P699, DOI 10.2307/2328502; Fawcett T., 1999, P 5 ACM SIGKDD INT C, P53, DOI 10.1145/312129.312195; FINGER CA, 1999, WHAT DO ANAL STOCK R; FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Getoor L., 2005, SIGKDD EXPLORATIONS, V7, P3; GOLDBERG HG, 2003, IAAI 2003; Greene William H., 2007, ECONOMETRIC ANAL; Hill S, 2006, STAT SCI, V21, P256, DOI 10.1214/088342306000000222; Hong H, 2003, J FINANC, V58, P313, DOI 10.1111/1540-6261.00526; Ivkovic Z, 2004, J FINANC ECON, V73, P433, DOI 10.1016/j.jfineco.2004.03.002; Jegadeesh N, 2004, J FINANC, V59, P1083, DOI 10.1111/j.1540-6261.2004.00657.x; Kirkland JD, 1999, AI MAG, V20, P55; KRISCHE SD, 2000, INFORM CONTENT ANAL; Larcker D. F., 2005, BACK DOOR LINKS DIRE; Lee CI, 2004, FINANC ANAL J, V60, P79, DOI 10.2469/faj.v60.n3.2623; Leskovec J, 2006, EC 06, P228; Freund Y, 1999, MACHINE LEARNING, PROCEEDINGS, P124; MENDENHALL RR, 1991, J ACCOUNTING RES, V29, P170, DOI 10.2307/2491035; Mikhail MB, 2004, J FINANC ECON, V74, P67, DOI 10.1016/j.jfineco.2003.11.001; Milgram S., 1967, PSYCHOL TODAY, V2, P60, DOI DOI 10.1145/335305.335325; Mintz B., 1985, POWER STRUCTURE AM B; Mizruchi M. S., 1992, STRUCTURE CORPORATE; MORENO JL, 1932, APPL GROUP METHOD CL; Newman M. E. J., 2001, PHYS REV E, V64; Newman MEJ, 2002, P NATL ACAD SCI USA, V99, P2566, DOI 10.1073/pnas.012582999; OU JA, 1989, J ACCOUNT RES, V27; PETERS D, 1993, J INVESTING, V2, P54, DOI 10.3905/joi.2.4.54; PETERS D, 1993, J INVEST, V2, P47, DOI 10.3905/joi.2.2.47; PETERSON D, 1995, J FINANC RES, V18, P465; Rao H, 2000, ADMIN SCI QUART, V45, P268, DOI 10.2307/2667072; Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1; Senator TE, 2005, SIGKDD EXPLORATIONS, V7, P76, DOI DOI 10.1145/1117454.1117465; SPARROW MK, 1991, SOC NETWORKS, V13, P251, DOI 10.1016/0378-8733(91)90008-H; Sticke S. E., 1995, FINANCIAL ANAL J, V51, P25, DOI 10.2469/faj.v51.n5.1933; STOBER TL, 1992, J ACCOUNT ECON, V15, P347, DOI 10.1016/0165-4101(92)90024-V; STOLFO S, 2006, P NAT C DIG GOV RES; Strogatz S H, 1998, NATURE, V440, P442; Thaler Richard, 2005, ADV BEHAV FINANCE, VII; Watts DJ, 1999, AM J SOCIOL, V105, P493, DOI 10.1086/210318; Witten IH, 2005, DATA MINING PRACTICA; Womack KL, 1996, J FINANC, V51, P137, DOI 10.2307/2329305; Wright Mills C., 1956, POWER ELITE	71	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2009	18	3					419	445		10.1007/s10618-008-0124-z		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RP	WOS:000265081200004	
J	Kakishita, Y; Sasahara, K; Nishino, T; Takahasi, M; Okanoya, K				Kakishita, Yasuki; Sasahara, Kazutoshi; Nishino, Tetsuro; Takahasi, Miki; Okanoya, Kazuo			Ethological data mining: an automata-based approach to extract behavioral units and rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Behavioral units and rules; N-gram models; Learning from positive data	MATHEMATICAL-THEORY; BENGALESE FINCHES; SONGBIRDS; LANGUAGE; COMMUNICATION; SEQUENCES; SYNTAX	We propose an efficient automata-based approach to extract behavioral units and rules from continuous sequential data of animal behavior. By introducing novel extensions, we integrate two elemental methods-the N-gram model and Angluin's machine learning algorithm into an ethological data mining framework. This allows us to obtain the minimized automaton-representation of behavioral rules that accept (or generate) the smallest set of possible behavioral patterns from sequential data of animal behavior. With this method, we demonstrate how the ethological data mining works using real birdsong data; we use the Bengalese finch song and perform experimental evaluations of this method using artificial birdsong data generated by a computer program. These results suggest that our ethological data mining works effectively even for noisy behavioral data by appropriately setting the parameters that we introduce. In addition, we demonstrate a case study using the Bengalese finch song, showing that our method successfully grasps the core structure of the singing behavior such as loops and branches.	[Kakishita, Yasuki; Nishino, Tetsuro] Univ Electrocommun, Dept Informat & Commun Engn, Grad Sch Electrocommuni, Chofu, Tokyo 1828585, Japan; [Sasahara, Kazutoshi; Takahasi, Miki; Okanoya, Kazuo] RIKEN, Lab Biolinguist, Brain Sci Inst, Wako, Saitama 3510198, Japan; [Sasahara, Kazutoshi] Japan Soc Promot Sci, Tokyo, Japan; [Kakishita, Yasuki] Hitachi Ltd, Embedded Syst Platform Res Dept, Tokyo, Japan	Kakishita, Y (reprint author), Univ Electrocommun, Dept Informat & Commun Engn, Grad Sch Electrocommuni, 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.	kakishita@ice.uec.ac.jp; kazutoshi.sasahara@gmail.com	Okanoya, Kazuo/F-8528-2010		Ministry of Education, Culture, Sports, Science and Technology of Japan [18500109]	We would like to thank the two anonymous reviewers for valuable comments on an earlier version of the manuscript. K. S. would like to thank Prof. Edward Stabler (UCLA) for his useful comments on this work. This work was supported in part by a Grant-in Aid (No.18500109) from the Ministry of Education, Culture, Sports, Science and Technology of Japan.	ANGLUIN D, 1982, J ACM, V29, P741, DOI 10.1145/322326.322334; Berwick R. C., 1987, Machine Learning, V2, DOI 10.1023/A:1022860810097; Brainard MS, 2002, NATURE, V417, P351, DOI 10.1038/417351a; BRIAN L, 1979, BIOL COMMUNICATION; Catchpole C, 1995, BIRD SONG BIOL THEME; CHATFIEL.C, 1970, J THEOR BIOL, V29, P427, DOI 10.1016/0022-5193(70)90107-4; Doupe AJ, 1999, ANNU REV NEUROSCI, V22, P567, DOI 10.1146/annurev.neuro.22.1.567; Gentner TQ, 2006, NATURE, V440, P1204, DOI 10.1038/nature04675; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; GRAHAM S, 2004, ESSENTIAL ANIMAL BEH; Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1; Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569; Hosino T, 2000, NEUROREPORT, V11, P2091, DOI 10.1097/00001756-200007140-00007; IAH HW, 2005, M KAUFMANN SERIES DA; Jelinek F., 1998, STAT METHODS SPEECH; JELINEK F, 1990, SELF ORG LANGUAGE MO, P450; Kakishita Y, 2007, LECT NOTES ARTIF INT, V4828, P320; Marler P., 2004, NATURES MUSIC SCI BI; Okanoya K, 2004, ADV STUD BEHAV, V34, P297, DOI 10.1016/S0065-3454(04)34008-8; Ramus F, 2000, SCIENCE, V288, P349, DOI 10.1126/science.288.5464.349; Sasahara K, 2006, CIC 2006: 15th International Conference on Computing, Proceedings, P80; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHANNON CE, 1948, AT&T TECH J, V27, P623; SHANNON CE, 1950, BELL SYST TECH J, V3, P50; Suzuki R, 2006, J ACOUST SOC AM, V119, P1849, DOI 10.1121/1.2161827; Ullman Jeffrey D., 1979, INTRO AUTOMATA THEOR; Wren JD, 2005, BIOINFORMATICS, V21, P4046, DOI 10.1093/bioinformatics/bti657	27	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2009	18	3					446	471		10.1007/s10618-008-0122-1		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RP	WOS:000265081200005	
J	Li, GL; Feng, JH; Wang, JY; Zhou, LZ				Li, Guoliang; Feng, Jianhua; Wang, Jianyong; Zhou, Lizhu			Incremental sequence-based frequent query pattern mining from XML queries	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						XML query patterns; Frequent query patterns; XML frequent pattern mining; Incremental mining; Sequential pattern mining	ASSOCIATION	Existing algorithms of mining frequent XML query patterns (XQPs) employ a candidate generate-and-test strategy. They involve expensive candidate enumeration and costly tree-containment checking. Further, most of existing methods compute the frequencies of candidate query patterns from scratch periodically by checking the entire transaction database, which consists of XQPs transferred from user query logs. However, it is not straightforward to maintain such discovered frequent patterns in real XML databases as there may be frequent updates that may not only invalidate some existing frequent query patterns but also generate some new frequent query patterns. Therefore, a drawback of existing methods is that they are rather inefficient for the evolution of transaction databases. To address above-mentioned problems, this paper proposes an efficient algorithm ESPRIT to mine frequent XQPs without costly tree-containment checking. ESPRIT transforms XML queries into sequences using a one-to-one mapping technique and mines the frequent sequences to generate frequent XQPs. We propose two efficient incremental algorithms, ESPRIT-i and ESPRIT-i (+), to incrementally mine frequent XQPs. We devise several novel optimization techniques of query rewriting, cache lookup, and cache replacement to improve the answerability and the hit rate of caching. We have implemented our algorithms and conducted a set of experimental studies on various datasets. The experimental results demonstrate that our algorithms achieve high efficiency and scalability and outperform state-of-the-art methods significantly.	[Li, Guoliang; Feng, Jianhua; Wang, Jianyong; Zhou, Lizhu] Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Li, GL (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	liguoliang@tsinghua.edu.cn; fengjh@tsinghua.edu.cn; jianyong@tsinghua.edu.cn; deszlz@tsinghua.edu.cn	Li, Guoliang/E-3481-2012		National Natural Science Foundation of China [60873065]; National High Technology Development 863 Program of China [2007AA01Z152]; National Grand Fundamental Research 973 Program of China [2006CB303103]	This work is partly supported by the National Natural Science Foundation of China under Grant No. 60873065, the National High Technology Development 863 Program of China under Grant No. 2007AA01Z152, and the National Grand Fundamental Research 973 Program of China under Grant No. 2006CB303103.	AGGARWAL C, 2007, KDD; Agrawal R., 1994, VLDB, P487; Asai T, 2002, SDM; Aumann Y, 1999, J INTELL INF SYST, V12, P61, DOI 10.1023/A:1026482903537; Ayres J., 2002, KDD; Balmin A., 2004, VLDB, P60; BETTINI C, 1998, IEEE DAT ENG B, V21, P32; CHEN L, 2002, SIGMOD; CHEN Y, 2004, ICDM, P343; Chung C., 2002, SIGMOD 2002, P121; Dehaspe L, 1998, KDD, V1998, P30; FENG J, 2006, ACM SAC; FENG J, 2007, WWW; Han J., 2000, KNOWLEDGE DISCOVERY, P355; HAN J, 1999, INT C DAT ENG, P106; HRISTIDIS V, 2002, WEBDB; KAUSHIK R, 2002, ICDE, P129; Kuramochi M., 2001, ICDM, P313; Kwon J., 2005, VLDB PAGES, P217; Li GL, 2006, IEEE DATA MINING, P350; Li GL, 2006, LECT NOTES COMPUT SC, V4255, P460; Luo Q, 2002, SIGMOD 02, P600; MANDHANI B, 2005, VLDB; MASSEGLIA F, 1998, PKDD; MILO T, 1999, ICDT, P277; OZDEN B, 1998, ICDE, P412; Pei J., 2001, ICDE, P215; Prufer H., 1918, ARCH MATH PHYS, V27, P142; QUN C, 2003, SIGMOD, P134; RAO PR, 2004, ICDE, P288; RE C, 2004, INFORM INTEGRATION W; Srikant R., 1996, EDBT, P3; TERMIER A, 2002, IEEE INT C DAT MIN I, P450; Wang H., 2003, SIGMOD, P110; WANG J, 2004, ICDE, P79; Wang K, 2000, IEEE T KNOWL DATA EN, V12, P353; XU W, 2005, WEBDB; Yan X, 2003, SDM; Yang J, 2002, SIGMOD, P406; YANG LH, 2003, DASFAA, P355; YANG LH, 2003, VLDB, P69; YANG LH, 2004, KDD; Zaki MJ, 2005, IEEE T KNOWL DATA EN, V17, P1021, DOI 10.1109/TKDE.2005.125; ZAKI MJ, 2002, SIGKDD, P71	44	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2009	18	3					472	516		10.1007/s10618-009-0126-5		45	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RP	WOS:000265081200006	
J	Agichtein, E; Liu, YD; Bian, J				Agichtein, Eugene; Liu, Yandong; Bian, Jiang			Modeling Information-Seeker Satisfaction in Community Question Answering	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Community question answering; information seeker satisfaction		Question Answering Communities such as Naver, Baidu Knows, and Yahoo! Answers have emerged as popular, and often effective, means of information seeking on the web. By posting questions for other participants to answer, information seekers can obtain specific answers to their questions. Users of CQA portals have already contributed millions of questions, and received hundreds of millions of answers from other participants. However, CQA is not always effective: in some cases, a user may obtain a perfect answer within minutes, and in others it may require hours-and sometimes days-until a satisfactory answer is contributed. We investigate the problem of predicting information seeker satisfaction in collaborative question answering communities, where we attempt to predict whether a question author will be satisfied with the answers submitted by the community participants. We present a general prediction model, and develop a variety of content, structure, and community-focused features for this task. Our experimental results, obtained from a large-scale evaluation over thousands of real questions and user ratings, demonstrate the feasibility of modeling and predicting asker satisfaction. We complement our results with a thorough investigation of the interactions and information seeking patterns in question answering communities that correlate with information seeker satisfaction. We also explore personalized models of asker satisfaction, and show that when sufficient interaction history exists, personalization can significantly improve prediction accuracy over a "one-size-fits-all" model. Our models and predictions could be useful for a variety of applications, such as user intent inference, answer ranking, interface design, and query suggestion and routing.	[Agichtein, Eugene; Liu, Yandong] Emory Univ, Dept Math & Comp Sci, Atlanta, GA 30322 USA; [Bian, Jiang] Georgia Inst Technol, Coll Comp, Atlanta, GA 30322 USA	Agichtein, E (reprint author), Emory Univ, Dept Math & Comp Sci, 400 Dowman Dr,Suite W401, Atlanta, GA 30322 USA.	eugene@mathcs.emory.edu; yliu49@mathcs.emory.edu; jbian3@mail.gatech.edu			Emory College	E. Agichtein and Y. Liu were partially supported by the Emory College Seed Fund.	Agarwal N, 2008, P INT C WEB SEARCH W, P207, DOI DOI 10.1145/1341531.134155; Agichtein E., 2006, P 29 ANN INT ACM SIG; Agichtein E., 2008, P INT C WEB SEARCH W, P183, DOI DOI 10.1145/1341531.1341557; BELKIN N. J., 1997, P 6 INT C US MOD UM9; BELKIN NJ, 1982, J DOC, V38, P145, DOI 10.1108/eb026726; BRILL E., 2002, P C EMP METH NAT LAN; CUTRELL E., 2007, MSRTR200701; DANG H. T., 2007, P 16 TEXT RETR C TRE; Demner-Fushman D, 2007, COMPUT LINGUIST, V33, P63, DOI 10.1162/coli.2007.33.1.63; Downey D., 2007, P 20 INT JOINT C ART; Freund Y, 1996, P 13 INT C MACH LEAR; Harter SP, 1997, ANNU REV INFORM SCI, V32, P3; Jeon J., 2006, P 29 ANN INT ACM SIG; JEON J., 2005, P 14 ACM INT C INF K; JOACHIMS T., 2007, ACM T INFORM SYST, V25, P2; Kobayashi M, 2000, ACM COMPUT SURV, V32, P144, DOI 10.1145/358923.358934; Lin J, 2006, INFORM RETRIEVAL, V9, P565, DOI 10.1007/s10791-006-9003-7; LIN J., 2007, P 30 ANN INT ACM SIG, P327, DOI 10.1145/1277741.1277799; Liu Y., 2008, P 31 ANN INT ACM SIG; LIU Y., 2008, P 46 ANN M ASS COMP, P97, DOI 10.3115/1557690.1557716; LIU Y., 2008, P 31 ANN INT ACM SIG, P737, DOI 10.1145/1390334.1390478; Platt J.C., 1998, ADV KERNEL METHODS S, P185; QUINLAN J., 1996, J ARTIF INTELL RESEA; Rose D.E., 2004, P 13 INT C WORLD WID; RUTHVEN I., 2007, P 30 ANN INT ACM SIG, P727, DOI 10.1145/1277741.1277879; Soricut R., 2004, P HUM LANG TECHN C N; SU Q., 2007, P 16 INT C WORLD WID; Voorhees E. M., 2003, P 12 TEXT RETR C TRE; VOORHEES E. M., 2001, P WORKSH CROSS LANG; WHITE R., 2007, P 30 ANN INT ACM SIG; White R. W., 2007, P 16 INT C WORLD WID; Witten IH, 2005, DATA MINING PRACTICA; Zobel J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.291014	33	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	APR	2009	3	2							10	10.1145/1514888.1514893		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VP	WOS:000208167800005	
J	Kimura, M; Saito, K; Motoda, H				Kimura, Masahiro; Saito, Kazumi; Motoda, Hiroshi			Blocking Links to Minimize Contamination Spread in a Social Network	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Contamination diffusion; link analysis; social networks		We address the problem of minimizing the propagation of undesirable things, such as computer viruses or malicious rumors, by blocking a limited number of links in a network, which is converse to the influence maximization problem in which the most influential nodes for information diffusion is searched in a social network. This minimization problem is more fundamental than the problem of preventing the spread of contamination by removing nodes in a network. We introduce two definitions for the contamination degree of a network, accordingly define two contamination minimization problems, and propose methods for efficiently finding good approximate solutions to these problems on the basis of a naturally greedy strategy. Using large social networks, we experimentally demonstrate that the proposed methods outperform conventional link-removal methods. We also show that unlike the case of blocking a limited number of nodes, the strategy of removing nodes with high out-degrees is not necessarily effective for these problems.	[Kimura, Masahiro] Ryukoku Univ, Dept Elect & Informat, Otsu, Shiga 5202194, Japan; [Saito, Kazumi] Univ Shizuoka, Sch Adm & Informat, Shizuoka 4228526, Japan; [Motoda, Hiroshi] Osaka Univ, Inst Sci & Ind Res, Osaka 5670047, Japan	Kimura, M (reprint author), Ryukoku Univ, Dept Elect & Informat, Otsu, Shiga 5202194, Japan.	kimura@rins.ryukoku.ac.jp; k-saito@ushizuoka-ken.ac.jp; motoda@ar.sanken.osaka-u.ac.jp			Asian Office of Aerospace Research and Development, Air Force Office of Scientific Research, U.S. Air Force Research Laboratory [AOARD-08-4027]; JSPS [20500147]	This work was partly supported by Asian Office of Aerospace Research and Development, Air Force Office of Scientific Research, U.S. Air Force Research Laboratory under Grant No. AOARD-08-4027, and JSPS Grant-in-Aid for Scientific Research (C) (No. 20500147).	Albert R, 2000, NATURE, V406, P378, DOI 10.1038/35019019; BRODER A., 2000, P 9 INT WORLD WID WE, P309; Callaway DS, 2000, PHYS REV LETT, V85, P5468, DOI 10.1103/PhysRevLett.85.5468; Domingos P, 2001, P 7 ACM SIGKDD INT C, P57, DOI 10.1145/502512.502525; Gruhl D., 2004, P 13 INT WORLD WID W, P107; Kempe D, 2003, P 9 ACM SIGKDD INT C, P137; KIMURA M., 2008, P 23 AAAI C ART INT, P1175; LESKOVEC J, 2007, P 13 ACM SIGKDD INT, P420, DOI 10.1145/1281192.1281239; Nakano R., 2007, P 22 AAAI C ART INT, P1371; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Newman MEJ, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.036122; Newman MEJ, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.035101; Richardson M, 2002, P 8 ACM SIGKDD INT C, P61	14	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	APR	2009	3	2							9	10.1145/1514888.1514892		23	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VP	WOS:000208167800004	
J	Lin, YR; Chi, Y; Zhu, SH; Sundaram, H; Tseng, BL				Lin, Yu-Ru; Chi, Yun; Zhu, Shenghuo; Sundaram, Hari; Tseng, Belle L.			Analyzing Communities and Their Evolutions in Dynamic Social Networks	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Community; community net; evolution; evolution net; nonnegative matrix factorization; soft membership		We discover communities from social network data and analyze the community evolution. These communities are inherent characteristics of human interaction in online social networks, as well as paper citation networks. Also, communities may evolve over time, due to changes to individuals' roles and social status in the network as well as changes to individuals' research interests. We present an innovative algorithm that deviates from the traditional two-step approach to analyze community evolutions. In the traditional approach, communities are first detected for each time slice, and then compared to determine correspondences. We argue that this approach is inappropriate in applications with noisy data. In this paper, we propose FacetNet for analyzing communities and their evolutions through a robust unified process. This novel framework will discover communities and capture their evolution with temporal smoothness given by historic community structures. Our approach relies on formulating the problem in terms of maximum a posteriori (MAP) estimation, where the community structure is estimated both by the observed networked data and by the prior distribution given by historic community structures. Then we develop an iterative algorithm, with proven low time complexity, which is guaranteed to converge to an optimal solution. We perform extensive experimental studies, on both synthetic datasets and real datasets, to demonstrate that our method discovers meaningful communities and provides additional insights not directly obtainable from traditional methods.	[Lin, Yu-Ru; Sundaram, Hari] Arizona State Univ, Arts Media & Engn Program, Tempe, AZ 85281 USA; [Chi, Yun; Zhu, Shenghuo] NEC Labs Amer, Cupertino, CA 95014 USA; [Tseng, Belle L.] YAHOO Inc, Santa Clara, CA 95054 USA	Lin, YR (reprint author), Arizona State Univ, Arts Media & Engn Program, Tempe, AZ 85281 USA.	Yu-ru.lin@asu.edu					Asur S., 2007, P 13 ACM INT SIGKDD; BACH F. R., 2006, J MACH LEAN RESEA, V7; CHAKRABARTI D., 2006, P 12 ACM INT SIGKDD; CHI Y., 2007, P 13 ACM INT SIGKDD; Chung F, 1997, SPECTRAL GRAPH THEOR; DHILLON I. S., 2004, P 10 ACM INT SIGKDD; FLAKE G., 2000, P 6 ACM INT SIGKDD C; KLEINBERG J. M., 1999, JACM, V46, P5; Kumar R., 2003, P 12 INT C WORLD WID; KUMAR R., 2006, P 12 ACM INT SIGKDD; LESKOVEC J., 2005, P 11 ACM INT SIGKDD; LIN Y., 2007, P INT C WEB INT; LIN Y., 2008, P 17 INT C WORLD WID; Lovasz L., 1986, MATCHING THEORY; MEI Q., 2005, P 11 ACM INT SIGKDD; MOORE A. W., 2005, SIGKDD EXPLOR NEWSL, V7, P2; Newman M, 2004, PHYS REV E; NING H., 2007, P SIAM INT C DAT MIN; Page L., 1998, PAGERANK CITATION RA; Palla G., 2007, NATURE, V446; SHI J., 2000, IEEE T PATTERN ANAL, V22, P8, DOI DOI 10.1109/34.868688; SPILIOPOULOU M., 2006, P 12 ACM INT SIGKDD; SUN J., 2007, P 13 ACM INT SIGKDD; TOYODA M., 2003, P 14 ACM C HYP HYP H; Wasserman S, 1994, SOCIAL NETWORK ANAL; White S., 2005, P SIAM INT C DAT MIN; Xu Wei, 2003, P 26 ANN INT ACM SIG; YU K., 2005, P C ADV NEUR INF PRO; ZHA H., 2001, P C ADV NEUR INF PRO	29	14	15	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	APR	2009	3	2							8	10.1145/1514888.1514891		31	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VP	WOS:000208167800003	
J	Liu, H; Salerno, J; Young, M; Agrawal, R; Yu, PS				Liu, Huan; Salerno, John; Young, Michael; Agrawal, Rakesh; Yu, Philip S.			Introduction to Special Issue on Social Computing, Behavioral Modeling, and Prediction	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Editorial Material																	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	APR	2009	3	2							6	10.1145/1514888.1514889		3	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VP	WOS:000208167800001	
J	Mehler, A; Skiena, S				Mehler, Andrew; Skiena, Steven			Expanding Network Communities from Representative Examples	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Discrete mathematics; artificial intelligence; social networks; news analysis; community discovery; graph theory		We present an approach to leverage a small subset of a coherent community within a social network into a much larger, more representative sample. Our problem becomes identifying a small conductance subgraph containing many (but not necessarily all) members of the given seed set. Starting with an initial seed set representing a sample of a community, we seek to discover as much of the full community as possible. We present a general method for network community expansion, demonstrating that our methods work well in expanding communities in real world networks starting from small given seed groups (20 to 400 members). Our approach is marked by incremental expansion from the seeds with retrospective analysis to determine the ultimate boundaries of our community. We demonstrate how to increase the robustness of the general approach through bootstrapping multiple random partitions of the input set into seed and evaluation groups. We go beyond statistical comparisons against gold standards to careful subjective evaluations of our expanded communities. This process explains the causes of most disagreement between our expanded communities and our gold-standards-arguing that our expansion methods provide more reliable communities than can be extracted from reference sources/gazetteers such as Wikipedia.	[Mehler, Andrew; Skiena, Steven] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	Mehler, A (reprint author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.	mehler@gmail.com; skiena@cs.sunysb.edu			NSF [EIA-0325123, DBI-0444815]	This work was partially supported by NSF Grants EIA-0325123 and DBI-0444815.	Andersen R, 2006, P 15 INT C WORLD WID, P223, DOI 10.1145/1135777.1135814; BACKSTROM L., 2006, P 12 ACM SIGKDD INT, P44, DOI 10.1145/1150402.1150412; Barabasi Albert-Laszlo, 2003, LINKED; Bautin M, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P586, DOI 10.1109/WI.2007.84; Cami A., 2006, Journal of Combinatorial Mathematics and Combinatorial Computing, V58; CIRASELLA J., 2007, REFER LIBR; Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830; de Rijke M, 2007, P 16 ACM C INF KNOWL, P959, DOI 10.1145/1321440.1321585; FAVARON O., 2002, DISCUSSIONES MATH GR; FERNAU H., 2007, P SOFTW SEM, V2, P61; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Flake G.W., 2004, INTERNET MATH, V1, P385, DOI DOI 10.1080/15427951.2004.10129093; GHAHRAMANI Z., 2005, P NIPS; Gibson D., 1998, P 9 ACM C HYP HYP, P225, DOI 10.1145/276627.276652; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Godbole N., 2007, P INT C WEBL SOC MED; Hopcroft J, 2003, P 9 ACM SIGKDD INT C, P541; Hopcroft J, 2004, P NATL ACAD SCI USA, V101, P5249, DOI 10.1073/pnas.0307750100; JAMIESON L. H., 2002, J COMBIN MATH COMBIN; Kernighan B. W., 1970, Bell System Technical Journal, V49; KIL J., 2005, P 14 TEXT RETR C TRE; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Kossinets G, 2006, SCIENCE, V311, P88, DOI 10.1126/science.1116869; Leskovec J., 2008, P 17 INT C WORLD WID, P695, DOI DOI 10.1145/1367497.1367591; Lloyd L, 2005, LECT NOTES COMPUT SC, V3772, P161; LLOYD L., 2006, P C COMP APPR AN WEB, P117; LLOYD L., 2006, P C COMB PATT MATCH; Mehler A, 2006, IEEE T VIS COMPUT GR, V12, P765, DOI 10.1109/TVCG.2006.179; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; POTHEN A, 1990, SIAM J MATRIX ANAL A, V11, P430, DOI 10.1137/0611030; SARKAR P., 2005, SIGKDD EXPLORATIONS; Scott J., 2000, SOCIAL NETWORK ANAL; SHAFIQUE K. H., 2001, THESIS U CENTRAL FLO; Thelen M., 2002, P C EMP METH NAT LAN; Tyler JR, 2003, COMMUNITIES AND TECHNOLOGIES, P81; WARD C., 2009, IDENTIFYING DIFFEREN; Wu F, 2004, EUR PHYS J B, V38, P331, DOI 10.1140/epjb/e2004-00125-x	38	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	APR	2009	3	2							7	10.1145/1514888.1514890		27	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VP	WOS:000208167800002	
J	Wong, TT				Wong, Tzu-Tsung			Alternative prior assumptions for improving the performance of naive Bayesian classifiers	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Conjugate; Dirichlet assumption; Generalized Dirichlet distribution; Liouville distribution; Naive Bayesian classifier	GENERALIZED DIRICHLET DISTRIBUTION	The prior distribution of an attribute in a naive Bayesian classifier is typically assumed to be a Dirichlet distribution, and this is called the Dirichlet assumption. The variables in a Dirichlet random vector can never be positively correlated and must have the same confidence level as measured by normalized variance. Both the generalized Dirichlet and the Liouville distributions include the Dirichlet distribution as a special case. These two multivariate distributions, also defined on the unit simplex, are employed to investigate the impact of the Dirichlet assumption in naive Bayesian classifiers. We propose methods to construct appropriate generalized Dirichlet and Liouville priors for naive Bayesian classifiers. Our experimental results on 18 data sets reveal that the generalized Dirichlet distribution has the best performance among the three distribution families. Not only is the Dirichlet assumption inappropriate, but also forcing the variables in a prior to be all positively correlated can deteriorate the performance of the naive Bayesian classifier.	Natl Cheng Kung Univ, Inst Informat Management, Tainan 701, Taiwan	Wong, TT (reprint author), Natl Cheng Kung Univ, Inst Informat Management, 1 Ta Sheuh Rd, Tainan 701, Taiwan.	tzutsung@mail.ncku.edu.tw					Aitchison J., 1986, STAT ANAL COMPOSITIO; ANDERSON DR, 2006, STAT BUSINESS EC PRA, pCH7; BIER VM, 1995, INT J FORECASTING, V11, P25, DOI 10.1016/0169-2070(94)02011-D; Blake C.L., 1998, UCI MACHINE LEARNING; Cestnik B, 1991, EWSL 91 P EUR WORK S, P138; CONNOR RJ, 1969, J AM STAT ASSOC, V64, P194, DOI 10.2307/2283728; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; Fang K.T., 1990, SYMMETRIC MULTIVARIA; Hsu CN, 2003, MACH LEARN, V53, P235, DOI 10.1023/A:1026367023636; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; Langley P., 1992, ANAL BAYESIAN CLASSI; LOCHNER RH, 1975, J ROY STAT SOC B MET, V37, P103; Mitchell T. M, 1997, MACHINE LEARNING; Wilks S. S., 1962, MATH STAT; WONG T, 2005, J CHIN I IND ENG, V22, P210; Wong TT, 1998, APPL MATH COMPUT, V97, P165, DOI 10.1016/S0096-3003(97)10140-0; Wong TT, 2007, STAT PAP, V48, P265, DOI 10.1007/s00362-006-0330-y	19	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2009	18	2					183	213		10.1007/s10618-008-0101-6		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RO	WOS:000265081100001	
J	Xia, Y				Xia, Yu			A global optimization method for semi-supervised clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Partitional clustering; Semi-supervised clustering; Instance-level constraints; Global optimization; Concavity cuts		In this paper, we adapt Tuy's concave cutting plane method to the semi-supervised clustering. We also give properties of local optimal solutions of the semi-supervised clustering. Numerical examples show that this method can give a better solution than other semi-supervised clustering algorithms do.	Univ Birmingham, Sch Math, Birmingham B15 2TT, W Midlands, England	Xia, Y (reprint author), Univ Birmingham, Sch Math, Birmingham B15 2TT, W Midlands, England.	xiay@maths.bham.ac.uk			Institute of Statistical Mathematics, Japan; JSPS ( Japan Society for the Promotion of Science).; Center of Operations Research and Econometrics ( CORE),; Universite catholique de Louvain, Belgium	This research was carried out when the author was a postdoctoral research fellow at the Institute of Statistical Mathematics, Japan. I thank the support from JSPS ( Japan Society for the Promotion of Science). The paper was revised when I was a research fellow with the Center of Operations Research and Econometrics ( CORE), Universite catholique de Louvain, Belgium. I also thank the support from CORE. Finally, I would like to thank the helpful suggestions and comments of two anonymous referees which help improve the paper.	Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937; BASU S, 2003, ICML, P27; Basu S, 2004, ICML 04, P11, DOI [10.1145/1015330.1015360, DOI 10.1145/1015330.1015360]; Basu S., 2004, KDD 04, P59; Chang H, 2006, PATTERN RECOGN, V39, P1253, DOI 10.1016/j.patcog.2005.12.012; Cohn D., 2003, SEMISUPERVISED CLUST; Davidson I., 2005, P 2005 SIAM INT C DA; DEMIRIZ A, 1999, P ANNIE 99 ART NEUR; Drineas P, 2004, MACH LEARN, V56, P9, DOI 10.1023/B:MACH.0000033113.59016.96; FORREST JJ, 1992, MATH PROGRAMMING A, V57, P374; FORREST JJH, 1992, IBM SYST J, V31, P11; Freund RW, 1997, MATH PROGRAM, V76, P183, DOI 10.1007/BF02614383; GAO J, 2006, SDM 06; Gordon AD, 1996, COMPUT STAT DATA AN, V21, P17, DOI 10.1016/0167-9473(95)00005-4; Horst R., 1993, GLOBAL OPTIMIZATION; Jain AK, 2006, INT C PATT RECOG, P374; KLEIN D, 2002, P INT C MACH LEARN; LANGE T, 2005, CVPR 05, V1, P731; Murphy P., 1994, UCI REPOSITORY MACHI; Nemhauser G.L., 1988, WILEY INTERSCIENCE S; Nesterov Y, 1994, SIAM STUDIES APPL MA, V13; NESTEROV Y, 2004, APPL OPTIMIZATION KL, V87; Shental N., 2003, NIPS; Tuy H., 1964, SOV MATH, V5, P1437; Wagstaff K, 2000, P 17 INT C MACH LEAR, P1103; Wagstaff K., 2001, ICML, P577; XIA Y, 2005, P 5 SIAM INT C DAT M, P150; XIA Y, 2007, CPAIOR 07, P318; Xing E. P., 2002, ADV NEURAL INFORMATI, V15, P505	29	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2009	18	2					214	256		10.1007/s10618-008-0104-3		43	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RO	WOS:000265081100002	
J	Davidson, I; Ravi, SS				Davidson, Ian; Ravi, S. S.			Using instance-level constraints in agglomerative hierarchical clustering: theoretical and empirical results	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Clustering; Constrained clustering; Semi-supervised learning		Clustering with constraints is a powerful method that allows users to specify background knowledge and the expected cluster properties. Significant work has explored the incorporation of instance-level constraints into non-hierarchical clustering but not into hierarchical clustering algorithms. In this paper we present a formal complexity analysis of the problem and show that constraints can be used to not only improve the quality of the resultant dendrogram but also the efficiency of the algorithms. This is particularly important since many agglomerative style algorithms have running times that are quadratic ( or faster growing) functions of the number of instances to be clustered. We present several bounds on the improvement in the running times of algorithms obtainable using constraints.	[Davidson, Ian] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA; [Ravi, S. S.] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA	Davidson, I (reprint author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.	davidson@cs.ucdavis.edu; ravi@cs.albany.edu					BAE E, 2006, P 6 IEEE INT C DAT M, P53; Basu S., 2006, P 10 EUR C PRINC PRA, P115; Basu S, 2002, P 19 INT C MACH LEAR, P27; BASU S, 2008, ADV CLUSTER IN PRESS; Basu S, 2004, SIAM PROC S, P333; Cormen T. H., 2001, INTRO ALGORITHMS; Davidson I, 2007, DATA MIN KNOWL DISC, V14, P25, DOI 10.1007/s10618-006-0053-7; DAVIDSON I, 2006, P 21 NAT C ART INT A; DAVIDSON I, 2007, P ACM C KNOWL DISC D, P240, DOI 10.1145/1281192.1281221; Davidson I., 2005, P 9 EUR C PRINC PRAC, P59, DOI DOI 10.1007/11564126_11; Davidson I., 2007, P INT C MACH LEARN I, P201, DOI DOI 10.1145/1273496.1273522; Davidson I, 2005, SIAM PROC S, P138; Dragomirescu L, 2007, BIOMETR J, V33, P841; Elkan C, 2003, P 20 INT C MACH LEAR, P147; Graham R. L., 1989, CONCRETE MATH FDN CO; Klein D., 2002, P 19 INT C MACH LEAR, P307; MITZENMACHER M., 2005, PROBABILITY COMPUTIN; Mohanta P. P., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1044838; NANNI M, 2005, PAC AS C KNOWL DISC, P378; Schaefer T.J., 1978, P 10 ANN ACM S THEOR, P216, DOI DOI 10.1007/S10601-009-9079-Y; Wagstaff K., 2001, P 18 INT C MACH LEAR, P577; Wagstaff K, 2000, P 17 INT C MACH LEAR, P1103; XING E., 2002, ADV NEURAL INFORM PR, V15, P505; Zho Y, 2005, DATA MIN KNOWL DISC, V10, P141	24	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2009	18	2					257	282		10.1007/s10618-008-0103-4		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RO	WOS:000265081100003	
J	Cebron, N; Berthold, MR				Cebron, Nicolas; Berthold, Michael R.			Active learning for object classification: from exploration to exploitation	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Active learning; Data mining; Subtractive clustering; Exploration; Exploitation; Prototype classification		Classifying large datasets without any a-priori information poses a problem in numerous tasks. Especially in industrial environments, we often encounter diverse measurement devices and sensors that produce huge amounts of data, but we still rely on a human expert to help give the data a meaningful interpretation. As the amount of data that must be manually classified plays a critical role, we need to reduce the number of learning episodes involving human interactions as much as possible. In addition for real world applications it is fundamental to converge in a stable manner to a solution that is close to the optimal solution. We present a new self-controlled exploration/exploitation strategy to select data points to be labeled by a domain expert where the potential of each data point is computed based on a combination of its representativeness and the uncertainty of the classifier. A new Prototype Based Active Learning (PBAC) algorithm for classification is introduced. We compare the results to other active learning approaches on several benchmark datasets.	[Cebron, Nicolas; Berthold, Michael R.] Univ Konstanz, Dept Comp & Informat Sci, Constance, Germany	Cebron, N (reprint author), Univ Konstanz, Dept Comp & Informat Sci, Constance, Germany.	nicolas.cebron@uni-konstanz.de			DFG Research Training Group [GK-1042]	This work was supported by the DFG Research Training Group GK-1042 " Explorative Analysis and Visualization of Large Information Spaces".	ASUNCION A., 2007, UCI MACHINE LEARNING; Baram Y, 2004, J MACH LEARN RES, V5, P255; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BUHMANN JM, 2000, INT C PATT REC ICPR, V2, P2186; Cebron N, 2006, LECT NOTES ARTIF INT, V4213, P79; CHIN SL, 1997, JACIII, V1, P31; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; COHN DA, 1994, NEURAL INFORM PROCES, P705; Kang JH, 2004, LECT NOTES ARTIF INT, V3056, P384; Luo T, 2005, J MACH LEARN RES, V6, P589; Mandel MI, 2006, MULTIMEDIA SYST, V12, P3, DOI 10.1007/s00530-006-0032-2; McCallum A., 1998, P 15 INT C MACH LEAR, P350; NGUYEN HT, 2004, MACHINE LEARNING; OSUGI T, 2005, ICDM 05, P330; Schohn G., 2000, P 17 INT C MACH LEAR, P839; WANG L, 2003, IEEE COMP SOC C COMP, P629; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; XU Z, 2004, ECIR 2003, V2633, P393	18	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2009	18	2					283	299		10.1007/s10618-008-0115-0		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RO	WOS:000265081100004	
J	Linstead, E; Bajracharya, S; Ngo, T; Rigor, P; Lopes, C; Baldi, P				Linstead, Erik; Bajracharya, Sushil; Ngo, Trung; Rigor, Paul; Lopes, Cristina; Baldi, Pierre			Sourcerer: mining and searching internet-scale software repositories	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Mining software; Program understanding; Code search; Software analysis; Author-topic probabilistic modeling; Code retrieval	SOURCE CODE; TOPICS	Large repositories of source code available over the Internet, or within large organizations, create new challenges and opportunities for data mining and statistical machine learning. Here we first develop Sourcerer, an infrastructure for the automated crawling, parsing, fingerprinting, and database storage of open source software on an Internet-scale. In one experiment, we gather 4,632 Java projects from SourceForge and Apache totaling over 38 million lines of code from 9,250 developers. Simple statistical analyses of the data first reveal robust power-law behavior for package, method call, and lexical containment distributions. We then develop and apply unsupervised, probabilistic, topic and author-topic (AT) models to automatically discover the topics embedded in the code and extract topic-word, document-topic, and AT distributions. In addition to serving as a convenient summary for program function and developer activities, these and other related distributions provide a statistical and information-theoretic basis for quantifying and analyzing source file similarity, developer similarity and competence, topic scattering, and document tangling, with direct applications to software engineering an software development staffing. Finally, by combining software textual content with structural information captured by our Code-Rank approach, we are able to significantly improve software retrieval performance, increasing the area under the curve (AUC) retrieval metric to 0.92-roughly 10-30% better than previous approaches based on text alone. A prototype of the system is available at: http://sourcerer.ics.uci.edu.	[Linstead, Erik; Bajracharya, Sushil; Ngo, Trung; Rigor, Paul; Lopes, Cristina; Baldi, Pierre] Univ Calif Irvine, Donald Bren Sch Informat & Comp Sci, Irvine, CA 92717 USA	Baldi, P (reprint author), Univ Calif Irvine, Donald Bren Sch Informat & Comp Sci, Irvine, CA 92717 USA.	elinstea@ics.uci.edu; sbajrach@ics.uci.edu; trungcn@ics.uci.edu; prigor@ics.uci.edu; lopes@ics.uci.edu; pfbaldi@ics.uci.edu					Andrzejewski D., 2007, 18 EUR C MACH LEARN; Anvik J., 2006, ICSE 06, P361; Baeza-Yates R. A., 1999, MODERN INFORM RETRIE; BALDI P, 2008, OOPSLA 08 IN PRESS; Baldi P., 2003, MODELING INTERNET WE; Blei D. M., 2006, ADV NEURAL INFORM PR, V18, P147; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BRILL E, 1994, NAT C ART INT, P722; Buntine W., 2005, SIGIR Forum, V39; Chen J, 2005, BIOINFORMATICS, V21, P4133, DOI 10.1093/bioinformatics/bti683; Concas G, 2007, IEEE T SOFTWARE ENG, V33, P687, DOI 10.1109/TSE.2007.1016; COX A, 1999, CASCON 99, P1; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Finnigan PJ, 1997, IBM SYST J, V36, P564; FREAN GBM, 2006, OOPSLA 06, P397; GIL JY, 2005, OOPSLA, P97; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Hajiyev E, 2006, LECT NOTES COMPUT SC, V4067, P2; HILL R, 2004, ASE, P228; Holmes R, 2005, PROC INT CONF SOFTW, P117; Holmes R, 2006, IEEE T SOFTWARE ENG, V32, P952, DOI 10.1109/TSE.2006.117; Inoue K, 2005, IEEE T SOFTWARE ENG, V31, P213, DOI 10.1109/TSE.2005.38; INOUE K, 2003, ICSE, P14; KAWAGUCHI S, 2004, APSEC 04, P184; Kiczales G., 1997, P EUR C OBJ OR PROGR, V1241, P220; Knuth D. E., 1971, Software - Practice and Experience, V1, DOI 10.1002/spe.4380010203; Kuhn A, 2007, INFORM SOFTWARE TECH, V49, P230, DOI 10.1016/j.infsof.2006.10.017; LINSTEAD E, 2007, MSR 2007, P30; LINSTEAD E, 2008, ADV NEURAL INFORM PR, V20, P929; Liu C., 2006, KDD 06, P872; Mandelin D., 2005, PLDI 05, P48, DOI 10.1145/1065010.1065018; Marcus A., 2004, Proceedings. 11th Working Conference on Reverse Engineering; MCCORMICK E, 2004, OOPSLA 04 COMP 19 AN, P9; Minto S., 2007, MSR 07, P5; MITZENMACHER M, 2003, INTERNET MATH, V1; Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365; Newman D, 2006, LECT NOTES COMPUT SC, V3975, P93; Newman DJ, 2006, J AM SOC INF SCI TEC, V57, P753, DOI 10.1002/asi.20342; Oman P., 1992, P C SOFTW MAINT NOV, P337, DOI 10.1109/ICSM.1992.242525; Page L, 1998, SIDLWP19990120; PAUL S, 1994, IEEE T SOFTWARE ENG, V20, P463, DOI 10.1109/32.295894; PAUL S, 1992, CASCON 92, P329; Poshyvanyk D, 2006, INT C PROGRAM COMPRE, P252, DOI 10.1109/ICPC.2006.32; Puppin D., 2006, SAC, P1409; Rosen-Zvi M., 2004, UAI 04, P487; Sahavechaphan N, 2006, ACM SIGPLAN NOTICES, V41, P413, DOI 10.1145/1167515.1167508; Schleimer S., 2003, SIGMOD 03, P76; Schroter A., 2006, P 5 INT S EMP SOFTW, V2, P18; SINDHGATTA R, 2006, ICSE, P905; Steyvers M., 2004, KDD 04, P306; Swamidass SJ, 2007, J CHEM INF MODEL, V47, P302, DOI 10.1021/ci600358f; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; UGUREL S., 2002, KDD 02, P632; UKKONEN E, 1992, THEOR COMPUT SCI, V92, P191, DOI 10.1016/0304-3975(92)90143-4; WELKER KD, 1995, J DEFENSE SOFTWARE E, V8, P19; WHEELDON R, 2003, INT WORKSH SOURC COD, P45; Ye YW, 2002, ICSE 2002: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P513; Zipf G., 1932, SELECTIVE STUDIES PR	58	15	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2009	18	2					300	336		10.1007/s10618-008-0118-x		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	431RO	WOS:000265081100005	
J	Angiulli, F; Fassetti, F				Angiulli, Fabrizio; Fassetti, Fabio			DOLPHIN: An Efficient Algorithm for Mining Distance-Based Outliers in Very Large Datasets	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Data mining; outlier detection; distance-based outliers		In this work a novel distance-based outlier detection algorithm, named DOLPHIN, working on disk-resident datasets and whose I/O cost corresponds to the cost of sequentially reading the input dataset file twice, is presented. It is both theoretically and empirically shown that the main memory usage of DOLPHIN amounts to a small fraction of the dataset and that DOLPHIN has linear time performance with respect to the dataset size. DOLPHIN gains efficiency by naturally merging together in a unified schema three strategies, namely the selection policy of objects to be maintained in main memory, usage of pruning rules, and similarity search techniques. Importantly, similarity search is accomplished by the algorithm without the need of preliminarily indexing the whole dataset, as other methods do. The algorithm is simple to implement and it can be used with any type of data, belonging to either metric or nonmetric spaces. Moreover, a modification to the basic method allows DOLPHIN to deal with the scenario in which the available buffer of main memory is smaller than its standard requirements. DOLPHIN has been compared with state-of-the-art distance-based outlier detection algorithms, showing that it is much more efficient.	[Angiulli, Fabrizio; Fassetti, Fabio] Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, DEIS, Via P Bucci,41C, I-87036 Arcavacata Di Rende, CS, Italy.	f.angiulli@deis.unical.it; f.fassetti@deis.unical.it					AGGARWAL CC, 2001, P INT C MAN DAT SIGM; Angiulli F, 2005, IEEE T KNOWL DATA EN, V17, P203, DOI 10.1109/TKDE.2005.31; Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); ANGIULLI F, 2007, P 16 ACM C C INF KNO, P791, DOI 10.1145/1321440.1321550; Arning A., 1996, P 2 INT C KNOWL DISC, P164; Barnett V., 1994, OUTLIERS STAT DATA; BAY SD, 2003, P INT C KNOWL DISC D; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Bohm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809; BREUNIG MM, 2000, P INT C MAN DAT SIGM; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; DAVIES L, 1993, J AM STAT ASSOC, V88, P782, DOI 10.2307/2290763; DAVIES L, 1989, 891 U DORTM DEP STAT; Eskin E., 2002, APPL DATA MINING COM; GHOTING A, 2006, P SIAM INT C DAT MIN; Hawkins D. M., 1980, MONOGRAPHS APPL PROB; JIN W, 2001, P ACM SIGKDD INT C K; Knorr E. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Lazarevic A., 2003, P SIAM INT C DAT MIN; Papadimitriou S, 2003, PROC INT CONF DATA, P315, DOI 10.1109/ICDE.2003.1260802; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; RIDER PR, 1962, AM MATH MON, V69, P302, DOI 10.2307/2312952; RUIZ EV, 1986, PATTERN RECOGN LETT, V4, P145; Samet H., 2005, MORGAN KAUFMANN SERI; Schultze V, 2002, STAT NEERL, V56, P41, DOI 10.1111/1467-9574.01600; Tao Y., 2006, P 12 ACM SIGKDD INT, P394, DOI 10.1145/1150402.1150447; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; WATANABE O, 2000, TIEICE IEICE T COMMU	34	6	7	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2009	3	1								10.1145/1497577.1497581		57	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VN	WOS:000208167600004	
J	Cerf, L; Besson, J; Robardet, C; Boulicaut, JF				Cerf, Loic; Besson, Jeremy; Robardet, Celine; Boulicaut, Jean-Francois			Closed Patterns Meet n-ary Relations	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Closed patterns; constraint-based mining; constraint properties; n-ary relations; tiling		Set pattern discovery from binary relations has been extensively studied during the last decade. In particular, many complete and efficient algorithms for frequent closed set mining are now available. Generalizing such a task to n-ary relations (n >= 2) appears as a timely challenge. It may be important for many applications, for example, when adding the time dimension to the popular objects x features binary case. The generality of the task (no assumption being made on the relation arity or on the size of its attribute domains) makes it computationally challenging. We introduce an algorithm called DATA-PEELER. From an n-ary relation, it extracts all closed n-sets satisfying given piecewise (anti) monotonic constraints. This new class of constraints generalizes both monotonic and antimonotonic constraints. Considering the special case of ternary relations, DATA-PEELER outperforms the state-of-the-art algorithms CUBEMINER and TRIAS by orders of magnitude. These good performances must be granted to a new clever enumeration strategy allowing to efficiently enforce the closeness property. The relevance of the extracted closed n-sets is assessed on real-life 3-and 4-ary relations. Beyond natural 3-or 4-ary relations, expanding a relation with an additional attribute can help in enforcing rather abstract constraints such as the robustness with respect to binarization. Furthermore, a collection of closed n-sets is shown to be an excellent starting point to compute a tiling of the dataset.	[Cerf, Loic; Robardet, Celine; Boulicaut, Jean-Francois] INSA, LIRIS CNRS UMR5205, F-69621 Villeurbanne, France; [Besson, Jeremy] Inst Math & Informat, LT-08663 Vilnius, Lithuania	Cerf, L (reprint author), INSA, LIRIS CNRS UMR5205, F-69621 Villeurbanne, France.	Loic.cerf@liris.cnrs.fr	InWeb, Inct/J-9839-2013		EU [IST-FET IQ FP6-516169]; INRA; ANR [BINGO2]	This work is partly funded by EU contract IST-FET IQ FP6-516169, INRA and ANR BINGO2 (MDCO 2007).	AFRATI F, 2005, P 5 IEEE INT C DAT M, P553; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Besson J, 2005, INTELL DATA ANAL, V9, P59; Boulicaut JF, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P399, DOI 10.1007/0-387-25465-X_18; Brayton RK, 1984, LOGIC MINIMIZATION A; CERF L, 2008, P 8 SIAM INT C DAT M; GAO M, 2000, IEEE INT WORKSH LOG; GARRIGA GC, 2007, P 20 INT JOINT C ART, P804; Gely A, 2005, LECT NOTES COMPUT SC, V3403, P223; Goethals B, 2004, ACM SIGKDD EXPLORATI, V6, P109, DOI 10.1145/1007730.1007744; Grahne G, 2005, IEEE T KNOWL DATA EN, V17, P1347, DOI 10.1109/TKDE.2005.166; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Jaschke R., 2006, P 6 IEEE INT C DAT M, P907; Ji L., 2006, P 32 INT C VER LARG, P811; Jiang D., 2004, P 10 ACM SIGKDD INT, P430, DOI 10.1145/1014052.1014101; Karnaugh M., 1953, Transactions of the American Institute of Electrical Engineers, Part I (Communications and Electronics), V72; MCCLUSKEY J, 1956, BELL SYST TECH J, V35, P1417; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Pan F., 2003, P 9 ACM SIGKDD INT C, P637; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; Pei J, 2001, PROC INT CONF DATA, P433; Pei J, 2000, WORKSH RES ISS DAT M, P21; Pensa RG, 2005, LECT NOTES ARTIF INT, V3539, P115, DOI 10.1007/11504245_8; Rudell R. L., 1985, Proceedings of the IEEE 1985 Custom Integrated Circuits Conference (Cat. No. 85CH2157-6); SHAO L, 2005, P ACM SIGMOD INT C M, P694; Stumme G, 2002, DATA KNOWL ENG, V42, P189, DOI 10.1016/S0169-023X(02)00057-5; Sun J, 2006, P 12 ACM SIGKDD INT, P374, DOI 10.1145/1150402.1150445; Uno T., 2005, P 1 INT WORKSH OP SO, P77, DOI 10.1145/1133905.1133916; Wang J., 2003, P 9 ACM SIGKDD INT C, P236; Wille R., 1982, ORDERED SETS, P445; Zaki M.J., 2002, P 2 SIAM INT C DAT M	32	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2009	3	1								10.1145/1497577.1497580		36	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VN	WOS:000208167600003	
J	Chen, BC; Ramakrishnan, R; Shavlik, JW; Tamma, P				Chen, Bee-Chung; Ramakrishnan, Raghu; Shavlik, Jude W.; Tamma, Pradeep			Bellwether Analysis: Searching for Cost-Effective Query-Defined Predictors in Large Databases	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Cost-effective prediction; data cube; OLAP queries; predictive models; scalable algorithms; bellwether		How to mine massive datasets is a challenging problem with great potential value. Motivated by this challenge, much effort has concentrated on developing scalable versions of machine learning algorithms. However, the cost of mining large datasets is not just computational; preparing the datasets into the "right form" so that learning algorithms can be applied is usually costly, due to the human labor that is typically required and a large number of choices in data preparation, which include selecting different subsets of data and aggregating data at different granularities. We make the key observation that, for a number of practically motivated problems, these choices can be defined using database queries and analyzed in an automatic and systematic manner. Specifically, we propose a new class of data-mining problem, called bellwether analysis, in which the goal is to find a few query-defined predictors (e. g., first week sales of Peoria, IL of an item) that can be used to accurately predict the result of a target query (e. g., first year worldwide sales of the item) from a large number of queries that define candidate predictors. To make a prediction for a new item, the data needed to generate such predictors has to be collected (e. g., selling the new item in Peoria, IL for a week and collecting the sales data). A useful predictor is one that has high prediction accuracy and a low data-collection cost. We call such a cost-effective predictor a bellwether. This article introduces bellwether analysis, which integrates database query processing and predictive modeling into a single framework, and provides scalable algorithms for large datasets that cannot fit in main memory. Through a series of extensive experiments, we show that bellwethers do exist in real-world databases, and that our computation techniques achieve good efficiency on large datasets.	[Chen, Bee-Chung; Ramakrishnan, Raghu] Yahoo Res, Santa Clara, CA 95054 USA; [Shavlik, Jude W.] Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA; [Tamma, Pradeep] Microsoft, Redmond, WA 98052 USA	Chen, BC (reprint author), Yahoo Res, 2821 Mission Coll Blvd, Santa Clara, CA 95054 USA.	beechun@yahoo-inc.com			NSF [ITR IIS-0326328, IIS-0524671]; University of Wisconsin, Madison	This research was supported in part by NSF grants ITR IIS-0326328 and IIS-0524671, and B.-C. Chen was supported by a Microsoft Research fellowship when he was at the University of Wisconsin, Madison where a major part of this research was done.	Agarwal S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; Benjamini Y, 2001, ANN STAT, V29, P1165; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BEYER K, 1999, P 1999 ACM SIGMOD IN, P359, DOI 10.1145/304182.304214; Breiman L, 1984, CLASSIFICATION REGRE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chai X., 2004, P 4 IEEE INT C DAT M, P51; Chatziantoniou D, 2001, PROC INT CONF DATA, P524, DOI 10.1109/ICDE.2001.914866; Chen B.-C., 2006, P 32 INT C VER LARG, P655; CHEN BC, 2008, THESIS U WISCONSIN M; CHEN L, 2006, P 32 INT C VER LARG, P403; Chvatal V., 1979, Mathematics of Operations Research, V4, DOI 10.1287/moor.4.3.233; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Dean J., 2004, P 6 S OP SYST DES IM; DIETTERICH TG, 1997, ARTIF INTELL J, V89; Efron B., 2005, 200520B234 STANF U D; Friedman N., 1999, P 16 INT JOINT C ART, P1300; Gehrke J., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843; Greiner R, 2002, ARTIF INTELL, V139, P137, DOI 10.1016/S0004-3702(02)00209-6; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hamilton JD, 1994, TIME SERIES ANAL; HAN J, 2001, P ACM SIGMOD INT C M, P1, DOI 10.1145/375663.375664; HAYKIN S, 1994, VARIABLE FEATURE SEL, V3, P1157; Kapoor A, 2005, LECT NOTES ARTIF INT, V3720, P170; Li Xuelong, 2004, P INT C VER LARG DAT, P528, DOI 10.1016/B978-012088469-8/50048-6; Ling C. X., 2004, P 21 INT C MACH LEAR; LIZOTTE D, 2003, P 19 C UNC ART INT U; Mehta M., 1995, P 1 INT C KNOWL DISC, P216; Melville P., 2004, P 4 IEEE INT C DAT M, P483; MELVILLE P, 2005, P 5 IEEE INT C DAT M, P745; Mitchell T. M, 1997, MACHINE LEARNING; NG R, 2001, P 2001 ACM SIGMOD C, P25, DOI 10.1145/375663.375666; Perlich C., 2003, P 9 ACM SIGKDD INT C, P167; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; Ramakrishnan R., 2002, DATABASE MANAGEMENT; Ramakrishnan R, 2007, DATA MIN KNOWL DISC, V15, P29, DOI 10.1007/s10618-007-0063-0; Ray S, 2005, P 22 INT C MACH LEAR, P697, DOI 10.1145/1102351.1102439; Ross K. A., 1998, P INT C EXT DAT TECH, P263; Rumelhart D, 1986, PARALLEL DISTRIBUTED; Seber G. A. F., 2003, LINEAR REGRESSION AN; Shao Z., 2004, P 16 INT C SCI STAT, P213; Sheng V. S., 2007, P 13 ACM SIGKDD INT, P638, DOI 10.1145/1281192.1281261; SHENG VS, 2006, P 23 INT C MACH LEAR; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Vapnik V.N., 1995, NATURE STAT LEARNING; Webb G. I., 2006, P 12 ACM SIGKDD INT, P434, DOI 10.1145/1150402.1150451; Witten IH, 2000, DATA MINING PRACTICA; Xin D., 2003, P 29 INT C VER LARG, P476, DOI 10.1016/B978-012722442-8/50049-5; Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P1542, DOI 10.1109/TKDE.2005.176	53	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2009	3	1								10.1145/1497577.1497582		49	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VN	WOS:000208167600005	
J	Dhurandhar, A; Dobra, A				Dhurandhar, Amit; Dobra, Alin			Semi-Analytical Method for Analyzing Models and Model Selection Measures Based on Moment Analysis	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Model selection; generalization error; classification		In this article we propose a moment-based method for studying models and model selection measures. By focusing on the probabilistic space of classifiers induced by the classification algorithm rather than on that of datasets, we obtain efficient characterizations for computing the moments, which is followed by visualization of the resulting formulae that are too complicated for direct interpretation. By assuming the data to be drawn independently and identically distributed from the underlying probability distribution, and by going over the space of all possible datasets, we establish general relationships between the generalization error, hold-out-set error, cross-validation error, and leave-one-out error. We later exemplify the method and the results by studying the behavior of the errors for the naive Bayes classifier.	[Dhurandhar, Amit; Dobra, Alin] Univ Florida, Gainesville, FL 32611 USA	Dhurandhar, A (reprint author), Univ Florida, Gainesville, FL 32611 USA.	amitdhur@ufl.edu			National Science Foundation [NSF-CAREER-IIS-0448264]	This work is supported by the National Science Foundation Grant, NSF-CAREER-IIS-0448264.	BENGIO Y., 2003, J MACH LEARN RES; BERTSIMAS D., 1998, OPTIMAL INEQUALITIES; BLUM A, 1999, COMPUTATIONAL LEARNI, P203; BOUCHERON S., 2005, INTRO STAT LEARNING; BOYD S., 1996, SDPSOL PARSER SOLVER; Boyd S., 2004, CONVEX OPTIMIZATION; Breiman L, 1996, ANN STAT, V24, P2350; Butler RW, 1998, J AM STAT ASSOC, V93, P596, DOI 10.2307/2670111; Connor-Linton Jeff, 2003, CHI SQUARE TUTORIAL; Devroye L, 1996, PROBABILISTIC THEORY; Doob J.L., 1994, MEASURE THEORY; ELISSEEFF A., 2003, LEARNING THEORY PRAC; Goutte C, 1997, NEURAL COMPUT, V9, P1245, DOI 10.1162/neco.1997.9.6.1245; Hall P, 1992, BOOTSTRAP EDGEWORTH; ISII K, 1963, ANN I STAT MATH, V14, P185; ISII K, 1960, ANN I STAT MATH, V12, P119, DOI 10.1007/BF01733120; Karlin S., 1953, MEMOIRS AM MATH SOC, V12; Kearns M. J., 1997, COMPUTATIONAL LEARNI, P152; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kutin S., 2002, P 18 C UNC ART IND E, P275; LANGFORD J, 2005, FILED PREDICTION THE; Langley P., 1999, P 16 INT C MACH LEAR, P220, DOI 10.1.1.43.3472; LEVIN B, 1981, ANN STAT, V9, P1123, DOI 10.1214/aos/1176345593; Moore A. W., 1994, P 11 INT C MACH LEAR, P190; PLUTOWSKI M, 1996, SURVEY CROSS VALIDAT; PREKOPA A, 1989, DISCRETE MOMENT PROB; SHAO J, 1993, J AM STAT ASS, V88; Vapnik V. N., 1998, STAT LEARNING THEORY; WILLIAMSON R, 2001, SRM VE THEORY STAT L; WOLFRAM-RESEARCH, 2009, MATH; Zhu HY, 1996, NEURAL COMPUT, V8, P1421, DOI 10.1162/neco.1996.8.7.1421	31	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2009	3	1								10.1145/1497577.1497579		51	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VN	WOS:000208167600002	
J	Kriegel, HP; Kroger, P; Zimek, A				Kriegel, Hans-Peter; Kroeger, Peer; Zimek, Arthur			Clustering High-Dimensional Data: A Survey on Subspace Clustering, Pattern-Based Clustering, and Correlation Clustering	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Survey; clustering; high-dimensional data		As a prolific research area in data mining, subspace clustering and related problems induced a vast quantity of proposed solutions. However, many publications compare a new proposition-if at all-with one or two competitors, or even with a so-called "naive" ad hoc solution, but fail to clarify the exact problem definition. As a consequence, even if two solutions are thoroughly compared experimentally, it will often remain unclear whether both solutions tackle the same problem or, if they do, whether they agree in certain tacit assumptions and how such assumptions may influence the outcome of an algorithm. In this survey, we try to clarify: (i) the different problem definitions related to subspace clustering in general; (ii) the specific difficulties encountered in this field of research; (iii) the varying assumptions, heuristics, and intuitions forming the basis of different approaches; and (iv) how several prominent solutions tackle different problems.	[Kriegel, Hans-Peter; Kroeger, Peer; Zimek, Arthur] Univ Munich, Inst Informat, D-80538 Munich, Germany	Kriegel, HP (reprint author), Univ Munich, Inst Informat, Oettingenstr 67, D-80538 Munich, Germany.	kriegel@dbs.ifi.lmu.de; kroegerp@dbs.ifi.lmu.de; zimek@dbs.ifi.lmu.de					ACHTERT E, 2006, P 18 INT C SCI STAT; Achtert E., 2007, P 7 SIAM INT C DAT M; Achtert E, 2007, P 19 INT C SCI STAT; Achtert E, 2007, P 12 INT C DAT SYST; Achtert E, 2006, P 12 ACM INT C KNOWL; Achtert E, 2008, P 8 SIAM INT C DAT M; Achtert Elke, 2008, P 20 INT C SCI STAT; Aggarwal C., 1999, P ACM INT C MAN DAT; Aggarwal CC, 2001, P 8 INT C DAT THEOR; Aggarwal CC, 2000, P ACM INT C MAN DAT; Agrawal R, 1994, P ACM INT C MAN DAT; Agrawal R, 1998, P ACM INT C MAN DAT; Ankerst M, 1999, P ACM INT C MAN DAT; Assent I., 2007, ACM SIGKDD EXPLORATI, V9, P5, DOI 10.1145/1345448.1345451; ASSENT I, 2007, P 7 INT C DAT MIN IC; Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95; BARBARA D, 2000, P 6 ACM INT C KNOWL; Bellman R., 1961, ADAPTIVE CONTROL PRO; BELUSSI A, 1995, P 21 INT C VER LARG; BENDOR A, 2002, P 6 ANN INT C COMP M; BERCHTOLD S, 2000, P 16 INT C DAT ENG I; BERCHTOLD S, 1998, P ACM INT C MAN DAT; BERCHTOLD S, 1998, P 14 INT C DAT ENG I; BERCHTOLD S, 1996, P 22 INT C VER LARG; Beyer K, 1999, P 7 INT C DAT THEOR; Bishop C. M., 2006, PATTERN RECOGNITION; BOHM C, 2000, P 16 INT C DAT ENG I; BOHM C, 2004, P 4 INT C DAT MIN IC; BOHM C, 2000, P 7 INT C EXT DAT TE; Bohm Ch., 2004, P ACM INT C MAN DAT; Bouveyron C, 2007, COMPUT STAT DATA AN, V52, P502, DOI 10.1016/j.csda.2007.02.009; CALIFANO A, 2000, P 8 INT C INT SYST M; Chakrabarti K, 2000, P 26 INT C VER LARG; Cheng C. H., 1999, P 5 ACM SIGKDD INT C, P84, DOI 10.1145/312129.312199; CHENG H, 2008, P 34 INT C VER LARG; Cheng Y, 2000, P 8 INT C INT SYST M; Cho H., 2004, P 4 SIAM INT C DAT M; DESOUSA PM, 2002, P KDD WORKSH FRACT S; DHILLON IS, 2001, P 7 ACM INT C KNOWL; Domeniconi C, 2004, P 4 SIAM INT C DAT M; Duda R.O., 2001, PATTERN CLASSIFICATI; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Ester M, 1996, P 2 ACM INT C KNOWL; FALOUTSOS C, 1994, P ACM INT C MAN DAT; Faloutsos C, 2007, DATA MIN KNOWL DISC, V15, P3, DOI 10.1007/s10618-006-0057-3; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Friedman JH, 2004, J R STAT SOC B, V66, P825; Ganter B., 1999, FORMAL CONCEPT ANAL; Garey M.R., 1979, COMPUTER INTRACTABIL; GEORGII E, 2005, BIOINFORMATICS, V21, P1; Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797; GIONIS A, 2005, P 11 ACM INT C KNOWL; Han J., 2001, DATA MINING CONCEPTS; Han J, 2006, DATA MINING CONCEPTS; Hand D. J., 2001, PRINCIPLES DATA MINI; Haralick R, 2005, P 4 INT C MACH LEARN; Harpaz R, 2007, P IEEE S COMP INT DA; HARPAZ R, 2007, THESIS CITY U NEW YO; HARPAZ R, 2007, INT J INF TECHNOL IN, V2, P2; HARTIGAN JA, 1972, J AM STAT ASSOC, V67, P123, DOI 10.2307/2284710; Hastie T., 2001, ELEMENTS STAT LEARNI; Hinneburg A., 2000, P 26 INT C VER LARG; Hough PVC, 1962, US patent, Patent No. [3,069,654, 3069654]; Huang JZX, 2005, IEEE T PATTERN ANAL, V27, P657, DOI 10.1109/TPAMI.2005.95; Ihmels J, 2004, BIOINFORMATICS, V20, P1993, DOI 10.1093/bioinformatics/bth166; Jain A. K., 1999, ACM COMPUT SURV; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; Jing L, 2007, IEEE T KNOWL DATA EN, V19, P1026, DOI 10.1109/TKDE.2007.1048; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kailing K, 2004, P 4 SIAM INT C DAT M; KATAYAMA N, 1997, P ACM INT C MAN DAT; KETTENRING JR, 2008, STAT ANAL DATA MININ, V1, P52, DOI 10.1002/sam.10001; Korn F, 2001, IEEE T KNOWL DATA EN, V13, P96, DOI 10.1109/69.908983; Kriegel H.-P., 2005, P 5 INT C DAT MIN IC; Kriegel H.-P., 2008, P 20 INT C SCI STAT; KRIEGEL HP, 2007, 7 INT C DAT MIN ICDM; Li J, 2007, P 11 PAC AS C KNOWL; LIN K, 1995, VLDB J, V3, P517; Liu B, 2000, P 9 INT C INF KNOWL; LIU G, 2007, P 23 INT C DAT ENG I; LIU J, 2003, P 3 INT C DAT MIN IC; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; Mirkin B, 1996, MATH CLASSIFICATION; Mitchell TM, 1997, MACH LEARN; Moise G, 2008, P 14 ACM INT C KNOWL; MOISE G, 2006, P 6 INT C DAT MIN IC; Moise G, 2008, KNOWL INF SYST, V14, P273, DOI 10.1007/s10115-007-0090-6; MURALI TM, 2003, P 8 PAC S BIOC PSB; Nagesh H, 2001, P 1 SIAM INT C DAT M; PAGEL BU, 2000, P 16 INT C DAT ENG I; Parsons L, 2004, ACM SIGKDD EXPLORATI, V6, P90, DOI 10.1145/1007730.1007731; PEI J, 2003, P 3 INT C DAT MIN IC; PFALTZ J, 2007, P 19 INT C SCI STAT; Prelic A, 2006, BIOINFORMATICS, V22, P1122, DOI 10.1093/bioinformatics/btl060; Procopiuc CM, 2002, P ACM INT C MAN DAT; RUCKERT U, 2004, P 4 IEEE INT C DAT M, P507; Segal E, 2001, Bioinformatics, V17 Suppl 1, pS243; Sequeira K., 2005, International Journal of Business Intelligence and Data Mining, V1, DOI 10.1504/IJBIDM.2005.008360; Sheng Q., 2003, BIOINFORMATICS S2, V19, pii196; SIM K, 2006, P 6 INT C DAT MIN IC; Slagle J., 1975, IEEE T SYST MAN CYB, V5, P121; Tan P-N, 2006, INTRO DATA MINING; Tanay Amos, 2002, Bioinformatics, V18 Suppl 1, pS136; Tanay A., 2006, HDB COMPUTATIONAL MO; TUNG AKH, 2005, P ACM INT C MAN DAT; Van Mechelen I, 2004, STAT METHODS MED RES, V13, P363, DOI 10.1191/0962280204sm373ra; WANG H, 2002, P ACM INT C MAN DAT; Webb G. I., 2001, P 7 ACM SIGKDD INT C, P383, DOI 10.1145/502512.502569; Weber R., 1998, P 24 INT C VER LARG; Witten IH, 2005, DATA MINING PRACTICA; Woo KG, 2004, INFORM SOFTWARE TECH, V46, P255, DOI 10.1016/j.infsof.2003.07.003; YANG J, 2002, P 18 INT C DAT ENG I; Yip KY, 2004, IEEE T KNOWL DATA EN, V16, P1387, DOI 10.1109/TKDE.2004.74; Yip K.Y., 2005, P 21 INT C DAT ENG I; YIU ML, 2003, P 3 INT C DAT MIN IC; Yiu ML, 2005, IEEE T KNOWL DATA EN, V17, P176	116	76	80	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2009	3	1								10.1145/1497577.1497578		58	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VN	WOS:000208167600001	
J	Wang, JY; Zhang, YZ; Zhou, LZ; Karypis, G; Aggarwal, CC				Wang, Jianyong; Zhang, Yuzhou; Zhou, Lizhu; Karypis, George; Aggarwal, Charu C.			CONTOUR: an efficient algorithm for discovering discriminating subsequences	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Sequence mining; Discriminating subsequence; Summarization subsequence; Clustering	MINING SEQUENTIAL PATTERNS; SEQUENCES	In recent years we have witnessed several applications of frequent sequence mining, such as feature selection for protein sequence classification and mining block correlations in storage systems. In typical applications such as clustering, it is not the complete set but only a subset of discriminating frequent subsequences which is of interest. One approach to discovering the subset of useful frequent subsequences is to apply any existing frequent sequence mining algorithm to find the complete set of frequent subsequences. Then, a subset of interesting subsequences can be further identified. Unfortunately, it is very time consuming to mine the complete set of frequent subsequences for large sequence databases. In this paper, we propose a new algorithm, CONTOUR, which efficiently mines a subset of high-quality subsequences directly in order to cluster the input sequences. We mainly focus on how to design some effective search space pruning methods to accelerate the mining process and discuss how to construct an accurate clustering algorithm based on the result of CONTOUR. We conducted an extensive performance study to evaluate the efficiency and scalability of CONTOUR, and the accuracy of the frequent subsequence-based clustering algorithm.	[Wang, Jianyong; Zhang, Yuzhou; Zhou, Lizhu] Tsinghua Univ, Beijing 100084, Peoples R China; [Karypis, George] Univ Minnesota, Minneapolis, MN 55455 USA; [Aggarwal, Charu C.] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Wang, JY (reprint author), Tsinghua Univ, Beijing 100084, Peoples R China.	jianyong@tsinghua.edu.cn			National Basic Research Program of China [2006CB303103]; New Century Excellent Talents in University [NCET-07-0491]; Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry of China; NSF [EIA-9986042, ACI-0133464, IIS-0431135]; Digital Technology Center; University of Minnesota and the Minnesota Supercomputing Institute;  [NIH RLM008713A];  [NIH T32GM008347]	Jianyong Wang was supported in part by National Basic Research Program of China under Grant No. 2006CB303103, Program for Selected Talents (i.e., "Gu Gan Ren Cai") in Tsinghua University, Program for New Century Excellent Talents in University under Grant No. NCET-07-0491, and the Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry of China. George Karypis was supported by NSF EIA-9986042, ACI-0133464, IIS-0431135, NIH RLM008713A, NIH T32GM008347, the Digital Technology Center, University of Minnesota and the Minnesota Supercomputing Institute. This paper is a major-value added version of a conference paper that appeared in the 2007 SIAM International Conference on Data Mining ( SIAM SDM'07).	Aggarwal C., 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1; AGGARWAL CC, 2007, P 13 ACM SIGKDD INT, P46, DOI 10.1145/1281192.1281201; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; AYRES J, 2002, P ACM SIGKDD INT C K, P426; Bettini C, 1998, DATA ENG B, V21, P32; Casas-Garriga G, 2005, SIAM PROC S, P380; Cormen T. H., 2001, INTRO ALGORITHMS; Dalamagas T, 2006, INFORM SYST, V31, P187, DOI 10.1016/j.is.2004.11.009; Garofalakis MN, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P223; Guralnik V., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989516; Han J., 2000, P 6 ACM SIGKDD INT C, P355, DOI 10.1145/347090.347167; Han JW, 1999, PROC INT CONF DATA, P106; Ji X, 2005, P 5 IEEE INT C DAT M, P194; Karypis George, 2002, P PAKDD 02, P417; LI C, 2008, P 2008 SIAM INT C DA; Li Z., 2004, P 3 USENIX C FIL STO, P173; Li ZM, 2006, IEEE T SOFTWARE ENG, V32, P176, DOI 10.1109/TSE.2006.28; Mannila H., 1995, P 1 INT C KNOWL DISC; Masseglia F, 1998, LECT NOTES ARTIF INT, V1510, P176; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; Pei J, 2001, PROC INT CONF DATA, P215; Pei J., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Seno M., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183937; SHE R, 2003, P 9 ACM SIGKDD INT C, P236; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; WANG J., 2005, P 5 IEEE INT C DAT M, P753; WANG J, 2004, P 4 IEEE INT C DAT M, P241; Wang JY, 2005, SIAM PROC S, P205; Wang JY, 2004, PROC INT CONF DATA, P79, DOI 10.1109/ICDE.2004.1319986; Yan X., 2003, P 3 SIAM INT C DAT M; Yang J., 2002, P 2002 ACM SIGMOD IN, P406; Yang J, 2003, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2003.1260785; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	34	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2009	18	1					1	29		10.1007/s10618-008-0100-7		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	387KR	WOS:000261951600001	
J	Whitrow, C; Hand, DJ; Juszczak, P; Weston, D; Adams, NM				Whitrow, C.; Hand, D. J.; Juszczak, P.; Weston, D.; Adams, N. M.			Transaction aggregation as a strategy for credit card fraud detection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Fraud detection; Supervised classification; Credit cards; Preprocessing		The problem of preprocessing transaction data for supervised fraud classification is considered. It is impractical to present an entire series of transactions to a fraud detection system, partly because of the very high dimensionality of such data but also because of the heterogeneity of the transactions. Hence, a framework for transaction aggregation is considered and its effectiveness is evaluated against transaction-level detection, using a variety of classification methods and a realistic cost-based performance measure. These methods are applied in two case studies using real data. Transaction aggregation is found to be advantageous in many but not all circumstances. Also, the length of the aggregation period has a large impact upon performance. Aggregation seems particularly effective when a random forest is used for classification. Moreover, random forests were found to perform better than other classification methods, including SVMs, logistic regression and KNN. Aggregation also has the advantage of not requiring precisely labeled data and may be more robust to the effects of population drift.	[Whitrow, C.; Hand, D. J.; Juszczak, P.; Weston, D.] Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, London, England; [Hand, D. J.; Adams, N. M.] Univ London Imperial Coll Sci Technol & Med, Dept Math, London, England	Whitrow, C (reprint author), Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, London, England.	c.whitrow@imperial.ac.uk	Adams, Niall/D-2472-2010		EPSRC [EP/C532589/1]; Institute for Mathematical Sciences, Imperial College London; Royal Society Wolfson research merit award	The work of Piotr Juszczak and David Weston described here was supported by the EPSRC under grant number EP/C532589/1: ThinkCrime: Statistical and machine learning tools for plastic card and other personal fraud detection. The work of Chris Whitrow was supported by a grant from the Institute for Mathematical Sciences, Imperial College London. The work of David Hand was partially supported by a Royal Society Wolfson research merit award. We are indebted to our commercial collaborators who prefer to remain anonymous for providing both data and useful insights about the fraud detection problem.	Adams NM, 1999, PATTERN RECOGN, V32, P1139, DOI 10.1016/S0031-3203(98)00154-X; Aleskerov E., 1997, COMPUT INTELL, P220; BOLTON RJ, 2001, C CRED SCOR CRED CON, V7; Bolton RJ, 2002, STAT SCI, V17, P235; Brause R., 1999, Proceedings 11th International Conference on Tools with Artificial Intelligence, DOI 10.1109/TAI.1999.809773; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Chan PK, 1999, IEEE INTELL SYST APP, V14, P67, DOI 10.1109/5254.809570; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dorronsoro JR, 1997, IEEE T NEURAL NETWOR, V8, P827, DOI 10.1109/72.595879; Duda R.O., 1973, PATTERN CLASSIFICATI, P10; FAIR I, 2007, FALCON FRAUD MANAGER; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GHOSH S, 1994, P 27 ANN HAW INT C S, V3; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.1111/j.1751-5823.2001.tb00465.x; Hand DJ, 2008, J OPER RES SOC, V59, P956, DOI 10.1057/palgrave.jors.2602418; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Hand DJ, 2005, J OPER RES SOC, V56, P1109, DOI 10.1057/palgrave.jors.2601932; Hastie T., 2001, ELEMENTS STAT LEARNI; Hosmer D., 2000, APPL LOGISTIC REGRES; Kelly M., 1999, P 5 ACM SIGKDD INT C, P367, DOI 10.1145/312129.312285; KOU Y, 2004, IEEE INT C NETW SENS, P749; MAES S, 2002, P 1 INT NAISO C NEUR, P16; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F, 2002, STAT SCI, V17, P249; Wheeler R, 2000, KNOWL-BASED SYST, V13, P93, DOI 10.1016/S0950-7051(00)00050-2; *APACS, 2006, FRAUD FACTS 2006	28	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2009	18	1					30	55		10.1007/s10618-008-0116-z		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	387KR	WOS:000261951600002	
J	Jaroszewicz, S; Scheffer, T; Simovici, DA				Jaroszewicz, Szymon; Scheffer, Tobias; Simovici, Dan A.			Scalable pattern mining with Bayesian networks as background knowledge	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Association rule; Background knowledge; Interestingness; Bayesian network; Data stream		We study a discovery framework in which background knowledge on variables and their relations within a discourse area is available in the form of a graphical model. Starting from an initial, hand-crafted or possibly empty graphical model, the network evolves in an interactive process of discovery. We focus on the central step of this process: given a graphical model and a database, we address the problem of finding the most interesting attribute sets. We formalize the concept of interestingness of attribute sets as the divergence between their behavior as observed in the data, and the behavior that can be explained given the current model. We derive an exact algorithm that finds all attribute sets whose interestingness exceeds a given threshold. We then consider the case of a very large network that renders exact inference unfeasible, and a very large database or data stream. We devise an algorithm that efficiently finds the most interesting attribute sets with prescribed approximation bound and confidence probability, even for very large networks and infinite streams. We study the scalability of the methods in controlled experiments; a case-study sheds light on the practical usefulness of the approach.	[Jaroszewicz, Szymon] Inst Natl Telecommun, Warsaw, Poland; [Scheffer, Tobias] Max Planck Inst Comp Sci, Saarbrucken, Germany; [Simovici, Dan A.] Univ Massachusetts, Boston, MA 02125 USA	Jaroszewicz, S (reprint author), Inst Natl Telecommun, Warsaw, Poland.	s.jaroszewicz@itl.waw.pl; scheffer@mpi-inf.mpg.de; dsim@cs.umb.edu					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Andreassen S., 1989, COMPUTER AIDED ELECT; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bottcher SG, 2003, DEAL PACKAGE LEARNIN; CARVALHO D, 2005, 9 EUR C PRINC DAT MI, P453; Cooper G, 1999, P C UNC ART INT, P116; Dechter R, 1999, ARTIF INTELL, V113, P41, DOI 10.1016/S0004-3702(99)00059-4; DuMouchel W., 2001, P 7 ACM SIGKDD INT C, P67, DOI 10.1145/502512.502526; EBERHARDT F, 2005, N 1 EXPT SUFFIC DETE; Eberhardt F., 2005, P 21 C UNC ART INT U, P178; Gray H., 1977, GRAYS ANATOMY; Harinarayan V., 1996, P ACM SIGMOD INT C M, P205, DOI 10.1145/233269.233333; Heckerman D., 1995, MSRTR9506; HILDERMAN R, 1999, 9904 CS U REG DEP CO; Huang C, 1996, INT J APPROX REASON, V15, P225, DOI 10.1016/S0888-613X(96)00069-2; JAROSZEWICZ S, 2001, 5 EUR C PRINC DAT MI, P253; Jaroszewicz S., 2002, Advances in Knowledge Discovery and Data Mining. 6th Pacific-Asia Conference, PAKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2336); JAROSZEWICZ S, 2004, 10 ACM SIGKDD INT C, P178; JAROSZEWICZ S, 2005, 11 ACM SIGKDD INT C, P118; JENSEN F, 2001, BAYESIAN NETWORKS DE; Kleiter GD, 1996, ARTIF INTELL, V88, P143, DOI 10.1016/S0004-3702(96)00021-5; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Liu B., 1997, P 3 INT C KNOWL DISC, P31; LIU B, 1999, P 5 ACM SIGKDD INT C, P430, DOI 10.1145/312129.312311; MANNILA H, 2002, ICALP 2002; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; MEGANCK S, 2006, P 3 INT C MOD DEC AR, P58; Mitchell T. M, 1997, MACHINE LEARNING; MURPHY K., 1998, BRIEF INTRO GRAPHICA; Murphy K. P., 2001, ACTIVE LEARNING CAUS; Myllymaki P., 2002, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V11, DOI 10.1142/S0218213002000940; OHSAKI M, 2004, 8 EUR C PRINC DAT MI, P362; Padmanabhan B., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347103; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Pearl J., 2000, CAUSALITY MODELS REA; Pearl J, 1998, PROBABILISTIC REASON; SHAH D, 1999, 1999 ACM SIGMOD WORK; Silberschatz A., 1995, KDD-95 Proceedings. First International Conference on Knowledge Discovery and Data Mining; Smith A., 2004, P 10 ACM SIGKDD INT, P286, DOI 10.1145/1014052.1014085; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; Spirtes P., 1996, P 6 INT WORKSH ART I; Spirtes P, 1999, COMPUTATION, CAUSATION, AND DISCOVERY, P211; Suzuki E, 1998, LECT NOTES ARTIF INT, V1510, P10; Suzuki E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Tan P., 2002, P 8 ACM SIGKDD INT C, P32, DOI DOI 10.1145/775047.775053; Tong S., 2001, P 17 INT JOINT C ART, P863; VANALLEN T, 2001, UAI 01, P522; Zaki M. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347101; *AM HEART ASS, 2003, RISK FACT HIGH BLOOD; *TETRAD PROJ, TETRAD PROJ CAUS MOD	50	4	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2009	18	1					56	100		10.1007/s10618-008-0102-5		45	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	387KR	WOS:000261951600003	
J	Agrawal, S; Haritsa, JR; Prakash, BA				Agrawal, Shipra; Haritsa, Jayant R.; Prakash, B. Aditya			FRAPP: a framework for high-accuracy privacy-preserving mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Privacy; Data mining		To preserve client privacy in the data mining process, a variety of techniques based on random perturbation of individual data records have been proposed recently. In this paper, we present FRAPP, a generalized matrix-theoretic framework of random perturbation, which facilitates a systematic approach to the design of perturbation mechanisms for privacy-preserving mining. Specifically, FRAPP is used to demonstrate that (a) the prior techniques differ only in their choices for the perturbation matrix elements, and (b) a symmetric positive-definite perturbation matrix with minimal condition number can be identified, substantially enhancing the accuracy even under strict privacy requirements. We also propose a novel perturbation mechanism wherein the matrix elements are themselves characterized as random variables, and demonstrate that this feature provides significant improvements in privacy at only a marginal reduction in accuracy. The quantitative utility of FRAPP, which is a general-purpose random-perturbation-based privacy-preserving mining technique, is evaluated specifically with regard to association and classification rule mining on a variety of real datasets. Our experimental results indicate that, for a given privacy requirement, either substantially lower modeling errors are incurred as compared to the prior techniques, or the errors are comparable to those of direct mining on the true database.	[Agrawal, Shipra; Haritsa, Jayant R.] Indian Inst Sci, Bangalore 560012, Karnataka, India	Haritsa, JR (reprint author), Indian Inst Sci, Bangalore 560012, Karnataka, India.	haritsa@dsl.serc.iisc.ernet.in					ADAM NR, 1989, ACM COMPUT SURV, V21, P515, DOI 10.1145/76894.76895; AGGARWAL CC, 2004, P 9 INT C EXT DAT TE; AGRAWAL D, 2001, P ACM S PRINC DAT SY; Agrawal R., 2005, P ACM SIGMOD INT C M; AGRAWAL R, 2004, P 30 INT C VER LARG; Agrawal R., 2002, P 28 INT C VER LARG; Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R., 2000, P ACM SIGMOD INT C M; Agrawal R., 2004, P ACM SIGMOD INT C M; AGRAWAL S, 2004, P 9 INT C DAT SYST A; ATALLAH M, 1999, P IEEE KNOWL DAT ENG; CRANOR LF, 1999, 9943 ATT TR; DASSENI E, 2001, P 4 INT INF HID WORK; Denning D.E., 1982, CRYPTOGRAPHY DATA SE; DEWOLF P, 1998, P STAT DAT PROT C LI; Duncan G., 1991, STAT SCI, V6, P219, DOI 10.1214/ss/1177011681; Evfimievski A., 2003, P ACM S PRINC DAT SY; EVFIMIEVSKI A. V., 2002, P 8 ACM SIGKDD INT C; FELLER W, 1988, INTRO PROBABILITY TH; GOUWELEEUW J, 1998, J OFF STAT, V14, P485; Kantarcioglu M., 2002, P ACM SIGMOD WORKSH; Kargupta H, 2003, P 3 IEEE INT C DAT M; LEFEVRE K, 2004, P 30 INT C VER LARG; MISHRA N, 2006, P ACM S PRINC DAT SY; Mitchell T. M, 1997, MACHINE LEARNING; Motwani R., 1995, RANDOMIZED ALGORITHM; Pudi V, 2000, INFORM SYST, V25, P323, DOI 10.1016/S0306-4379(00)00021-1; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RASTOGI V, 2007, P 33 INT C VER LARG; Rizvi S., 2002, P 28 INT C VER LARG; SAMARATI P, 1998, P ACM S PRINC DAT SY; Saygin Y, 2001, SIGMOD RECORD, V30, P45; SAYGIN Y, 2002, P 1I INT WORKSH RES; SHOSHANI A, 1982, P 8 INT C VER LARG D; STRANG G, 1988, LINEAR ALGEBRA ITS A; Vaidya J, 2004, P SIAM INT C DAT MIN; Vaidya J, 2003, P 9 ACM SIGKDD INT C; VAIDYA J, 2002, P 8 ACM SIKGDD INT C; WANG Y, 1993, STAT SILICA, V3; WARNER SL, 1965, J AM STAT ASSOC, V60, P63, DOI 10.2307/2283137; Westin A., 1999, FREEBIES PRIVACY WHA; ZHANG N, 2004, P 8 EUR C PRINC PRAC	42	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2009	18	1					101	139		10.1007/s10618-008-0119-9		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	387KR	WOS:000261951600004	
J	Kohavi, R; Longbotham, R; Sommerfield, D; Henne, RM				Kohavi, Ron; Longbotham, Roger; Sommerfield, Dan; Henne, Randal M.			Controlled experiments on the web: survey and practical guide	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Controlled experiments; A/B testing; e-commerce; Website optimization; MultiVariable Testing; MVT	PORTABLE POWER	The web provides an unprecedented opportunity to evaluate ideas quickly using controlled experiments, also called randomized experiments, A/B tests (and their generalizations), split tests, Control/Treatment tests, MultiVariable Tests (MVT) and parallel flights. Controlled experiments embody the best scientific design for establishing a causal relationship between changes and their influence on user-observable behavior. We provide a practical guide to conducting online experiments, where end-users can help guide the development of features. Our experience indicates that significant learning and return-on-investment (ROI) are seen when development teams listen to their customers, not to the Highest Paid Person's Opinion (HiPPO). We provide several examples of controlled experiments with surprising results. We review the important ingredients of running controlled experiments, and discuss their limitations (both technical and organizational). We focus on several areas that are critical to experimentation, including statistical power, sample size, and techniques for variance reduction. We describe common architectures for experimentation systems and analyze their advantages and disadvantages. We evaluate randomization and hashing techniques, which we show are not as simple in practice as is often assumed. Controlled experiments typically generate large amounts of data, which can be analyzed using data mining techniques to gain deeper understanding of the factors influencing the outcome of interest, leading to new hypotheses and creating a virtuous cycle of improvements. Organizations that embrace controlled experiments with clear evaluation criteria can evolve their systems with automated optimizations and real-time analyses. Based on our extensive practical experience with multiple systems and organizations, we share key lessons that will help practitioners in running trustworthy controlled experiments.	[Kohavi, Ron; Longbotham, Roger; Sommerfield, Dan; Henne, Randal M.] Microsoft Corp, Redmond, WA 98052 USA	Kohavi, R (reprint author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.	ronnyk@microsoft.com; rogerlon@microsoft.com; dans@microsoft.com; rhenne@microsoft.com					ALT B, 2005, MARKET EXP J    1229; Boos DD, 2000, AM STAT, V54, P121, DOI 10.2307/2686030; Box G., 2005, STAT EXPT DESIGN INN; BURNS M, 2006, WEB ANAL SPENDINGS T; CHARLES RS, 2004, HDB PRACTICAL PROGRA; CHATHAM B, 2004, PRIMER A B TESTING; DAVIES OL, 1950, BIOMETRICS, V233, P121; EISENBERG B, 2005, CALL ACTION SECRET F; EISENBERG B, 2003, DECRESE SALES 90; EISENBERG B, 2005, IMPROVE A B TESTING; EISENBERG B, 2004, A B TESTING MATH DIS; EISENBERG B, 2003, INCREASE CONVERSION; EISENBERG B, 2006, SELLS BEST QUICK STA; Google, GOOGL WEBS OPT; Hopkins Claude C., 1923, SCI ADVERTISING; Kaplan R. S., 1996, BALANCED SCORECARD T; KAUSHIK A, 2006, EXPT TESTING PRIMER; KEPPEL G, 1992, INTRO DESIGN ANAL; KOHAVI R, 2004, FRONT LINE INTERNET; KOHAVI R, 2003, 10 SUPPLEMENTARY ANA; Kohavi R, 2004, MACH LEARN, V57, P83, DOI 10.1023/B:MACH.0000035473.11134.83; KOHAVI R, 2007, EMETRICS 2007 PRACTI; Koselka R., 1996, FORBES          0311, P114; Linden G., 2006, MAKE DATA USEFUL; LINDEN G, 2006, GEEKING GREG    0425; MANNING H, 2006, DONT TRATIONALIZE BA; Marks H, 2000, PROGR EXPT SCI THERA; MARON O, 1994, HOEFFDING RACES ACCE; Mason R.L., 1989, STAT DESIGN ANAL EXP; MCGLAUGHLIN F, 2006, MARKET EXP J    0321; MILLER S, 2006, CONVERSIONLAB COM EX; MILLER S, 2007, WEB MARKETING T 0118; MORAN M, 2007, DO IT WRONG QUICKLY; NIELSEN J, 2005, USEIT COM ALERT 0815; Peterson E., 2004, WEB ANAL DEMYSTIFIED; PETERSON ET, 2005, WEB SITE MEASUREMENT; Plackett RL, 1946, BIOMETRIKA, V33, P305, DOI 10.2307/2332195; QUARTOVONTIVADA.J, 2006, FUTURE NOW; Rossi PH, 2003, EVALUATION SYSTEMATI; Roy R. K., 2001, DESIGN EXPT USING TA; SPOOL JM, 2004, WEBPRONEWS      0920; Sterne J, 2002, WEB METRICS PROVEN M; TAN PN, 2002, DATA MIN KNOWL DIS; Thomke S. H, 2003, EXPT MATTERS UNLOCKI; Thomke S.H., 2001, ENLIGHTENED EXPT NEW; TYLER ME, 2006, GOOGLE ANAL; Ulwick A., 2005, WHAT CUSTOMERS WANT; USBORNE N, 2005, DESIGN CHOICES CRIPP; van Belle G., 2002, STAT RULES THUMB; VARIAN HR, 2007, NY TIMES        0208; Weiss C, 1997, EVALUATION METHODS S; WEISS TR, 2000, SAFECOUNT NET   0928; WHEELER RE, 1975, TECHNOMETRICS, V17, P177, DOI 10.2307/1268349; WHEELER RE, 1974, TECHNOMETRICS, V16, P193, DOI 10.2307/1267939; Willan AR, 2006, STAT ANAL COST EFFEC; *FORR RES, 2005, STAT RET ONL; *WIK, 2007, HAWTH EFF; *WIK, 2008, MULT BAND	58	12	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2009	18	1					140	181		10.1007/s10618-008-0114-1		42	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	387KR	WOS:000261951600005	
J	Wei, L; Keogh, E; Xi, XP; Yoder, M				Wei, Li; Keogh, Eamonn; Xi, Xiaopeng; Yoder, Melissa			Efficiently finding unusual shapes in large image databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Anomaly detection; Shape; Rotation invariance	PLANAR CURVES; REPRESENTATION; OUTLIERS; CONTOUR	Among the visual features of multimedia content, shape is of particular interest because humans can often recognize objects solely on the basis of shape. Over the past three decades, there has been a great deal of research on shape analysis, focusing mostly on shape indexing, clustering, and classification. In this work, we introduce the new problem of finding shape discords, the most unusual shapes in a collection. We motivate the problem by considering the utility of shape discords in diverse domains including zoology, microscopy, anthropology, and medicine. While the brute force search algorithm has quadratic time complexity, we avoid this untenable lethargy by using locality-sensitive hashing to estimate similarity between shapes which enables us to reorder the search more efficiently and thus extract the maximum benefit from an admissible pruning strategy we introduce. An extensive experimental evaluation demonstrates that our approach is empirically linear in time.	[Wei, Li; Keogh, Eamonn; Xi, Xiaopeng] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA; [Yoder, Melissa] Univ Calif Riverside, Dept Entomol, Riverside, CA 92521 USA	Wei, L (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	wli@cs.ucr.edu; eamonn@cs.ucr.edu; xxi@cs.ucr.edu; melissay@ucr.edu					Andre-Jonsson H, 1997, LECT NOTES ARTIF INT, V1263, P211; Angiulli F, 2006, IEEE T KNOWL DATA EN, V18, P145, DOI 10.1109/TKDE.2006.29; Bay SD, 2003, P 9 ACM SIGKDD INT C, P29; Bentley JL, 1997, PROCEEDINGS OF THE EIGHTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P360; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; Castrejon-Pita AA, 2005, J MATH BIOL, V50, P584, DOI 10.1007/s00285-004-0302-6; Chen DC, 2003, J MOL DIAGN, V5, P243, DOI 10.1016/S1525-1578(10)60481-3; Chiu B., 2003, P 9 ACM SIGKDD INT C, P493; Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671; CLARK JT, 2002, P VAST EUR AR; Davies E.R., 1997, MACHINE VISION THEOR, P171; Daw CS, 2003, REV SCI INSTRUM, V74, P915, DOI 10.1063/1.1531823; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; Ghoting A., 2006, P 6 SIAM INT C DAT M, P608; Grass J., 1996, SIGART Bulletin, V7; Huang YW, 1999, P 5 INT C KNOWL DISC, P282, DOI 10.1145/312129.318357; INDYK P., 1997, P 29 ANN ACM S THEOR, P618, DOI 10.1145/258533.258656; Jalba AC, 2005, MACH VISION APPL, V16, P217, DOI 10.1007/s00138-005-0175-8; Jolliffe I. T., 2002, PRINCIPLE COMPONENT; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Keogh E., 2006, P 32 INT C VER LARG, P882; KEOGH E, 2001, THESIS U CALIFORNIA; Keogh E., 2001, J KNOWL INF SYST, V3, P263; Keogh E., 2002, P 8 ACM SIGKDD INT C, P550; Keogh E., 2005, P 5 IEEE INT C DAT M, P226; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; KITAGUCHI S, 2004, P 18 ANN C JAP SOC A; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; LATECKI LJ, 1999, P 3 INT C VIS INF SY, P617; LEE DJ, 2004, P SPIE OPTICS E 2 3, V5606; Lin J., 2003, P 8 ACM SIGMOD WORKS, P2; Lin JJ, 2004, PARKINSONISM RELAT D, V10, P469, DOI 10.1016/j.parkreldis.2004.06.001; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mollineda RA, 2002, INT J PATTERN RECOGN, V16, P291, DOI 10.1142/S0218001402001678; NARAYANAN M, 2004, P 4 WORKSH ALG BIO W, P74; O'Brien MJ, 2001, J ARCHAEOL SCI, V28, P1115, DOI 10.1006/jasc.2001.0681; PHILIP JW, 2006, COMMUNICATION; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; ROMBO S, 2004, P 6 INT C FLEX QUER, P84; Shahabi C., 2000, Proceedings. 12th International Conference on Scientific and Statistica Database Management, DOI 10.1109/SSDM.2000.869778; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; SODERKVIST OJO, 2001, THESIS LINKOPING U S; TANAKA Y, 2004, P 18 ANN C JAP SOC A; Tao Y., 2006, P 12 ACM SIGKDD INT, P394, DOI 10.1145/1150402.1150447; TOMPA M., 2001, P 5 INT C COMP MOL B, P67; VANOTTERLOO PJ, 1991, CONTOUR ORIENTED APP, P90; Vlachos M., 2005, P ACM C INF KNOWL MA, P131, DOI 10.1145/1099554.1099580; Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604; Yankov D., 2005, P 17 IEEE INT C TOOL, P159; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008; Zimmerman E, 2000, GENETICS, V155, P671	54	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2008	17	3					343	376		10.1007/s10618-008-0094-1		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	360NW	WOS:000260065200001	
J	Chundi, P; Rosenkrantz, DJ				Chundi, Parvathi; Rosenkrantz, Daniel J.			Efficient algorithms for segmentation of item-set time series	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Item-set time series; Measure function; Segment difference; Segmentation algorithms; Optimal segmentation		We propose a special type of time series, which we call an item-set time series, to facilitate the temporal analysis of software version histories, email logs, stock market data, etc. In an item-set time series, each observed data value is a set of discrete items. We formalize the concept of an item-set time series and present efficient algorithms for segmenting a given item-set time series. Segmentation of a time series partitions the time series into a sequence of segments where each segment is constructed by combining consecutive time points of the time series. Each segment is associated with an item set that is computed from the item sets of the time points in that segment, using a function which we call a measure function. We then define a concept called the segment difference, which measures the difference between the item set of a segment and the item sets of the time points in that segment. The segment difference values are required to construct an optimal segmentation of the time series. We describe novel and efficient algorithms to compute segment difference values for each of the measure functions described in the paper. We outline a dynamic programming based scheme to construct an optimal segmentation of the given item-set time series. We use the item-set time series segmentation techniques to analyze the temporal content of three different data sets-Enron email, stock market data, and a synthetic data set. The experimental results show that an optimal segmentation of item-set time series data captures much more temporal content than a segmentation constructed based on the number of time points in each segment, without examining the item set data at the time points, and can be used to analyze different types of temporal data.	[Chundi, Parvathi] Univ Nebraska, Dept Comp Sci, Omaha, NE 68106 USA; [Rosenkrantz, Daniel J.] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA	Chundi, P (reprint author), Univ Nebraska, Dept Comp Sci, Omaha, NE 68106 USA.	pchundi@mail.unomaha.edu; djr@cs.albany.edu			NSF [IIS-0534616]; National Center for Research Resources (NCRR) [P20 RR16469]; National Institutes of Health (NIH)	P. Chundi's work was supported in part by NSF Grant IIS-0534616 and by Grant Number P20 RR16469 from the National Center for Research Resources (NCRR), a component of the National Institutes of Health (NIH).	BELLMAN R, 1961, COMMUN ACM, V4, P384; CHUNDI P, 2008, ENCY DATA W IN PRESS; CHUNDI P, 2004, P 4 SIAM INT C DAT M; CHUNDI P, 2005, P 16 INT C DAT EXP S; Chundi P, 2006, DATA MIN KNOWL DISC, V13, P41, DOI 10.1007/s10618-005-0035-1; CHUNDI P, 2004, P 13 ACM C INF KNOWL; CHUNG KKS, 2005, P 2 INT C KNOWL MAN; COHEN P, 2001, LNCS, V2189; DAS G, 1998, P 4 INT C KNOWL DISC; DIESNER J, 2005, 2005 WORKSH LINK AN; FLANAGAN JA, 2002, P 2 IEEE INT C DAT M; Gaber MM, 2005, SIGMOD RECORD, V34, P18, DOI 10.1145/1083784.1083789; GE X, 1999, P 22 INT C RES DEV I; GIONIS A, 2003, P 7 INT C RES COMP M; GIONIS A, 2005, TUT 5 SIAM INT C DAT; GWADERA R, 2006, P 6 INT C DAT MIN; HIMBER J, 2001, P 1 IEEE INT C DAT M; Kehagias A, 1997, NEURAL COMPUT, V9, P1691, DOI 10.1162/neco.1997.9.8.1691; KEOGH E, 2001, P 1 IEEE INT C DAT M; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; KEOGH E, 1998, P 4 ACM INT C KNOWL; Lin J., 2003, P 8 ACM SIGMOD WORKS; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; PATHAK N, 2006, P 6 IEEE INT C DAT M; PERLMANE E, 2003, ASP C SERIES, V295; SHETTY J, 2005, WORKSH LINK DISC ISS; SIY H, 2007, P 23 IEEE INT C SOFT; SIY H, 2008, J SOFTW EVO IN PRESS; Yang Yiming, 2004, 1 C EM ANT CEAS; *ENR, 2005, ENR EM CORP	30	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2008	17	3					377	401		10.1007/s10618-008-0095-0		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	360NW	WOS:000260065200002	
J	Baluja, S; Covell, M				Baluja, Shumeet; Covell, Michele			Learning to hash: forgiving hash functions and applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Hashing; Audio matching; Machine learning; Locality sensitive hashing		The problem of efficiently finding similar items in a large corpus of high-dimensional data points arises in many real-world tasks, such as music, image, and video retrieval. Beyond the scaling difficulties that arise with lookups in large data sets, the complexity in these domains is exacerbated by an imprecise definition of similarity. In this paper, we describe a method to learn a similarity function from only weakly labeled positive examples. Once learned, this similarity function is used as the basis of a hash function to severely constrain the number of points considered for each lookup. Tested on a large real-world audio dataset, only a tiny fraction of the points (similar to 0.27%) are ever considered for each lookup. To increase efficiency, no comparisons in the original high-dimensional space of points are required. The performance far surpasses, in terms of both efficiency and accuracy, a state-of-the-art Locality-Sensitive-Hashing-based (LSH) technique for the same problem and data set.	[Baluja, Shumeet; Covell, Michele] Google Inc, Mountain View, CA 94043 USA	Baluja, S (reprint author), Google Inc, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.	shumeet@google.com; covell@google.com					AUCOUTURIER J, 2002, P 3 INT C MUS INF RE; BALUJA S, 2006, 3 EUR C VIS MED PROD, P198; BALUJA S, 2007, INT JOINT C ART INT; Baluja S, 2007, PATTERN ANAL APPL, V10, P247, DOI 10.1007/s10044-006-0059-1; BARHILLEL A, 2003, P 12 INT C MACH LEAR; Brieman L, 1996, MACH LEARN, V24, P123; Burges CJC, 2003, IEEE T SPEECH AUDI P, V11, P165, DOI 10.1109/TSA.2003.811538; Bylander T., 2006, P 19 INT FLOR ART IN, P544; Caruana R, 1996, ADV NEUR IN, V8, P959; Chaudhuri S, 2003, P ACM SIGMOD INT C M, P313; Cohen E, 2001, IEEE T KNOWL DATA EN, V13, P64, DOI 10.1109/69.908981; COVELL M, 2007, P INT C AC SPEECH SI; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Haitsma J., 2002, P INT C MUS INF RETR; HASTIE T, 1996, DISCRIMINANT ADAPTIV, P18; JACOBS C, 1995, P SIGGRAPH; Ke Y, 2005, PROC CVPR IEEE, P597; Pampalk E., 2006, THESIS VIENNA U TECH; SHAKHNAROVICH G, 2003, P INT C COMP VIS; TIEU K, 2000, P COMP VIS PATT REC; TSANG IW, 2005, P 2005 IEEE INT JOIN, V2, P954, DOI 10.1109/IJCNN.2005.1555981; Viola P., 2001, P IEEE WORKSH STAT C; WU J, 2003, ADV NEURAL INF PROCE, V16; ZHANG L, 2002, IEEE WORKSH APPL COM	25	9	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2008	17	3					402	430		10.1007/s10618-008-0096-z		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	360NW	WOS:000260065200003	
J	Corander, J; Ekdahl, M; Koski, T				Corander, Jukka; Ekdahl, Magnus; Koski, Timo			Parallell interacting MCMC for learning of topologies of graphical models	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						MCMC; Equivalence search; Learning graphical models	CHAIN MONTE-CARLO; MARKOV EQUIVALENCE CLASSES; EFFICIENT ESTIMATION; BAYESIAN NETWORKS; ACYCLIC DIGRAPHS; SELECTION	Automated statistical learning of graphical models from data has attained a considerable degree of interest in the machine learning and related literature. Many authors have discussed and/or demonstrated the need for consistent stochastic search methods that would not be as prone to yield locally optimal model structures as simple greedy methods. However, at the same time most of the stochastic search methods are based on a standard Metropolis-Hastings theory that necessitates the use of relatively simple random proposals and prevents the utilization of intelligent and efficient search operators. Here we derive an algorithm for learning topologies of graphical models from samples of a finite set of discrete variables by utilizing and further enhancing a recently introduced theory for non-reversible parallel interacting Markov chain Monte Carlo-style computation. In particular, we illustrate how the non-reversible approach allows for novel type of creativity in the design of search operators. Also, the parallel aspect of our method illustrates well the advantages of the adaptive nature of search operators to avoid trapping states in the vicinity of locally optimal network topologies.	[Corander, Jukka] Abo Akad Univ, Dept Math, SF-20500 Turku, Finland; [Ekdahl, Magnus] Linkoping Univ, Dept Math, S-58183 Linkoping, Sweden; [Koski, Timo] Royal Inst Technol, Dept Math, S-10044 Stockholm, Sweden	Corander, J (reprint author), Abo Akad Univ, Dept Math, SF-20500 Turku, Finland.	jukka.corander@abo.fi			Swedish Research Council [4042/401, 621-2004-4214, VR/NT621-2004-4214]; EU [QLK3-CT-2002-02097]; Academy of Finland [121301]	The work of M. E. and T. K. was partially supported by Swedish Research Council, Grants 4042/401 and 621-2004-4214, and EU 6th Programme Grant QLK3-CT-2002-02097 (BACDIV-ERS). The work of J.C. was supported by the Grant 121301 from Academy of Finland and the Swedish research council VR/NT621-2004-4214.	Andersson SA, 2001, SCAND J STAT, V28, P33, DOI 10.1111/1467-9469.00224; Andersson SA, 1997, ANN STAT, V25, P505; Andersson SA, 1996, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P40; Chickering D. M, 2002, J MACHINE LEARNING R, V3, p[507, 524]; Chickering D. M., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995); Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Corander J, 2006, STAT COMPUT, V16, P355, DOI 10.1007/s11222-006-9391-y; Corander J, 2003, J MULTIVARIATE ANAL, V85, P253, DOI 10.1016/S0047-259X(02)00033-7; Cowell R. G., 1999, PROBABILISTIC NETWOR; DAWID AP, 1993, ANN STAT, V21, P1272, DOI 10.1214/aos/1176349260; DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1; Dellaportas P, 1999, BIOMETRIKA, V86, P615, DOI 10.1093/biomet/86.3.615; Durrett R., 1996, PROBABILITY THEORY E; FRYDENBERG M, 1990, SCAND J STAT, V17, P333; FRYDENBERG M, 1989, BIOMETRIKA, V76, P539, DOI 10.1093/biomet/76.3.539; GEYER CJ, 1995, J AM STAT ASSOC, V90, P909, DOI 10.2307/2291325; GILLISPIE S, 2001, UNCERTAINTY ARTIFICI, P171; Giudici P, 1999, BIOMETRIKA, V86, P785, DOI 10.1093/biomet/86.4.785; Giudici P, 2003, MACH LEARN, V50, P127, DOI 10.1023/A:1020202028934; Isaacson D., 1976, MARKOV CHAINS THEORY; Janzura M, 2006, INT J INTELL SYST, V21, P335, DOI 10.1002/int.20138; Jones B, 2005, STAT SCI, V20, P388, DOI 10.1214/088342305000000304; Jordan M., 1998, LEARNING GRAPHICAL M; Koivisto M, 2004, J MACH LEARN RES, V5, P549; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; Madigan D, 1996, COMMUN STAT THEORY, V25, P2493, DOI 10.1080/03610929608831853; PENA JM, 2007, P 11 INT C ART INT, P352; POLI I, 1998, J ITALIAN STAT SOC, V2, P197; RIGGELSEN C, 2005, MCMC LEARNING BAYESI; Robert C., 2004, MONTE CARLO STAT MET; Roverato A, 2006, J MACH LEARN RES, V7, P1045; SANGUESA R, 1997, AI COMMUN, V4, P1; Scheines R., 1993, CAUSATION PREDICTION; Studeny M, 1998, P 14 C UNC ART INT U, P496; SUNDBERG R, 1975, SCAND J STAT, V2, P771; SUZUKI J, 1996, INT C MAH LEARN, P462; Suzuki J, 2006, IEEE T INFORM THEORY, V52, P4767, DOI 10.1109/TIT.2006.883611; van Laarhoven P., 1987, SIMULATED ANNEALING; VERMA E, 1990, UNCERTAINTY ARTIFICI, P220; Volf M, 1999, INT J APPROX REASON, V20, P209, DOI 10.1016/S0888-613X(99)00003-1; Wedelin D, 1996, STAT COMPUT, V6, P313, DOI 10.1007/BF00143552; Whittaker J., 1990, GRAPHICAL MODELS APP; Wong F, 2003, BIOMETRIKA, V90, P809, DOI 10.1093/biomet/90.4.809	45	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2008	17	3					431	456		10.1007/s10618-008-0099-9		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	360NW	WOS:000260065200004	
J	Chaoji, V; Al Hasan, M; Salem, S; Zaki, MJ				Chaoji, Vineet; Al Hasan, Mohammad; Salem, Saeed; Zaki, Mohammed J.			An integrated, generic approach to pattern mining: data mining template library	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Frequent pattern mining; Itemset mining; Sequence mining; Tree mining; Graph mining; Generic programming	EFFICIENT ALGORITHM; FREQUENT; TREES	Frequent pattern mining (FPM) is an important data mining paradigm to extract informative patterns like itemsets, sequences, trees, and graphs. However, no practical framework for integrating the FPM tasks has been attempted. In this paper, we describe the design and implementation of the Data Mining Template Library (DMTL) for FPM. DMTL utilizes a generic data mining approach, where all aspects of mining are controlled via a set of properties. It uses a novel pattern property hierarchy to define and mine different pattern types. This property hierarchy can be thought of as a systematic characterization of the pattern space, i.e., a meta-pattern specification that allows the analyst to specify new pattern types, by extending this hierarchy. Furthermore, in DMTL all aspects of mining are controlled by a set of different mining properties. For example, the kind of mining approach to use, the kind of data types and formats to mine over, the kind of back-end storage manager to use, are all specified as a list of properties. This provides tremendous flexibility to customize the toolkit for various applications. Flexibility of the toolkit is exemplified by the ease with which support for a new pattern can be added. Experiments on synthetic and public dataset are conducted to demonstrate the scalability provided by the persistent back-end in the library. DMTL been publicly released as open-source software (http://dmtl.sourceforge.net/), and has been downloaded by numerous researchers from all over the world.	[Chaoji, Vineet; Al Hasan, Mohammad; Salem, Saeed; Zaki, Mohammed J.] Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Zaki, MJ (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.	chaojv@cs.rpi.edu; alhasan@cs.rpi.edu; salems@cs.rpi.edu; zaki@cs.rpi.edu					AGRAWAL R, 1993, ACM SIGMOD C MAN DAT; Agrawal R., 1995, 11 INT C DAT ENG; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Antunes C., 2004, 2 INT WORKSH MIN GRA; ASAI T, 2003, 6 INT C DISC SCI; ASAI T, 2002, 2 SIAM INT C DAT MIN; AYRES J, 2002, ACM SIGKDD INT C KNO; BALCAZAR JL, 2005, 10 INT C DAT THEOR; Bayardo R.J., 1998, SIGMOD, P85; Brin Sergey, 1997, ACM SIGMOD C MAN DAT; BUEHRER G, 2006, ACM SIGKDD INT C KNO; BURDICK D, 2001, 17 INT C DAT ENG; BURDICK D, 2001, IEEE INT C DAT ENG; CHI Y, 2003, 3 IEEE INT C DAT MIN; Chi Y., 2004, 8 PAC AS C KNOWL DIS; CHI Y, 2004, 16 INT C SCI STAT DA; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; DEHASPE L, 1998, 4 ACM SIGKDD INT C K; Ganter B., 1999, FORMAL CONCEPT ANAL; GAROFALAKIS M, 1999, 25 INT C VER LARG DA; GHOTING A, 2005, 31 INT C VER LARG DA; Goethals B, 2004, SIGKDD EXPLORATIONS, V6, P109; Gouda K, 2003, 9 ACM SIGKDD INT C K, P326; GSCHWIND T, 2001, 6 USENIX C OBJ OR TE; HAN J, 2000, ACM SIGMOD C MAN DAT; HASAN MA, 2005, 1 WORKSH LIB CENTR S; HORVATH T, 2006, 12 ACM SIGKDD INT C; HUAN J, 2003, IEEE INT C DAT MIN; HUAN J, 2003, TR03021 U N CAR; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; INOKUCHI A, 2000, 4 EUR C PRINC KNOWL; KRAMER S, 2001, ACM SIGKDD INT C KNO; Kuramochi M, 2004, IEEE T KNOWL DATA EN, V16, P1038, DOI 10.1109/TKDE.2004.33; Mannila H., 1996, 2 INT C KNOWL DISC D; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Mannila H., 1995, 1 INT C KNOWL DISC D; NIJSSEN S, 2003, 1 INT WORKSH MIN GRA; NIJSSEN S, 2004, ACM SIGKDD INT C KNO; OATES T, 1997, 6 INT WORKSH AI STAT; PASQUIER N, 1999, 7 INT C DAT THEOR; PEI J, 2001, IEEE INT C DAT ENG; Saini A., 2001, STL TUTORIAL REFEREN; Savasere A., 1995, 21 INT C VER LARG DA; SHASHA D, 2004, IEEE INT C DAT ENG; Sick JG, 2002, BOOST GRAPH LIB; Srikant R, 1996, 5 INT C EXT DAT TECH; TERMIER A, 2002, IEEE INT C DAT MIN; TERMIER A, 2004, IEEE INT C DAT MIN; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; WANG C, 2004, PAC AS C KNOWL DISC; WANG J, 2004, IEEE INT C DAT ENG; WANG J, 2003, ACM SIGKDD INT C KNO; WANG K, 1998, ACM SIGIR INT C INF; Witten I.H., 1999, DATA MINING PRACTICA; XIAO Y, 2003, IEEE INT C DAT MIN; Yan X., 2002, UIUCDCSR20022296; Yan X, 2002, IEEE INT C DAT MIN; YAN X, 2003, ACM SIGKDD INT C KNO; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A; Zaki M. J., 2002, 2 SIAM INT C DAT MIN; Zaki M. J., 1997, 3 INT C KNOWL DISC D; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315; Zaki MJ, 2005, IEEE T KNOWL DATA EN, V17, P1021, DOI 10.1109/TKDE.2005.125; ZAKI MJ, 2000, 9 INT C INF KNOWL MA; Zaki MJ, 2005, FUND INFORM, V66, P33; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291; Zaki MJ, 2005, IEEE T KNOWL DATA EN, V17, P462, DOI 10.1109/TKDE.2005.60; ZAKI MJ, 2004, INT C FORM CONC AN; ZOU B, 2006, PAC AS C KNOWL DISC	69	4	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2008	17	3					457	495		10.1007/s10618-008-0098-x		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	360NW	WOS:000260065200005	
J	Weiss, GM; Zadrozny, B; Saar-Tsechansky, M				Weiss, Gary M.; Zadrozny, Bianca; Saar-Tsechansky, Maytal			Guest editorial: special issue on utility-based data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Weiss, Gary M.] Fordham Univ, Dept Comp & Informat Sci, Bronx, NY 10458 USA; [Zadrozny, Bianca] Univ Fed Fluminense, Dept Comp Sci, Niteroi, RJ, Brazil; [Saar-Tsechansky, Maytal] Univ Texas Austin, McCombs Sch Business, Dept Informat Risk & Operat Management, Austin, TX 78712 USA	Weiss, GM (reprint author), Fordham Univ, Dept Comp & Informat Sci, Bronx, NY 10458 USA.	gweiss@cis.fordham.edu; bianca@ic.uff.br; maytal@mail.utexas.edu					BRYDON M, 2008, DATA MIN KNOWL DISCO, V17; CHAWLA NV, 2008, DATA MIN KNOWL DISCO, V17; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; FAWCETT T, 2008, DATA MIN KNOWL DISCO, V17; FORMAN G, 2008, DATA MIN KNOWL DISCO, V17; MELVILLE P, 2005, P 16 EUR C MACH LEAR; ROKACH L, 2008, DATA MIN KNOWL DISCO, V17; Saarela MH, 2007, AGRO FOOD IND HI TEC, V18, P19; Saar-Tsechansky M, 2004, MACH LEARN, V54, P153, DOI 10.1023/B:MACH.0000011806.12374.c3; SEN P, 2008, DATA MIN KNOWL DISCO, V17; Shen Y., 2002, P 2002 IEEE INT C DA, P426; WEISS GM, 2005, P 1 INT WORKSH UT BA; WEISS GM, 2008, DATA MIN KNOWL DISCO, V17; Yao H, 2006, DATA KNOWL ENG, V59, P603, DOI 10.1016/j.datak.2005.10.004; Zadrozny B., 2006, P 2 INT WORKSH UT BA	15	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2008	17	2					129	135		10.1007/s10618-008-0117-y		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	339TZ	WOS:000258601500001	
J	Sen, P; Getoor, L				Sen, Prithviraj; Getoor, Lise			Cost-sensitive learning with conditional Markov networks	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						cost-sensitive learning; machine learning; Markov networks; structured output spaces	GENERALIZED BELIEF PROPAGATION	There has been a recent, growing interest in classification and link prediction in structured domains. Methods such as conditional random fields and relational Markov networks support flexible mechanisms for modeling correlations due to the link structure. In addition, in many structured domains, there is an interesting structure in the risk or cost function associated with different misclassifications. There is a rich tradition of cost-sensitive learning applied to unstructured (IID) data. Here we propose a general framework which can capture correlations in the link structure and handle structured cost functions. We present two new cost-sensitive structured classifiers based on maximum entropy principles. The first determines the cost-sensitive classification by minimizing the expected cost of misclassification. The second directly determines the cost-sensitive classification without going through a probability estimation step. We contrast these approaches with an approach which employs a standard 0/1-loss structured classifier to estimate class conditional probabilities followed by minimization of the expected cost of misclassification and with a cost-sensitive IID classifier that does not utilize the correlations present in the link structure. We demonstrate the utility of our cost-sensitive structured classifiers with experiments on both synthetic and real-world data.	[Sen, Prithviraj; Getoor, Lise] Univ Maryland, Dept Comp Sci, College Pk, MD 20783 USA	Sen, P (reprint author), Univ Maryland, Dept Comp Sci, College Pk, MD 20783 USA.	sen@cs.umd.edu; getoor@cs.umd.edu					ABE N, 2004, ACM SIGKDD INT C KNO, P3; Berrou C., 1993, P IEEE INT C COMM IC, V2, P1064, DOI 10.1109/ICC.1993.397441; BESAG J, 1986, J ROY STAT SOC B MET, V48, P259; BODIK P, 2004, INTEL LAB DATASET; Bollobas B, 2003, SIAM PROC S, P132; Bradford J. P., 1998, P 10 EUR C MACH LEAR, P131; BREFELD U, 2003, P 14 EUR C MACH LEAR, P23; Chakrabarti S., 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Cohn D, 2001, ADV NEUR IN, V13, P430; Deshpande A, 2005, PROC INT CONF DATA, P143; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Duda R.O., 2001, PATTERN CLASSIFICATI; Elkan C, 2001, P 17 INT JOINT C ART, P973; FUMERA G, 2002, CONVEGNO ASS ITALIAN; GEIBEL P, 2003, P 20 INT C MACH LEAR, P218; Getoor L., 2002, J MACHINE LEARNING R, V3, P679; JAYNES ET, 2003, ET JAYNES PAPERS PRO; KNOLL U., 1994, P 8 EUR C MACH LEARN, P383; Kschischang FR, 1998, IEEE J SEL AREA COMM, V16, P219, DOI 10.1109/49.661110; Lafferty J, 2001, P 18 INT C MACH LEAR, P282; Lu Q., 2003, P 20 INT C MACH LEAR, P496; McEliece RJ, 1998, IEEE J SEL AREA COMM, V16, P140, DOI 10.1109/49.661103; Minka T. P., 2001, P 17 C UNC ART INT, P362; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Neville J., 2000, AAAI WORKSH LEARN ST, P13; SEN P, 2006, P 23 INT C MACH LEAR, P801, DOI 10.1145/1143844.1143945; Singhvi V., 2005, P 3 INT C EMB NETW S, P218, DOI 10.1145/1098918.1098942; SLATTERY S., 1998, P 8 INT C IND LOG PR, P38; Taskar B., 2004, P 21 INT C MACH LEAR, P807; Taskar B, 2004, ADV NEUR IN, V16, P25; Tasker B., 2002, P 18 C UNC ART INT U, P485; TSOCHANTARIDIS I, 2004, P 21 INT C MACH LEAR, P823; Xu L., 2006, P 23 INT C MACH LEAR, P1057, DOI 10.1145/1143844.1143977; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085; Yedidia JS, 2001, ADV NEUR IN, V13, P689; Zadrozny B., 2003, P 3 IEEE INT C DAT M, P435; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	39	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2008	17	2					136	163		10.1007/s10618-008-0090-5		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	339TZ	WOS:000258601500002	
J	Forman, G				Forman, George			Quantifying counts and costs via classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						supervised machine learning; classification; prevalence estimation; class distribution estimation; quantification research methodology; detecting and tracking trends; concept drift; class imbalance; text mining	PROBABILITIES	Many business applications track changes over time, for example, measuring the monthly prevalence of influenza incidents. In situations where a classifier is needed to identify the relevant incidents, imperfect classification accuracy can cause substantial bias in estimating class prevalence. The paper defines two research challenges for machine learning. The 'quantification' task is to accurately estimate the number of positive cases (or class distribution) in a test set, using a training set that may have a substantially different distribution. The 'cost quantification' variant estimates the total cost associated with the positive class, where each case is tagged with a cost attribute, such as the expense to resolve the case. Quantification has a very different utility model from traditional classification research. For both forms of quantification, the paper describes a variety of methods and evaluates them with a suitable methodology, revealing which methods give reliable estimates when training data is scarce, the testing class distribution differs widely from training, and the positive class is rare, e.g., 1% positives. These strengths can make quantification practical for business use, even where classification accuracy is poor.	Hewlett Packard Labs, Palo Alto, CA USA	Forman, G (reprint author), Hewlett Packard Labs, Palo Alto, CA USA.	ghforman@hpl.hp.com					Fawcett T, 2005, MACH LEARN, V58, P33, DOI 10.1007/s10994-005-5256-4; FAWCETT T, 2003, TRHPL20034; FORMAN G, 2006, P 12 ACM SIGKDD INT, P852, DOI 10.1145/1150402.1150520; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Forman G., 2006, PRINCIPLES PRACTICE, P157, DOI 10.1145/1150402.1150423; FORMAN G, 2005, P 16 EUR C MACH LEAR, P564; GHANI R, 2000, P 17 INT C MACH LEAR, P303; Han E.-H., 2000, PRINCIPLES DATA MINI, P424; Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848; Hulten G., 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; Lachiche N., 2003, P 20 INT C MACH LEAR, P416; MacKenzie DI, 2002, ECOLOGY, V83, P2248, DOI 10.2307/3072056; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Saerens M, 2002, NEURAL COMPUT, V14, P21, DOI 10.1162/089976602753284446; Seber G. A. F., 1982, ESTIMATION ANIMAL AB; Turney P.D., 2000, WORKSH COST SENS LEA; VALENSTEIN PN, 1990, AM J CLIN PATHOL, V93, P252; Van Hulse J, 2007, P 24 INT C MACH LEAR, P935, DOI 10.1145/1273496.1273614; Vucetic S., 2001, P 12 EUR C MACH LEAR, P527; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Witten IH, 2005, DATA MINING PRACTICA; Wu G, 2005, IEEE T KNOWL DATA EN, V17, P786, DOI 10.1109/TKDE.2005.95; Zhou X.H., 2002, STAT METHODS DIAGNOS	23	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2008	17	2					164	206		10.1007/s10618-008-0097-y		43	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	339TZ	WOS:000258601500003	
J	Fawcett, T				Fawcett, Tom			PRIE: a system for generating rulelists to maximize ROC performance	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						classification; ROC analysis; rule learning; cost-sensitive learning	ALGORITHMS; CURVE; AREA	Rules are commonly used for classification because they are modular, intelligible and easy to learn. Existing work in classification rule learning assumes the goal is to produce categorical classifications to maximize classification accuracy. Recent work in machine learning has pointed out the limitations of classification accuracy: when class distributions are skewed, or error costs are unequal, an accuracy maximizing classifier can perform poorly. This paper presents a method for learning rules directly from ROC space when the goal is to maximize the area under the ROC curve (AUC). Basic principles from rule learning and computational geometry are used to focus the search for promising rule combinations. The result is a system that can learn intelligible rulelists with good ROC performance.	Stanford Univ, Ctr Study Language & Informat, Stanford, CA 94305 USA	Fawcett, T (reprint author), Stanford Univ, Ctr Study Language & Informat, Stanford, CA 94305 USA.	tfawcett@acm.org					BARAKAT N, 2006, ICPR 2006, V2, P812; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; CLARK P, 1991, LECT NOTES ARTIF INT, V482, P151; COHEN WW, 1996, AAAI IAAI, V1, P709; EGAN JP, 2001, P IEEE INT C DAT MIN, P131; Fawcett T., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989510; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P882, DOI 10.1016/j.patrec.2005.10.012; FLACH P, 2004, ICML04; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Furnkranz J, 2005, MACH LEARN, V58, P39, DOI 10.1007/s10994-005-5011-x; HANLEY JA, 1982, RADIOLOGY, V143, P29; Ling CX, 2003, LECT NOTES ARTIF INT, V2671, P329; Niculescu-Mizil A., 2005, P 22 INT C MACH LEAR, P625, DOI 10.1145/1102351.1102430; PRATI RC, 2005, IJCAI, P823; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; PROVOST F, 2001, IS0004 CEDER; SANTINI S, 1995, NEURAL NETWORKS, V8, P25, DOI 10.1016/0893-6080(94)00059-U; Srinivasan A., 1999, PRGTR299 OXF U COMP; Swets JA, 2000, SCI AM, V283, P82; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609	24	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2008	17	2					207	224		10.1007/s10618-008-0089-y		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	339TZ	WOS:000258601500004	
J	Chawla, NV; Cieslak, DA; Hall, LO; Joshi, A				Chawla, Nitesh V.; Cieslak, David A.; Hall, Lawrence O.; Joshi, Ajay			Automatically countering imbalance and its empirical relationship to cost	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						classification; unbalanced data; cost-sensitive learning	TREE INDUCTION	Learning from imbalanced data sets presents a convoluted problem both from the modeling and cost standpoints. In particular, when a class is of great interest but occurs relatively rarely such as in cases of fraud, instances of disease, and regions of interest in large-scale simulations, there is a correspondingly high cost for the misclassification of rare events. Under such circumstances, the data set is often re-sampled to generate models with high minority class accuracy. However, the sampling methods face a common, but important, criticism: how to automatically discover the proper amount and type of sampling? To address this problem, we propose a wrapper paradigm that discovers the amount of re-sampling for a data set based on optimizing evaluation functions like the f-measure, Area Under the ROC Curve (AUROC), cost, cost-curves, and the cost dependent f-measure. Our analysis of the wrapper is twofold. First, we report the interaction between different evaluation and wrapper optimization functions. Second, we present a set of results in a cost- sensitive environment, including scenarios of unknown or changing cost matrices. We also compared the performance of the wrapper approach versus cost-sensitive learning methods-MetaCost and the Cost-Sensitive Classifiers-and found the wrapper to outperform the cost-sensitive classifiers in a cost-sensitive environment. Lastly, we obtained the lowest cost per test example compared to any result we are aware of for the KDD-99 Cup intrusion detection data set.	[Chawla, Nitesh V.; Cieslak, David A.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA; [Hall, Lawrence O.; Joshi, Ajay] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	Chawla, NV (reprint author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.	nchawla@cse.nd.edu; dcieslak@cse.nd.edu; hall@cse.usf.edu; ajoshi@cse.usf.edu			Arthur J. Schmitt Fellowship	We are grateful to Robert Holte for providing the Cost Curves software and Oil data set. David Cieslak was partially supported by the the Arthur J. Schmitt Fellowship. We are very thankful to the reviewers and the guest editors for their helpful comments.	Amor N.B, 2004, P 2004 ACM S APPL CO, P420, DOI 10.1145/967900.967989; BANFIELD RE, 2005, P 6 INT C MULT CLASS, P196; Batista G. E., 2004, SIGKDD EXPLORATIONS, V6, P20, DOI DOI 10.1145/1007730.1007735; Blake C, 1998, UCI REPOSITORY MACHI; BOWYER KW, 2000, P IEEE INT C SYST MA; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; CHAWLA NV, 2005, KDD WORKSH UT BAS DA; Chawla NV, 2004, SIGKDD EXPLORATIONS, V6, P1; Chawla NV, 2003, P ICML 2003 WORKSH L; CIESLAK D, 2006, 200612 TR U NOTR DEP; Cohen W, 1995, 12 INT C MACH LEARN, P115; COHEN WW, 1995, 5 INT WORKSH IND LOG, P3; DIETTERICH T, 2000, P ICML 2000 WORKSH C; Domingos P., 1999, KNOWLEDGE DISCOVERY, P155; Drummond C, 2003, P ICML 03 WORKSH LEA; Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5; Dumais S, 1998, 7 INT C INF KNOWL MA, P148; Elkan C, 2001, P 17 INT JOINT C ART, P973; ELKAN C, 1999, RESULTS KDD 99 CLASS; ESPOSITO F, 1994, APPL ARTIF INTELL, V8, P33, DOI 10.1080/08839519408945432; FERRI C, 2004, 1 WORKSH ROC AN AI E; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; Lingjaerde O, 1998, ACTA PSYCHIAT SCAND, V98, P73, DOI 10.1111/j.1600-0447.1998.tb10045.x; Maloof M, 2003, P ICML 03 WORKSH LEA; Mladenic D., 1999, ICML 99 P 16 INT C M; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Provost F., 1998, 15 INT C MACH LEARN, P445; Quinlan JR, 1993, PROGRAMS MACHINE LEA; Sabhnani M., 2003, Proceedings of the International Conference on Machine Learning; Models, Technologies and Applications. MLMTA'03; Thain D, 2005, CONCURR COMP-PRACT E, V17, P323, DOI 10.1002/cpe.938; WEISS GM, 2007, DMIN, P35; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Witten IH, 2005, DATA MINING PRACTICA; Woods K. S., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000698; Zadrozny B., 2003, ICDM, P435; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63	40	32	32	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2008	17	2					225	252		10.1007/s10618-008-0087-0		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	339TZ	WOS:000258601500005	
J	Weiss, GM; Tian, Y				Weiss, Gary M.; Tian, Ye			Maximizing classifier utility when there are data acquisition and modeling costs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; machine learning; induction; decision trees; utility-based data mining; cost-sensitive learning; active learning		Classification is a well-studied problem in data mining. Classification performance was originally gauged almost exclusively using predictive accuracy, but as work in the field progressed, more sophisticated measures of classifier utility that better represented the value of the induced knowledge were introduced. Nonetheless, most work still ignored the cost of acquiring training examples, even though this cost impacts the total utility of the data mining process. In this article we analyze the relationship between the number of acquired training examples and the utility of the data mining process and, given the necessary cost information, we determine the number of training examples that yields the optimum overall performance. We then extend this analysis to include the cost of model induction-measured in terms of the CPU time required to generate the model. While our cost model does not take into account all possible costs, our analysis provides some useful insights and a template for future analyses using more sophisticated cost models. Because our analysis is based on experiments that acquire the full set of training examples, it cannot directly be used to find a classifier with optimal or near-optimal total utility. To address this issue we introduce two progressive sampling strategies that are empirically shown to produce classifiers with near-optimal total utility.	[Weiss, Gary M.; Tian, Ye] Fordham Univ, Dept Comp & Informat Sci, Bronx, NY 10458 USA	Weiss, GM (reprint author), Fordham Univ, Dept Comp & Informat Sci, Bronx, NY 10458 USA.	gweiss@cis.fordham.edu					Berry M. J. A., 2004, DATA MINING TECHNIQU; Breiman L., 1983, CLASSIFICATION REGRE; CARUANA R, 2004, SIGKDD EXPLORATIONS, V6, P95; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5; Elkan C, 2001, P 17 INT JOINT C ART, P973; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Fayyad U, 1996, AI MAG, V17, P37; Greiner R, 2002, ARTIF INTELL, V139, P137, DOI 10.1016/S0004-3702(02)00209-6; Hettich S., 1999, UCI KDD ARCH; HOEHN B, 2005, P 20 NAT C ART INT P, P783; KAPOOR A, 2005, P 16 EUR C MACH LEAR, P170; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; Li R. H., 2002, P 8 ACM SIGKDD INT C, P570; MARTIN JK, 1996, P 4 INT S ART INT MA; MELVILLE P, 2005, P 1 INT WORKSH UT BA, P10, DOI 10.1145/1089827.1089828; Newman D.J., 1998, UCI REPOSITORY MACHI; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Snedecor GW, 1989, STAT METHODS; Turney P.D., 2000, WORKSH COST SENS LEA; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; VEERAMACHANENI S, 2003, P IEEE INT C DAT MIN, P665; WEISS GM, 2005, SIGKDD EXPLOR, V17, P145; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Zadrozny B., 2006, SIGKDD EXPLOR NEWSL, V8, P98	27	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2008	17	2					253	282		10.1007/s10618-007-0082-x		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	339TZ	WOS:000258601500006	
J	Rokach, L; Naamani, L; Shmilovici, A				Rokach, Lior; Naamani, Lihi; Shmilovici, Armin			Pessimistic cost-sensitive active learning of decision trees for profit maximizing targeting campaigns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						cost-sensitive learning; reinforcement learning; active learning; direct marketing; decision trees; design of experiments	EXPLOITATION; EXPLORATION; CLASSIFIERS; NETWORKS; TRIALS; MODELS	In business applications such as direct marketing, decision-makers are required to choose the action which best maximizes a utility function. Cost-sensitive learning methods can help them achieve this goal. In this paper, we introduce Pessimistic Active Learning (PAL). PAL employs a novel pessimistic measure, which relies on confidence intervals and is used to balance the exploration/exploitation trade-off. In order to acquire an initial sample of labeled data, PAL applies orthogonal arrays of fractional factorial design. PAL was tested on ten datasets using a decision tree inducer. A comparison of these results to those of other methods indicates PAL's superiority.	[Rokach, Lior; Shmilovici, Armin] Ben Gurion Univ Negev, Dept Informat Syst Engn, IL-84105 Beer Sheva, Israel; [Naamani, Lihi] Ben Gurion Univ Negev, Deutsch Telekom Labs, IL-84105 Beer Sheva, Israel	Rokach, L (reprint author), Ben Gurion Univ Negev, Dept Informat Syst Engn, POB 653, IL-84105 Beer Sheva, Israel.	liorrk@bgu.ac.il; ln@bgu.ac.il; armin@bgu.ac.il	SHMILOVICI, ARMIN/F-2136-2012; Rokach, Lior/F-8247-2010				Blake C, 1998, UCI REPOSITORY MACHI; Buchheit RG, 1998, CORROSION, V54, P61; Cestnik B., 1990, P EUR C ART INT, P147; Clarke P, 2006, J CONSUM MARK, V23, P283, DOI 10.1108/07363760610681673; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domingos P, 2005, IEEE INTELL SYST, V20, P80; FONG PWL, 1995, 12 INT C MACH LEARN, P226; Hedayat A. S., 1999, ORTHOGONAL ARRAYS TH; Hwang JTG, 1997, J AM STAT ASSOC, V92, P748, DOI 10.2307/2965723; Kaelbling L. P., 1993, LEARNING EMBEDDED SY; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Kirkpatrick S, 1983, SCIENCE, P4598; Kyriakopoulos K, 2004, INT J RES MARK, V21, P219, DOI 10.1016/j.ijresmar.2004.01.001; Leemis LM, 1996, AM STAT, V50, P63, DOI 10.2307/2685046; Levin N, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1261, DOI 10.1007/0-387-25465-X_61; Lewis DD, 1994, P 17 ANN INT ACM SIG, P3; Lingjaerde O, 1998, ACTA PSYCHIAT SCAND, V98, P73, DOI 10.1111/j.1600-0447.1998.tb10045.x; MARGINEANTU D, 2005, P 19 INT JOINT C ART; MAYER UF, 2003, P 9 ACM SIGKDD INT C, P717; Montgomery D. C., 1997, DESIGN ANAL EXPT; PEDNAULT E, 2002, P 8 ACM SIGKDD INT C, P259; PERCUS OE, 1984, COMPUT BIOL MED, V14, P127, DOI 10.1016/0010-4825(84)90001-5; PETKAU AJ, 1978, J AM STAT ASSOC, V73, P328, DOI 10.2307/2286661; POTHARST R, 2002, NEURAL NETWORKS BUSI, P89; PUTTEN P, 2000, COIL CHALLENGE 2000; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8; Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247; Rothaermel FT, 2004, STRATEGIC MANAGE J, V25, P201, DOI 10.1002/smj.376; Roy N., 2001, P INT C MACH LEARN; Saar-Tsechansky M, 2004, MACH LEARN, V54, P153, DOI 10.1023/B:MACH.0000011806.12374.c3; Saar-Tsechansky M, 2007, INFORM SYST RES, V18, P4, DOI 10.1287/isre.1070.0111; Schein AI, 2007, MACH LEARN, V68, P235, DOI 10.1007/s10994-007-5019-5; Sloane N.J.A., 2007, LIB ORTHOGONAL ARRAY; Sofroniou N., 2002, Understanding Statistics, V1, DOI 10.1207/S15328031US0101_02; Strehl A., 2005, P 22 INT C MACH LEAR, P856, DOI DOI 10.1145/1102351.1102459; Sutton R. S., 1998, REINFORCEMENT LEARNI; Turney P.D., 2000, WORKSH COST SENS LEA; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; Viaene S, 2001, INT J INTELL SYST, V16, P1023, DOI 10.1002/int.1047; WEISS G, 2008, MAXIMIZING CLASSIFIE; WIERING M, 1998, P 5 INT C SIM AD BEH, P223; YINGHUI Y, 2004, THESIS U PENNSYLVANI; ZADROZNY B, 2005, P WORKSH UT BAS DAT; ZAHAVI J, 1995, J DIRECT MARKET, V9, P7; Zahavi J., 1997, J DIRECT MARKETING, V11, P5, DOI 10.1002/(SICI)1522-7138(199724)11:1<5::AID-DIR2>3.0.CO;2-S	48	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2008	17	2					283	316		10.1007/s10618-008-0105-2		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	339TZ	WOS:000258601500007	
J	Brydon, M; Gemino, A				Brydon, Michael; Gemino, Andrew			Classification trees and decision-analytic feedforward control: a case study from the video game industry	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; probability estimation trees; decision tree analysis; video game development; real options	REAL OPTIONS; WORLD	The objective of this paper is to use a challenging real-world problem to illustrate how a probabilistic predictive model can provide the foundation for decision-analytic feedforward control. Commercial data mining software and sales data from a market research firm are used to create a predictive model of market success in the video game industry. A procedure is then described for transforming the classification trees into a decision-analytic model that can be solved to produce a value-maximizing game development policy. The video game example shows how the compact predictive models created by data mining algorithms can help to make decision-analytic feedforward control feasible, even for large, complex problems. However, the example also highlights the bounds placed on the practicality of the approach due to combinatorial explosions in the number of contingencies that have to be modeled. We show, for example, how the "option value" of sequels creates complexity that is effectively impossible to address using conventional decision analysis tools.	[Brydon, Michael; Gemino, Andrew] Simon Fraser Univ, Fac Business Adm, Burnaby, BC V5A 1S6, Canada	Brydon, M (reprint author), Simon Fraser Univ, Fac Business Adm, Burnaby, BC V5A 1S6, Canada.	mjbrydon@sfu.ca			Natural Science and Engineering Research Council of Canada (NSERC); Social Sciences and Humanities Resource Council of Canada (SSHRC)	The authors thank the Natural Science and Engineering Research Council of Canada (NSERC) and the Social Sciences and Humanities Resource Council of Canada (SSHRC) Initiatives for the New Economy (INE) for financial assistance.	Apte C, 2002, COMMUN ACM, V45, P49; Barry EJ, 2006, MANAGE SCI, V52, P448, DOI 10.1287/mnsc.1050.0463; Boutilier C, 1999, J ARTIF INTELL RES, V11, P1; Breiman L, 1984, CLASSIFICATION REGRE; Brooks RA, 1991, P 12 INT JOINT C ART, P569; Brydon M., 2006, Information Technology & Management, V7, DOI 10.1007/s10799-006-5728-7; CHARNE J, 2006, COMPUT INTERNET LAWY, V23, P27; Clemen R. T., 1996, MAKING HARD DECISION; Copeland T, 2004, HARVARD BUS REV, V82, P90; Davenport TH, 2001, CALIF MANAGE REV, V43, P117; GAUME N, 2006, EUROPEAN MANAGEMENT, V24, P299; Haughton D, 2003, AM STAT, V57, P290, DOI 10.1198/0003130032486; Holloway CA, 1979, DECISION MAKING UNCE; Keeney Ralph L., 1976, DECISIONS MULTIPLE O; Khatri N, 2000, HUM RELAT, V53, P57; KOLODNY L, 2006, GLOBAL VIDEO GAME MA; Lander D., 1998, Q REV EC FINANCE, V38, P537, DOI 10.1016/S1062-9769(99)80089-1; Luehrman TA, 1998, HARVARD BUS REV, V76, P89; McCarthy IP, 2006, J PROD INNOVAT MANAG, V23, P437, DOI 10.1111/j.1540-5885.2006.00215.x; MELVILLE P, 2005, P 1 INT WORKSH UT BA, P10, DOI 10.1145/1089827.1089828; PEDNAULT E, 2002, P 8 ACM SIGKDD INT C; PHAM A, 2007, LOS ANGELES TIM 0924; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Pyle D, 1999, DATA PREPARATION DAT; RAHUL A, 2006, BUS INTELL J, V11, P1; Raiffa H., 1968, DECISION ANAL INTRO; REIMER J, 2005, CROSS PLATFORM GAME; Russell S., 1995, ARTIFICIAL INTELLIGE; SCHOCKEN S, 1993, INFORMATION SYSTEMS, V4, P55, DOI 10.1287/isre.4.1.55; Simon H., 1977, NEW SCI MANAGEMENT D; Smith JE, 1999, OPER RES, V47, P1, DOI 10.1287/opre.47.1.1; Trigeorgis L, 1996, REAL OPTIONS MANAGER; Walfisz Martin, 2006, BUS HORIZONS, V49, P487, DOI 10.1016/j.bushor.2006.04.001; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609; ZHANG K, 2006, P 6 INT C DAT MIN IC, P741	35	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2008	17	2					317	342		10.1007/s10618-007-0086-6		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	339TZ	WOS:000258601500008	
J	Daelemans, W; Goethals, B; Morik, K				Daelemans, Walter; Goethals, Bart; Morik, Katharina			Guest editors' introduction: Special issue of selected papers from ECML PKDD 2008	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									[Goethals, Bart] Univ Antwerp, B-2020 Antwerp, Belgium; [Daelemans, Walter] Univ Antwerp, B-2000 Antwerp, Belgium; [Morik, Katharina] Univ Dortmund, TU Dortmund, D-44221 Dortmund, Germany	Goethals, B (reprint author), Univ Antwerp, Middelheimlaan 1, B-2020 Antwerp, Belgium.	bart.goethals@ua.ac.be						0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2008	17	1					1	2		10.1007/s10618-008-0113-2		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	335KY	WOS:000258290700001	
J	Hintsanen, P; Toivonen, H				Hintsanen, Petteri; Toivonen, Hannu			Finding reliable subgraphs from large probabilistic graphs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	19th European Conference on Machine Learning	SEP   15, 2008-SEP 19, 2009	Antwerp, BELGIUM			link discovery and analysis; graph mining; graph visualization; reliability		Reliable subgraphs can be used, for example, to find and rank nontrivial links between given vertices, to concisely visualize large graphs, or to reduce the size of input for computationally demanding graph algorithms. We propose two new heuristics for solving the most reliable subgraph extraction problem on large, undirected probabilistic graphs. Such a problem is specified by a probabilistic graph G subject to random edge failures, a set of terminal vertices, and an integer K. The objective is to remove K edges from G such that the probability of connecting the terminals in the remaining subgraph is maximized. We provide some technical details and a rough analysis of the proposed algorithms. The practical performance of the methods is evaluated on real probabilistic graphs from the biological domain. The results indicate that the methods scale much better to large input graphs, both computationally and in terms of the quality of the result.	[Hintsanen, Petteri; Toivonen, Hannu] Univ Helsinki, Dept Comp Sci, Helsinki Inst Informat Technol, Helsinki 00014, Finland	Hintsanen, P (reprint author), Univ Helsinki, Dept Comp Sci, Helsinki Inst Informat Technol, POB 68, Helsinki 00014, Finland.	petteri.hintsanen@cs.helsinki.fi; hannu.toivonen@cs.helsinki.fi	Toivonen, Hannu/A-3657-2012	Toivonen, Hannu/0000-0003-1339-8022			Birnbaum ZW, 1969, MULTIVARIATE ANAL, P581; BRYANT RE, 1986, IEEE T COMPUT, V35, P677; Colbourn Charles J., 1987, COMBINATORICS NETWOR; De Raedt L, 2008, MACH LEARN, V70, P151, DOI 10.1007/s10994-007-5030-x; DUFFIN RJ, 1965, J MATH ANAL APPL, V10, P303, DOI 10.1016/0022-247X(65)90125-3; Eppstein D, 1998, SIAM J COMPUT, V28, P652, DOI 10.1137/S0097539795290477; Hershberger J., 2007, ACM T ALGORITHMS, V3, P45, DOI 10.1145/1290672.1290682; HINTSANEN P, 2007, P 11 EUR C PRINC PRA, P471; LAWLER EL, 1972, MANAGE SCI, V18, P401, DOI 10.1287/mnsc.18.7.401; Roditty L, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P920; SEVON P, 2006, P DAT INT LIF SCI 3, P35; VALDES J, 1982, SIAM J COMPUT, V11, P298, DOI 10.1137/0211023	12	11	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2008	17	1					3	23		10.1007/s10618-008-0106-1		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	335KY	WOS:000258290700002	
J	Kugel, A; Ohlebusch, E				Kuegel, Adrian; Ohlebusch, Enno			A space efficient solution to the frequent string mining problem for many databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	19th European Conference on Machine Learning	SEP   15, 2008-SEP 19, 2009	Antwerp, BELGIUM			string mining; enhanced suffix array	SUFFIX ARRAY CONSTRUCTION; LINEAR-TIME CONSTRUCTION	The frequent string mining problem is to find all substrings of a collection of string databases which satisfy database specific minimum and maximum frequency constraints. Our contribution improves the existing linear- time algorithm for this problem in such a way that the peak memory consumption is a constant factor of the size of the largest database of strings. We show how the results for each database can be stored implicitly in space proportional to the size of the database, making it possible to traverse the results in lexicographical order. Furthermore, we present a linear- time algorithm which calculates the intersection of the results of different databases. This algorithm is based on an algorithm to merge two suffix arrays, and our modification allows us to also calculate the LCP table of the resulting suffix array during the merging.	[Kuegel, Adrian; Ohlebusch, Enno] Univ Ulm, Fac Engn & Comp Sci, D-89069 Ulm, Germany	Kugel, A (reprint author), Univ Ulm, Fac Engn & Comp Sci, D-89069 Ulm, Germany.	Adrian.Kuegel@uni-ulm.de; Enno.Ohlebusch@uni-ulm.de					Abouelhoda M. I., 2004, Journal of Discrete Algorithms, V2, DOI 10.1016/S1570-8667(03)00065-0; CHANG WI, 1994, ALGORITHMICA, V12, P327, DOI 10.1007/BF01185431; FISCHER J, 2007, LINEAR FREQUENT STRI; Fischer J, 2007, LECT NOTES COMPUT SC, V4614, P459; Fischer J, 2006, LECT NOTES ARTIF INT, V4213, P139; Gusfield D., 1997, ALGORITHMS STRINGS T; HUI LCK, 1992, LECT NOTES COMPUT SC, V644, P230; JEON JE, 2005, J KISS COMPUT SYST T, V32, P268; Karkkainen J, 2003, LECT NOTES COMPUT SC, V2719, P943; Kasai T., 2001, LNCS, V2089, P181; Kim DK, 2003, LECT NOTES COMPUT SC, V2676, P186; Ko P, 2003, LECT NOTES COMPUT SC, V2676, P200; Maass MG, 2007, INFORM PROCESS LETT, V101, P250, DOI 10.1016/j.ipl.2005.12.012; Manzini G, 2004, ALGORITHMICA, V40, P33, DOI 10.1007/s00453-004-1094-1	14	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2008	17	1					24	38		10.1007/s10618-008-0110-5		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	335KY	WOS:000258290700003	
J	Miettinen, P				Miettinen, Pauli			The Boolean column and column-row matrix decompositions	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	19th European Conference on Machine Learning	SEP   15, 2008-SEP 19, 2009	Antwerp, BELGIUM			matrix decompositions; approximation; CX decomposition; CUR decomposition; Boolean decompositions		Matrix decompositions are used for many data mining purposes. One of these purposes is to find a concise but interpretable representation of a given data matrix. Different decomposition formulations have been proposed for this task, many of which assume a certain property of the input data ( e. g., nonnegativity) and aim at preserving that property in the decomposition. In this paper we propose new decomposition formulations for binary matrices, namely the Boolean CX and CUR decompositions. They are natural combinations of two previously presented decomposition formulations. We consider also two subproblems of these decompositions and present a rigorous theoretical study of the subproblems. We give algorithms for the decompositions and for the subproblems, and study their performance via extensive experimental evaluation. We show that even simple algorithms can give accurate and intuitive decompositions of real data, thus demonstrating the power and usefulness of the proposed decompositions.	Univ Helsinki, Helsinki Inst Informat Technol, Helsinki, Finland	Miettinen, P (reprint author), Univ Helsinki, Helsinki Inst Informat Technol, Helsinki, Finland.	pauli.miettinen@cs.helsinki.fi					Berry MW, 2005, ACM T MATH SOFTWARE, V31, P252, DOI 10.1145/1067967.1067972; Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; DRINEAS P, 2007, ARXIV07083696V1CSDS; Fortelius M, 2006, PALEOBIOLOGY, V32, P206, DOI 10.1666/04087.1; FORTELIUS M., 2003, NEOGENE OLD WORLD DA; Golub G.H., 1996, MATRIX COMPUTATIONS; Hofmann T., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312649; HYVONEN S, 2008, P 14 ACM SI IN PRESS; Jimeng Sun, 2008, STAT ANAL DATA MIN, V1, P6, DOI 10.1002/sam.102; Kozlov M., 1979, SOV MATH DOKL, V20, P1108; Lu HB, 2008, PROC INT CONF DATA, P297, DOI 10.1109/ICDE.2008.4497438; MIETTINEN P, 2008, INFORM PROC IN PRESS; MIETTINEN P, 2008, IEEE T KNOW IN PRESS; Peleg D., 2007, J DISCRETE ALGORITHM, V5, P55, DOI 10.1016/j.jda.2006.03.008; Zhang JL, 2007, LECT NOTES OPER RES, V7, P391	16	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2008	17	1					39	56		10.1007/s10618-008-0107-0		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	335KY	WOS:000258290700004	
J	Papadopoulos, AN; Lyritsis, A; Manolopoulos, Y				Papadopoulos, Apostolos N.; Lyritsis, Apostolos; Manolopoulos, Yannis			SkyGraph: an algorithm for important subgraph discovery in relational graphs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	19th European Conference on Machine Learning	SEP   15, 2008-SEP 19, 2009	Antwerp, BELGIUM			graph mining; skyline processing; edge connectivity	THEORETIC APPROACH; CONNECTIVITY	A significant number of applications require effective and efficient manipulation of relational graphs, towards discovering important patterns. Someexample applications are: ( i) analysis of microarray data in bioinformatics, ( ii) pattern discovery in a large graph representing a social network, ( iii) analysis of transportation networks, ( iv) community discovery in Web data. The basic approach followed by existing methods is to apply mining techniques on graph data to discover important patterns, such as subgraphs that are likely to be useful. However, in some cases the number of mined patterns is large, posing difficulties in selecting the most important ones. For example, applying frequent subgraph mining on a set of graphs the system returns all connected subgraphs whose frequency is above a specified ( usually user- defined) threshold. The number of discovered patterns may be large, and this number depends on the data characteristics and the frequency threshold specified. It would be more convenient for the user if " goodness" criteria could be set to evaluate the usefulness of these patterns, and if the user could provide preferences to the system regarding the characteristics of the discovered patterns. In this paper, we propose a methodology to support such preferences by applying subgraph discovery in relational graphs towards retrieving important connected subgraphs. The importance of a subgraph is determined by: ( i) the order of the subgraph ( the number of vertices) and ( ii) the subgraph edge connectivity. The performance of the proposed technique is evaluated by using real- life as well as synthetically generated data sets.	[Papadopoulos, Apostolos N.; Lyritsis, Apostolos; Manolopoulos, Yannis] Aristotle Univ Thessaloniki, Dept Informat, Data Engn Res Lab, Thessaloniki 54124, Greece	Papadopoulos, AN (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Data Engn Res Lab, Thessaloniki 54124, Greece.	apostol@delab.csd.auth.gr; lyritsis@delab.csd.auth.gr; manolopo@delab.csd.auth.gr					Behzad M., 1979, GRAPHS DIGRAPHS; Bell M.G.H., 1997, TRANSPORTATION NETWO, P07030; Borzsonyi S, 2001, PROC INT CONF DATA, P421, DOI 10.1109/ICDE.2001.914855; CHARTRAND G, 1966, SIAM J APPL MATH, V14, P778, DOI 10.1137/0114065; Cook D., 2007, MINING GRAPH DATA; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Gibson D., 2005, P 31 INT C VER LARG, P721; Gross J., 1999, GRAPH THEORY ITS APP; HAO JX, 1992, PROCEEDINGS OF THE THIRD ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P165; Hartuv E, 2000, INFORM PROCESS LETT, V76, P175, DOI 10.1016/S0020-0190(00)00142-3; Hu H., 2005, BIOINFORMATICS, V21, pi213; Karger D. R., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237829; Matula D.W., 1987, P 28 S FDN COMP SCI, P249; NAGAMOCHI H, 1992, SIAM J DISCRETE MATH, V5, P54, DOI 10.1137/0405004; Papadias D, 2005, ACM T DATABASE SYST, V30, P41, DOI 10.1145/1061318.1061320; Stoer M, 1997, J ACM, V44, P585, DOI 10.1145/263867.263872; Wang J., 2005, DATA MINING BIOINFOR; Wasserman S, 1994, SOCIAL NETWORK ANAL; Whitney H, 1932, AM J MATH, V54, P150, DOI 10.2307/2371086; WOLLE T, 2004, UUCS2004042; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; Yan X., 2007, BIOINFORMATICS, V23, P577; Yan X., 2005, P 11 ACM SIGKDD INT, P324, DOI 10.1145/1081870.1081908; ZHU F, 2007, P PAKDD C, P388	24	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2008	17	1					57	76		10.1007/s10618-008-0109-y		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	335KY	WOS:000258290700005	
J	Raissi, C; Calders, T; Poncelet, P				Raissi, Chedy; Calders, Toon; Poncelet, Pascal			Mining conjunctive sequential patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	19th European Conference on Machine Learning	SEP 15-19, 2008-2009	Antwerp, BELGIUM			sequential patterns; condensed representation; deduction; non-derivability		In this paper we aim at extending the non- derivable condensed representation in frequent itemset mining to sequential pattern mining. We start by showing a negative example: in the context of frequent sequences, the notion of nonderivability is meaningless. Therefore, we extend our focus to the mining of conjunctions of sequences. Besides of being of practical importance, this class of patterns has some nice theoretical properties. Based on a new unexploited theoretical definition of equivalence classes for sequential patterns, we are able to extend the notion of a non- derivable itemset to the sequence domain. We present a new depth- first approach to mine non- derivable conjunctive sequential patterns and show its use inmining association rules for sequences. This approach is based on a well known combinatorial theorem: the Mbius inversion. A performance study using both synthetic and real datasets illustrates the efficiency of our mining algorithm. These new introduced patterns have a high- potential for real- life applications, especially for network monitoring and biomedical fields with the ability to get sequential association rules with all the classical statistical metrics such as confidence, conviction, lift etc.	[Calders, Toon] Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands; [Raissi, Chedy] Univ Montpellier, LIRMM, F-34059 Montpellier, France; [Raissi, Chedy; Poncelet, Pascal] Ecole Mines Ales, LGI2P, Nimes, France	Calders, T (reprint author), Eindhoven Univ Technol, POB 513, NL-5600 MB Eindhoven, Netherlands.	raissi@lirmm.fr; t.calders@tue.nl; pascal.poncelet@ema.fr					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; AYRES J, 2002, P 8 SIGKDD INT C KNO, P439; Balcazar JL, 2007, THEOR COMPUT SCI, V371, P247, DOI 10.1016/j.tcs.2006.11.009; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; CALDERS T, 2003, P 7 EUR C PRINC PRAC, P71; Calders T, 2007, DATA MIN KNOWL DISC, V14, P171, DOI 10.1007/s10618-006-0054-6; Calders T., 2006, LNCS, V3848, P64; CALDERS T, 2007, THEOR COMPUT SCI; Calders T., 2002, LECT NOTES ARTIF INT, V2431, P74; CALDERS T, 2005, SDM; Ireland K., 1990, CLASSICAL INTRO MODE; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; XING Z, 2008, P 2008 SIAM INT C DA; Yan X, 2003, SDM; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315	15	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2008	17	1					77	93		10.1007/s10618-008-0108-z		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	335KY	WOS:000258290700006	
J	Soulet, A; Cremilleux, B				Soulet, Arnaud; Cremilleux, Bruno			Adequate condensed representations of patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	19th European Conference on Machine Learning	SEP   15, 2008-SEP 19, 2009	Antwerp, BELGIUM			pattern mining; condensed representation; closure operator	FREQUENT PATTERNS; KNOWLEDGE DISCOVERY; ASSOCIATION RULES; SEARCH	Patterns are at the core of the discovery of a lot of knowledge from data but their uses are limited due to their huge number and their mining cost. During the last decade, many works addressed the concept of condensed representation w. r. t. frequency queries. Such representations are several orders of magnitude smaller than the size of the whole collections of patterns, and also enable us to regenerate the frequency information of any pattern. In this paper, we propose a framework for condensed representations w. r. t. a large set of new and various queries named condensable functions based on interestingnessmeasures ( e. g., frequency, lift, minimum). Such condensed representations are achieved thanks to new closure operators automatically derived from each condensable function to get adequate condensed representations. We propose a generic algorithm MicMac to efficiently mine the adequate condensed representations. Experiments show both the conciseness of the adequate condensed representations and the efficiency of our algorithm.	[Soulet, Arnaud] Univ Tours, LI, F-41029 Blois, France; [Cremilleux, Bruno] Univ Caen, CNRS, GREYC, F-14032 Caen, France	Soulet, A (reprint author), Univ Tours, LI, 3 Pl Jean Jaures, F-41029 Blois, France.	arnaud.soulet@univ-tours.fr; bruno.cremilleux@info.unicaen.fr					Agrawal R., 1994, VLDB, P487; Bastide Y., 2000, LNCS, V1861, P972; BIRKHOFF G, 1967, LATTICES THEORY, V25; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Bykowski A, 2003, INFORM SYST, V28, P949, DOI 10.1016/S0306-4379(03)00002-4; CALDERS T, 2003, P 7 EUR C PRINC PRAC, P71; Calders T, 2004, LECT NOTES ARTIF INT, V3848, P64; Calders T., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Casali A, 2005, LECT NOTES COMPUT SC, V3589, P428; CREMILLEUX B, 2002, 22 INT C KNOWL BAS S, P33; Gasmi G, 2007, LECT NOTES COMPUT SC, V4654, P293; GIACOMETTI A, 2002, KNOWLEDGE DISCOVERY; Goethals B., 2003, CEUR WORKSH P; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Kryszkiewicz M, 2005, J EXP THEOR ARTIF IN, V17, P63, DOI 10.1080/09528130512331315882; Li JY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P430; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MORIK K, 2005, LNAI, V3539; NG R, 1998, SIGMOD, P13; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; SOULET A, 2004, POSTPR KNOWL DISC IN; YAO H, 2004, P 4 SIAM INT C DAT M; Zaki M. J., 2000, KDD 00, P34; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291	25	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2008	17	1					94	110		10.1007/s10618-008-0111-4		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	335KY	WOS:000258290700007	
J	Sun, J; Tsourakakis, CE; Hoke, E; Faloutsos, C; Eliassi-Rad, T				Sun, Jimeng; Tsourakakis, Charalampos E.; Hoke, Evan; Faloutsos, Christos; Eliassi-Rad, Tina			Two heads better than one: pattern discovery in time-evolving multi-aspect data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	19th European Conference on Machine Learning	SEP   15, 2008-SEP 19, 2009	Antwerp, BELGIUM			tensor; multilinear analysis; stream mining; wavelet		Data stream values are often associated with multiple aspects. For example, each value observed at a given time- stamp from environmental sensors may have an associated type ( e. g., temperature, humidity, etc.) as well as location. Time- stamp, type and location are the three aspects, which can be modeled using a tensor ( highorder array). However, the time aspect is special, with a natural ordering, and with successive time- ticks having usually correlated values. Standard multiway analysis ignores this structure. To capture it, we propose 2 Heads Tensor Analysis ( 2- heads), which provides a qualitatively different treatment on time. Unlike most existing approaches that use a PCA- like summarization scheme for all aspects, 2- heads treats the time aspect carefully. 2- heads combines the power of classic multilinear analysis with wavelets, leading to a powerful mining tool. Furthermore, 2- heads has several other advantages as well: ( a) it can be computed incrementally in a streaming fashion, ( b) it has a provable error guarantee and, ( c) it achieves significant compression ratio against competitors. Finally, we show experiments on real datasets, and we illustrate how 2- heads reveals interesting trends in the data. This is an extended abstract of an article published in the Data Mining and Knowledge Discovery journal.	[Sun, Jimeng] IBM TJ Watson Res Ctr, Hawthorne, NY USA; [Tsourakakis, Charalampos E.; Faloutsos, Christos] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Hoke, Evan] Apple Comp Inc, Cupertino, CA 95014 USA; [Eliassi-Rad, Tina] Lawrence Livermore Natl Lab, Livermore, CA USA	Sun, J (reprint author), IBM TJ Watson Res Ctr, Hawthorne, NY USA.	jimeng@cs.cmu.edu					Acar E, 2005, LECT NOTES COMPUT SC, V3495, P256; Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794; Chew PA, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P143; Daubechies I, 1992, 10 LECT WAVELETS; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; Gilbert AC, 2003, IEEE T KNOWL DATA EN, V15, P541, DOI 10.1109/TKDE.2003.1198389; KOLDA TG, 2005, ICDM; Papadimitriou S., 2003, VLDB; Press WH, 1992, NUMERICAL RECIPES C; SUN J, 2006, KDD; SUN J, 2006, P INT C DAT MIN ICDM; Sun J. T., 2005, WWW 05, P382; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Vasilescu M. A. O., 2002, ECCV; XU D, 2005, CVPR	15	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2008	17	1					111	128		10.1007/s10618-008-0112-3		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	335KY	WOS:000258290700008	
J	Aggarwal, CC; Yu, PS				Aggarwal, Charu C.; Yu, Philip S.			A framework for condensation-based anonymization of string data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						privacy; strings; condensation		In recent years, privacy preserving data mining has become an important problem because of the large amount of personal data which is tracked by many business applications. An important method for privacy preserving data mining is the method of condensation. This method is often used in the case of multi-dimensional data in which pseudo-data is generated to mask the true values of the records. However, these methods are not easily applicable to the case of string data, since they require the use of multi-dimensional statistics in order to generate the pseudo-data. String data are especially important in the privacy preserving data-mining domain because most DNA and biological data are coded as strings. In this article, we will discuss a new method for privacy preserving mining of string data with the use of simple template-based models. The template-based model turns out to be effective in practice, and preserves important statistical characteristics of the strings such as intra-record distances. We will explore the behavior in the context of a classification application, and show that the accuracy of the application is not affected significantly by the anonymization process.	[Aggarwal, Charu C.] TJ Watson Res Ctr, IBM, Hawthorne, NY USA; [Yu, Philip S.] Univ Illinois, Chicago, IL USA	Aggarwal, CC (reprint author), TJ Watson Res Ctr, IBM, Hawthorne, NY USA.	charu@us.ibm.com; psyu@cs.uic.edu					AGGARWAL CC, 2007, SIAM C DAT MIN; AGGARWAL CC, 2002, ACM KDD C; AGGARWAL CC, 2004, VLDB C SCAL CLUST BA; AGGARWAL CC, 2005, ACM SIAM DAT MIN C; AGGARWAL CC, 2004, EDBT C; Agrawal D, 2002, ACM PODS C; Agrawal R., 2000, P ACM SIGMOD C; AGRAWAL R, 1994, P VLDB C; Banerjee A, 2006, DATA MIN KNOWL DISC, V13, P365, DOI 10.1007/s10618-006-0040-z; BAYARDO RJ, 2005, ICDE C; EVFIMIEVSKI AV, 2002, KDD C; IYENGAR V, 2000, ACM KDD C; KIFER D, 2006, ACM SIGMOD C; LEFEVRE K, 2006, ICDE C; MACHANAVAJJHALA A, 2006, ICDE C; Malin B, 2001, Proc AMIA Symp, P423; MALIN B, 2004, AAAS ANN M SEATTL WA; Meyerson A, 2004, ACM PODS C; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Rizvi S., 2002, VLDB C; Samarati P., 1998, P IEEE S RES SEC PRI; SWEENEY L, 1996, P AMIA S; WANG K, 2006, KNOWLEDGE INFORM SYS	23	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2008	16	3					251	275		10.1007/s10618-008-0088-z		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289MI	WOS:000255058200001	
J	Rege, M; Dong, M; Fotouhi, F				Rege, Manjeet; Dong, Ming; Fotouhi, Farshad			Bipartite isoperimetric graph partitioning for data co-clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; clustering; graph algorithms; linear systems; singular value decomposition; eigenvalues and eigenvectors	IMAGE SEGMENTATION; ALGORITHM; EIGENVECTORS; EIGENVALUES; RETRIEVAL; NETWORKS; MATRICES	Data co-clustering refers to the problem of simultaneous clustering of two data types. Typically, the data is stored in a contingency or co-occurrence matrix C where rows and columns of the matrix represent the data types to be co-clustered. An entry C (ij) of the matrix signifies the relation between the data type represented by row i and column j. Co-clustering is the problem of deriving sub-matrices from the larger data matrix by simultaneously clustering rows and columns of the data matrix. In this paper, we present a novel graph theoretic approach to data co-clustering. The two data types are modeled as the two sets of vertices of a weighted bipartite graph. We then propose Isoperimetric Co-clustering Algorithm (ICA)-a new method for partitioning the bipartite graph. ICA requires a simple solution to a sparse system of linear equations instead of the eigenvalue or SVD problem in the popular spectral co-clustering approach. Our theoretical analysis and extensive experiments performed on publicly available datasets demonstrate the advantages of ICA over other approaches in terms of the quality, efficiency and stability in partitioning the bipartite graph.	[Rege, Manjeet; Dong, Ming; Fotouhi, Farshad] Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA	Rege, M (reprint author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA.	rege@wayne.edu					ALON N, 1986, COMBINATORICA, V6, P83, DOI 10.1007/BF02579166; ALON N, 1985, J COMB THEORY B, V38, P73, DOI 10.1016/0095-8956(85)90092-9; ALPERT CJ, 1995, INTEGRATION, V19, P1, DOI 10.1016/0167-9260(95)00008-4; Anderson W.N., 1985, LINEAR MULTILINEAR A, V18, P141, DOI 10.1080/03081088508817681; Arfken G. B., 2000, MATH METHODS PHYS; Banerjee A, 2004, P 10 ACM SIGKDD INT, P509, DOI 10.1145/1014052.1014111; Biggs N., 1974, ALGEBRAIC GRAPH THEO; BOLEY D, 1999, AI REV, V11, P365; Cal R., 2005, P ACM MULT 05, P628, DOI 10.1145/1101149.1101292; Cheeger J, 1970, PROBLEMS ANAL, P195; Chung F, 1997, SPECTRAL GRAPH THEOR; Demmel J., 1997, APPL NUMERICAL LINEA; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; Dhillon I.S., 2001, P 7 ACM SIGKDD INT C; Ding C, 2004, PROTEINS, V57, P99, DOI 10.1002/prot.20147; Ding CHQ, 2003, BIOINFORMATICS, V19, P1259, DOI 10.1093/bioinformatics/btg149; DING CHQ, 2003, P INT PAR DISTR PROC; DODZIUK J, 1984, T AM MATH SOC, V284, P787, DOI 10.2307/1999107; Donath W. E., 1972, IBM Technical Disclosure Bulletin, V15; DONATH WE, 1973, IBM J RES DEV, V17, P420; Dongen S. V., 2000, THESIS U UTRECHT; Duda R. O., 2000, PATTERN CLASSIFICATI; Enright AJ, 2002, NUCLEIC ACIDS RES, V30, P1575, DOI 10.1093/nar/30.7.1575; FIEDLER M, 1975, CZECH MATH J, V25, P607; FIEDLER M, 1973, CZECH MATH J, V23, P298; FIEDLER M, 1975, CZECH MATH J, V25, P619; FIEDLER M, 1986, SPECIAL MATRICES THE; Garey M.R., 1979, COMPUTER INTRACTABIL; GEORGE T, 2005, P 5 IEEE INT C DAT M; Gilbert JR, 1998, SIAM J SCI COMPUT, V19, P2091, DOI 10.1137/S1064827594275339; Golub G.H., 1989, MATRIX COMPUTATIONS; Gonzalez R. C., 2002, DIGITAL IMAGE PROCES; Grady L, 2006, SIAM J SCI COMPUT, V27, P1844, DOI 10.1137/040609008; Grady L, 2006, IEEE T PATTERN ANAL, V28, P469, DOI 10.1109/TPAMI.2006.57; Guattery S, 1998, SIAM J MATRIX ANAL A, V19, P701, DOI 10.1137/S0895479896312262; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Han E.-H., 2000, PRINCIPLES DATA MINI, P424; Hendrickson B., 1995, SAND952344 SAND NAT; Hersh W. R., 1994, P 17 ANN INT ACM SIG, P192; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kendall W. S., 1986, PITMAN RES NOTES MAT, V150, P68; Kuijlaars ABJ, 2000, SIAM J MATRIX ANAL A, V22, P306, DOI 10.1137/S089547989935527X; Kumar R., 2004, P 2004 ACM SIGKDD IN, P216, DOI 10.1145/1014052.1014078; Kummamuru K., 2003, Proceedings of the 12th IEEE International Conference on Fuzzy Systems (Cat. No.03CH37442); LEWIS DD, 1999, REUTER 21578 TEXT CA; Long B., 2005, P 11 ACM SIGKDD INT, P635, DOI 10.1145/1081870.1081949; Mandhani B., 2003, P 12 INT C WORLD WID, P511; Merris R., 1994, LINEAR ALGEBRA APPL, V197, P143, DOI 10.1016/0024-3795(94)90486-3; Mohar B., 1991, GRAPH THEORY COMBINA, V2, P871; MOHAR B, 1989, J COMB THEORY B, V47, P274, DOI 10.1016/0095-8956(89)90029-4; Oh C., 2001, P JOINT 9 IFSA WORLD, P2154; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; QIU G, 2004, P IEEE ICPR; REGE M, 2006, P 6 IEEE INT C DAT M; REGE M, 2006, P IEEE INT C IM PROC; Rui Y., 1997, P IEEE INT C IM PROC; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Simon H. D., 1991, Computing Systems in Engineering, V2, DOI 10.1016/0956-0521(91)90014-V; SLONIM N, 2000, RES DEV INFORM RETRI, P208; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Wu X., 2005, P IEEE INT C MULT EX, P117; ZHA H, 2002, P 25 ANN INT ACM SIG; ZHA H, 2001, P 10 INT C INF KNOWL; Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189	66	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2008	16	3					276	312		10.1007/s10618-008-0091-4		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289MI	WOS:000255058200002	
J	Sanchez, D; Serrano, JM; Blanco, I; Martin-Bautista, MJ; Vila, MA				Sanchez, Daniel; Serrano, Jose Maria; Blanco, Ignacio; Martin-Bautista, Maria Jose; Vila, Maria-Amparo			Using association rules to mine for strong approximate dependencies	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						approximate dependencies; association rules; data mining; relational databases	INFERRING FUNCTIONAL-DEPENDENCIES; DISCOVERY; DATABASE	In this paper we deal with the problem of mining for approximate dependencies (AD) in relational databases. We introduce a definition of AD based on the concept of association rule, by means of suitable definitions of the concepts of item and transaction. This definition allow us to measure both the accuracy and support of an AD. We provide an interpretation of the new measures based on the complexity of the theory (set of rules) that describes the dependence, and we employ this interpretation to compare the new measures with existing ones. A methodology to adapt existing association rule mining algorithms to the task of discovering ADs is introduced. The adapted algorithms obtain the set of ADs that hold in a relation with accuracy and support greater than user-defined thresholds. The experiments we have performed show that our approach performs reasonably well over large databases with real-world data.	[Sanchez, Daniel] ETSIIT, Granada 18071, Spain; [Sanchez, Daniel; Blanco, Ignacio; Martin-Bautista, Maria Jose; Vila, Maria-Amparo] Univ Granada, Dept Comp Sci & AI, Granada, Spain; [Serrano, Jose Maria] Univ Jaen, Dept Informat, Jaen, Spain	Sanchez, D (reprint author), ETSIIT, C Periodista Daniel Saucedo Aranda S-N, Granada 18071, Spain.	daniel@decsai.ugr.es	Serrano, Jose/K-2734-2012; Prieto, Ignacio/B-5361-2013				Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; BELL S, 1997, P ECSQARU FAPR 97, P16; BELL S, 1995, P 1 INT C KNOWL DISC, P27; Berzal F, 2005, FUZZY SET SYST, V149, P105, DOI 10.1016/j.fss.2004.07.012; BERZAL F, 2003, P ECML PKDD 2003 WOR, P34; Berzal F., 2002, Intelligent Data Analysis, V6; BITTON D, 1989, PROCEEDINGS : FIFTH INTERNATIONAL CONFERENCE ON DATA ENGINEERING, P635, DOI 10.1109/ICDE.1989.47271; BOSE P, 1997, ANN M NAFIPS, P57; BRA PD, 1983, ADV DATABASE THEORY, V2, P123; Brin S., 1997, SIGMOD Record, V26; Calero J, 2004, ADV SOFT COMP, P447; CALERO J, 2004, P 6 INT C ENT INF SY, P138; Calero J., 2003, P 5 INT C ENT INF SY, P533; CALERO J, 2004, P IADIS INT C APPL C, P396; Cubero J. C., 1998, P EUFIT 98, P731; Delgado M, 2003, IEEE T FUZZY SYST, V11, P214, DOI 10.1109/TFUZZ.2003.809896; Dubois D, 2006, DATA MIN KNOWL DISC, V13, P167, DOI 10.1007/s10618-005-0032-4; Flach PA, 1999, AI COMMUN, V12, P139; GUNOPULOS D, 1997, P INT C DAT THEOR, P215; Huhtala Y, 1998, PROC INT CONF DATA, P392, DOI 10.1109/ICDE.1998.655802; Huhtala Y, 1999, COMPUT J, V42, P100, DOI 10.1093/comjnl/42.2.100; KIVINEN J, 1995, THEOR COMPUT SCI, V149, P129, DOI 10.1016/0304-3975(95)00028-U; KRAMER S, 1996, P 2 INT C KNOWL DISC, P371; LAVRAC N, 1999, LECT NOTES ARTIF INT, V1634, P74; Lopes S, 2002, J EXP THEOR ARTIF IN, V14, P93, DOI 10.1080/09528130210164143; Lukasiewicz J., 1970, J LUKASIEWICZ SELECT, P16; MANNILA H, 1992, DISCRETE APPL MATH, V40, P237, DOI 10.1016/0166-218X(92)90031-5; MANNILA H, 1994, DATA KNOWL ENG, V12, P83, DOI 10.1016/0169-023X(94)90023-X; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1991, ROUGH SETS THEORETIC; PFAHRINGER B, 1995, P 1 INT C KNOWL DISC, P234; PIATETSKYSHAPIR.G, 1992, P ML 92 WORKSH MACH, P11; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; RUSSELL SJ, 1989, USE KNOWLEDGE ANALOG; SANCHEZ D, 2003, ENTERPRISE INFORMATI, V4, P75; Sanchez D, 1999, THESIS U GRANADA; SAVNIK I, 1993, KNOWLEDGE DISCOVERY, P174; Schlimmer J.C., 1993, P 10 INT C MACH LEAR, P284; SHEN W, 1991, P 8 INT WORKSH MACH, P539; Shortliffe E. H., 1975, Mathematical Biosciences, V23, DOI 10.1016/0025-5564(75)90047-4; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; Ziarko W., 1991, Knowledge discovery in databases	42	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2008	16	3					313	348		10.1007/s10618-008-0092-3		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289MI	WOS:000255058200003	
J	Ghoting, A; Parthasarathy, S; Otey, ME				Ghoting, Amol; Parthasarathy, Srinivasan; Otey, Matthew Eric			Fast mining of distance-based outliers in high-dimensional datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						outlier detection; high-dimensional datasets; approximate k-nearest neighbors; clustering		Defining outliers by their distance to neighboring data points has been shown to be an effective non-parametric approach to outlier detection. In recent years, many research efforts have looked at developing fast distance-based outlier detection algorithms. Several of the existing distance-based outlier detection algorithms report log-linear time performance as a function of the number of data points on many real low-dimensional datasets. However, these algorithms are unable to deliver the same level of performance on high-dimensional datasets, since their scaling behavior is exponential in the number of dimensions. In this paper, we present RBRP, a fast algorithm for mining distance-based outliers, particularly targeted at high-dimensional datasets. RBRP scales log-linearly as a function of the number of data points and linearly as a function of the number of dimensions. Our empirical evaluation demonstrates that we outperform the state-of-the-art algorithm, often by an order of magnitude.	[Ghoting, Amol] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; [Parthasarathy, Srinivasan] Ohio State Univ, Columbus, OH 43210 USA; [Otey, Matthew Eric] Google Inc, Pittsburgh, PA USA	Ghoting, A (reprint author), IBM Corp, Thomas J Watson Res Ctr, 1101 Kitchawan Rd,Yorktown Hts, Yorktown Hts, NY 10598 USA.	aghoting@us.ibm.com; srini@cse.ohio-state.edu; otey@google.com					ANGIULLI F, 2002, P INT C PRINC DAT MI; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Barnett V., 1994, OUTLIERS STAT DATA; BAY S, 1999, UCI KDD ARCHIVE; BAY SD, 2003, P INT C KNOWL DISC D; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S., 1996, P INT C VER LARG DAT; Bolton RJ, 2002, STAT SCI, V17, P235; GAMBERGER D, 1999, P INT C MACH LEARN; GHOTING A, 2005, TR71 OH STAT U DEP C; GUTTMANN R, 1984, P INT C MAN DAT SIGM; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; JAGADISH H, 1998, P INT C VER LARG DAT; Jolliffe I., 1986, PRINCIPAL COMPONENT; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Knorr E.M., 1999, P INT C VER LARG DAT; KUSHILEVITZ E, 1998, P S THEOR COMP STOC; MURALIKRISHNA M, 1988, P INT C MAN DAT SIGM; RAMASWAMY S, 2000, P INT C MAN DAT; Ruggles S., 1997, INTEGRATED PUBLIC US; SEQUIRA K, 2002, P INT C KNOWL DISC D; ZHANG T, 1996, P INT C MAN DAT SIGM	23	15	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2008	16	3					349	364		10.1007/s10618-008-0093-2		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289MI	WOS:000255058200004	
J	Palshikar, GK; Apte, MM				Palshikar, Girish Keshav; Apte, Manoj M.			Collusion set detection using graph clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						graph clustering; clustering; fraud detection; collusion set	CIRCUITS	Many mal-practices in stock market trading-e.g., circular trading and price manipulation-use the modus operandi of collusion. Informally, a set of traders is a candidate collusion set when they have "heavy trading" among themselves, as compared to their trading with others. We formalize the problem of detection of collusion sets, if any, in the given trading database. We show that naive approaches are inefficient for real-life situations. We adapt and apply two well-known graph clustering algorithms for this problem. We also propose a new graph clustering algorithm, specifically tailored for detecting collusion sets. A novel feature of our approach is the use of Dempster-Schafer theory of evidence to combine the candidate collusion sets detected by individual algorithms. Treating individual experiments as evidence, this approach allows us to quantify the confidence (or belief) in the candidate collusion sets. We present detailed simulation experiments to demonstrate effectiveness of the proposed algorithms.	[Palshikar, Girish Keshav] TRDDC, Pune 411013, Maharashtra, India; [Apte, Manoj M.] Tata Consultanct Serv, R&D Engn & Ind Serv, Pune 411001, Maharashtra, India	Palshikar, GK (reprint author), TRDDC, 54B Hadapsar Ind Estate, Pune 411013, Maharashtra, India.	gk.palshikar@tcs.com; manoj.apte@tcs.com					GOWDA KC, 1978, PATTERN RECOGN, V10, P105; HONKANEN PA, 1978, P 16 ACM SE REG C, P49, DOI 10.1145/503643.503655; Jain A. K., 1999, ACM COMPUT SURV, V31; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; Le Hegarat-Mascle S, 2003, INTEGR COMPUT-AID E, V10, P9; PALSHIKAR GK, 2005, P C MAN DAT COMAD 20, P101; Palshikar G.K., 2000, P INT C ADV DAT MAN, P135; RAO VVB, 1985, P IEEE, V73, P1524, DOI 10.1109/PROC.1985.13325; RICH E, 1995, ARTIFICIAL INTELLIGE; RUBIN F, 1974, J ACM, V21, P576, DOI 10.1145/321850.321854; SHAFER G, MATH THEORY EVIDENCE; TARJAN RE, 1975, NETWORKS, V5, P237; *SEBI, CO109ISD122004 SEBI	14	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2008	16	2					135	164		10.1007/s10618-007-0076-8		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	257KK	WOS:000252797800001	
J	Manning, AM; Haglin, DJ; Keane, JA				Manning, Anna M.; Haglin, David J.; Keane, John A.			A recursive search algorithm for statistical disclosure assessment	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						unique itemset; search space; algorithm; recursion; statistical disclosure	ASSOCIATION RULES; K-ANONYMITY; MICRODATA; ITEMSETS; PRIVACY	A new algorithm, SUDA2, is presented which finds minimally unique itemsets i.e., minimal itemsets of frequency one. These itemsets, referred to as Minimal Sample Uniques (MSUs), are important for statistical agencies who wish to estimate the risk of disclosure of their datasets. SUDA2 is a recursive algorithm which uses new observations about the properties of MSUs to prune and traverse the search space. Experimental comparisons with previous work demonstrate that SUDA2 is several orders of magnitude faster, enabling datasets of significantly more columns to be addressed. The ability of SUDA2 to identify the boundaries of the search space for MSUs is clearly demonstrated.	[Manning, Anna M.; Keane, John A.] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England; [Haglin, David J.] Minnesota State Univ, Dept Informat & Comp Sci, Mankato, MN 56001 USA	Manning, AM (reprint author), Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England.	anna@manchester.ac.uk; david.haglin@mnsu.edu; john.keane@manchester.ac.uk					AGGARWAL G., 2005, P 10 INT C DAT THEOR, P246; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, VLDB, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Berge C., 1989, HYPERGRAPHS COMBINAT; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Burdick D, 2001, PROC INT CONF DATA, P443, DOI 10.1109/ICDE.2001.914857; CALDERS T, 2005, P 2005 SIAM INT C DA; Domingo-Ferrer J, 2005, DATA MIN KNOWL DISC, V11, P195, DOI 10.1007/s10618-005-0007-5; DONG G, 2005, P 10 INT C DAT SYST, P175; Elliot M. J., 1999, NETHERLANDS OFFICIAL, V14, P6; Elliot MJ, 2002, INT J UNCERTAIN FUZZ, V10, P493, DOI 10.1142/S0218488502001600; ELLIOT MJ, 1998, RES OFF STAT, V1, P53; ELLIOT MJ, 2005, P JOINT UN EC COMM E, P353; Fienberg S.E., 1998, J OFF STAT, V14, P385; FLOUVAT F, 2004, CONJUCTION IEEE INT; Ghoting A., 2004, P 4 IEEE INT C DAT M, P387; Golle P, 2006, P 5 ACM WORKSH PRIV, P77, DOI 10.1145/1179601.1179615; Gouda K, 2005, DATA MIN KNOWL DISC, V11, P223, DOI 10.1007/s10618-005-0002-x; Gunopulos D, 2003, ACM T DATABASE SYST, V28, P140, DOI 10.1145/777943.777945; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Hipp J., 2000, SIGKDD EXPLORATIONS, V2, P58; Lin XD, 2005, KNOWL INF SYST, V8, P68, DOI 10.1007/s10115-004-0148-7; LIU G, 2006, P 2006 SIAM INT C DA; Lucchese C, 2006, IEEE T KNOWL DATA EN, V18, P21, DOI 10.1109/TKDE.2006.10; LUCCHESE C, 2004, IEEE INT C DAT MIN; Machanavajjhala A, 2006, P 22 IEEE INT C DAT; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; MANNING AM, 2005, P 5 IEEE INT C DAT M, P290; MERZ G, 1996, UCI REPOSITORY MACHI; Muralidhar K, 1999, ACM T DATABASE SYST, V24, P487, DOI 10.1145/331983.331986; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; Samarati P., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275508; Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193; SINGH A, 2003, JOINT ECE EUROSTAT W; Skinner C. J., 1998, J OFF STAT, V14, P361; Skinner CJ, 1994, J OFF STAT, V10, P31; Skinner CJ, 2002, J ROY STAT SOC B, V64, P855, DOI 10.1111/1467-9868.00365; Fienberg SE, 2005, DATA MIN KNOWL DISC, V11, P155, DOI 10.1007/s10618-005-0010-x; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Truta TM., 2004, WPES 04 P 2004 ACM W, P85; Uno T., 2004, P 7 INT C DISC SCI P, P16; Willenborg L., 2001, ELEMENTS STAT DISCLO; Willenborg L., 1996, LECT NOTES STAT, VIII; ZAKI M, 2002, P 2002 SIAM INT C DA; *SAR1991, 1993, GREAT BRIT SAMPL AN; *SAR2001, 2004, GREAT BRIT SAMPL AN	50	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2008	16	2					165	196		10.1007/s10618-007-0078-6		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	257KK	WOS:000252797800002	
J	Yao, H; Hamilton, HJ				Yao, Hong; Hamilton, Howard J.			Mining functional dependencies from data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						discovering functional dependencies; mining functional dependencies; implication rule; functional dependencies; data mining; knowledge discovery; FD_mine; relational databases	POINT-OF-VIEW; PROPOSITIONAL LOGIC; RELATIONAL DATABASE; DISCOVERY	In this paper, we propose an efficient rule discovery algorithm, called FD_Mine, for mining functional dependencies from data. By exploiting Armstrong's Axioms for functional dependencies, we identify equivalences among attributes, which can be used to reduce both the size of the dataset and the number of functional dependencies to be checked. We first describe four effective pruning rules that reduce the size of the search space. In particular, the number of functional dependencies to be checked is reduced by skipping the search for FDs that are logically implied by already discovered FDs. Then, we present the FD_Mine algorithm, which incorporates the four pruning rules into the mining process. We prove the correctness of FD_Mine, that is, we show that the pruning does not lead to the loss of useful information. We report the results of a series of experiments. These experiments show that the proposed algorithm is effective on 15 UCI datasets and synthetic data.	[Yao, Hong; Hamilton, Howard J.] Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Hamilton, HJ (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.	yao2hong@cs.uregina.ca; hamilton@cs.uregina.ca					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Baixeries J., 2004, P WORKSH MATH METH L; Baixeries J., 2007, THESIS U POLITECNICA; Carpineto C, 1999, COMPUT INTELL, V15, P415, DOI 10.1111/0824-7935.00100; DEMETROVICS J, 1992, DISCRETE APPL MATH, V40, P155, DOI 10.1016/0166-218X(92)90028-9; FAGIN R, 1977, IBM J RES DEV, V21, P534; Flach PA, 1999, AI COMMUN, V12, P139; Flesca Sergio, 2005, ENCY DATABASE TECHNO, P542; Ganter B., 1999, FORMAL CONCEPT ANAL; GOODAIRE EG, 1992, DISCRETE MATH GRAPH; Huhtala Y, 1999, COMPUT J, V42, P100, DOI 10.1093/comjnl/42.2.100; KALASHNIKOV VD, 2006, ACM T DATABASE SYST, V31, P716; LOPES S, 2000, 7 INT C EXT DAT TECH, P350; Lopes S, 2002, J EXP THEOR ARTIF IN, V14, P93, DOI 10.1080/09528130210164143; Maier D., 1983, THEORY RELATIONAL DA; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; MANNILA H, 1994, DATA KNOWL ENG, V12, P83, DOI 10.1016/0169-023X(94)90023-X; Novelli N, 2001, INFORM SYST, V26, P477, DOI 10.1016/S0306-4379(01)00032-1; NOVELLI N, 2001, P 8 ICDT LOND UK, P189; Ramakrishnan R., 2002, DATABASE MANAGEMENT; SAGIV Y, 1981, J ACM, V28, P435, DOI 10.1145/322261.322263; Tan HBK, 2004, INFORM SOFTWARE TECH, V46, P109, DOI 10.1016/S0950-5849(03)00113-7; Ullman J.D., 1982, PRINCIPLES DATABASE; Wyss C.M., 2001, P 3 INT C DAT WAR KN, P101; Yao H, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P945, DOI 10.1007/0-387-25465-X_44; Yao H., 2002, P 2 IEEE INT C DAT M, P729; *UCI, 2005, UCI REP MACH LEARN D	27	11	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2008	16	2					197	219		10.1007/s10618-007-0083-9		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	257KK	WOS:000252797800003	
J	Cheng, J; Ke, YP; Ng, W				Cheng, James; Ke, Yiping; Ng, Wilfred			Effective elimination of redundant association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association rules; redundancy elimination; concise representation		It is well-recognized that the main factor that hinders the applications of Association Rules (ARs) is the huge number of ARs returned by the mining process. In this paper, we propose an effective solution that presents concise mining results by eliminating the redundancy in the set of ARs. We adopt the concept of delta tolerance to define the set of delta-Tolerance ARs (delta-TARs), which is a concise representation for the set of ARs. The notion of delta-tolerance is a relaxation on the closure defined on the support of frequent itemsets, thus allowing us to effectively prune the redundant ARs. We devise a set of inference rules, with which we prove that the set of delta-TARs is a non-redundant representation of ARs. In addition, we prove that the set of ARs that is derived from the delta-TARs by the inference rules is sound and complete. We also develop a compact tree structure called the delta-TAR tree, which facilitates the efficient generation of the delta-TARs and derivation of other ARs. Experimental results verify the efficiency of using the delta-TAR tree to generate the delta-TARs and to query the ARs. The set of delta-TARs is shown to be significantly smaller than the state-of-the-art concise representations of ARs. In addition, the approximation on the support and confidence of the ARs derived from the delta-TARs are highly accurate.	[Cheng, James; Ke, Yiping; Ng, Wilfred] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China	Cheng, J (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.	csjames@cse.ust.hk; keyiping@cse.ust.hk; wilfred@cse.ust.hk					Aggarwal CC, 2001, IEEE T KNOWL DATA EN, V13, P527, DOI 10.1109/69.940730; AGRAWAL R, 1993, P ACM C MAN DAT SIGM; Bastide Y., 2000, Computational Logic - CL 2000. First International Conference. Proceedings (Lecture Notes in Artificial Intelligence Vol.1861); Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Calders T., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); CEGLAR A, 2006, ACM COMPUT SURV, V38; CHENG J, 2007, IN PRESS J INTELL IN; Cheng J., 2007, P ACM SIGMOD INT C M, P857, DOI 10.1145/1247480.1247574; CHENG J, 2006, P 6 IEEE INT C DAT M; Fonseca B. M., 2005, P 14 ACM INT C INF K, P696, DOI 10.1145/1099554.1099726; Geurts K, 2003, P 82 ANN TRANSP RES, P18; GOETHALS B, 2005, P SIAM INT C DAT MIN; Jeudy B., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Kryszkiewicz M, 1998, LECT NOTES ARTIF INT, V1510, P361; Kumar N, 2007, DECIS SUPPORT SYST, V43, P16, DOI 10.1016/j.dss.2005.05.004; LI G, 2004, P SIAM INT C DAT MIN; Li Wenmin, 2001, ICDM, P369; LIU B, 2001, P 7 ACM SIGKDD INT C; MORCHEN F, 2007, DATA MIN KNOWL DISC, V15, P107; Palshikar GK, 2007, DATA KNOWL ENG, V61, P93, DOI 10.1016/j.datak.2006.04.009; PASQUIER N, 1999, P INT C DAT THEORY I; Pasquier N, 2005, J INTELL INF SYST, V24, P29, DOI 10.1007/s10844-005-0266-z; Thabtah FA, 2007, APPL SOFT COMPUT, V7, P1102, DOI 10.1016/j.asoc.2006.10.008; Yang Q, 2004, DATA MIN KNOWL DISC, V8, P253, DOI 10.1023/B:DAMI.0000023675.04946.f1; Yin X, 2003, P SDM; Zaki MJ, 2004, DATA MIN KNOWL DISC, V9, P223, DOI 10.1023/B:DAMI.0000040429.96086.c7; *FIMI, 2003, FIMI DAT REP FIMI FR	28	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2008	16	2					221	249		10.1007/s10618-007-0084-8		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	257KK	WOS:000252797800004	
J	Li, T; Perng, CS; Ma, S				Li, Tao; Perng, Chang-Shing; Ma, Sheng			Guest editorial: special issue on temporal data mining: theory, algorithms and applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material						temporal; data mining		This special issue provides a leading forum for timely, in-depth presentation of recent advances in algorithms, theories and applications in temporal data mining. The selected papers underwent a rigorous refereeing and revision process.	[Perng, Chang-Shing] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY USA; [Li, Tao] Florida Int Univ, Sch Comp Sci, Miami, FL 33199 USA; [Ma, Sheng] Movivi Inc, Beijing, Peoples R China	Perng, CS (reprint author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY USA.	taoli@cs.fiu.edu; perng@us.ibm.com; shengma2005@gmail.com						0	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2008	16	1					1	3		10.1007/s10618-007-0085-7		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	245WP	WOS:000251969800001	
J	Verhein, F; Chawla, S				Verhein, Florian; Chawla, Sanjay			Mining spatio-temporal patterns in object mobility databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						spatio-temporal data mining; spatio-temporal association rules (STARs); sources; sinks; thoroughfares; stationary regions; STAR-Miner		With the increasing use of wireless communication devices and the ability to track people and objects cheaply and easily, the amount of spatio-temporal data is growing substantially. Many of these applications cannot easily locate the exact position of objects, but they can determine the region in which each object is contained. Furthermore, the regions are fixed and may vary greatly in size. Examples include mobile/cell phone networks, RFID tag readers and satellite tracking. This demands techniques to mine such data. These techniques must also correct for the bias produced by different sized regions. We provide a comprehensive definition of Spatio-Temporal Association Rules (STARs) that describe how objects move between regions over time. We also present other patterns that are useful for mobility data; stationary regions and high traffic regions. The latter consists of sources, sinks and thoroughfares. These patterns describe important temporal characteristics of regions and we show that they can be considered as special STARs. We define spatial support to effectively deal with the problem of different sized regions. We provide an efficient algorithm-STAR-Miner-to find these patterns by exploiting several pruning properties.	[Verhein, Florian; Chawla, Sanjay] Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia	Verhein, F (reprint author), Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.	fverhein@it.usyd.edu.au; chawla@it.usyd.edu.au					Agrawal R., 1994, P 20 INT C VER LARG, P487; ALE JM, 2000, SAC 00, P2941; FLAJOLET P, 1985, J COMPUT SYST SCI, V31, P182, DOI 10.1016/0022-0000(85)90041-8; Wang JM, 2004, PROC INT C TOOLS ART, P14; HUANG Y, 2003, P 18 ACM S APPL COMP; ISHIKAWA Y, 2004, STDBM, P9; Li YJ, 2003, DATA KNOWL ENG, V44, P193, DOI 10.1016/S0169-023X(02)00135-0; Mamoulis N., 2004, KDD 04, P236; MENNIS J, 2003, P 7 INT C GEOC; Shekhar S, 2001, P 7 INT S SPAT TEMP; Tao YF, 2004, PROC INT CONF DATA, P214; TSOUKATOS I, 2001, SSTD 01, P425; VERHEIN F, 2006, DASFAA	13	4	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2008	16	1					5	38		10.1007/s10618-007-0079-5		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	245WP	WOS:000251969800002	
J	Masseglia, F; Poncelet, P; Teisseire, M; Marascu, A				Masseglia, F.; Poncelet, P.; Teisseire, M.; Marascu, A.			Web usage mining: extracting unexpected periods from web logs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						web usage mining; sequential patterns; periods; users behaviour		Existing Web usage mining techniques are currently based on an arbitrary division of the data (e.g. "one log per month") or guided by presumed results (e.g. "what is the customers' behaviour for the period of Christmas purchases?"). These approaches have two main drawbacks. First, they depend on the above-mentioned arbitrary organization of data. Second, they cannot automatically extract "seasonal peaks" from among the stored data. In this paper, we propose a specific data mining process (in particular, to extract frequent behaviour patterns) in order to reveal the densest periods automatically. From the whole set of possible combinations, our method extracts the frequent sequential patterns related to the extracted periods. A period is considered to be dense if it contains at least one frequent sequential pattern for the set of users connected to the website in that period. Our experiments show that the extracted periods are relevant and our approach is able to extract both frequent sequential patterns and the associated dense periods.	[Masseglia, F.; Marascu, A.] Axis Project Team, INRIA Sophia Antipolis, F-06902 Sophia Antipolis, France; [Poncelet, P.] EMA LGI2P Site EERIE, F-30035 Nimes 1, France; [Teisseire, M.] CNRS, UMR 5506, LIRMM, F-34392 Montpellier 5, France	Masseglia, F (reprint author), Axis Project Team, INRIA Sophia Antipolis, 2004 Route Lucioles,POB BP 93, F-06902 Sophia Antipolis, France.	Florent.Masseglia@sophia.inria.fr; Pascal.Poncelet@ema.fr; teisseire@lirmm.fr; Alice.Marascu@sophia.inria.fr	Teisseire, Maguelonne/A-6576-2011				Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1995, P 11 INT C DAT ENG I; Bonchi F, 2001, DATA KNOWL ENG, V39, P165, DOI 10.1016/S0169-023X(01)00038-6; Cooley R., 1999, Knowledge and Information Systems, V1; Cormen T. H., 1994, INTRO ALGORITHMS; Fayad U., 1996, ADV KNOWLEDGE DISCOV; Han J., 2001, DATA MINING CONCEPTS; Hay B, 2004, KNOWL INF SYST, V6, P150, DOI 10.1007/s10115-003-0109-6; Kleinberg J., 2002, P 8 ACM SIGKDD INT C; KUM H, 2003, P SIAM INT C DAT MIN; Kumar R., 2003, WWW 03, P568; Masseglia F, 1998, LECT NOTES ARTIF INT, V1510, P176; Masseglia F., 1999, NETWORKING INFORMATI, V2, P571; MASSEGLIA F, 2005, P 2 WORKSH TEMP DAT; Meger N., 2004, P 8 EUR C PRINC PRAC, P313; Mobasher B, 2002, DATA MIN KNOWL DISC, V6, P61, DOI 10.1023/A:1013232803866; MUELLER A, 1995, CSTR3515; NAKAGAWA M, 2003, P IJCAI 03 WORKSH IN; NEUSS C, 1996, APPL CGI PERL WEBMAS; Pei J., 2001, PREFIXSPAN MINING SE; SPILIOPOULOU M, 1999, P WORKSH MACH LEARN; Srikant R., 1996, P 5 INT C EXT DAT TE; Tanasa D, 2004, IEEE INTELL SYST, V19, P59, DOI 10.1109/MIS.2004.1274912; ZHU J, 2002, P SOFTW BELF N IR, P60	24	10	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2008	16	1					39	65		10.1007/s10618-007-0080-z		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	245WP	WOS:000251969800003	
J	Wang, X; Kaban, A				Wang, Xin; Kaban, Ata			A dynamic bibliometric model for identifying online communities	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						online community identification; latent variable model; clustering; temporal delay; Markov chain	ORDER MARKOV-CHAINS; AGGLOMERATIVE CLUSTERING METHOD; EM ALGORITHM; MIXTURES	Predictive modelling of online dynamic user-interaction recordings and community identification from such data becomes more and more important with the widespread use of online communication technologies. Despite of the time-dependent nature of the problem, existing approaches of community identification are based on static or fully observed network connections. Here we present a new, dynamic generative model for the inference of communities from a sequence of temporal events produced through online computer- mediated interactions. The distinctive feature of our approach is that it tries to model the process in a more realistic manner, including an account for possible random temporal delays between the intended connections. The inference of these delays from the data then forms an integral part of our state-clustering methodology, so that the most likely communities are found on the basis of the likely intended connections rather than just the observed ones. We derive a maximum likelihood estimation algorithm for the identification of our model, which turns out to be computationally efficient for the analysis of historical data and it scales linearly with the number of non-zero observed (L + 1)-grams, where L is the Markov memory length. In addition, we also derive an incremental version of the algorithm, which could be used for real-time analysis. Results obtained on both synthetic and real-world data sets demonstrate the approach is flexible and able to reveal novel and insightful structural aspects of online interactions. In particular, the analysis of a full day worth synchronous Internet relay chat participation sequence, reveals the formation of an extremely clear community structure.	[Wang, Xin; Kaban, Ata] Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England	Wang, X (reprint author), Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England.	X.C.Wang@cs.bham.ac.uk; A.Kaban@cs.bham.ac.uk					Baldi P., 2003, MODELING INTERNET WE; Berchtold A, 2002, STAT SCI, V17, P328; BINGHAM E, 2006, P 6 SIAM INT C DAT M; BRIN S., 1998, COMPUTER NETWORKS IS, V30, p[1, 107]; Cadez I, 2003, DATA MIN KNOWL DISC, V7, P399, DOI 10.1023/A:1024992613384; Celeux G, 2001, J COMPUT GRAPH STAT, V10, P697, DOI 10.1198/106186001317243403; CHOUDHURY T, 2004, ADV NEURAL INFORM PR; Cohn D., 2000, P 17 INT C MACH LEAR, P167; Cooley R., 1999, Knowledge and Information Systems, V1; Danon L, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/09/P09008; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; FLAKE GW, 2002, IEEE COMPUT, V35, P66; Guedalia ID, 1999, NEURAL COMPUT, V11, P521, DOI 10.1162/089976699300016755; He X., 2001, P 2001 IEEE INT C DA, P195; Jain A.K., 1988, ALGORITHMS CLUSTERIN; KABAN A, 2006, 17 EUR C MACH LEARN, V4212, P246; Kaban A, 2007, MACH LEARN, V68, P63, DOI 10.1007/s10994-007-5008-8; KABAN A, 2004, P IEEE INT JOINT C N, P3287; Kleinberg J, 2003, DATA MIN KNOWL DISC, V7, P373, DOI 10.1023/A:1024940629314; KLEINBERG J., 2006, DATA STREAM MANAGEME; KLEINBERG J. M., 1999, JACM, V46, P5; KRISHNAN T, 1997, EM ALGORITH EXTENSIO; Manning C. D., 1999, FDN STAT NATURAL LAN; Neal R., 1999, LEARNING GRAPHICAL M, P355; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; Ng A, 2001, P 17 INT JOINT C ART, P903; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAFTERY AE, 1985, J ROY STAT SOC B MET, V47, P528; Ripley B, 1995, PATTERN RECOGNITION; Saul LK, 1999, MACH LEARN, V37, P75, DOI 10.1023/A:1007649326333; SAUL LK, 1997, CMPLG9706007 CORR; UEDA N, 1994, NEURAL NETWORKS, V7, P1211, DOI 10.1016/0893-6080(94)90003-5; Wang X, 2006, LECT NOTES COMPUT SC, V4224, P1023; Wasserman S, 1994, SOCIAL NETWORK ANAL; YPMA A, 2002, LECT NOTES COMPUTER, V2703, P35; Zhang DQ, 2005, NEURAL PROCESS LETT, V21, P45, DOI 10.1007/s11063-004-2793-y; Zhong S, 2005, IEEE IJCNN, P3180	37	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2008	16	1					67	107		10.1007/s10618-007-0081-y		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	245WP	WOS:000251969800004	
J	Vlachos, M; Wu, KL; Chen, SK; Yu, PS				Vlachos, Michail; Wu, Kun-Lung; Chen, Shyh-Kwei; Yu, Philip S.			Correlating burst events on streaming stock market data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						time-series; indexing; burst detection; correlation		We address the problem of monitoring and identification of correlated burst patterns in multi-stream time series databases. We follow a two-step methodology: first we identify the burst sections in our data and subsequently we store them for easy retrieval in an efficient in-memory index. The burst detection scheme imposes a variable threshold on the examined data and takes advantage of the skewed distribution that is typically encountered in many applications. The detected bursts are compacted into burst intervals and stored in an interval index. The index facilitates the identification of correlated bursts by performing very efficient overlap operations on the stored burst regions. We present the merits of the proposed indexing scheme through a thorough analysis of its complexity. We also manifest the real-time response of our burst indexing technique, and demonstrate the usefulness of the approach for correlating surprising volume trading events using historical stock data of the NY stock exchange. While the focus of this work is on financial data, the proposed methods and data-structures can find applications for anomaly or novelty detection in telecommunication, network traffic and medical data.	[Vlachos, Michail; Wu, Kun-Lung; Chen, Shyh-Kwei; Yu, Philip S.] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Vlachos, M (reprint author), IBM TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.						Cormode G, 2005, SIAM PROC S, P44; Dovrolis C., 2005, P ACM SIGMETRICS, P241, DOI 10.1145/1064212.1064240; Friss-Christensen E., 1991, SCIENCE, V245, P698; Guttman A., 1984, P ACM SIGMOD INT C M, P47; Hanson EN, 1996, INFORM SYST, V21, P269, DOI 10.1016/0306-4379(96)00015-4; Harries M., 1995, Eighth Australian Joint Conference on Artificial Intelligence; HEYER LJ, 1999, GENOME RES, V9, P11; Kleinberg J, 2002, P 8 ACM SIGKDD INT C, P91, DOI DOI 10.1023/A:1024940629314; LAEVEN R, 2001, SLEEP WAKE RES NETHE, V12, P75; Lazarescu M. M., 2004, Intelligent Data Analysis, V8; Leland Will E., 1993, P ACM SIGCOMM 93 SAN, P183; LERNER A, 2003, IEEE DATA ENG B, P49; LIU B, 2006, P ACM CIKM, P836, DOI 10.1145/1183614.1183755; Lux T, 1996, APPL ECON LETT, V3, P701, DOI 10.1080/135048596355691; Muthuswamy J, 1999, IEEE T BIO-MED ENG, V46, P92, DOI 10.1109/10.736762; NGYEN TM, 2004, P PAKM; Scott SL, 2004, COMPUT STAT DATA AN, V45, P69, DOI 10.1016/S0167-9473(03)00177-4; SHASHA D, 2005, TR2005876; Stern L, 1999, EPIDEMIOL INFECT, V122, P103, DOI 10.1017/S0950268898001939; Turiel A, 2003, PHYSICA A, V322, P629, DOI 10.1016/S0378-4371(02)01830-7; Vlachos M., 2005, P PKDD, P368; VLACHOS M, 2004, P ACM SIGMOD INT C M, P131, DOI DOI 10.1145/1007568.1007586; WIDDOWSON MA, 2003, EMERG INFECT DIS, V9, P9; WONG WK, 2003, J URBAN HEALTH, V80, P66; WU KL, 2004, P ACM CIKM, P88, DOI 10.1145/1031171.1031188; Zhu Y., 2003, P 9 ACM SIGKDD INT C, P336	26	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2008	16	1					109	133		10.1007/s10618-007-0066-x		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	245WP	WOS:000251969800005	
J	Prabakaran, S; Sahu, R; Verma, S				Prabakaran, S.; Sahu, Rajendra; Verma, Sekher			Classification of multi class dataset using wavelet power spectrum	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						multi class; wavelet power spectrum; feature selection; RPV	GENE-EXPRESSION; DISCOVERY; CANCER; PREDICTION; PATTERNS	Data mining techniques are widely used in many fields. One of the applications of data mining in the field of the Bioinformatics is classification of tissue samples. In the present work, a wavelet power spectrum based approach has been presented for feature selection and successful classification of the multi class dataset. The proposed method was applied on SRBCT and the breast cancer datasets which are multi class cancer datasets. The selected features are almost those selected in previous works. The method was able to produce almost 100% accurate classification results. The method is very simple and robust to noise. No extensive preprocessing is required. The classification was performed with comparatively very lesser number of features than those used in the original works. No information is lost due to the initial pruning of the data usually performed using a threshold in other methods. The method utilizes the inherent nature of the data in performing various tasks. So, the method can be used for a wide range of data.	Ind Inst Informat Technol & Management, Gwalior 474010, India	Prabakaran, S (reprint author), Ind Inst Informat Technol & Management, Morena Link Rd, Gwalior 474010, India.	drpra@rediffmail.com					ABRAMOVICH F, 2000, JRSSD, V48, P1; ALDRUBI A, 1996, WAVELETS MED BIOL; Azuaje F, 2002, ANN MED, V34, P299, DOI 10.1080/078538902320322565; Azuaje F, 2001, IEEE T BIO-MED ENG, V48, P332, DOI 10.1109/10.914796; Bittner M, 1999, NAT GENET, V22, P213, DOI 10.1038/10265; Chui C. K., 1992, INTRO WAVELETS; DAUBECHIES T, 1992, 10 LECT WAVELETS; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dougherty ER, 2001, COMPAR FUNCT GENOM, V2, P28, DOI 10.1002/cfg.62; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HAN J, 2001, DATA MINING CONCEPTS, P121; KAPLAN J, 2001, SPECTRAL ANAL FILTER; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Li T., 2003, SIGKDD EXPLORATIONS, V4, P49; Lio P, 2003, BIOINFORMATICS, V19, P2, DOI 10.1093/bioinformatics/19.1.2; Lobenhofer EK, 2001, ENVIRON HEALTH PERSP, V109, P881, DOI 10.2307/3454988; Mallat S., 1998, WAVELET TOUR SIGNAL; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Rifkin R, 2003, SIAM REV, V45, P706, DOI 10.1137/S0036144502411986; SOUTHERN EM, 1975, J MOL BIOL, V98, P503, DOI 10.1016/S0022-2836(75)80083-0; STRANG G, 1989, SIAM REV, V31, P614, DOI 10.1137/1031128; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tan Aik Choon, 2003, Appl Bioinformatics, V2, pS75; Thomas JG, 2001, GENOME RES, V11, P1227, DOI 10.1101/gr.165101; Witten Ian H., 2005, DATA MINING PRACTICA; Zhou XB, 2004, J FRANKLIN I, V341, P137, DOI 10.1016/j.jfranklin.2003.12.010; Zhou XB, 2004, J COMPUT BIOL, V11, P147, DOI 10.1089/106652704773416939	28	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2007	15	3					297	319		10.1007/s10618-007-0068-8		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	223WU	WOS:000250407100001	
J	Yin, XX; Han, JW; Yu, PS				Yin, Xiaoxin; Han, Jiawei; Yu, Philip S.			CrossClus: user-guided multi-relational clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						relational data mining; clustering	FEATURE-SELECTION	Most structured data in real-life applications are stored in relational databases containing multiple semantically linked relations. Unlike clustering in a single table, when clustering objects in relational databases there are usually a large number of features conveying very different semantic information, and using all features indiscriminately is unlikely to generate meaningful results. Because the user knows her goal of clustering, we propose a new approach called CrossClus, which performs multi-relational clustering under user's guidance. Unlike semi-supervised clustering which requires the user to provide a training set, we minimize the user's effort by using a very simple form of user guidance. The user is only required to select one or a small set of features that are pertinent to the clustering goal, and CrossClus searches for other pertinent features in multiple relations. Each feature is evaluated by whether it clusters objects in a similar way with the user specified features. We design efficient and accurate approaches for both feature selection and object clustering. Our comprehensive experiments demonstrate the effectiveness and scalability of CrossClus.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; IBM TJ Watson Res Ctr, Yorktown Hts, NY USA	Yin, XX (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	xyin1@cs.uiuc.edu; hanj@cs.uiuc.edu; psyu@us.ibm.com					Aggarwal C. C., 2000, P ACM SIGMOD INT C M, P70, DOI 10.1145/342009.335383; AGGARWAL CC, 2000, P 1999 ACM SIGMOD IN, P61; Bilenko M., 2004, P 21 INT C MACH LEAR, P81; Blockeel H, 2002, J ARTIF INTELL RES, V16, P135; Cheeseman P., 1988, P 5 INT C MACH LEARN, P54; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523; Dy JG, 2004, J MACH LEARN RES, V5, P845; Emde W., 1996, P 13 INT C MACH LEAR, P122; Gartner T, 2004, MACH LEARN, V57, P205, DOI 10.1023/B:MACH.0000039777.23772.30; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M. A., 2000, P 17 INT C MACH LEAR, P359; Hristidis V., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kaufman L., 1990, FINDING GROUPS DATA; Klein D., 2002, P 19 INT C MACH LEAR, P307; KRISTEN M, 2000, P 2000 INT WORKSH IN, P112; KRISTEN M, 1998, P 1998 INT WORKSH IN, P261; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Mitchell T. M, 1997, MACHINE LEARNING; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Quinlan J. R., 1993, P EUR C MACH LEARN, P3; RT NG, 1994, P 1994 INT C VER LAR, P144; Tan P.N, 2005, INTRO DATA MINING; Wagstaff K., 2001, P 18 INT C MACH LEAR, P577; Xing E. P, 2002, P ADV NEUR INF PROC, P505; Yin X., 2005, P 2005 ACM SIGKDD IN, P344, DOI 10.1145/1081870.1081910; Yin XX, 2004, PROC INT CONF DATA, P399; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	28	10	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2007	15	3					321	348		10.1007/s10618-007-0072-z		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	223WU	WOS:000250407100002	
J	Wong, W; Liu, W; Bennamoun, M				Wong, Wilson; Liu, Wei; Bennamoun, Mohammed			Tree-Traversing Ant Algorithm for term clustering based on featureless similarities	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						ontology learning; text mining; term clustering; concept discovery; cluster analysis; featureless similarity measures		Many conventional methods for concepts formation in ontology learning have relied on the use of predefined templates and rules, and static resources such as WordNet. Such approaches are not scalable, difficult to port between different domains and incapable of handling knowledge fluctuations. Their results are far from desirable, either. In this paper, we propose a new ant-based clustering algorithm, Tree-Traversing Ant (TTA), for concepts formation as part of an ontology learning system. With the help of Normalized Google Distance (NGD) and n degrees of Wikipedia (n degrees W) as measures for similarity and distance between terms, we attempt to achieve an adaptable clustering method that is highly scalable and portable across domains. Evaluations with an seven datasets show promising results with an average lexical overlap of 97% and ontological improvement of 48%. At the same time, the evaluations demonstrated several advantages that are not simultaneously present in standard ant-based and other conventional clustering methods.	Univ Western Australia, Sch Comp Sci & Software Engn, Crawley, WA 6009, Australia	Liu, W (reprint author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	wilson@csse.uwa.edu.au; wei@csse.uwa.edu.au; bennamou@csse.uwa.edu.au					Bennett CH, 1998, IEEE T INFORM THEORY, V44, P1407, DOI 10.1109/18.681318; Berkhin P., 2002, SURVEY CLUSTERING DA; CHOI B, 2005, FDN ADV DATA MINING; CILIBRASI R, 2006, P IEEE INT S INF THE; CILIBRASI R, 2005, AUTOMATIC MEANING DI; Cimiano P., 2005, P WORKSH LEARN EXT L; DELLSCHAFT K., 2006, P 5 INT SEM WEB C IS; DENEUBOURG J, 1991, P 1 INT C SIM AD BEH; FAURE D., 2000, P 1 WORKSH ONT LEARN; FAURE D., 1998, P 1 INT C LANG RES E; Gomez-Perez A, 2003, SURVEY ONTOLOGY LEAR; Grunwald P. D., 2003, Journal of Logic, Language and Information, V12, DOI 10.1023/A:1025011119492; GUTOWITZ H, 1993, P 3 EUR C ART LIF; HANDL J, 2002, P 7 INT C PAR PROBL; Handl J, 2006, ARTIF LIFE, V12, P35, DOI 10.1162/106454606775186400; Handl J., 2003, TRIRIDIA200324 U LIB; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; LAGUS L, 1996, P 2 INT C KNOWL DISC; LELEWER DA, 1987, ACM COMPUT SURV, V19, P261, DOI 10.1145/45072.45074; Lumer E., 1994, P 3 INT C SIM AD BEH, V3; MAEDCHE A, 2002, P EUR C KNOW ACQ MAN; MAEDCHE A., 2001, P IEEE INT C DAT MIN; RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171; SABOU M., 2005, P 14 INT C WORLD WID; Shamsfard M, 2004, INT J HUM-COMPUT ST, V60, P17, DOI [10.1016/j.ijhcs.2003.08.001, 10.1016/jijhcs.2003.08.001]; SHAMSFARD M, 2002, P 7 2R C E6 ENG TEHR; Steinbach M., 2000, 00034 U MINN; VITANYI P, 2005, P IEEE ITSOC INF THE; Vizine A. L., 2005, Informatica, V29; WONG W, 2006, P INT S PRACT COGN A; YAO Z, 2003, P IEEE WIC INT C WEB	31	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2007	15	3					349	381		10.1007/s10618-007-0073-y		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	223WU	WOS:000250407100003	
J	Malthouse, EC				Malthouse, Edward C.			Mining for trigger events with survival analysis	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						survival analysis; customer lifetime value; CRM; trigger events; one-to-one marketing; time-dependent covariates	CUSTOMER LIFETIME VALUE	This paper discusses a new application of data mining, quantifying the importance of responding to trigger events with reactive contacts. Trigger events happen during a customer's lifecycle and indicate some change in the relationship with the company. If detected early, the company can respond to the problem and retain the customer; otherwise the customer may switch to another company. It is usually easy to identify many potential trigger events. What is needed is a way of prioritizing which events demand interventions. We conceptualize the trigger event problem and show how survival analysis can be used to quantify the importance of addressing various trigger events. The method is illustrated on four real data sets from different industries and countries.	Northwestern Univ, Evanston, IL 60208 USA	Malthouse, EC (reprint author), Northwestern Univ, 1845 Sheridan Rd, Evanston, IL 60208 USA.	ecm@northwestern.edu					ABE N, 2004, KDD 04 P 10 ACM SIGK, P767; Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Allison PD, 1996, SOCIOL METHOD RES, V25, P207, DOI 10.1177/0049124196025002003; ALLISONN P, 1995, SURVIVAL ANAL USING; Chamberlain G., 1985, LONGITUDINAL ANAL LA, P3, DOI 10.1017/CCOL0521304539.001; Fader PS, 2005, J MARKETING RES, V42, P415, DOI 10.1509/jmkr.2005.42.4.415; JONES TO, 1995, HARVARD BUSINESS REV; MANNILA H, 2002, HDB DATA MINING KNOW, P344; Pfeifer PE, 2005, J INTERACT MARK, V19, P48, DOI 10.1002/dir.20049; Rosset S, 2003, DATA MIN KNOWL DISC, V7, P321, DOI 10.1023/A:1024036305874; SHEPARD D, 1999, NEW DIRECT MARKETING; Therneau T., 2000, MODELING SURVIVAL DA; ZADROZNY B, 2001, P KDD 2001, P201	14	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	2007	15	3					383	402		10.1007/s10618-007-0074-x		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	223WU	WOS:000250407100004	
J	Lin, J; Keogh, E; Wei, L; Lonardi, S				Lin, Jessica; Keogh, Eamonn; Wei, Li; Lonardi, Stefano			Experiencing SAX: a novel symbolic representation of time series	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						time series; data mining; symbolic representation; discretize		Many high level representations of time series have been proposed for data mining, including Fourier transforms, wavelets, eigenwaves, piecewise polynomial models, etc. Many researchers have also considered symbolic representations of time series, noting that such representations would potentiality allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities. While many symbolic representations of time series have been introduced over the past decades, they all suffer from two fatal flaws. First, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Second, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. In this work we formulate a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. In particular, we will demonstrate the utility of our representation on various data mining tasks of clustering, classification, query by content, anomaly detection, motif discovery, and visualization.	George Mason Univ, Informat & Software Engn Dept, Fairfax, VA 22030 USA; Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA	Lin, J (reprint author), George Mason Univ, Informat & Software Engn Dept, Fairfax, VA 22030 USA.	jessica@ise.gmu.edu					Agrawal R., 1995, P 21 INT C VER LARG, P502; ANDREJONSSON H, 1997, 1 EUR S TRONDH NORW, P211; ANDROULAKIS IP, 2005, P 15 EUR S COMP AID; Apostolico A., 2002, P 6 INT C RES COMP M, P22, DOI 10.1145/565196.565200; Bagnall A, 2004, P ACM KDD 04 SEATTL, P49, DOI 10.1145/1014052.1014061; BAKALOV P, 2005, P ACM INT S ADV GEOG; BASTOGNE T., 2002, P 4 EUR CONTR C BRUS; BERNDT D, 1994, 12 INT C ART INT SEA, P229; CAHN K, 1999, P INT DAT ENG SYDN M, P126; CELLY B, 2004, P 17 INT C COMP AN S; Cheng MF, 2005, BMC INFECT DIS, V5, DOI 10.1186/1471-2334-5-22; Chiu B., 2003, P 9 ACM SIGKDD INT C, P493; DASGUPTA D, 1999, P 8 INT C INT DENV C; Daw CS, 2003, REV SCI INSTRUM, V74, P915, DOI 10.1063/1.1531823; Ding C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183897; DUCHENE F, 2005, P C FRAN APPR AUT NI; DUCHENE F, 2004, 10702 I INF MATH APP; Durbin R., 1998, BIOL SEQUENCE ANAL P; FALOUTSOS C, 1994, FAST SUBSEQUENCE MAT, V23, P419; FERREIRA PG, 2006, P 9 INT C DISC SCI B; Gavrilov M., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347189; Geurts P., 2001, P 5 EUR C PRINC DAT, P115; Gionis A, 2003, P 7 INT C RES COMP M, P123, DOI 10.1145/640075.640091; Hellerstein J. M., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263688; Huang YW, 1999, P 5 INT C KNOWL DISC, P282, DOI 10.1145/312129.318357; HUGUENEY B, 2006, P 10 EUR C PRINC PRA, P545; Kalpakis K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989529; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Keogh E., 2001, J KNOWL INF SYST, V3, P263; Keogh E., 2002, P 8 ACM SIGKDD INT C, P550; Keogh E., 2005, P 5 IEEE INT C DAT M, P226; Kumar N, 2005, SIAM PROC S, P531; LARSEN RJ, 1986, INTRO MATH STAT APPL; LIN J, 2003, 8 ACM SIGMOD SAN DIE; Lin J., 2005, Information Visualization, V4, DOI 10.1057/palgrave.ivs.9500089; Lin J., 2002, 8 ACM SIGKDD INT C K, P53; LIN J, 2006, P 10 EUR C PRINC PRA, P284; Lin J., 2004, P 10 ACM SIGKDD INT, P460, DOI 10.1145/1014052.1014104; Lkhagva B., 2006, P 22 INT C DAT ENG W, P115; LONARDIS S, 2001, GLOBAL DETECTORS UNU; MCGOVERN A, 2006, P ICML WORKSH OP PRO; Morchen F., 2005, P 11 ACM SIGKDD INT, P660, DOI 10.1145/1081870.1081953; MURAKAMI K, 2004, P JSME C ROB MECH NA; OHSAKI M, 2006, 14 EUR C MACH LEARN; POUGET F, 2006, P 18 ANN 1 C BALT MD; RATANAMAHATANA CA, 2005, P ADV KNOWL DISC DAT, P771; Reinert G, 2000, J COMPUT BIOL, V7, P1, DOI 10.1089/10665270050081360; RODDICK JF, 2001, POST WORKSH P INT WO, P147; Shahabi C., 2000, Proceedings. 12th International Conference on Scientific and Statistica Database Management, DOI 10.1109/SSDM.2000.869778; SILVENT A, 2003, P INT DAT AN MED PHA; SILVENT A, 2004, MULT LEV TEMP ABSTR; STADEN R, 1989, COMPUT APPL BIOSCI, V5, P293; TANAKA Y, 2004, P 18 ANN C JAP SOC A; TANAKA Y, 2003, P 3 INT C MACH LEARN, P252; TOMPA M., 2001, P 5 INT C COMP MOL B, P67; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; WEI L, 2006, P 2006 IEEE INT C DA; Yi B.K., 2000, P 26 INT C VER LARG, P385; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680; *NIST EMATECH, 2003, E HDB STAT METH	62	70	76	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2007	15	2					107	144		10.1007/s10618-007-0064-z		38	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	202IC	WOS:000248894200001	
J	Wen, L; van der Aalst, WMP; Wang, J; Sun, J				Wen, Lijie; van der Aalst, Wil M. P.; Wang, Jianmin; Sun, Jiaguang			Mining process models with non-free-choice constructs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						process mining; implicit dependency; event log; non-free-choice constructs	WORKFLOW MANAGEMENT; EVENT LOGS; BEHAVIOR	Process mining aims at extracting information from event logs to capture the business process as it is being executed. Process mining is particularly useful in situations where events are recorded but there is no system enforcing people to work in a particular way. Consider for example a hospital where the diagnosis and treatment activities are recorded in the hospital information system, but where health-care professionals determine the "careflow." Many process mining approaches have been proposed in recent years. However, in spite of many researchers' persistent efforts, there are still several challenging problems to be solved. In this paper, we focus on mining non-free-choice constructs, i.e., situations where there is a mixture of choice and synchronization. Although most real-life processes exhibit non-free-choice behavior, existing algorithms are unable to adequately deal with such constructs. Using a Petri-net-based representation, we will show that there are two kinds of causal dependencies between tasks, i.e., explicit and implicit ones. We propose an algorithm that is able to deal with both kinds of dependencies. The algorithm has been implemented in the ProM framework and experimental results shows that the algorithm indeed significantly improves existing process mining techniques.	Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China; Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands	Wen, L (reprint author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.	wenlj00@mails.tsinghua.edu.cn	van der Aalst, Wil/G-1248-2011	van der Aalst, Wil/0000-0002-0955-6940			Agrawal R., 1998, 6 INT C EXT DAT TECH, P469; ANDREWS T, 2003, BUSINESS PROCES EXEC; BIERMANN AW, 1972, FRONTIERS PATTERN RE, P31; BIERMANN AW, 1972, IEEE T COMPUT, VC 21, P592; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Cook JE, 2005, J SYST SOFTWARE, V77, P285, DOI 10.1016/j.jss.2004.04.029; Cook JE, 2004, COMPUT IND, V53, P297, DOI 10.1016/j.compind.2003.10.005; Datta A, 1998, INFORM SYST RES, V9, P275, DOI 10.1287/isre.9.3.275; de Medeiros AKA, 2004, LECT NOTES COMPUTER, V3272, P154; DEMEDEIROS AAK, 2005, P 6 WORKSH PRACT US, V576, P177; de Medeiros AKA, 2003, LECT NOTES COMPUT SC, V2888, P389; Desel J, 1995, FREE CHOICE PETRI NE, V40; DESEL J, 2004, LECT CONCURRENCY PET; Dumas M, 2005, PROCESS-AWARE INFORMATION SYSTEMS: BRIDGING PEOPLE AND SOFTWARE THROUGH PROCESS TECHNOLOGY, P1, DOI 10.1002/0471741442; Ehrenfeucht A., 1989, ACTA INFORM, V27, P315; GRECO G, 2004, 8 PAC AS C PAKDD 200, P52; Grigori D, 2004, COMPUT IND, V53, P321, DOI 10.1016/j.compind.2003.10.007; Grigori D., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Harel D, 2005, LECT NOTES COMPUT SC, V3393, P309; Herbst J, 2000, LECT NOTES ARTIF INT, V1810, P183; IDS Scheer, 2002, ARIS PROC PERF MAN A; Jablonski S., 1996, WORKFLOW MANAGEMENT; KELLER G., 1992, SEMANTISCHE PROCESSM; Leymann F., 1999, PRODUCTION WORKFLOW; Liang H., 2006, P 2006 INT WORKSH SC; Parekh R, 2001, MACH LEARN, V44, P9, DOI 10.1023/A:1010822518073; PAREKH R, 1996, INT C GRAMM INF LEAR, P238; ROZINAT A, 2005, 1 INT WORKSH BUS PRO, P1; Rozinat A, 2006, LECT NOTES COMPUT SC, V3812, P163; Sayal M., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; Scheer A-W, 2000, ARIS BUSINESS PROCES; Scott J., 1992, SOCIAL NETWORK ANAL; TIBCO, 2005, TIBCO STAFFW PROC MO; van der Aalst W. M. P., 2002, WORKFLOW MANAGEMENT; van der Aalst W.M.P., 2004, P 5 WORKSH BUS PROC, V2, P138; van der Aalst WMP, 2004, LECT NOTES COMPUT SC, V3098, P1; van Dongen B.F., 2005, P CAISE 05 WORKSH EM, P309; Van der Aalst WMP, 1998, J CIRCUIT SYST COMP, V8, P21, DOI 10.1142/S0218126698000043; VANDERAALST WMP, 2005, LECT NOTES COMPUTER, V3536; van der Aalst WMP, 2006, LECT NOTES COMPUT SC, V4102, P129; van der Aalst WMP, 2003, DATA KNOWL ENG, V47, P237, DOI 10.1016/S0169-023X(03)00066-1; van der Aalst WMP, 2005, DATA KNOWL ENG, V53, P129, DOI 10.1016/j.datak.2004.07.003; VANDERAALST WMP, 2005, BPM0525; VANDERAALST WMP, 2004, PROCESS MINING SPECI, V53; VANDERAALST WMP, 2004, 2 INT WORKSH SEC ISS; VANDERAALST WMP, 2004, INT C BUS PROC MAN B, P244; van der Aalst WMP, 2005, INFORM SYST, V30, P245, DOI 10.1016/j.is.2004.02.002; van Dongen BF, 2005, LECT NOTES COMPUT SC, V3536, P444; WANDERAALST WMP, 2004, IEEE T KNOWL DATA EN, V16, P1128; Weijters A. J. M. M., 2002, P ECAI WORKSH KNOWL, P78; Weijters AJMM, 2003, INTEGR COMPUT-AID E, V10, P151; WEN L, 2004, BETA WORKIN PAPER SE, V118; Wen LJ, 2006, LECT NOTES COMPUT SC, V3841, P591; ZUEMUHLEN MR, 2000, P 33 HAW INT C SYST, P1; *PALL ATH, 2004, PROT US MAN	55	32	42	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2007	15	2					145	180		10.1007/s10618-007-0065-y		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	202IC	WOS:000248894200002	
J	Morchen, F; Ultsch, A				Moerchen, Fabian; Ultsch, Alfred			Efficient mining of understandable patterns from multivariate interval time series	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						knowledge discovery; time series; interval patterns; Allen's relations	CLOSED ITEMSETS; KNOWLEDGE DISCOVERY; SEQUENCES	We present a new method for the understandable description of local temporal relationships in multivariate data, called Time Series Knowledge Mining (TSKM). We define the Time Series Knowledge Representation (TSKR) as a new language for expressing temporal knowledge in time interval data. The patterns have a hierarchical structure, with levels corresponding to the temporal concepts duration, coincidence, and partial order. The patterns are very compact, but offer details for each element on demand. In comparison with related approaches, the TSKR is shown to have advantages in robustness, expressivity, and comprehensibility. The search for coincidence and partial order in interval data can be formulated as instances of the well known frequent itemset problem. Efficient algorithms for the discovery of the patterns are adapted accordingly. A novel form of search space pruning effectively reduces the size of the mining result to ease interpretation and speed up the algorithms. Human interaction is used during the mining to analyze and validate partial results as early as possible and guide further processing steps. The efficacy of the methods is demonstrated using two real life data sets. In an application to sports medicine the results were recognized as valid and useful by an expert of the field.	Siemens Corp Res, Princeton, NJ 08540 USA; Univ Marburg, Databion Res Grp, Marburg, Germany	Morchen, F (reprint author), Siemens Corp Res, Princeton, NJ 08540 USA.	fabian.moerchen@siemens.com					Afrati F. N., 2004, P 10 ACM SIGKDD INT, P12, DOI 10.1145/1014052.1014057; AGGARWAL CC, 2001, P 7 ACM SIGKDD INT C, P221, DOI 10.1145/502512.502542; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Aiello M., 2002, International Journal on Document Analysis and Recognition, V5, DOI 10.1007/s10032-002-0080-x; Allen J.F., 1983, COMMUN ACM, V26, P11; Ankerst M., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347124; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Belazzi R, 2005, ARTIF INTELL MED, V34, P25, DOI 10.1016/j.artmed.2004.07.010; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Bykowski A, 2001, P 20 ACM SIGACT SIGM, P267, DOI 10.1145/375551.375604; CALDERS T, 2003, P 7 EUR C PRINC PRAC, P71; Casas-Garriga G, 2005, SIAM PROC S, P380; CHEN G, 2006, CS0504 U VERM BURL; CHENG J., 2006, P 6 IEEE INT C DAT M, P139; COHEN PR, 2001, P 4 INT C INT DAT AN, P268; Dubois D, 2006, DATA MIN KNOWL DISC, V13, P167, DOI 10.1007/s10618-005-0032-4; FERN A, 2004, THESIS PURDUE U W LA; GIONIS A, 2004, 10 ACM SIGKDD INT C; Grice H. P., 1989, STUDIES WAY WORDS; GUIMARAES G, 1998, THESIS PHILIPS U MAR; Guimaraes G., 1999, P IDA99 3 S INT DAT, P369; GUIMARAES G, 1997, P 20 ANN C GERM CLAS, P105; HOOS O, 2003, BEWEGUNGSSTRUKTUR BE; HOPPNER F, 2003, THESIS TECHNICAL U B; HOPPNER F., 2001, P 5 EUR C PRINC PRAC, P192; Kam P.-S., 2000, P 2 INT C DAT WAR KN, P317; Keogh E., 2004, DATA MINING TIME SER, P1; Hoppner F., 2002, Intelligent Data Analysis, V6; Kryszkiewicz M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989533; Last M, 2001, IEEE T SYST MAN CY B, V31, P160, DOI 10.1109/3477.907576; LIN J, 2002, 8 ACM SIGKDD INT C K; Lin J., 2004, P 10 ACM SIGKDD INT, P460, DOI 10.1145/1014052.1014104; Lin M.-Y., 2002, P 4 INT C DAT WAR KN, P150; Lucchese C, 2006, IEEE T KNOWL DATA EN, V18, P21, DOI 10.1109/TKDE.2006.10; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; MOONEY C, 2004, P 4 SIAM INT C DAT M; Morchen F., 2005, P 11 ACM SIGKDD INT, P660, DOI 10.1145/1081870.1081953; MORCHEN F, 2004, P 8 EUR C PRINC PRAC, P512; MORCHEN F, 2006, INT J KNOWL BASED IN, V9, P197; Morchen F., 2006, WORKSH TEMP DAT 12 A, P25; Morchen F., 2006, P 12 ACM SIGKDD INT; Palpanas T, 2004, PROC INT CONF DATA, P338; PALPANAS T., 2004, P 30 INT C VER LARG, P780; Papadimitriou S., 2005, P 31 INT C VER LARG, P697; Papapetrou P., 2005, P354; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J., 2002, P 2002 IEEE INT C DA, P378; Pei J, 2006, IEEE T KNOWL DATA EN, V18, P1467, DOI 10.1109/TKDE.2006.172; PEI J, 2001, 20 ACM SIGMOD SIGACT; Pudi V, 2003, PROC INT CONF DATA, P714; Rainsford CP, 1999, LECT NOTES ARTIF INT, V1704, P504; Roddick JF, 2005, IEEE T KNOWL DATA EN, V17, P133, DOI 10.1109/TKDE.2005.12; Schwalb E., 1997, TEMPORAL CONSTRAINTS; Seppanen JK, 2004, P 10 ACM SIGKDD INT, P683, DOI 10.1145/1014052.1014140; Shneiderman B., 1996, Proceedings. IEEE Symposium on Visual Languages (Cat. No.96TB100066), DOI 10.1109/VL.1996.545307; Siskind JM, 2001, J ARTIF INTELL RES, V15, P31; SRIPADA SG, 2003, P 9 ACM SIGKDD INT C, P187; ULTCH A, 1999, KOHENEN MAPS, P33; ULTSCH A, 1996, UNIFIKATIONSBASIERTE; ULTSCH A, 2004, 37 PHIL U MARB DEP M; Vilain M., 1989, READINGS QUALITATIVE, P373; Villafane R, 2000, J INTELL INF SYST, V15, P71, DOI 10.1023/A:1008781812242; WANG J., 2005, P 5 IEEE INT C DAT M, P753; Wang JY, 2004, PROC INT CONF DATA, P79, DOI 10.1109/ICDE.2004.1319986; WINARKO E, 2007, DATA KNOWL ENG; Yahia S. B., 2006, ACM SIGKDD EXPLORATI, V8, P93, DOI 10.1145/1147234.1147248; Yan XF, 2003, SIAM PROC S, P166; Yan X., 2005, P 11 ACM SIGKDD INT, P314, DOI 10.1145/1081870.1081907; Yang H, 2001, MOL BREEDING, V7, P203, DOI 10.1023/A:1011363205557; Zaki MJ, 2002, SIAM PROC S, P457; Zaki MJ, 2005, IEEE T KNOWL DATA EN, V17, P462, DOI 10.1109/TKDE.2005.60; [Anonymous], 2006, THESIS PHILIPPS U MA	72	12	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2007	15	2					181	215		10.1007/s10618-007-0070-1		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	202IC	WOS:000248894200003	
J	Sacchi, L; Larizza, C; Combi, C; Bellazzi, R				Sacchi, Lucia; Larizza, Cristiana; Combi, Carlo; Bellazzi, Riccardo			Data mining with temporal abstractions: learning rules from time series	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						temporal data mining; rule discovery; temporal abstractions; biomedical time series	KNOWLEDGE DISCOVERY; SEQUENTIAL PATTERNS; ASSOCIATION RULES; MODEL	A large volume of research in temporal data mining is focusing on discovering temporal rules from time-stamped data. The majority of the methods proposed so far have been mainly devoted to the mining of temporal rules which describe relationships between data sequences or instantaneous events and do not consider the presence of complex temporal patterns into the dataset. Such complex patterns, such as trends or up and down behaviors, are often very interesting for the users. In this paper we propose a new kind of temporal association rule and the related extraction algorithm; the learned rules involve complex temporal patterns in both their antecedent and consequent. Within our proposed approach, the user defines a set of complex patterns of interest that constitute the basis for the construction of the temporal rule; such complex patterns are represented and retrieved in the data through the formalism of knowledge-based Temporal Abstractions. An Apriori-like algorithm looks then for meaningful temporal relationships (in particular, precedence temporal relationships) among the complex patterns of interest. The paper presents the results obtained by the rule extraction algorithm on a simulated dataset and on two different datasets related to biomedical applications: the first one concerns the analysis of time series coming from the monitoring of different clinical variables during hemodialysis sessions, while the other one deals with the biological problem of inferring relationships between genes from DNA microarray data.	Univ Pavia, Dipartimento Informat & Sistemist, I-27100 Pavia, Italy; Univ Verona, Dipartimento Informat, I-37100 Verona, Italy	Sacchi, L (reprint author), Univ Pavia, Dipartimento Informat & Sistemist, Via Palestro 3, I-27100 Pavia, Italy.	lucia.sacchi@unipv.it					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; ALLEN JF, 1984, ARTIF INTELL, V23, P123, DOI 10.1016/0004-3702(84)90008-0; Belazzi R, 2005, ARTIF INTELL MED, V34, P25, DOI 10.1016/j.artmed.2004.07.010; Bellazzi R., 1998, INTELL DATA ANAL, V2, P97, DOI DOI 10.1016/S1088-467X(98)00020-1; BELLAZZI R, 2003, P 9 C ART INT MED AI, P11; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; Chen JQ, 1998, FUZZY SET SYST, V98, P319, DOI 10.1016/S0165-0114(96)00384-3; Chiu B., 2003, P 9 ACM SIGKDD INT C, P493; COHEN PR, 2001, P 4 INT C INT DAT AN, P268; Combi C, 1999, ARTIF INTELL MED, V17, P271, DOI 10.1016/S0933-3657(99)00022-6; Guimaraes G., 1999, P IDA99 3 S INT DAT, P369; Guimaraes G, 2001, ARTIF INTELL MED, V23, P211, DOI 10.1016/S0933-3657(01)00089-6; HAIMOWITZ IJ, 1993, P 13 INT JOINT C ART, P146; Hau DT, 1997, MACH LEARN, V26, P177, DOI 10.1023/A:1007317323969; HOPPNER F, 2002, INTELLIGENT SYSTEMS, V4, P201; HOPPNER F, 2003, THESIS TECHNICAL U B; Kam P.-S., 2000, P 2 INT C DAT WAR KN, P317; Keogh E., 2004, DATA MINING TIME SER, P1; Hoppner F., 2002, Intelligent Data Analysis, V6; KUIPERS B, 1986, ARTIF INTELL, V29, P289, DOI 10.1016/0004-3702(86)90073-1; Larizza C., 1992, Artificial Intelligence in Medicine, V4, DOI 10.1016/0933-3657(92)90049-U; Last M, 2001, IEEE T SYST MAN CY B, V31, P160, DOI 10.1109/3477.907576; Li YJ, 2003, DATA KNOWL ENG, V44, P193, DOI 10.1016/S0169-023X(02)00135-0; Lin MY, 2005, J INF SCI ENG, V21, P109; Lin W., 2002, P 1 AUSTR DAT MIN WO, P83; Papapetrou P., 2005, P354; Roddick JF, 2002, IEEE T KNOWL DATA EN, V14, P750, DOI 10.1109/TKDE.2002.1019212; Sacchi L., 2005, Proceedings. 18th IEEE Symposium on Computer-Based Medical Systems; Sacchi L, 2005, INT J MED INFORM, V74, P505, DOI 10.1016/j.ijmedinf.2005.03.014; Shah A, 1997, J ROY SOC MED, V90, P1; Shahar Y, 1996, ARTIF INTELL MED, V8, P267, DOI 10.1016/0933-3657(95)00036-4; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; Tung AKH, 2003, IEEE T KNOWL DATA EN, V15, P43, DOI 10.1109/TKDE.2003.1161581; Tyson JJ, 2001, NAT REV MOL CELL BIO, V2, P908, DOI 10.1038/35103078; Villafane R, 2000, J INTELL INF SYST, V15, P71, DOI 10.1023/A:1008781812242; Whitley Richard J, 2002, Semin Pediatr Infect Dis, V13, P6, DOI 10.1053/spid.2002.29752; WINARKO E, 2000, P INT C DAT WAR KNOW, P315; [Anonymous], 2006, THESIS PHILIPPS U MA	39	23	23	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2007	15	2					217	247		10.1007/s10618-007-0077-7		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	202IC	WOS:000248894200004	
J	Ohshima, M; Zhong, N; Yao, YY; Liu, C				Ohshima, Muneaki; Zhong, Ning; Yao, Yiyu; Liu, Chunnian			Relational peculiarity-oriented mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						peculiarity-oriented mining; relational data mining; identification of peculiar records; relational peculiarity rules; multi-database mining	SECURITY; LOGIC	Peculiarity rules are a new type of useful knowledge that can be discovered by searching the relevance among peculiar data. A main task in mining such knowledge is peculiarity identification. Previous methods for finding peculiar data focus on attribute values. By extending to record-level peculiarity, this paper investigates relational peculiarity-oriented mining. Peculiarity rules are mined, and more importantly explained, in a relational mining framework. Several experiments are carried out and the results show that relational peculiarity-oriented mining is effective.	Maebashi Inst Technol, Dept Informat Engn, Maebashi, Gumma 3710816, Japan; Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada; Beijing Univ Technol, Coll Comp Sci, Beijing 100022, Peoples R China	Zhong, N (reprint author), Maebashi Inst Technol, Dept Informat Engn, 460-1 Kamisadori Cho, Maebashi, Gumma 3710816, Japan.	zhong@maehashi-it.ac.jp	Yao, Yiyu/B-2926-2008				ARONIS J, 1997, P 10 INT FLOR AI RES, P337; Chen HC, 2005, IEEE INTELL SYST, V20, P12; Han J., 2001, DATA MINING CONCEPTS; Kerber R., 1992, P 10 NAT C ART INT, P123; Lin T.Y., 1998, ROUGH SETS KNOWLEDGE, P107; Liu CN, 2001, COMPUT INTELL, V17, P446, DOI 10.1111/0824-7935.00157; Liu H., 1998, P PAC AS C KNOWL DIS, P210; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; NIENHUYSCHEN SH, 1997, LECT NOTES COMPUTER, V1228, P163; Ohshima M, 2004, LECT NOTES ARTIF INT, V3056, P508; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; QUINLAN JR, 1995, NEW GENERAT COMPUT, V13, P287; RIBEIRO JS, 1995, P 1 INT C KNOWL DISC, P240; SASO D, 2001, RELATIONAL DATA MINI, P48; SASO D, 2001, RELATIONAL DATA MINI, P3; Skowron A., 1992, INTELLIGENT DECISION, P331; WROBEL S, 1997, LECT NOTES ARTIF INT, V1263, P367; Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353; Yao YJ, 2002, ESA SP PUBL, V501, P185; Yao Y.Y., 1999, ADV SOFT COMPUTING E, P539; Yao YY, 2003, LECT NOTES ARTIF INT, V2639, P165; Yao YY, 2005, IEEE INTELL SYST, V20, P52; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zheng L, 2005, INT J PATTERN RECOGN, V19, P91, DOI 10.1142/S0218001405003946; Zhong N, 2003, IEEE T KNOWL DATA EN, V15, P952; Zhong N., 2001, P 2001 IEEE INT C DA, P566; Zhong N., 2004, P 2004 IEEE INT C DA, P575; Zhong N., 2001, Advances in Knowledge Discovery and Data Mining. 5th Pacific-Asia Conference, PAKDD 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2035); Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; ZHONG N, 2005, P SAINT 2005 WORKSH, P306	31	8	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2007	15	2					249	273		10.1007/s10618-006-0046-6		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	202IC	WOS:000248894200005	
J	Chen, QF; Chen, YPP; Zhang, CQ				Chen, Qingfeng; Chen, Yi-Ping Phoebe; Zhang, Chengqi			Detecting inconsistency in biological molecular databases using ontologies	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data preparation; inconsistency; ontology; measure; biological molecular databases; integration	SEMANTIC INTEGRATION; GENE ONTOLOGY; BIOINFORMATICS; XML	The rapid growth of life science databases demands the fusion of knowledge from heterogeneous databases to answer complex biological questions. The discrepancies in nomenclature, various schemas and incompatible formats of biological databases, however, result in a significant lack of interoperability among databases. Therefore, data preparation is a key prerequisite for biological database mining. Integrating diverse biological molecular databases is an essential action to cope with the heterogeneity of biological databases and guarantee efficient data mining. However, the inconsistency in biological databases is a key issue for data integration. This paper proposes a framework to detect the inconsistency in biological databases using ontologies. A numeric estimate is provided to measure the inconsistency and identify those biological databases that are appropriate for further mining applications. This aids in enhancing the quality of databases and guaranteeing accurate and efficient mining of biological databases.	Deakin Univ, Sch Informat Technol, Melbourne, Vic 3125, Australia; Univ Technol Sydney, Fac Informat Technol, Sydney, NSW 2007, Australia	Chen, QF (reprint author), Deakin Univ, Sch Informat Technol, Melbourne, Vic 3125, Australia.	qingfeng.chen@deakin.edu.au; phoebe@deakin.edu.au; chengqi@it.uts.edu.au					Ashburner M, 2000, NAT GENET, V25, P25; Baker PG, 1999, BIOINFORMATICS, V15, P510, DOI 10.1093/bioinformatics/15.6.510; Benson D. A., 2004, NUCLEIC ACIDS RES, V32, P23; CHEN RO, 1997, P 5 INT C INT SYST M, P84; CHEN YPP, 2003, KNOWL INF SYST, V5, P288, DOI 10.1007/s10115-002-0087-0; Chen Y.P.P., 2005, BIOINFORMATICS TECHN; Etzold T, 1996, METHOD ENZYMOL, V266, P114; Fujibuchi W, 1998, Pac Symp Biocomput, P683; Haas L.M., 2001, IBM SYST J, V40; Hunter A., 2003, P INT JOINT C AI IJC, P468; HUNTER A, 2002, P NAT C ART INT AAAI, P68; Hunter L., 1993, ARTIFICIAL INTELLIGE; Karp PD, 2002, NUCLEIC ACIDS RES, V30, P59, DOI 10.1093/nar/30.1.59; Karp PD, 2000, BIOINFORMATICS, V16, P269, DOI 10.1093/bioinformatics/16.3.269; Karpierz M. A., 1995, Pure and Applied Optics, V4, DOI 10.1088/0963-9659/4/2/002; Kohler J, 2003, BIOINFORMATICS, V19, P2420, DOI 10.1093/bioinformatics/btg340; Lin JX, 1996, ARTIF INTELL, V83, P363, DOI 10.1016/0004-3702(95)00019-4; Miyazaki S, 2003, NUCLEIC ACIDS RES, V31, P13, DOI 10.1093/nar/gkg088; OINN T, 2003, BIOINFORMATICS S1, V19, P212; Philippi S, 2004, IEEE T INF TECHNOL B, V8, P154, DOI 10.1109/TITB.2004.826724; Stevens R, 2002, IEEE T INF TECHNOL B, V6, P129, DOI 10.1109/TITB.2002.1006300; Williams N, 1997, SCIENCE, V275, P301, DOI 10.1126/science.275.5298.301; Yeh I, 2003, BIOINFORMATICS, V19, P241, DOI 10.1093/bioinformatics/19.2.241; Zhang SC, 2003, APPL ARTIF INTELL, V17, P375, DOI 10.1080/08839510390219264; Zhang SC, 2004, IEEE INTELL SYST, V19, P12; *EMBL, 2005, EUR MOL BIOL LAB; 2006, GENE ONTOLOGY ANNOTA	27	4	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2007	15	2					275	296		10.1007/s10618-007-0071-0		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	202IC	WOS:000248894200006	
J	Webb, GI				Webb, Geoffrey I.			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia	Webb, GI (reprint author), Monash Univ, Fac Informat Technol, Clayton Campus,Wellingotn Rd, Clayton, Vic 3800, Australia.	Geoff.Webb@infotech.monash.edu	Webb, Geoffrey/A-1347-2008					0	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2007	15	1					1	2		10.1007/s10618-007-0075-9		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	189PD	WOS:000248000100001	
J	Faloutsos, C; Megalooikonomou, V				Faloutsos, Christos; Megalooikonomou, Vasileios			On data mining, compression, and Kolmogorov complexity	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; compression; Kolmogorov complexity; clustering; classification; forecasting; outliers	SEQUENCES	Will we ever have a theory of data mining analogous to the relational algebra in databases? Why do we have so many clearly different clustering algorithms? Could data mining be automated? We show that the answer to all these questions is negative, because data mining is closely related to compression and Kolmogorov complexity; and the latter is undecidable. Therefore, data mining will always be an art, where our goal will be to find better models (patterns) that fit our datasets as best as possible.	Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	Faloutsos, C (reprint author), Carnegie Mellon Univ, Sch Comp Sci, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	christos@cs.cmu.edu; vasilis@cis.temple.edu					Barnsley M., 1998, FRACTALS EVERYWHERE; Barnsley M. F., 1988, BYTE             JAN, P215; BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688; Breiman L, 1984, CLASSIFICATION REGRE; CHAKRABARTI D, 2004, KDD C SEATTL WA, P78; CODD EF, 1971, SIGFIDET WORKSH, P35; Cover T. M., 1991, ELEMENTS INFORM THEO; DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994; ELIAS P, 1975, IEEE T INFORM THEORY, V21, P194, DOI 10.1109/TIT.1975.1055349; ESCHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398; Gersho A., 1992, VECTOR QUANTIZATION; HAMELY G, 2003, P NIPS; KEOGH E, 2002, EXACT INDEXING DYNAM, P406; Keogh E, 2004, KDD 04, P206; Kumaraswamy A, 2004, INFORM PROCESS LETT, V91, P107, DOI 10.1016/j.ipl.2004.04.005; Li M, 2001, BIOINFORMATICS, V17, P149, DOI 10.1093/bioinformatics/17.2.149; Li Ming, 1997, INTRO KOLMOGOROV COM; LIM CX, 2003, P 14 ANN ACM SIAM S, P863; Mackenzie D, 1999, SCIENCE, V284, P1607, DOI 10.1126/science.284.5420.1607; MARTINLO.P, 1966, INFORM CONTROL, V9, P602, DOI 10.1016/S0019-9958(66)80018-9; MEGALOOIKONOMOU V, 1997, CS9701 TR U MAR DEP; MEGALOOIKONOMOU V, 2005, P IEEE INT C DAT ENG, P668; MEGALOOIKONOMOU V, 2006, P SPIE C MED IM SAND, V6144, P497; Mehta M., 1996, P 5 INT C EXT DAT TE, P18; Mitchell T. M, 1997, MACHINE LEARNING; PAPADIMITRIOU S, 2003, LOCI FAST OUTLIER DE, P315; PELLEG D, 2000, ICML 00 P 17 INT C M, P227; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rabiner L., 1993, FUNDAMENTALS SPEECH; Ramakrishnan R., 2002, DATABASE MANAGEMENT; Schroeder M., 1991, FRACTALS CHAOS POWER; Yi B-K, 1998, ICDE; Zhang T., 1996, ACM SIGMOD INT C MAN, P103; Zhu L, 2002, ACM T INFORM SYST, V20, P224, DOI 10.1145/506309.506313; ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934; ZOBEL J, 1992, PROC INT CONF VERY L, P352	36	12	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2007	15	1					3	20		10.1007/s10618-006-0057-3		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	189PD	WOS:000248000100002	
J	Domingos, P				Domingos, Pedro			Toward knowledge-rich data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Markov logic; first-order logic; Markov random fields		This position paper proposes knowledge-rich data mining as a focus of research, and describes initial steps in pursuing it.	Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Domingos, P (reprint author), Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.	pedrod@cs.washington.edu					Bergen W. R., 1988, Journal of Atmospheric and Oceanic Technology, V5, DOI 10.1175/1520-0426(1988)005<0305:TATDDA>2.0.CO;2; Clayton J.E., 1991, PRACTICAL GUIDE KNOW; FIREDMAN N, 1999, P 16 INT JOINT C ART, P1300; HENRION M, 1987, P 3 C UNC ART INT EL, P161; KERSTING K, 2001, P 11 INT C IND LOG P, P118; KOK S, 2006, ALCHEMY SYSTEM STAT; MARCUS S, 1989, SPECIAL ISSUE KNOWLE; Muggleton S., 1996, ADV INDUCTIVE LOGIC, P254; OURSTON D, 1994, ARTIF INTELL, V66, P273, DOI 10.1016/0004-3702(94)90028-0; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; PAZZANI M, 1992, MACH LEARN, V9, P57, DOI 10.1007/BF00993254; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Tasker B., 2002, P 18 C UNC ART INT U, P485; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; WELLMAN M, 1992, KNOWL ENG REV, V7	15	18	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2007	15	1					21	28		10.1007/s10618-007-0069-7		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	189PD	WOS:000248000100003	
J	Ramakrishnan, R; Chen, BC				Ramakrishnan, Raghu; Chen, Bee-Chung			Exploratory mining in cube space	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; exploratory analysis; OLAP; cube; feature space; multidimensional data model		Data Mining has evolved as a new discipline at the intersection of several existing areas, including Database Systems, Machine Learning, Optimization, and Statistics. An important question is whether the field has matured to the point where it has originated substantial new problems and techniques that distinguish it from its parent disciplines. In this paper, we discuss a class of new problems and techniques that show great promise for exploratory mining, while synthesizing and generalizing ideas from the parent disciplines. While the class of problems we discuss is broad, there is a common underlying objective-to look beyond a single data-mining step (e.g., data summarization or model construction) and address the combined process of data selection and transformation, parameter and algorithm selection, and model construction. The fundamental difficulty lies in the large space of alternative choices at each step, and good solutions must provide a natural framework for managing this complexity. We regard this as a grand challenge for Data Mining, and see the ideas discussed here as promising initial steps towards a rigorous exploratory framework that supports the entire process.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	Ramakrishnan, R (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.	ramakris@yahoo-inc.com; beechung@cs.wisc.edu					Agrawal R., 1993, ACM SIGMOD RECORD, V22, P207, DOI DOI 10.1145/170035.170072; Barbara D, 2001, J INTELL INF SYST, V16, P255, DOI 10.1023/A:1011224019249; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burdick D., 2005, P INT C VER LARG DAT, P970; BURDICK D, 2006, P 32 INT C VER LARG, P391; Chen B.-C., 2006, P 32 INT C VER LARG, P655; Chen CY, 2005, ACTA MECH SOLIDA SIN, V18, P173, DOI 10.1007/s10338-005-0522-3; Chen EH, 2005, DERMATOL SURG, V31, P982; CHEN L, 2006, P 32 INT C VER LARG, P403; CHEN Y., 2002, P 28 INT C VER LARG, P323; Danna A, 2002, J BUS ETHICS, V40, P373, DOI 10.1023/A:1020845814009; DOBRA G, 2001, STAT J U N, V18, P363; Fagin R., 2005, P 24 ACM SIGACT SIGM, P184, DOI 10.1145/1065167.1065191; FAGIN R, 2005, P 31 INT C VER LARG, P958; GRAY J, 1997, J DATA MINING KNOWLE, V1, P29, DOI DOI 10.1023/A:1009726021843; Han J., 1998, ACM SIGMOD RECORD, V27, P97, DOI 10.1145/273244.273273; Harinarayan V., 1996, SIGMOD Record, V25; Imielinski T, 2002, DATA MIN KNOWL DISC, V6, P219, DOI 10.1023/A:1015417610840; Kifer D., 2006, P ACM SIGMOD INT C M, P217, DOI 10.1145/1142473.1142499; LeFevre K, 2006, P 12 ACM SIGKDD INT, P277, DOI 10.1145/1150402.1150435; Machanavajjhala A., 2006, P 22 INT C DAT ENG I, P24, DOI DOI 10.1109/ICDE.2006.1; Margaritis D., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Mitchell T. M, 1997, MACHINE LEARNING; Parsons L, 2004, ACM SIGKDD EXPLORATI, V6, P90, DOI 10.1145/1007730.1007731; Samarati P, 1998, SRICSL9804; Sarawagi S, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P42; Sarawagi S, 2001, VLDB J, V10, P224, DOI 10.1007/s007780100046; SARAWAGI S, 1998, P INT C EXT DAT TECH, P168; Sathe G., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; WRITTEN IH, 2000, DATA MIN PRACT MACH	30	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2007	15	1					29	54		10.1007/s10618-007-0063-0		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	189PD	WOS:000248000100004	
J	Han, JW; Cheng, H; Xin, D; Yan, XF				Han, Jiawei; Cheng, Hong; Xin, Dong; Yan, Xifeng			Frequent pattern mining: current status and future directions	DATA MINING AND KNOWLEDGE DISCOVERY			English	Review						frequent pattern mining; association rules; data mining research; applications	ASSOCIATION RULES; SEQUENTIAL PATTERNS; PERIODIC PATTERNS; LARGE DATABASES; ALGORITHM; EFFICIENT; ITEMSETS; CONSTRAINTS; PREFIXSPAN; DISCOVERY	Frequent pattern mining has been a focused theme in data mining research for over a decade. Abundant literature has been dedicated to this research and tremendous progress has been made, ranging from efficient and scalable algorithms for frequent itemset mining in transaction databases to numerous research frontiers, such as sequential pattern mining, structured pattern mining, correlation mining, associative classification, and frequent pattern-based clustering, as well as their broad applications. In this article, we provide a brief overview of the current status of frequent pattern mining and discuss a few promising research directions. We believe that frequent pattern mining research has substantially broadened the scope of data analysis and will have deep impact on data mining methodologies and applications in the long run. However, there are still some challenging research issues that need to be solved before frequent pattern mining can claim a cornerstone approach in data mining applications.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Han, JW (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	hanj@cs.uiuc.edu	Cheng, Hong/F-7228-2011				Afrati F. N., 2004, P 10 ACM SIGKDD INT, P12, DOI 10.1145/1014052.1014057; Agarwal RC, 2001, J PARALLEL DISTR COM, V61, P350, DOI 10.1006/jpdc.2000.1693; Aggarwal C. C., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275490; Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; AGRAWAL R, 1993, P 1993 ACM SIGMOD IN; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Ahmed K. M., 2000, SIGKDD EXPLORATIONS, V1, P46; Asai T, 2002, SIAM PROC S, P158; Aumann Y., 1999, P 5 ACM SIGKDD INT C, P261, DOI 10.1145/312129.312243; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Beil F., 2002, P 8 ACM SIGKDD INT C, P436; Bennett K. P., 2005, P 11 ACM SIGKDD INT, P562, DOI 10.1145/1081870.1081937; BETTINI C, 1998, B IEEE COMPUTER SOC, V21, P32; BEYER K, 1999, P 1999 ACM SIGMOD IN, P359, DOI 10.1145/304182.304214; Blanchard G, 2005, J FISH BIOL, V66, P73, DOI 10.1111/j.1095-8649.2004.00578.x; BONCHI F, 2003, P 7 EUR C PRINC PRAC, P59; Bonchi F, 2004, P 4 IEEE INT C DAT M, P35; Borgelt C., 2002, P 2002 INT C DAT MIN, P211; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Bucila C, 2003, DATA MIN KNOWL DISC, V7, P241, DOI 10.1023/A:1024076020895; Burdick D, 2001, PROC INT CONF DATA, P443, DOI 10.1109/ICDE.2001.914857; Calders T, 2005, SIAM PROC S, P250; Calders T., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Cao H., 2005, P 5 IEEE INT C DAT M, P82, DOI DOI 10.1109/ICDM.2005.95; CHANG JH, 2003, P 9 ACM SIGKDD INT C, P487; Chen MS, 1996, INT CON DISTR COMP S, P385; Pinto H., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management; Cheng C. H., 1999, P 5 ACM SIGKDD INT C, P84, DOI 10.1145/312129.312199; CHENG H, 2007, P 2007 INT C DAT ENG; Cheng H, 2005, SIAM PROC S, P601; Cheng H., 2004, P 10 ACM SIGKDD INT, P527, DOI 10.1145/1014052.1014114; Cheung DW, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P31, DOI 10.1109/PDIS.1996.568665; Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094; Chi Y, 2004, P 4 IEEE INT C DAT M, P59; Cong G., 2005, P ACM SIGMOD INT C M, P670, DOI 10.1145/1066157.1066234; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Deshpande M., 2003, P 3 IEEE INT C DAT M, P35; Dong GZ, 2004, IEEE T KNOWL DATA EN, V16, P922, DOI 10.1109/TKDE.2004.28; Eirinaki M., 2003, ACM T INTERNET TECHN, V3, P1, DOI DOI 10.1145/643477.643478; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; GADE K, 2004, P 10 ACM SIGKDD INT, P138, DOI 10.1145/1014052.1014070; Garofalakis MN, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P223; Geerts F., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989513; Gionis A., 2006, P 12 ACM SIGKDD INT, P167, DOI 10.1145/1150402.1150424; GIONIS A, 2003, P 9 ACM SIGKDD INT C, P129; Goethals B., 2003, P ICDM 03 INT WORKSH, P1; Grahne G, 2003, P ICDM 03 INT WORKSH, P123; Grahne G., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839450; Grossman R., 2005, P 2005 INT C KNOWL D, P285, DOI 10.1145/1081870.1081904; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HAN J, 2001, P ACM SIGMOD INT C M, P1, DOI 10.1145/375663.375664; Han J, 1995, P 21 INT C VER LARG, P420; Han J, 2006, DATA MINING CONCEPTS; Han JW, 1999, PROC INT CONF DATA, P106; Hilderman R., 2001, KNOWLEDGE DISCOVERY; Holder L.B., 1994, P AAAI WORKSH KNOWL, P169; Holsheimer M, 1995, P 1 INT C KNOWL DISC, P150; Huan J., 2004, P 8 ANN INT C RES CO, P308, DOI 10.1145/974614.974655; Huan J, 2003, P 3 IEEE INT C DAT M, P549; Huan J, 2004, P 10 ACM SIGKDD INT, P581, DOI 10.1145/1014052.1014123; Imielinski T, 2002, DATA MIN KNOWL DISC, V6, P219, DOI 10.1023/A:1015417610840; Inokuchi A., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Jaroszewicz S., 2004, P 10 ACM SIGKDD INT, P178, DOI 10.1145/1014052.1014074; Jaroszewicz S., 2005, P 11 ACM SIGKDD INT, P118, DOI 10.1145/1081870.1081887; Ji X, 2005, P 5 IEEE INT C DAT M, P194; JIN R, 2005, P 11 ACM SIGKDD INT, P606, DOI 10.1145/1081870.1081944; Jin R., 2005, P 5 IEEE INT C DAT M, P210; Kamber M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Karp RM, 2003, ACM T DATABASE SYST, V28, P51, DOI 10.1145/762471.762473; KOPERSKI K., 1995, P 4 INT S LARG SPAT, P47; KOSALA R, 2000, SIGKDD EXPLOR 2; Kuramochi M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989534; Kuramochi M., 2004, P ICDM 2004, P439; Lakshmanan L. V. S., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; LAKSHMANAN LVS, 1999, P 1999 ACM SIGMOD IN, P157, DOI 10.1145/304182.304196; Lee Y.-K., 2003, P 2003 INT C DAT MIN, P581, DOI DOI 10.1109/ICDM.2003.1250982; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li J, 2000, P 4 PAC AS C KNOWL D, P220; Li W., 2001, P IEEE INT C DAT MIN, P369; Li XL, 2006, LECT NOTES COMPUT SC, V3975, P166; Li Z., 2004, P 3 USENIX C FIL STO, P173; Li Z., 2005, P 10 EUR SOFTW ENG C, P306, DOI DOI 10.1145/1081706.1081755; Li Z., 2004, Proceedings of the Sixth Symposium on Operating Systems Design and Implementation (OSDI'04); Lin CH, 2005, SIAM PROC S, P68; Liu C, 2005, SIAM PROC S, P286, DOI 10.1145/1081706.1081753; Liu G, 2003, P 9 ACM SIGKDD INT C, P607; LIU G, 2006, P 2006 SIAM INT C DA, P467; Liu H, 1998, ELEC SOC S, V98, P86; Liu H., 2006, P 2006 SIAM INT C DA, P280; Liu J, 2002, P 2002 ACM SIGKDD IN, P239; Liu J, 2006, P 2006 SIAM INT C DA, P405; Lu H., 1998, P 1998 SIGMOD WORKSH, P12; Luo CN, 2005, SIAM PROC S, P415; Ma S, 2001, PROC INT CONF DATA, P205; Manku GS, 2002, P 28 INT C VER LARG, P346; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Mei Q, 2006, P 2006 ACM SIGKDD IN, P337, DOI 10.1145/1150402.1150441; METWALLY A, 2005, P 10 INT C DAT THEOR, P398; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; Nanopoulos A, 2001, DATA KNOWL ENG, V37, P243, DOI 10.1016/S0169-023X(01)00008-8; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Nijssen S, 2004, P 10 ACM SIGKDD INT, P647, DOI 10.1145/1014052.1014134; Omiecinski ER, 2003, IEEE T KNOWL DATA EN, V15, P57, DOI 10.1109/TKDE.2003.1161582; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; Pan F., 2003, P 9 ACM SIGKDD INT C, P637; Pan F., 2004, P 2004 INT C SCI STA, P21; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Park J.S., 1995, P 4 INT C INF KNOWL, P31, DOI 10.1145/221270.221320; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J., 2000, P PAC AS C KNOWL DIS, P396; Pei J, 2001, PROC INT CONF DATA, P433; Pei J., 2002, P 2002 IEEE INT C DA, P378; Pei J, 2001, PROC INT CONF DATA, P215; Pei J, 2004, IEEE T KNOWL DATA EN, V16, P1424; Pei J., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Pei J., 2000, P 2000 ACM SIGMOD IN, P11; PIATETSKYSHAPIR.G, 1991, NOTES AAAI 91 WORKSH; PUNIN JR, 2001, WEB USAGE MINING LAN; RAMESH G, 2003, P 2003 ACM S PRINC D, P284, DOI 10.1145/773153.773181; SAPPANEN J, 2004, P 2004 INT C KNOWL D, P683; Sarawagi S, 1998, P ACM SIGMOD INT C M, P343, DOI 10.1145/276304.276335; Savasere A, 1995, P 21 INT C VER LARG, P432; Shekar B., 2004, P 4 IEEE INT C DAT M, P194; Siebes A, 2006, P SIAM C DAT MIN, P393; Silverstein C., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Sismanis Y., 2002, P ACM SIGMOD INT C M, P464; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; Srikant R., 1995, P 21 INT C VER LARG, P407; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12; Steinbach M., 2004, P 2004 ACM SIGKDD IN, P296, DOI 10.1145/1014052.1014086; Tan P., 2002, P 8 ACM SIGKDD INT C, P32, DOI DOI 10.1145/775047.775053; TING R, 2006, P 2006 SIAM INT C DA, P638; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Vanetik N., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183988; Wang C., 2004, P 10 ACM SIGKDD INT, P316, DOI 10.1145/1014052.1014088; Wang H., 2002, P 2002 ACM SIGMOD IN, P418; WANG J, 2003, P 2003 ACM SIGKDD IN, P246; Wang J., 2003, P 9 ACM SIGKDD INT C, P236; WANG J., 2005, P 5 IEEE INT C DAT M, P753; Wang JY, 2005, SIAM PROC S, P205; Wang JY, 2005, IEEE T KNOWL DATA EN, V17, P652; Wang JY, 2004, PROC INT CONF DATA, P79, DOI 10.1109/ICDE.2004.1319986; Wang W, 2002, PROC INT CONF DATA, P155; WASHIO T, 2003, SIGKDD EXPLORATIONS, V5, P59; Xin D., 2003, P 29 INT C VER LARG, P476, DOI 10.1016/B978-012722442-8/50049-5; Xin D., 2006, P 2006 INT C DAT ENG, P4; Xin D., 2005, P 31 INT C VER LARG, P709; Xin D., 2006, P 2006 ACM SIGKDD IN, P773, DOI 10.1145/1150402.1150502; Xiong H, 2004, SIAM PROC S, P78; YAN U, 2005, P 2005 SIAM INT C DA, P636; Yan X., 2002, P 2002 IEEE INT C DA, P721; Yan XF, 2003, SIAM PROC S, P166; Yan X, 2005, P ACM SIGMOD INT C M, P766, DOI 10.1145/1066157.1066244; Yan X., 2006, P ICDE 2006, P88; Yan X., 2005, P 11 ACM SIGKDD INT, P314, DOI 10.1145/1081870.1081907; Yan X., 2005, P 11 ACM SIGKDD INT, P324, DOI 10.1145/1081870.1081908; YAN X, 2003, P 9 ACM SIGKDD INT C, P286; Yan X., 2004, P ACM SIGMOD INT C M, P335, DOI 10.1145/1007568.1007607; Yang C., 2001, P 7 ACM SIGKDD INT C, P194, DOI 10.1145/502512.502539; Yang G., 2004, P 10 ACM SIGKDD INT, P344, DOI 10.1145/1014052.1014091; Yang J, 2003, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2003.1260785; Yang J, 2003, IEEE T KNOWL DATA EN, V15, P613; YANG LH, 2003, VLDB, P69; Yin XX, 2003, SIAM PROC S, P331; Yoda K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Yu JX, 2004, P 30 INT C VER LARG, P204, DOI 10.1016/B978-012088469-8/50021-8; Zaiane O. R., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839445; Zaki M., 2000, MACH LEARN, V40, P31; Zaki M. J., 2002, P 8 ACM SIGKDD INT C, P71, DOI DOI 10.1145/775047.775058; Zaki M. J., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288643; Zaki M. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Zaki MJ, 2002, SIAM PROC S, P457; Zaki MJ, 1997, DATA MIN KNOWL DISC, V1, P343, DOI 10.1023/A:1009773317876; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291; Zhang GS, 2004, CRYST GROWTH DES, V4, P383, DOI 10.1021/cg034177r; Zhang X., 2004, P 10 ACM SIGKDD INT, P384, DOI 10.1145/1014052.1014095; ZHU F, 2007, P 2007 INT C DAT ENG	182	137	156	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2007	15	1					55	86		10.1007/s10618-006-0059-1		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	189PD	WOS:000248000100005	
J	Kriegel, HP; Borgwardt, KM; Kroger, P; Pryakhin, A; Schubert, M; Zimek, A				Kriegel, Hans-Peter; Borgwardt, Karsten M.; Kroeger, Peer; Pryakhin, Alexey; Schubert, Matthias; Zimek, Arthur			Future trends in data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; knowledge discovery; future trends		Over recent years data mining has been establishing itself as one of the major disciplines in computer science with growing industrial impact. Undoubtedly, research in data mining will continue and even increase over coming decades. In this article, we sketch our vision of the future of data mining. Starting from the classic definition of "data mining", we elaborate on topics that - in our opinion - will set trends in data mining.	Univ Munich, D-80538 Munich, Germany	Kriegel, HP (reprint author), Univ Munich, Oettingenstr 67, D-80538 Munich, Germany.	kriegel@dbs.ifi.lmu.de					Achtert E., 2005, P 5 INT C DAT MIN IC, P10; Bille P, 2005, THEOR COMPUT SCI, V337, P217, DOI 10.1016/j.tcs.2004.12.030; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Bo T.H., 2004, NUCL ACIDS RES, V32; Bohm C., 2004, P 2004 ACM SIGMOD IN, P455, DOI 10.1145/1007568.1007620; CRONEA SF, 2005, EUR J OPER RES; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Domeniconi C., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989572; Eiter T., 1997, ACTA INFORM, V34, P103; GABER MM, 2005, MINING DATA STREAMS, P34; Gartner T, 2002, P 19 INT C MACH LEAR, P179; HALEVY AY, 2003, BTW, P24; Han J., 2001, DATA MINING CONCEPTS; Kailing K., 2004, P 8 PAC AS C KNOWL D, P394; KANELLOPOULOS Y, 2006, SIGKDD EXPLORATIONS, V8, P33; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kriegel H-P, 2005, P 10 INT C DAT SYST, P511; KRIEGEL HP, 2004, P 4 SIAM INT C DAT M, P103; KRIEGEL HP, 2006, P 10 PAC AS C KNOWL, P139; Liu C, 2005, SIAM PROC S, P286, DOI 10.1145/1081706.1081753; Liu C, 2006, SIAM PROC S, P106; LIU K, 2006, DISTRIBUTED DATA MIN; Pyle D, 1999, DATA PREPARATION DAT; Ramon J, 2001, ACTA INFORM, V37, P765, DOI 10.1007/PL00013304; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Wang J, 2005, ACTA PHYS-CHIM SIN, V21, P22; WASHIO T, 2003, SIGKDD EXPLORATIONS, V5, P59; Weidmann N., 2003, P EUR C MACH LEARN, P468; YAROWSKY D, 1995, M ASS COMP LING	32	30	30	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2007	15	1					87	97		10.1007/s10618-007-0067-9		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	189PD	WOS:000248000100006	
J	Piatetsky-Shapiro, G				Piatetsky-Shapiro, Gregory			Data mining and knowledge discovery 1996 to 2005: overcoming the hype and moving from "university" to "business" and "analytics"	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						hype curve; business analytics; KDnuggets; data mining jobs		I survey the transformation of the data mining and knowledge discovery field over the last 10 years from the unique vantage point of KDnuggets as a leading chronicler of the field. Analysis of the most frequent words in KDnuggets News leads to revealing observations.	KDnuggets, Brookline, MA 02446 USA	Piatetsky-Shapiro, G (reprint author), KDnuggets, 22 Atherton Rd, Brookline, MA 02446 USA.	gregory@kdnuggets.com					*SIGKDD EXPL, 1999, KDD99 PANEL REPORT	1	6	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	AUG	2007	15	1					99	105		10.1007/s10618-006-0058-2		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	189PD	WOS:000248000100007	
J	Noren, GN; Orre, R; Bate, A; Edwards, IR				Noren, G. Niklas; Orre, Roland; Bate, Andrew; Edwards, I. Ralph			Duplicate detection in adverse drug reaction surveillance	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data cleaning; duplicate detection; hit-miss model	RECORD-LINKAGE; PHARMACOVIGILANCE; MANAGEMENT	The WHO Collaborating Centre for International Drug Monitoring in Uppsala, Sweden, maintains and analyses the world's largest database of reports on suspected adverse drug reaction (ADR) incidents that occur after drugs are on the market. The presence of duplicate case reports is an important data quality problem and their detection remains a formidable challenge, especially in the WHO drug safety database where reports are anonymised before submission. In this paper, we propose a duplicate detection method based on the hit-miss model for statistical record linkage described by Copas and Hilton, which handles the limited amount of training data well and is well suited for the available data (categorical and numerical rather than free text). We propose two extensions of the standard hit-miss model: a hit-miss mixture model for errors in numerical record fields and a new method to handle correlated record fields, and we demonstrate the effectiveness both at identifying the most likely duplicate for a given case report (94.7% accuracy) and at discriminating true duplicates from random matches (63% recall with 71% precision). The proposed method allows for more efficient data cleaning in post-marketing drug safety data sets, and perhaps other knowledge discovery applications as well.	WHO Collaborating Ctr Int Drug Monitoring, Uppsala, Sweden; Stockholm Univ, S-10691 Stockholm, Sweden; Neurolog Sweden AB, Stockholm, Sweden	Noren, GN (reprint author), WHO Collaborating Ctr Int Drug Monitoring, Uppsala, Sweden.	niklas.noren@who.umc.org	Noren, G. Niklas/D-4739-2012				Bate A, 1998, EUR J CLIN PHARMACOL, V54, P315, DOI 10.1007/s002280050466; BELIN TR, 1995, J AM STAT ASSOC, V90, P694, DOI 10.2307/2291082; Bilenko M., 2003, P KDD 2003 WORKSH DA, P7; Bilenko M., 2003, KDD 03, P39; Bortnichak EA, 2001, PHARMACOEPIDEM DR S, V10, P191, DOI 10.1002/pds.587; Brinker AD, 2002, AM J HEMATOL, V70, P313, DOI 10.1002/ajh.10148; COPAS JB, 1990, J ROY STAT SOC A STA, V153, P287, DOI 10.2307/2982975; De Veaux RD, 2005, STAT SCI, V20, P231, DOI 10.1214/088342305000000269; Edwards IR, 2000, LANCET, V356, P1255, DOI 10.1016/S0140-6736(00)02799-9; Edwards IR, 1999, BRIT J CLIN PHARMACO, V48, P138, DOI 10.1046/j.1365-2125.1999.00000.x; Edwards IR, 1997, BRIT MED J, V315, P500; Evans SJW, 2000, STAT MED, V19, P3199, DOI 10.1002/1097-0258(20001215)19:23<3199::AID-SIM621>3.0.CO;2-Q; Fayyad U., 1996, COMMUN ACM, V39, P11; FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061; Hernandez MA, 1998, DATA MIN KNOWL DISC, V2, P9, DOI 10.1023/A:1009761603038; JARO MA, 1989, J AM STAT ASSOC, V84, P414, DOI 10.2307/2289924; Kim W, 2003, DATA MIN KNOWL DISC, V7, P81, DOI 10.1023/A:1021564703268; Lindquist M, 2004, DRUG SAFETY, V27, P857, DOI 10.2165/00002018-200427120-00003; MONGE AE, 1997, RES ISSUES DATA MINI; NEWCOMBE HB, 1962, COMMUN ACM, V5, P563, DOI 10.1145/368996.369026; Nkanza JN, 2004, DRUG SAFETY, V27, P951; NOREN GN, 2005, KDD 05 P 11 ACM SIGK, P459; Noren GN, 2006, STAT MED, V25, P3740, DOI 10.1002/sim.2473; Orre R, 2000, COMPUT STAT DATA AN, V34, P473, DOI 10.1016/S0167-9473(99)00114-0; RAWLINS MD, 1988, BRIT J CLIN PHARMACO, V26, P7; Sarawagi S., 2002, KDD, P269	26	25	26	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2007	14	3					305	328		10.1007/s10618-006-0052-8		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	156SK	WOS:000245669600001	
J	Ooi, CH; Chetty, M; Teng, SW				Ooi, Chia Huey; Chetty, Madhu; Teng, Shyh Wei			Differential prioritization in feature selection and classifier aggregation for multiclass microarray datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						tissue classification; microarray data analysis; multiclass classification; feature selection; classifier aggregation	GENE-EXPRESSION DATA; SUPPORT VECTOR MACHINES; DNA MICROARRAY; CANCER; PREDICTION; ADENOCARCINOMA; EXTRACTION; DISCOVERY; PATTERNS; LEUKEMIA	The high dimensionality of microarray datasets endows the task of multiclass tissue classification with various difficulties-the main challenge being the selection of features deemed relevant and non-redundant to form the predictor set for classifier training. The necessity of varying the emphases on relevance and redundancy, through the use of the degree of differential prioritization (DDP) during the search for the predictor set is also of no small importance. Furthermore, there are several types of decomposition technique for the feature selection (FS) problem-all-classes-at-once, one-vs.-all (OVA) or pairwise (PW). Also, in multiclass problems, there is the need to consider the type of classifier aggregation used-whether non-aggregated (a single machine), or aggregated (OVA or PW). From here, first we propose a systematic approach to combining the distinct problems of FS and classification. Then, using eight well-known multiclass microarray datasets, we empirically demonstrate the effectiveness of the DDP in various combinations of FS decomposition types and classifier aggregation methods. Aided by the variable DDP, feature selection leads to classification performance which is better than that of rank-based or equal-priorities scoring methods and accuracies higher than previously reported for benchmark datasets with large number of classes. Finally, based on several criteria, we make general recommendations on the optimal choice of the combination of FS decomposition type and classifier aggregation method for multiclass microarray datasets.	Monash Univ, Gippsland Sch Informat Technol, Churchill, Vic, Australia	Ooi, CH (reprint author), Monash Univ, Gippsland Sch Informat Technol, Churchill, Vic, Australia.	chia.huey.ooi@infotech.monash.edu.au; madhu.chetty@infotech.monash.edu.au; shyh.wei.teng@infotech.monash.edu.au					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; FRANC V, 2005, THESIS CZECH TU; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall MA, 1998, AUST COMP S, V20, P181; HOLM S, 1979, SCAND J STAT, V6, P65; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jirapech-Umpai T, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-148; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KNIJNENBURG TA, 2005, P 11 ANN C ADV SCH C; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Linder R, 2004, BIOINFORMATICS, V20, P3544, DOI 10.1093/bioinformatics/bth441; MASSART DL, 1988, CHEMOMETRICS TXB DAT, V2, P395; Mitchell T. M, 1997, MACHINE LEARNING; Munagala K, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-21; OOI CH, 2005, P 4 AUSTR C KNOWL DI, P115; OOI CH, 2004, ADV BIOINFORMATICS I, V8, P197; Ooi CH, 2005, LECT NOTES COMPUT SC, V3745, P367; PARK H, 2005, HIERARCHICAL CLASSIF; Platt J.C., 1998, ADV KERNEL METHODS S, P185; Platt JC, 2000, ADV NEUR IN, V12, P547; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Shalon D, 1996, GENOME RES, V6, P639, DOI 10.1101/gr.6.7.639; Slonim D. K., 2000, RECOMB 2000. Proceedings of the Fourth Annual International Conference on Computational Molecular Biology; Vapnik V. N., 1998, STAT LEARNING THEORY; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	35	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2007	14	3					329	366		10.1007/s10618-006-0055-5		38	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	156SK	WOS:000245669600002	
J	de Sousa, EPM; Traina, C; Traina, AJM; Wu, LJ; Faloutsos, C				de Sousa, Elaine P. M.; Traina, Caetano, Jr.; Traina, Agma J. M.; Wu, Leejay; Faloutsos, Christos			A fast and effective method to find correlations among attributes in databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						attribute correlation; attribute selection; intrinsic dimension; fractals	NONLINEAR DIMENSIONALITY REDUCTION; COMPONENT ANALYSIS; SELF-SIMILARITY; DATA SETS; CLASSIFICATION; SELECTION	The problem of identifying meaningful patterns in a database lies at the very heart of data mining. A core objective of data mining processes is the recognition of inter-attribute correlations. Not only are correlations necessary for predictions and classifications - since rules would fail in the absence of pattern - but also the identification of groups of mutually correlated attributes expedites the selection of a representative subset of attributes, from which existing mappings allow others to be derived. In this paper, we describe a scalable, effective algorithm to identify groups of correlated attributes. This algorithm can handle non-linear correlations between attributes, and is not restricted to a specific family of mapping functions, such as the set of polynomials. We show the results of our evaluation of the algorithm applied to synthetic and real world datasets, and demonstrate that it is able to spot the correlated attributes. Moreover, the execution time of the proposed technique is linear on the number of elements and of correlations in the dataset.	Univ Sao Paulo, Dept Comp Sci, BR-13560 Sao Carlos, Brazil; Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA	de Sousa, EPM (reprint author), Univ Sao Paulo, Dept Comp Sci, BR-13560 Sao Carlos, Brazil.	parros@icmc.usp.br; caetano@icmc.usp.br; agma@icmc.usp.br; lw2j@cs.cmu.edu; christos@cs.cmu.edu	Sousa, Elaine/E-8906-2011; Traina, Caetano/E-9814-2011; Traina, Agma/F-1299-2011	Traina, Caetano/0000-0002-6625-6047; 			Aha D., 1995, P 5 INT WORKSH ART I, P1; BABU S, 2001, P ACM SIGMOD 2001, P283, DOI 10.1145/375663.375693; Balan A. G. R., 2005, Proceedings. 18th IEEE Symposium on Computer-Based Medical Systems; Barbara D, 2003, DATA MIN KNOWL DISC, V7, P123, DOI 10.1023/A:1022493416690; BELUSSI A., 1995, P 21 INT C VER LARG, P299; Belussi A, 1998, ACM T INFORM SYST, V16, P161, DOI 10.1145/279339.279342; Blake C, 1998, UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Bohm C, 2000, LECT NOTES COMPUT SC, V1777, P36; Bohm C, 2000, ACM T DATABASE SYST, V25, P129, DOI 10.1145/357775.357776; Calvo RA, 1998, P 9 AUSTR C NEUR NET; CHAKRABARTI D, 2002, INT C INF KNOWL MAN, V1, P2; Chakrabarti K, 2002, ACM T DATABASE SYST, V27, P188, DOI 10.1145/568518.568520; Chang KY, 1998, P SOC PHOTO-OPT INS, V3307, P120, DOI 10.1117/12.304651; Dash M, 1997, PROC INT C TOOLS ART, P532, DOI 10.1109/TAI.1997.632300; DeMers D., 1993, ADV NEURAL INFORMATI, P580; FALOUTSOS C, 2000, P 2000 ACM SIGMOD IN, P177, DOI 10.1145/342009.335412; Fayyad U, 1998, IEEE B TECHNICAL COM, V21, P39; Hyvarinen A., 1999, NEURAL COMPUTING SUR, V2, P94; JEBARA TS, 2000, P 16 C UNC ART INT U, P291; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kamel Ibrahim, 1994, P 20 INT C VER LARG, P500; KANTARDZIC M, 2004, P 2004 ACM S APPL CO, P637, DOI 10.1145/967900.968034; Kanth K. V., 1998, P ACM SIGMOD INT C M, P166; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kononenko I., 1994, LECT NOTES ARTIF INT, V784, P171; Korn F, 2001, IEEE T KNOWL DATA EN, V13, P96, DOI 10.1109/69.908983; Korn F., 1997, P ACM SIGMOD INT C M, P289, DOI DOI 10.1145/253260.253332; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; LANGLEY P, 1997, COMPUTATIONAL LEARNI, V4; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; LIU Y, 2001, VISIM WORKSH INF RET; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985; Pagel B.-U., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839457; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Reynolds H. T., 1977, ANAL CROSS CLASSIFIC; ROBNIKSIKONJA M, 1997, P ERK 97 PORT SLOV; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SCHERF M, 1997, FKI22197 MUN U TECHN; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Schroeder M., 1991, FRACTALS CHAOS POWER; Singh M, 1995, P 12 INT C MACH LEAR, P497; TAKAHASHI T, 1999, P 1999 INT NAT S NON, V2, P863; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TRAINA A, 2001, P KDD, P184, DOI 10.1145/502512.502538; Traina C, 2002, IEEE T KNOWL DATA EN, V14, P244, DOI 10.1109/69.991715; Traina A. J. M., 2003, Proceedings 16th IEEE Symposium on Computer-Based Medical Systems. CBMS 2003; TRAINA C, 1999, CMUCS99110; TRAINA C, 2000, AN 15 S BRAS BANC DA, P158; Turk M., 1991, J COGNITIVE SCI, V3; Vafaie H., 1993, Proceedings. Fifth International Conference on Tools with Artificial Intelligence TAI '93 (Cat. No.93CH3325-8), DOI 10.1109/TAI.1993.633981; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; WACTLAR HD, 1996, IEEE COMPUT, V29, P46; Witten IH, 2000, DATA MINING PRACTICA; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680	57	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2007	14	3					367	407		10.1007/s10618-006-0056-4		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	156SK	WOS:000245669600003	
J	Berrado, A; Runger, GC				Berrado, Abdelaziz; Runger, George C.			Using metarules to organize and group discovered association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						item sets; data sparseness; clustering rules; classification; rules pruning		The high dimensionality of massive data results in the discovery of a large number of association rules. The huge number of rules makes it difficult to interpret and react to all of the rules, especially because many rules are redundant and contained in other rules. We discuss how the sparseness of the data affects the redundancy and containment between the rules and provide a new methodology for organizing and grouping the association rules with the same consequent. It consists of finding metarules, rules that express the associations between the discovered rules themselves. The information provided by the metarules is used to reorganize and group related rules. It is based only on data-determined relationships between the rules. We demonstrate the suggested approach on actual manufacturing data and show its effectiveness on several benchmark data sets.	Arizona State Univ, Dept Ind Engn, Tempe, AZ 85287 USA	Berrado, A (reprint author), Arizona State Univ, Dept Ind Engn, Tempe, AZ 85287 USA.	berrado@asu.edu; runger@asu.edu					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Aumann Y, 2003, J INTELL INF SYST, V20, P255, DOI 10.1023/A:1022812808206; Bay SD, 2001, DATA MIN KNOWL DISC, V5, P213, DOI 10.1023/A:1011429418057; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; Blake C, 1998, UCI REPOSITORY MACHI; CHAWLA C, 2004, P 20 INT C DAT ENG B, P832; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; Fukuda T, 1999, J COMPUT SYST SCI, V58, P1, DOI 10.1006/jcss.1998.1595; GUPTA KG, 1999, P ANNIE INT ENG SYST, P759; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HUANG S, 2005, P SIAM 2005 DAT MIN, P541; Huang SY, 2005, LECT NOTES ARTIF INT, V3518, P71; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; LI J, 2002, KENT RIDGE BIOMEDICA; Li Wenmin, 2001, ICDM, P369; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Liu B., 1997, P 3 INT C KNOWL DISC, P31; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; Liu B., 1999, P 5 ACM SIGKDD INT C, P125, DOI 10.1145/312129.312216; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Quinlan J.R., 1992, C4 5 PROGRAM MACHINE; Scott DW, 1983, P 15 S INT, P173; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Srikant R, 1996, P ACM SIGMOD C MAN D; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; TAN PN, 2002, P 8 ACM INT C KNOWL, P183; TOIVONEN H, 1995, P MLNET WORKSH STAT, P47; Yang Y., 2002, P PAC RIM KNOWL ACQ, P159	31	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	2007	14	3					409	431		10.1007/s10618-006-0062-6		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	156SK	WOS:000245669600004	
J	Fyfe, C				Fyfe, Colin			Two topographic maps for data visualisation	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						topographic mapping; product of experts	EXPLORATORY PROJECTION PURSUIT	We review a new form of self-organizing map which is based on a nonlinear projection of latent points into data space, identical to that performed in the Generative Topographic Mapping (GTM) [Bishop et al. (1997) Neurl Comput 10(1): 215-234]. But whereas the GTM is an extension of a mixture of experts, our new model is an extension of a product of experts [Hinton (2000) Technical report GCNU TR 2000-004, Gatsby Computational Neuroscience Unit, University College, London]. We show visualisation results on some real data sets and compare with the GTM. We then introduce a second mapping based on harmonic averages and show that it too creates a topographic mapping of the data. We compare these mappings on real and artificial data sets.	Univ Paisley, Appl Computat Intelligence Res Unit, Paisley PA1 2BE, Renfrew, Scotland	Fyfe, C (reprint author), Univ Paisley, Appl Computat Intelligence Res Unit, Paisley PA1 2BE, Renfrew, Scotland.	colin.fyfe@paisley.ac.uk					Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Corchado E, 2004, DATA MIN KNOWL DISC, V8, P203, DOI 10.1023/B:DAMI.0000023673.23078.a3; Fyfe C, 1997, NEURAL NETWORKS, V10, P257, DOI 10.1016/S0893-6080(96)00058-5; FYFE C, 2005, P INT C ART NEUR NET; Hastie T., 2001, ELEMENTS STAT LEARNI; HINTON GE, 2001, P 7 C UNC ART INT, P227; HINTON GE, 2000, 2000004 GCNU TR U CO; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kohonen Teuvo, 1995, SELF ORG MAPS; WILLIAMS C, 2001, EDIINFRR0043 U ED; Zhang B, 2000, GEN K HARMONIC MEANS; Zhang B., 1999, K HARMONIC MEANS DAT, P5	13	18	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2007	14	2					207	224		10.1007/s10618-006-0047-5		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	151HR	WOS:000245281600001	
J	Robnik-Sikonja, M; Vanhoof, K				Robnik-Sikonja, Marko; Vanhoof, Koen			Evaluation of ordinal attributes at value level	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						attribute evaluation; ordinal attributes; attribute values; visualization; marketing	CUSTOMER SATISFACTION; CONSUMER SATISFACTION; DETERMINANTS; PERFORMANCE; INFORMATION; MODELS	We propose a novel context sensitive algorithm for evaluation of ordinal attributes which exploits the information hidden in ordering of attributes' and class' values and provides a separate score for each value of the attribute. Similar to feature selection algorithm ReliefF, the proposed algorithm exploits the contextual information via selection of nearest instances. The ordEval algorithm outputs probabilistic factors corresponding to the effect an increase/decrease of attribute's value has on the class value. While the ordEval algorithm is general and can be used for analysis of any survey with graded answers, we show its utility on an important marketing problem of customer (dis) satisfaction. We develop a visualization technique and show how we can use it to detect and confirm several findings from marketing theory.	Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1001, Slovenia; Univ Hasselt, Dept Econ, B-3590 Diepenbeek, Belgium	Robnik-Sikonja, M (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, Ljubljana 1001, Slovenia.	Marko.Robnik@fri.uni-lj.si; koen.vanhoof@uhasselt.be					Anderson E. W., 1994, MARKET LETT, V5, P19, DOI 10.1007/BF00993955; ANDERSON EW, 1994, J MARKETING, V58, P63; ANDERSON EW, 1993, MARKET SCI, V12, P125, DOI 10.1287/mksc.12.2.125; ANDERSON RE, 1973, J MARKETING RES, V10, P38, DOI 10.2307/3149407; Breiman L, 1984, CLASSIFICATION REGRE; CARDOZO RN, 1965, J MARKETING RES, V2, P244, DOI 10.2307/3150182; CHURCHILL GA, 1982, J MARKETING RES, V19, P491, DOI 10.2307/3151722; Duda R.O., 2001, PATTERN CLASSIFICATI; EINHORN HJ, 1981, ANNU REV PSYCHOL, V32, P53, DOI 10.1146/annurev.ps.32.020181.000413; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; Kononenko I., 1995, P 14 INT JOINT C ART, P1034; Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings; Mittal V, 1998, J MARKETING, V62, P33, DOI 10.2307/1251801; Mittal V, 2001, J MARKETING RES, V38, P131, DOI 10.1509/jmkr.38.1.131.18832; OLIVER RL, 1993, J CONSUM RES, V20, P418, DOI 10.1086/209358; Oliver R.L., 1997, SATISFACTION BEHAV P; Peeters Guido, 1990, EUROPEAN REV SOCIAL, V1, P33, DOI 10.1080/14792779108401856; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Sethi V, 1999, INFORM SYST RES, V10, P87, DOI 10.1287/isre.10.1.87; Spreng RA, 1996, J MARKETING, V60, P15, DOI 10.2307/1251839; Szymanski DM, 2001, J ACAD MARKET SCI, V29, P16, DOI 10.1177/009207030102900102; TSE DK, 1988, J MARKETING RES, V25, P204, DOI 10.2307/3172652; Yi Y., 1991, REV MARKETING 1990, P68	24	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2007	14	2					225	243		10.1007/s10618-006-0048-4		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	151HR	WOS:000245281600002	
J	de Medeiros, AKA; Weijters, AJMM; van der Aalst, WMP				de Medeiros, A. K. A.; Weijters, A. J. M. M.; van der Aalst, W. M. P.			Genetic process mining: an experimental evaluation	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						process mining; genetic mining; genetic algorithms; Petri nets; workflow nets	EXPRESSIVE PROCESS MODELS; EVENT-BASED DATA; GRAMMATICAL EVOLUTION; PETRI NETS; WORKFLOW MODELS; LOGS; SYSTEMS; ALGORITHM; TRACES	One of the aims of process mining is to retrieve a process model from an event log. The discovered models can be used as objective starting points during the deployment of process-aware information systems (Dumas et al., eds., Process-Aware Information Systems: Bridging People and Software Through Process Technology. Wiley, New York, 2005) and/or as a feedback mechanism to check prescribed models against enacted ones. However, current techniques have problems when mining processes that contain non-trivial constructs and/or when dealing with the presence of noise in the logs. Most of the problems happen because many current techniques are based on local information in the event log. To overcome these problems, we try to use genetic algorithms to mine process models. The main motivation is to benefit from the global search performed by this kind of algorithms. The non-trivial constructs are tackled by choosing an internal representation that supports them. The problem of noise is naturally tackled by the genetic algorithm because, per definition, these algorithms are robust to noise. The main challenge in a genetic approach is the definition of a good fitness measure because it guides the global search performed by the genetic algorithm. This paper explains how the genetic algorithm works. Experiments with synthetic and real-life logs show that the fitness measure indeed leads to the mining of process models that are complete (can reproduce all the behavior in the log) and precise (do not allow for extra behavior that cannot be derived from the event log). The genetic algorithm is implemented as a plug-in in the ProM framework.	Eindhoven Univ Technol, Dept Technol Management, NL-5600 MB Eindhoven, Netherlands	de Medeiros, AKA (reprint author), Eindhoven Univ Technol, Dept Technol Management, POB 513, NL-5600 MB Eindhoven, Netherlands.	a.k.medeiros@tm.tue.nl	weijters, ton/D-1779-2010; van der Aalst, Wil/G-1248-2011	van der Aalst, Wil/0000-0002-0955-6940			Agrawal R, 1998, LECT NOTES COMPUT SC, V1377, P469; ANGLUIN D, 1983, COMPUT SURV, V15, P237; Bourdeaud'huy T., 2002, P 2 IEEE INT C SYST, V1, P528; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Cook J.E., 1998, P 6 INT S FDN SOFTW, P35, DOI 10.1145/288195.288214; Cook JE, 2004, COMPUT IND, V53, P297, DOI 10.1016/j.compind.2003.10.005; Cook JE, 1999, ACM T SOFTW ENG METH, V8, P147, DOI 10.1145/304399.304401; de Medeiros A., 2004, BETA WORKING PAPER S; de Medeiros AKA, 2003, LECT NOTES COMPUT SC, V2888, P389; Desel J., 1995, CAMBRIDGE TRACTS THE, V40; Dumas M, 2005, PROCESS-AWARE INFORMATION SYSTEMS: BRIDGING PEOPLE AND SOFTWARE THROUGH PROCESS TECHNOLOGY, P1, DOI 10.1002/0471741442; Eder J, 2002, LECT NOTES COMPUT SC, V2480, P1; EIBEN AE, 2003, INTRO EVOLUTIONAYR C; Greco G, 2006, IEEE T KNOWL DATA EN, V18, P1010, DOI 10.1109/TKDE.2006.123; Greco G, 2005, LECT NOTES COMPUT SC, V3649, P32; Greco G, 2004, LECT NOTES ARTIF INT, V3056, P52; Grigori D., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Grunwald P. D., 2005, ADV MINIMUM DESCRIPT; Herbst J., 2000, EUR CONC ENG C SCS E; Herbst J., 2001, THESIS U ULM; Herbst J, 2004, COMPUT IND, V53, P245, DOI 10.1016/j.compind.2003.10.002; Herbst J., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<67::AID-ISAF186>3.0.CO;2-7; MALPATHAK S, 2002, J INT MANUFACT, V13, P339; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; Maruster L, 2002, LECT NOTES COMPUT SC, V2534, P364; MARUSTER L, 2003, THESIS EINDHOVEN U T; Mauch H, 2003, LECT NOTES COMPUT SC, V2724, P1810; Maxeiner M.K., 2001, P DAT BUR TECHN WISS, P75; MILNER R, 1992, INFORM COMPUT, V100, P1, DOI 10.1016/0890-5401(92)90008-4; Moore JH, 2003, LECT NOTES COMPUT SC, V2724, P2412; Moore JH, 2003, BIOSYSTEMS, V72, P177, DOI 10.1016/S0303-2647(03)00142-4; Moore JH, 2004, LECT NOTES COMPUT SC, V3005, P63; MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143; Nummela J, 2005, GECCO 2005: Genetic and Evolutionary Computation Conference, Vols 1 and 2, P2133; Pinter SS, 2004, COMPUT IND, V53, P283, DOI 10.1016/j.compind.2003.10.004; PITT L, 1989, LECT NOTES ARTIF INT, V397, P18; Reddy JP, 2001, INT J ADV MANUF TECH, V17, P305; Reisig W., 1998, LECT NOTES COMPUTER, V1491; Rosemann M., 2000, P 33 HAW INT C SYST, P1; Rozinat A, 2006, LECT NOTES COMPUT SC, V3812, P163; SCHEER IDS, 2002, ARIS PROC PERF MAN; Schimm G, 2002, LECT NOTES ARTIF INT, V2424, P525, DOI 10.1007/3-540-45757-7_47; SCHIMM G, PROCESS MINING; Schipper HM, 2004, AGEING RES REV, V3, P265, DOI 10.1016/j.arr.2004.02.001; Tohme H, 1999, P IEEE INT C SYST MA, V4, P441; van der Aalst W, 2004, IEEE T KNOWL DATA EN, V16, P1128, DOI 10.1109/TKDE.2004.47; VANDERAALST WMP, 2005, LECT NOTES COMPUTER, V3536; van der Aalst WMP, 2003, DATA KNOWL ENG, V47, P237, DOI 10.1016/S0169-023X(03)00066-1; van der Aalst WMP, 2002, LECT NOTES COMPUT SC, V2480, P45; van der Aalst WMP, 2004, LECT NOTES COMPUT SC, V3080, P244; VANDERAALST WMP, 2004, PROCESS MINING SPECI, V53; VanGlabbeek RJ, 1996, J ACM, V43, P555, DOI 10.1145/233551.233556; de Medeiros AK, 2006, LECT NOTES COMPUT SC, V3812, P203; Weijters AJMM, 2003, INTEGR COMPUT-AID E, V10, P151; Wen LJ, 2006, LECT NOTES COMPUT SC, V3841, P591; zur M''uhlen M., 2001, P INT C EL COMM RES, P550; 2002, STAFFWARE PROCESS MO	57	50	50	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2007	14	2					245	304		10.1007/s10618-006-0061-7		60	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	151HR	WOS:000245281600003	
J	Vilalta, R; Stepinski, T; Achari, M				Vilalta, R.; Stepinski, T.; Achari, M.			An efficient approach to external cluster assessment with an application to Martian topography	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						external cluster validation; multivariate Gaussian distributions; Martian topography		Automated tools for knowledge discovery are frequently invoked in databases where objects already group into some known (i.e., external) classification scheme. In the context of unsupervised learning or clustering, such tools delve inside large databases looking for alternative classification schemes that are meaningful and novel. An assessment of the information gained with new clusters can be effected by looking at the degree of separation between each new cluster and its most similar class. Our approach models each cluster and class as a multivariate Gaussian distribution and estimates their degree of separation through an information theoretic measure (i.e., through relative entropy or Kullback-Leibler distance). The inherently large computational cost of this step is alleviated by first projecting all data over the single dimension that best separates both distributions (using Fisher's Linear Discriminant). We test our algorithm on a dataset of Martian surfaces using the traditional division into geological units as external classes and the new, hydrology-inspired, automatically performed division as novel clusters. We find the new partitioning constitutes a formally meaningful classification that deviates substantially from the traditional classification.	Univ Houston, Dept Comp Sci, Houston, TX 77204 USA; Lunar & Planetary Inst, Houston, TX 77058 USA	Vilalta, R (reprint author), Univ Houston, Dept Comp Sci, 4800 Calhoun Rd, Houston, TX 77204 USA.	vilalta@cs.uh.edu; tom@lpi.usra.edu; amkchari@cs.uh.edu					Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Cover T. M., 1991, ELEMENTS INFORM THEO; Diggle P. J., 1983, STAT ANAL SPATIAL PO; DOM B, 2001, 10219 IBM TJ WATS RE; Duda R.O., 2001, PATTERN CLASSIFICATI; FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117; HUBERT L, 1976, BRIT J MATH STAT PSY, V29, P190; Jain A.K., 1988, ALGORITHMS CLUSTERIN; KANUNGO T, 1996, IMAGE TECHNOLOGY; KRISHNAPURAM R, 1995, IEEE T FUZZY SYST, V3, P44, DOI 10.1109/91.366570; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; MILLIGAN GW, 1983, IEEE T PATTERN ANAL, V5, P40; PANAYIRCI E, 1983, PATTERN RECOGN, V16, P433, DOI 10.1016/0031-3203(83)90066-3; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Ripley B.D., 1981, SPATIAL STAT; Rolph F.J., 1968, SYST ZOOL, V17, P407; Smith AB, 2003, ORG LETT, V5, P1, DOI 10.1021/ol0202520; STEPINSKI T, 2002, GEOPHYS RES LETT, V29; Stepinski TF, 2004, J GEOPHYS RES-PLANET, V109, DOI 10.1029/2004JE002269; TANAKA K, 1994, 99438 US GEOL SURV; Theodoridis S, 2003, PATTERN RECOGNITION; VAITHYANATHAN S, 2000, P 6 INT C MACH LEARN; WILHELMS DE, 1990, PLANETARY MAPPING; Witten IH, 2000, DATA MINING PRACTICA; ZENG GZ, 1985, PATTERN RECOGN, V18, P191, DOI 10.1016/0031-3203(85)90043-3; ZUBER MT, 1992, J GEOPHYS RES-PLANET, V97, P7781	26	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2007	14	1					1	23		10.1007/s10618-006-0045-7		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	140DE	WOS:000244483000001	
J	Davidson, I; Ravi, SS				Davidson, Ian; Ravi, S. S.			The complexity of non-hierarchical clustering with instance and cluster level constraints	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						non-hierarchical clustering; constraints; complexity		Recent work has looked at extending clustering algorithms with instance level must-link (ML) and cannot-link (CL) background information. Our work introduces delta and epsilon cluster level constraints that influence inter-cluster distances and cluster composition. The addition of background information, though useful at providing better clustering results, raises the important feasibility question: Given a collection of constraints and a set of data, does there exist at least one partition of the data set satisfying all the constraints? We study the complexity of the feasibility problem for each of the above constraints separately and also for combinations of constraints. Our results clearly delineate combinations of constraints for which the feasibility problem is computationally intractable (i.e., NP-complete) from those for which the problem is efficiently solvable (i.e., in the computational class P). We also consider the ML and CL constraints in conjunctive and disjunctive normal forms (CNF and DNF respectively). We show that for ML constraints, the feasibility problem is intractable for CNF but efficiently solvable for DNF. Unfortunately, for CL constraints, the feasibility problem is intractable for both CNF and DNF. This effectively means that CL-constraints in a non-trivial form cannot be efficiently incorporated into clustering algorithms. To overcome this, we introduce the notion of a choice-set of constraints and prove that the feasibility problem for choice-sets is efficiently solvable for both ML and CL constraints. We also present empirical results which indicate that the feasibility problem occurs extensively in real world problems.	SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA	Davidson, I (reprint author), SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA.	davidson@cs.albany.edu; ravi@cs.albany.edu					Bansal N., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181947; Basu S, 2002, P 19 INT C MACH LEAR, P19; Basu S, 2004, SIAM PROC S, P333; Basu S., 2004, P 10 ACM SIGKDD INT, P59, DOI 10.1145/1014052.1014062; Bilenko M., 2004, P 21 INT C MACH LEAR, P11; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; CAMPERS G, 1987, P OP RES 87 BUEN AIR, P917; Charikar M., 2003, Proceedings 44th IEEE Symposium on Foundations of Computer Science - FOCS 2003; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Cormen T. H., 2001, INTRO ALGORITHMS; Davidson I., 2005, P 9 EUR C PRINC PRAC, P59, DOI DOI 10.1007/11564126_11; Davis PM, 2005, PORTAL-LIBR ACAD, V5, P149, DOI 10.1353/pla.2005.0021; DYER M, 1986, J ALGORITHM, P174; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Feige U, 1998, J COMPUT SYST SCI, V57, P187, DOI 10.1006/jcss.1998.1587; Garey M. R., 1979, COMPUTERS INTRACTABI; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; Hansen P, 1997, MATH PROGRAM, V79, P191, DOI 10.1007/BF02614317; HERTZ A, 1987, COMPUTING, V39, P345, DOI 10.1007/BF02239976; Klein D., 2002, P 19 INT C MACH LEAR, P307; PELLEG D, 1999, P ACM SIGKDD INT C K, P277, DOI 10.1145/312129.312248; TAMASSIA R, 1989, IEEE T CIRCUITS SYST, V36, P1230, DOI 10.1109/31.34669; WAGSTAFF K, 2002, THESIS CORNELL U ITH, P50; Wagstaff K., 2001, P 18 INT C MACH LEAR, P577; Wagstaff K, 2000, P 17 INT C MACH LEAR, P1103; West D., 2001, INTRO GRAPH THEORY; Wijsen J, 1998, DATA MIN KNOWL DISC, V2, P263, DOI 10.1023/A:1009755120593	27	9	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2007	14	1					25	61		10.1007/s10618-006-0053-7		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	140DE	WOS:000244483000002	
J	Domeniconi, C; Gunopulos, D; Ma, S; Yan, BJ; Al-Razgan, M; Papadopoulos, D				Domeniconi, Carlotta; Gunopulos, Dimitrios; Ma, Sheng; Yan, Bojun; Al-Razgan, Muna; Papadopoulos, Dimitris			Locally adaptive metrics for clustering high dimensional data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						subspace clustering; dimensionality reduction; local feature relevance; clustering ensembles; gene expression data; text data		Clustering suffers from the curse of dimensionality, and similarity functions that use all input features with equal relevance may not be effective. We introduce an algorithm that discovers clusters in subspaces spanned by different combinations of dimensions via local weightings of features. This approach avoids the risk of loss of information encountered in global dimensionality reduction techniques, and does not assume any data distribution model. Our method associates to each cluster a weight vector, whose values capture the relevance of features within the corresponding cluster. We experimentally demonstrate the gain in perfomance our method achieves with respect to competitive methods, using both synthetic and real datasets. In particular, our results show the feasibility of the proposed technique to perform simultaneous clustering of genes and conditions in gene expression data, and clustering of very high-dimensional data such as text data.	George Mason Univ, Fairfax, VA 22030 USA; Univ Calif Riverside, Riverside, CA 92521 USA; Vivido Media Inc, Beijing 100085, Peoples R China	Domeniconi, C (reprint author), George Mason Univ, Fairfax, VA 22030 USA.	carlotta@ise.gmu.edu					Agarwal R, 1998, P ACM SIGMOD INT C M, P94; Aggarwal C., 1999, P 1999 ACM SIGMOD IN, P61, DOI 10.1145/304182.304188; Aggarwal C. C., 2000, P ACM SIGMOD INT C M, P70, DOI 10.1145/342009.335383; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Al-Razgan M, 2006, SIAM PROC S, P258; ARABIE P, 1996, OVERVIEW COMBINATORI, P5; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Chakrabarti K., 2000, P 26 INT C VER LARG, P89; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; Cheng Y., 2000, P 8 INT C INT SYST M, P93; Dhillon I. S, 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; Domeniconi C, 2004, SIAM PROC S, P517; Duda R., 1973, PATTERN CLASSIFICATI; Dy J, 2000, P 17 INT C MACH LEAR, P247; Ester M., 1995, P 1 INT C KNOWL DISC, P94; Fern XZ, 2004, P 21 INT C MACH LEAR, P281; Friedman J.H., 2002, CLUSTERING OBJECTS S; Fukunaga K., 1990, INTRO STAT PATTERN R; Ghahramani Z, 1996, CRGTR961 U TOR DEP C; HARTIGAN JA, 1972, J AM STAT ASSOC, V67, P123, DOI 10.2307/2284710; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; KHARYPIS G, 1995, MULTILEVEL K WAY PAR; MICHALSKI RS, 1983, MACHINE LEARNING ART, V2, P331; MLADENOVIC N, 1996, CAHIERS GERAD; Modha DS, 2003, MACH LEARN, V52, P217, DOI 10.1023/A:1024016609528; Ng R, 1994, P 20 INT C VER LARG, P144; Parsons L, 2004, ACM SIGKDD EXPLORATI, V6, P90, DOI 10.1145/1007730.1007731; Procopiuc CM, 2002, P ACM SIGMOD INT C M, P418; Rubin D, 1997, J ROYAL STAT SOC B, V39, P1; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Thomasian A., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288658; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Wang H., 2002, P 2002 ACM SIGMOD IN, P394; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; YANG J, 2002, P INT C DAT ENG, P517; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680	38	45	54	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2007	14	1					63	97		10.1007/s10618-006-0060-8		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	140DE	WOS:000244483000003	
J	Keogh, E; Lonardi, S; Ratanamahatana, CA; Wei, L; Lee, SH; Handley, J				Keogh, Eamonn; Lonardi, Stefano; Ratanamahatana, Chotirat Ann; Wei, Li; Lee, Sang-Hee; Handley, John			Compression-based data mining of sequential data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	10th International Conference on Knowledge Discovery and Data Mining	2004	Seattle, WA			Kolmogorov complexity; parameter-free data mining; anomaly detection; clustering		The vast majority of data mining algorithms require the setting of many input parameters. The dangers of working with parameter-laden algorithms are twofold. First, incorrect settings may cause an algorithm to fail in finding the true patterns. Second, a perhaps more insidious problem is that the algorithm may report spurious patterns that do not really exist, or greatly overestimate the significance of the reported patterns. This is especially likely when the user fails to understand the role of parameters in the data mining process. Data mining algorithms should have as few parameters as possible. A parameter-light algorithm would limit our ability to impose our prejudices, expectations, and presumptions on the problem at hand, and would let the data itself speak to us. In this work, we show that recent results in bioinformatics, learning, and computational theory hold great promise for a parameter-light data-mining paradigm. The results are strongly connected to Kolmogorov complexity theory. However, as a practical matter, they can be implemented using any off-the-shelf compression algorithm with the addition of just a dozen lines of code. We will show that this approach is competitive or superior to many of the state-of-the-art approaches in anomaly/interestingness detection, classification, and clustering with empirical tests on time series/DNA/text/XML/video datasets. As a further evidence of the advantages of our method, we will demonstrate its effectiveness to solve a real world classification problem in recommending printing services and products.	Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA; Chulalongkorn Univ, Dept Comp Engn, Bangkok, Thailand; Univ Calif Riverside, Dept Anthropol, Riverside, CA 92521 USA; Xerox Corp, Xerox Innovat Grp, Webster, NY 14580 USA	Keogh, E (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	eamonn@cs.ucr.edu; stelo@cs.ucr.edu; ann@cp.eng.chula.ac.th; wli@cs.ucr.edu; shlee@ucr.edu; jhandley@xeroxlabs.com					Allison L, 2000, COMPUT CHEM, V24, P43, DOI 10.1016/S0097-8485(99)00046-7; Baronchelli A, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/04/P04002; Benedetto D, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.048702; CHAKRABARTI D, 2004, P KDD 2004 SEATTL WA; CHRISTEN P, 2005, AUTOMATED DATA LINKA; Cook DJ, 2000, IEEE INTELL SYST APP, V15, P32, DOI 10.1109/5254.850825; DASGUPTA D, 1999, P INT C INT SYST HEI; DOMINGOS P, 1998, P 15 INT C, P27; Elkan C, 2003, P 20 INT C MACH LEAR, P147; FALOUTSOS C, 1995, P 24 ACM SIGMOD SAN; FARACH M, 1995, PROCEEDINGS OF THE SIXTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P48; Ferranti F., 1994, Proceedings, 18th World Buiatrics Congress: 26th Congress of the Italian Association of Buiatrics, Bologna, Italy, August 29-September 2, 1994. Volume 1., P261; Flexer A., 1996, P 13 EUR M CYB SYST, V2, P1005; Frank E., 2000, Proceedings DCC 2000. Data Compression Conference, DOI 10.1109/DCC.2000.838202; Gatlin L. L., 1972, INFORM THEORY LIVING; GAUSSIER E, 2002, P 24 BCS IRSG EUR C, V2291; GAVRILOV M, 2000, P 6 ACM SIGKDD 2000; Ge X., 2000, P 6 ACM SIGKDD INT C, P81, DOI 10.1145/347090.347109; Goldberger AL, 2000, CIRCULATION, V101, pE215; Kalpakis K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989529; Kennel MB, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.056208; Keogh E., 2003, P 3 IEEE INT C DAT M, P115; KEOGH E, 2002, P SIGKDD EDM ALB CAN; Keogh E., 2002, UCR TIME SERIES DATA; KIT C, 1998, ESSLLI 98 STUDENT SE, P175; Li M, 2003, SIAM PROC S, P863; Li M, 2001, BIOINFORMATICS, V17, P149, DOI 10.1093/bioinformatics/17.2.149; Li Ming, 1997, INTRO KOLMOGOROV COM; Lin J., 2003, P 8 ACM SIGMOD WORKS; LOEWENSTERN D, 1995, 9504 DIMACS; LOEWENSTERN D, 1999, J COMPUT BIOL, V6; MA J, 2003, P INT C KNOWL DISC D; MAHONEY M, 2005, LEARNING RULES TIME; Mehta M., 1995, P 1 INT C KNOWL DISC; Needham S. L., 2001, P 8 INT WORKSH ART I, P253; ORTEGA A, 2000, P EUR SIGN PROC C EU; PAPADIMITRIOU S, 2005, P 5 INT C DAT MIN IC; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; Ratanamahatana C. A., 2004, P SIAM INT C DAT MIN; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Sculley D., 2006, P DAT COMPR C DCC 20, P332; SEGEN J, 1990, P MACH LEARN C AUST, P93; Shahabi C., 2000, P 12 INT C SCI STAT; Teahan WJ, 2000, COMPUT LINGUIST, V26, P375, DOI 10.1162/089120100561746; Vlachos M, 2003, P 9 ACM SIGKDD INT C, P216; WALLACE CS, 1968, COMPUT J, V11, P185; YAIRI T, 2001, P INT SYM AI ROB AUT; [Anonymous], 2001, P 7 ACM SIGKDD INT C, P426, DOI 10.1145/502512.502576	49	11	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2007	14	1					99	129		10.1007/s10618-006-0049-3		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	140DE	WOS:000244483000004	
J	Gambs, S; Kegl, B; Aimeur, E				Gambs, Sebastien; Kegl, Balazs; Aimeur, Esma			Privacy-preserving boosting	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						privacy-preserving data mining; boosting; AdaBoost distributed learning; secure multiparty computation	ALGORITHMS	We describe two algorithms, BiBoost ( Bipartite Boosting) and MultBoost ( Multiparty Boosting), that allow two or more participants to construct a boosting classifier without explicitly sharing their data sets. We analyze both the computational and the security aspects of the algorithms. The algorithms inherit the excellent generalization performance of AdaBoost. Experiments indicate that the algorithms are better than AdaBoost executed separately by the participants, and that, independently of the number of participants, they perform close to AdaBoost executed using the entire data set.	Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada	Kegl, B (reprint author), Univ Montreal, Dept Comp Sci & Operat Res, CP 6128,Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.	gambsseb@iro.umontreal.ca; kegl@iro.umontreal.ca; aimeur@iro.umontreal.ca					Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; AIMEUR E, 2004, P INT WORKSH PRIV SE, P51; AMIT Y, 2000, 496 U CHIC DEP STAT; Atallah M, 1999, P 1999 IEEE KNOWL DA, P45; Bayardo R.J., 2005, P 21 INT C DAT ENG I, P217; Rabin T., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, DOI 10.1145/73007.73014; Bertino E, 2005, DATA MIN KNOWL DISC, V11, P121, DOI 10.1007/s10618-005-0006-6; Blake C, 1998, UCI REPOSITORY MACHI; CHANG L, 2000, P DAT APPL SEC, P161; Chang YC, 2001, P AS 01, P369; Chaum D., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/62212.62214; CHAUM D., 1981, COMMUN ACM, V24, P2; Chaum D., 1987, P CRYPTO 87, P87; Chawla S, 2005, P 2 THEOR CRYPT C; Clifton C., 2002, SIGKDD EXPLORATIONS, V4, P28; CLIFTON C, 2004, DATA MINING NEXT GEN; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dinur I., 2003, P 22 ACM SIGACT SIGM, P202, DOI DOI 10.1145/773153.773173; Evfimievski A, 2002, SIGKDD EXPLORATIONS, V4, P43; Evfimievski A., 2003, P 22 ACM SIGMOD SIGA, P211, DOI 10.1145/773153.773174; Fan W, 1999, P 5 ACM SIGKDD INT C, P362, DOI 10.1145/312129.312283; Feigenbaum J., 2001, P 28 INT C AUT LANG, P927; Fienberg SE, 2004, ANN NY ACAD SCI, V3050, P14; Freedman M., 2004, P INT C THEOR APPL C, P1; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Furukawa J, 2001, P CRYPTO 01, P368; Goldreich O., 2004, FDN CRYPTOGRAPHY, V2; Goldreich Oded, 1987, P 19 ANN ACM S THEOR, P218, DOI 10.1145/28395.28420; Ben-Or M., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/62212.62213; Iyengar V.S., 2002, P 8 ACM SIGKDD INT C, P279; Kalyanasundaram B., 1987, Proceedings of Structure in Complexity Theory Second Annual Conference (Cat. No.87CH2438-0); Kantarcioglu M, 2004, IEEE T KNOWL DATA EN, V16, P1026, DOI 10.1109/TKDE.2004.45; Kantarcioglu M., 2004, P 10 ACM SIGKDD INT, P599; KANTARCIOGLU M, 2004, P WORKSH PRIV PRES D; KANTARCIOGLU M, 2004, EUR C PRINC DAT MIN, P279; KEGL B, 2003, P 16 C COMP LEARN TH, P258; Kissner L, 2005, P CRYPT 2005, P241; KOLCZ A, 2002, P 8 C KNOWL DISC DAT, P307; KRUGER L, 2005, P 10 EUR S RES COMP, P397; Lazarevic A, 2002, DISTRIB PARALLEL DAT, V11, P203, DOI 10.1023/A:1013992203485; Lindell Y, 2002, J CRYPTOL, V15, P177, DOI 10.1007/s00145-001-0019-2; NEFF A, 2001, ACM CCS, pFB116; PAILLIER P, 2000, P ASIACRYPT, P573; Predd JB, 2006, IEEE T INFORM THEORY, V52, P52, DOI 10.1109/TIT.2005.860420; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P571, DOI 10.1142/S021848850200165X; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Verykios VS, 2004, SIGMOD REC, V33, P50; Yao A., 1986, P 27 IEEE S FDN COMP, P162; YU H, 2006, P 2006 ACM S APPL CO, P603, DOI 10.1145/1141277.1141415	54	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2007	14	1					131	170		10.1007/s10618-006-0051-9		40	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	140DE	WOS:000244483000005	
J	Calders, T; Goethals, B				Calders, Toon; Goethals, Bart			Non-derivable itemset mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; itemsets; condensed representation	INCLUSION-EXCLUSION; APPROXIMATE	All frequent itemset mining algorithms rely heavily on the monotonicity principle for pruning. This principle allows for excluding candidate itemsets from the expensive counting phase. In this paper, we present sound and complete deduction rules to derive bounds on the support of an itemset. Based on these deduction rules, we construct a condensed representation of all frequent itemsets, by removing those itemsets for which the support can be derived, resulting in the so called Non-Derivable Itemsets (NDI) representation. We also present connections between our proposal and recent other proposals for condensed representations of frequent itemsets. Experiments on real-life datasets show the effectiveness of the NDI representation, making the search for frequent non-derivable itemsets a useful and tractable alternative to mining all frequent itemsets.	Tech Univ Eindhoven, NL-5600 MB Eindhoven, Netherlands; Univ Antwerp, B-2020 Antwerp, Belgium	Calders, T (reprint author), Tech Univ Eindhoven, POB 513, NL-5600 MB Eindhoven, Netherlands.	t.calders@tue.nl; bart.goethals@ua.ac.be					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bastide Yves, 2000, SIGKDD EXPLORATIONS, V2, P66, DOI DOI 10.1145/380995.381017; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bonferroni C. E., 1936, PUBBL R INT SUPER SC, V8, P1; BOULICAUT J, 2003, DATA MIN KNOWL DISC, V4, P5; BOULICAUT JF, 2000, P PAKDD, P62; Boulicaut J.-F., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Bykowski A, 2003, INFORM SYST, V28, P949, DOI 10.1016/S0306-4379(03)00002-4; Bykowski A, 2001, P 20 ACM SIGACT SIGM, P267, DOI 10.1145/375551.375604; Calders T, 2003, LECT NOTES ARTIF INT, V2838, P71; CALDERS T, 2005, LNCS, V3933, P86; Calders T., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); CALDERS T, 2003, THESIS U ANTWERP BEL; CALDERS T, 2003, LNCS, V2682, P214; CALDERS T, 2005, P SIAM INT C DAT MIN; DEXTERS N, 2004, P ECML PKDD 2004 WOR, P25; Dobra A, 2002, THESIS CARNEGIE MELL; Dobra A, 2000, P NATL ACAD SCI USA, V97, P11885, DOI 10.1073/pnas.97.22.11885; DOBRA A, 2001, UNECE STAT J, V18, P363; FIENBERG SE, 1998, STAT DAT PROT P C EU, P115; Frechet M., 1951, ANN U LYON         A, V4, P53; Galambos J., 1996, BONFERRONI TYPE INEQ; GOETHALS B, 2005, P SIAM INT C DAT MIN; Goethals B, 2004, SIGKDD EXPLORATIONS, V6, P109; GROTH D, 2001, P WORKSH RUL BAS DAT; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Jaroszewicz S., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); JAROSZEWICZ S, 2002, P DISCR MATH DAT MIN; JORDAN C, 1927, MAT PHYS LAPOK, V34, P109; Kahn J, 1996, COMBINATORICA, V16, P465, DOI 10.1007/BF01271266; Kryszkiewicz M, 2002, P 6 PAKDD C, P159; Kryszkiewicz M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989533; KRYSZKIEWICZ M, 2002, P INT S METH INT SYS, P382; MANNILA H, 1996, P KDD INT C KNOWL DI; Melkman AA, 1997, DISCRETE APPL MATH, V73, P23, DOI 10.1016/S0166-218X(96)00048-0; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; PEI J, 2000, ACM SIGMOD WORKSH RE; Pei J, 2004, KNOWL INF SYST, V6, P570, DOI 10.1007/s10115-003-0133-6; ZAKI M, 1999, 9910 RENSS POL I COM; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291	42	33	34	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	FEB	2007	14	1					171	206		10.1007/s10618-006-0054-6		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	140DE	WOS:000244483000006	
J	Yang, Y; Wu, XD; Zhu, XQ				Yang, Ying; Wu, Xindong; Zhu, Xingquan			Mining in anticipation for concept change: Proactive-reactive prediction in data streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data stream; concept change; classification; proactive learning; reactive learning; conceptual equivalence		Prediction in streaming data is an important activity in the modern society. Two major challenges posed by data streams are (1) the data may grow without limit so that it is difficult to retain a long history of raw data; and (2) the underlying concept of the data may change over time. The novelties of this paper are in four folds. First, it uses a measure of conceptual equivalence to organize the data history into a history of concepts. This contrasts to the common practice that only keeps recent raw data. The concept history is compact while still retains essential information for learning. Second, it learns concept-transition patterns from the concept history and anticipates what the concept will be in the case of a concept change. It then proactively prepares a prediction model for the future change. This contrasts to the conventional methodology that passively waits until the change happens. Third, it incorporates proactive and reactive predictions. If the anticipation turns out to be correct, a proper prediction model can be launched instantly upon the concept change. If not, it promptly resorts to a reactive mode: adapting a prediction model to the new data. Finally, an efficient and effective system RePro is proposed to implement these new ideas. It carries out prediction at two levels, a general level of predicting each oncoming concept and a specific level of predicting each instance's class. Experiments are conducted to compare RePro with representative existing prediction methods on various benchmark data sets that represent diversified scenarios of concept change. Empirical evidence offers inspiring insights and demonstrates the proposed methodology is an advisable solution to prediction in data streams.	Monash Univ, Sch Comp Sci & Software Engn, Melbourne, Vic 3800, Australia; Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA	Yang, Y (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Melbourne, Vic 3800, Australia.	yyang@csse.monash.edu.au; xwu@cs.uvm.edu; xqzhu@cs.uvm.edu					Aggarwal C., 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1; BLAKE CL, 2005, UCI REPOSITORY MACHI; Ganti V, 2001, IEEE T KNOWL DATA EN, V13, P50, DOI 10.1109/69.908980; Gehrke J., 1999, P ACM SIGMOD INT C M, P169, DOI 10.1145/304182.304197; HARRIES MB, 1996, PRICAI WORKSH, P106; Hulten G., 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; Jain R. K., 1991, ART COMPUTER SYSTEMS; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; KOLTER JZ, 2003, P 3 IEEE INT C DAT M, P123; Lanquillon C, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P538, DOI 10.1145/319950.320061; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Salganicoff M, 1997, ARTIF INTELL REV, V11, P133, DOI 10.1023/A:1006515405170; STNALEY KO, 2003, AI03302 U TEX AUST D; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; Tsymbal A., 2004, TCDCS200415 TRIN COL; Wang H., 2003, P 9 ACM SIGKDD INT C, P226, DOI DOI 10.1145/956750.956778; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280; YANG Y, 2004, P 8 EUR C PRINC PRAC, P471	18	14	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2006	13	3					261	289		10.1007/s10618-006-0050-x		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	088IV	WOS:000240806300001	
J	Verbeek, JJ; Nunnink, JRJ; Vlassis, N				Verbeek, Jakob J.; Nunnink, Jan R. J.; Vlassis, Nikos			Accelerated EM-based clustering of large data sets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Gaussian mixtures; EM algorithm; free energy; kd-trees; large data sets	DENSITY-ESTIMATION; ALGORITHM; MODELS; TREES	Motivated by the poor performance (linear complexity) of the EM algorithm in clustering large data sets, and inspired by the successful accelerated versions of related algorithms like k-means, we derive an accelerated variant of the EM algorithm for Gaussian mixtures that: (1) offers speedups that are at least linear in the number of data points, (2) ensures convergence by strictly increasing a lower bound on the data log-likelihood in each learning step, and (3) allows ample freedom in the design of other accelerated variants. We also derive a similar accelerated algorithm for greedy mixture learning, where very satisfactory results are obtained. The core idea is to define a lower bound on the data log-likelihood based on a grouping of data points. The bound is maximized by computing in turn (i) optimal assignments of groups of data points to the mixture components, and (ii) optimal re-estimation of the model parameters based on average sufficient statistics computed over groups of data points. The proposed method naturally generalizes to mixtures of other members of the exponential family. Experimental results show the potential of the proposed method over other state-of-the-art acceleration techniques.	INRIA Rhone Alpes, F-38330 Montbonnot St Martin, France; Univ Amsterdam, Inst Informat, NL-1098 SJ Amsterdam, Netherlands	Verbeek, JJ (reprint author), INRIA Rhone Alpes, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	verbeek@inrialpes.fr; jnunnink@science.uva.nl; vlassis@science.uva.nl					Bentley JL, 1975, COMMUN ACM, V18; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; BRADLEY P, 1998, MSRTR9835 MICR RES; Dasgupta S., 1999, P IEEE S FDN COMP SC, V40, P634; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Gersho A., 1992, VECTOR QUANTIZATION; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Li JQ, 2000, ADV NEUR IN, V12, P279; LINDSAY BG, 1983, ANN STAT, V11, P86, DOI 10.1214/aos/1176346059; MCCALLUM A, 2000, P ACM SIGKDD INT C K, V6; McLachlan G., 2000, FINITE MIXTURE MODEL; MOORE A, 1999, P 5 INT C KNOWL DISC, P277; Moore A, 1998, J ARTIF INTELL RES, V8, P67; MOORE AW, 2000, P ANN C UNC ART INT, V16, P397; Moore AW, 1999, ADV NEUR IN, V11, P543; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; NUNNINK JRJ, 2003, THESIS U AMSTERDAM; Omohundro S. M., 1989, TR89063 INT COMP SCI; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; SAND P, 2001, P INT C MACH LEARN, V18, P457; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Thiesson B, 2001, MACH LEARN, V45, P279, DOI 10.1023/A:1017986506241; Titsias MK, 2001, IEEE T NEURAL NETWOR, V12, P987, DOI 10.1109/72.950129; Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004; Vlassis N, 2002, NEURAL PROCESS LETT, V15, P77, DOI 10.1023/A:1013844811137; ZHANG T, 2002, ADV NEURAL INFORMATI, V14	26	16	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2006	13	3					291	307		10.1007/s10618-005-0033-3		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	088IV	WOS:000240806300002	
J	De Vel, O				De Vel, Olivier			Learning semi-structured document categorization using bounded-length spectrum sub-sequence kernels	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						document categorization; suffix tree; bounded-length spectrum; kernel; support vector machines; Naive Bayes classifier; computer forensics; digital forensics	CONSTRUCTION	In this paper we report an investigation into the learning of semi-structured document categorization. We automatically discover low-level, short-range byte data structure patterns from a document data stream by extracting all byte sub-sequences within a sliding window to form an augmented (or bounded-length) string spectrum feature map and using a modified suffix trie data structure (called the coloured generalized suffix tree or CGST) to efficiently store and manipulate the feature map. Using the CGST we are able to efficiently compute the stream's bounded-length sequence spectrum kernel. We compare the performance of two classifier algorithms to categorize the data streams, namely, the SVM and Naive Bayes (NB) classifiers. Experiments have provided good classification performance results on a variety of document byte streams, particularly when using the NB classifier under certain parameter settings. Results indicate that the bounded-length kernel is superior to the standard fixed-length kernel for semi-structured documents.	Def Sci & Technol Org, Informat Networks Div, Informat Assurance Branch, Edinburgh, SA 5111, Australia	De Vel, O (reprint author), Def Sci & Technol Org, Informat Networks Div, Informat Assurance Branch, POB 1500, Edinburgh, SA 5111, Australia.	olivier.devel@dsto.defence.gov.au					BAYS J, 1974, THESIS U OKLAHOMA; Bieganski P., 1994, Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences. Vol.V: Biotechnology Computing (Cat. No.94TH0607-2), DOI 10.1109/HICSS.1994.323593; CANCEDDA N, 2002, P 11 TEXT RETR C TRE; Cancedda N, 2003, J MACH LEARN RES, V3, P1059, DOI 10.1162/153244303322533197; Collins M, 2002, ADV NEUR IN, V14, P625; Cristianini N., 2001, P 18 INT C MACH LEAR, P66; de Vel O., 2000, P WORKSH TEXT MIN AC; DEVEL O, 2002, DIG FOR RES WORKSH D; Eskin E., 2002, APPL DATA MINING COM; Hastie T., 2001, ELEMENTS STAT LEARNI; HAUSSLER D, 1999, UCSCCRL9910 U CAL SA; Jensen K., 1997, COLOURED PETRI NETS; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; JOACHIMS T, 1999, ADV KEMEL METHODS SU; Leslie C, 2003, LECT NOTES ARTIF INT, V2777, P114, DOI 10.1007/978-3-540-45167-9_10; LESLIE C, 2002, P NEUR INF PROC SYST; LESLIE C, 2002, P PAC S BIOC PSB 200; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Manevitz LM, 2001, J MACHINE LEARNING R, V2, P139; MCCREIGHT EM, 1976, J ACM, V23, P262, DOI 10.1145/321941.321946; Mitchell T. M, 1997, MACHINE LEARNING; MLADENIC D, 1998, LEARN TEXT WEB C AUT; OCALLAGHAN L, 2001, P DIMACS WORKSH STRE; Scholkopf B., 2002, LEARNING KERNELS; TEYTAUD O, 2001, INT JOINT C NEUR NET; UKKONEN E, 1995, ALGORITHMICA, V14, P249, DOI 10.1007/BF01206331; Vapnik V.N., 1995, NATURE STAT LEARNING; VISHWANATHAN S, 2003, ADV NEURAL INFORMATI, V15, P66; VISHWANATHAN S, 2002, THESIS INDIAN I SCI; WATKINS C, 1999, CSDTR9811 U LOND ROY; Yang Y., 1999, P 22 INT ACM SIGIR C, P67; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205	33	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2006	13	3					309	334		10.1007/s10618-005-0037-z		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	088IV	WOS:000240806300003	
J	Wang, XZ; Smith, K; Hyndman, R				Wang, Xiaozhe; Smith, Kate; Hyndman, Rob			Characteristic-based clustering for time series data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						time series clustering; clustering; global characteristics; feature measures; dimensionality reduction	VALIDATION; WAVELETS	With the growing importance of time series clustering research, particularly for similarity searches amongst long time series such as those arising in medicine or finance, it is critical for us to find a way to resolve the outstanding problems that make most clustering methods impractical under certain circumstances. When the time series is very long, some clustering algorithms may fail because the very notation of similarity is dubious in high dimension space; many methods cannot handle missing data when the clustering is based on a distance metric. This paper proposes a method for clustering of time series based on their structural characteristics. Unlike other alternatives, this method does not cluster point values using a distance metric, rather it clusters based on global features extracted from the time series. The feature measures are obtained from each individual series and can be fed into arbitrary clustering algorithms, including an unsupervised neural network algorithm, self-organizing map, or hierarchal clustering algorithm. Global measures describing the time series are obtained by applying statistical operations that best capture the underlying characteristics: trend, seasonality, periodicity, serial correlation, skewness, kurtosis, chaos, nonlinearity, and self-similarity. Since the method clusters using extracted global measures, it reduces the dimensionality of the time series and is much less sensitive to missing or noisy data. We further provide a search mechanism to find the best selection from the feature set that should be used as the clustering inputs. The proposed technique has been tested using benchmark time series datasets previously reported for time series clustering and a set of time series datasets with known characteristics. The empirical results show that our approach is able to yield meaningful clusters. The resulting clusters are similar to those produced by other methods, but with some promising and interesting variations that can be intuitively explained with knowledge of the global characteristics of the time series.	Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia; Monash Univ, Dept Econometr & Business Stat, Clayton, Vic 3800, Australia	Wang, XZ (reprint author), Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia.	catherine.wang@infotech.monash.edu.au; kate.smith@infotech.monash.edu.au; rob.hyndman@buseco.monash.edu.au	Hyndman, Rob/A-2268-2008; Smith-Miles, Kate/B-7493-2008				Armstrong J. S, 2001, PRINCIPLES FORECASTI; Atkinson AC, 2000, ROBUST DIAGNOSTIC RE; Berndtand D., 1994, P AAAI 94 WORKSH KNO, P229; BOX GEP, 1964, J ROY STAT SOC B, V26, P211; Box G. E. P., 1970, J AM STAT ASSOC, V65, P1509, DOI DOI 10.2307/2284333; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; Chan KP, 1999, PROC INT CONF DATA, P126; Chatfield C., 1996, ANAL TIME SERIES INT; Chu K. K. W., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, DOI 10.1145/303976.304000; Cleveland R.B., 1990, J OFF STAT, V6, P3; Cleveland W. S., 1994, ELEMENTS GRAPHING DA; COX DR, 1984, P 50 ANN C, P55; David BL., 1993, P 4 INT C FDN DAT OR, P69; Debregeas A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Dellaert F., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.608022; Deng K., 1997, P INT S COMP INT ROB, P246; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; Ge X., 2000, P 6 ACM SIGKDD INT C, P81, DOI 10.1145/347090.347109; GROSSI L, 2002, P 15 S COMP STAT BER, P521; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Hamilton JD, 1994, TIME SERIES ANAL; Hand D.J., 1994, HDB SMALL DATA SETS; Harvill JL, 1999, BIOMETRIKA, V86, P728, DOI 10.1093/biomet/86.3.728; HASLETT J, 1989, APPL STAT-J ROY ST C, V38, P1, DOI 10.2307/2347679; Hilborn R. C., 1994, CHAOS NONLINEAR DYNA; Honkela T., 1997, THESIS HELSINKI U TE; HOSKING JRM, 1984, WATER RESOUR RES, V20, P1898, DOI 10.1029/WR020i012p01898; HUNTALA Y, 1999, P DAT MIN KNOWL DISC, P150; Indyk P., 2000, P 26 INT C VER LARG, P363; Jain A. K., 1999, ACM COMPUT SURV, V31; Kalpakis K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989529; Keogh E., 2003, P 3 IEEE INT C DAT M, P115; KEOGH E, 1997, P 3 INT C KNOWL DISC, P20; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Keogh E., 2002, UCR TIME SERIES DATA; KOHONEN T, 2002, 0002001 BIENN; Lange T, 2004, NEURAL COMPUT, V16, P1299, DOI 10.1162/089976604773717621; LEE K, 2001, J ARTIFICIAL LIFE RO, V4, P182; LIN J, 2004, P 9 INT C EXT DAT TE, P106; LU ZQ, 1996, THESIS U N CAROLINA; Makridakis S., 1998, FORECASTING METHODS; MORCEN F, 2003, TIME SERIES FEATURE; Nanopoulos A, 2001, INFORMATION PROCESSING AND TECHNOLOGY, P49; Popivanov I, 2002, PROC INT CONF DATA, P212, DOI 10.1109/ICDE.2002.994711; Pyle D, 1999, DATA PREPARATION DAT; Ratanamahatana CA, 2005, SIAM PROC S, P506; ROCCA ML, 2004, P 36 S INT BALT MARY; Rose O., 1996, ESTIMATION HURST PAR; ROYSTON JP, 1982, APPL STAT-J ROY ST C, V31, P115, DOI 10.2307/2347973; Scargle J, 2000, B AM ASTRONOMICAL SO, V32, P1438; Teraesvirta T., 1993, J TIME SER ANAL, V14, P209, DOI 10.1111/j.1467-9892.1993.tb00139.x; TERASVIRTA T, 1996, STUDIES NONLINEAR DY, V1, P3, DOI 10.2202/1558-3708.1008; VANLAERHOVEN K, 2001, LECT NOTES ARTIF INT, P464; Wallace C. S., 1999, MIT ENCY COGNITIVE S, P550; Wang CH, 2000, ENDOCRINE, V12, P69, DOI 10.1385/ENDO:12:1:69; WILLINGER W, 1996, SELF SIMILARITY HEAV, P27; WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9; Wood SN, 2000, J ROY STAT SOC B, V62, P413, DOI 10.1111/1467-9868.00240; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680	61	40	42	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2006	13	3					335	364		10.1007/s10618-005-0039-x		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	088IV	WOS:000240806300004	
J	Banerjee, A; Ghosh, J				Banerjee, Arindam; Ghosh, Joydeep			Scalable clustering algorithms with balancing constraints	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						scalable clustering; balanced clustering; constrained clustering; sampling; stable marriage problem; text clustering		Clustering methods for data-mining problems must be extremely scalable. In addition, several data mining applications demand that the clusters obtained be balanced, i.e., of approximately the same size or importance. In this paper, we propose a general framework for scalable, balanced clustering. The data clustering process is broken down into three steps: sampling of a small representative subset of the points, clustering of the sampled data, and populating the initial clusters with the remaining data followed by refinements. First, we show that a simple uniform sampling from the original data is sufficient to get a representative subset with high probability. While the proposed framework allows a large class of algorithms to be used for clustering the sampled set, we focus on some popular parametric algorithms for ease of exposition. We then present algorithms to populate and refine the clusters. The algorithm for populating the clusters is based on a generalization of the stable marriage problem, whereas the refinement algorithm is a constrained iterative relocation scheme. The complexity of the overall method is O(kN log N) for obtaining k balanced clusters from N data points, which compares favorably with other existing techniques for balanced clustering. In addition to providing balancing guarantees, the clustering performance obtained using the proposed framework is comparable to and often better than the corresponding unconstrained solution. Experimental results on several datasets, including high-dimensional (> 20,000) ones, are provided to demonstrate the efficacy of the proposed framework.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; Univ Texas, Coll Engn, Dept Elect & Comp Engn, Austin, TX 78712 USA	Banerjee, A (reprint author), Univ Minnesota, Dept Comp Sci & Engn, 200 Union St SE, Minneapolis, MN 55455 USA.	banerjee@cs.umn.edu; jd@ece.utexas.edu					BAEZAYATES R, 1999, MODEM INFORMATION ET; Banerjee A, 2004, IEEE T NEURAL NETWOR, V15, P702, DOI 10.1109/TNN.2004.824416; Banerjee A, 2005, J MACH LEARN RES, V6, P1345; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; BENNETT KP, 2000, TR200065 MICR RES; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Bradley P.S., 1998, SCALING EM EXPECTATI; Cover T. M., 1991, ELEMENTS INFORMATION; CUTTING DR, 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Domingos P, 2001, P 18 INT C MACH LEAR, P106; Duda R.O., 2001, PATTERN CLASSIFICATI; Fasulo D., 1999, ANAL RECENT WORK CLU; Feller W., 1967, INTRO PROBABILITY TH; Ghiasi S, 2002, SENSORS, V2, P258, DOI 10.3390/s20700258; Ghosh J, 2003, HUM FAC ER, P247; Guan Y., 2003, P CAN C EL COMP ENG, P1083; Gupta G., 2003, P IEEE INT C COMM IC, V3, P1848; GUPTA GK, 2001, P 1 SIAM INT C DAT M; Gusfield D, 1989, STABLE MARRIAGE PROB; Han J., 2001, SPATIAL CLUSTERING M; Jain A. K., 1999, ACM COMPUT SURV, V31; Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997; Kearns M., 1997, P 13 C UNC ART INT, P282; AHALT SC, 1990, NEURAL NETWORKS, V3, P277, DOI 10.1016/0893-6080(90)90071-R; Lynch P.J., 2002, WEB STYLE GUIDE BASI; McQueen J, 1967, P 5 BERK S MATH STAT, V1, P281; Modha DS, 2003, MACH LEARN, V52, P217, DOI 10.1023/A:1024016609528; MOTWANI R, 1995, RANDMIZED ALGORITHMS; PALMER CR, 1999, DENSITY BIASED SAMPL; Papoulis A., 1991, PROBABILITY RANDOM V; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; SINGH P, 2005, COMMUNICATION; Strehl A, 2003, INFORMS J COMPUT, V15, P208, DOI 10.1287/ijoc.15.2.208.14448; Tung AKH, 2001, P INT C DAT THEOR IC; Yang Y., 2003, P 3 IEEE INT C DAT M, P411; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324; *NEILS MARK RES, 1993, CAT MAN POS YOUR ORG	38	9	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2006	13	3					365	395		10.1007/s10618-006-0040-z		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	088IV	WOS:000240806300005	
J	Leban, G; Zupan, B; Vidmar, G; Bratko, I				Leban, Gregor; Zupan, Blaz; Vidmar, Gaj; Bratko, Ivan			VizRank: Data visualization guided by machine learning	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data visualization; data mining; visual data mining; machine learning; exploratory data analysis	PROJECTION PURSUIT; GENE-EXPRESSION	Data visualization plays a crucial role in identifying interesting patterns in exploratory data analysis. Its use is, however, made difficult by the large number of possible data projections showing different attribute subsets that must be evaluated by the data analyst. In this paper, we introduce a method called VizRank, which is applied on classified data to automatically select the most useful data projections. VizRank can be used with any visualization method that maps attribute values to points in a two-dimensional visualization space. It assesses possible data projections and ranks them by their ability to visually discriminate between classes. The quality of class separation is estimated by computing the predictive accuracy of k-nearest neighbor classifier on the data set consisting of x and y positions of the projected data points and their class information. The paper introduces the method and presents experimental results which show that VizRank's ranking of projections highly agrees with subjective rankings by data analysts. The practical use of VizRank is also demonstrated by an application in the field of functional genomics.	Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana, Slovenia; Baylor Coll Med, Dept Mol & Human Genet, Houston, TX 77030 USA; Univ Ljubljana, Inst Biomed Informat, Ljubljana, Slovenia; Jozef Stefan Inst, Ljubljana, Slovenia	Leban, G (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, Ljubljana, Slovenia.	gregor.leban@fri.uni-lj.si; blaz.zupan@fri.uni-lj.si; gaj.vidmar@mf.uni-lj.si; ivan.bratko@fri.uni-lj.si	Vidmar, Gaj/H-5950-2011	Vidmar, Gaj/0000-0002-5682-3124			Bardorfer A, 2001, IEEE-ASME T MECH, V6, P253, DOI 10.1109/3516.951363; Blake C, 1998, UCI REPOSITORY MACHI; Brier G, 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Chambers J. M., 1983, GRAPHICAL METHODS DA; Cleveland W. S., 1993, VISUALIZING DATA; CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P807, DOI 10.2307/2288711; Cook RD, 2001, AUST NZ J STAT, V43, P147, DOI 10.1111/1467-842X.00164; Cutting J. E., 1995, HDB PERCEPTION COGNI, V5, P69; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DEMSAR J, 2004, EXPT MACHINE LEARNIN; DeRisi JL, 1997, SCIENCE, V278, P680, DOI 10.1126/science.278.5338.680; DIACONIS P, 1984, ANN STAT, V12, P793, DOI 10.1214/aos/1176346703; DILLON I, 1998, P 30 S INT COMP SCI; Duda R.O., 2001, PATTERN CLASSIFICATI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Grinstein G., 2001, P VIS DAT MIN WORKSH; HARRIS RL, 1999, INFORM GRAPHICS COMP, P290; Hastie T., 2001, ELEMENTS STAT LEARNI; HOFFMAN PE, 1997, IEEE VISUALIZATION, V1, P437; HOFFMAN PE, 1999, P NPIV 99; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; INSELBERG A, 1981, G3202711 IBM LOS ANG; KASKI S, 2003, P 20 INT C MACH LEAR, V1, P329; KEIM DA, 1996, T KNOWLEDGE DATA ENG, V8, P923; KONONENKO I, 1995, INDUCTION DECISION T; Leban G, 2005, BIOINFORMATICS, V21, P413, DOI 10.1093/bioinformatics/bti016; NASON G, 1992, THESIS U BATH; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; SANTINI S, 1996, USE PSYCHOL SIMILARI; SCHUCANY WR, 1973, PSYCHOMETRIKA, V38, P249, DOI 10.1007/BF02291117; Siegel S, 1988, NONPARAMETRIC STAT B; Torkkola K., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753742	36	16	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2006	13	2					119	136		10.1007/s10618-005-0031-5		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	082BQ	WOS:000240361900001	
J	Hahsler, M				Hahsler, Michael			A model-based frequency constraint for mining associations from transaction data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; associations; interest measures; mixture models; transaction data	RULES; DATABASES	Mining frequent itemsets is a popular method for finding associated items in databases. For this method, support, the co-occurrence frequency of the items which form an association, is used as the primary indicator of the associations's significance. A single, user-specified support threshold is used to decided if associations should be further investigated. Support has some known problems with rare items, favors shorter itemsets and sometimes produces misleading associations. In this paper we develop a novel model-based frequency constraint as an alternative to a single, user-specified minimum support. The constraint utilizes knowledge of the process generating transaction data by applying a simple stochastic mixture model (the NB model) which allows for transaction data's typically highly skewed item frequency distribution. A user-specified precision threshold is used together with the model to find local frequency thresholds for groups of itemsets. Based on the constraint we develop the notion of NB-frequent itemsets and adapt a mining algorithm to find all NB-frequent itemsets in a database. In experiments with publicly available transaction databases we show that the new constraint provides improvements over a single minimum support threshold and that the precision threshold is more robust and easier to set and interpret by the user.	Vienna Univ Econ & Business Adm, Vienna, Austria	Hahsler, M (reprint author), Vienna Univ Econ & Business Adm, Vienna, Austria.	michael.hahsler@wu-wien.ac.at					Agarwal R., 1994, P 20 INT C VER LARG, P487; Agarwal R. C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347114; Borgelt C., 2003, P IEEE ICDM WORKSH F; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Creighton C, 2003, BIOINFORMATICS, V19, P79, DOI 10.1093/bioinformatics/19.1.79; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DuMouchel W., 2001, P 7 ACM SIGKDD INT C, P67, DOI 10.1145/502512.502526; GEYERSCHULZ A, 2003, STAT DATA MINING KNO, P433; Geyer-Schulz A, 2002, LECT NOTES ARTIF INT, V2356, P25; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Johnson N. L., 1993, UNIVARIATE DISCRETE; KOHAVI R, 1988, MACH LEARN, V30, P271; KOHAVI R., 2000, SIGKDD EXPLORATIONS, V2, P86; Luo JX, 2000, INT J INTELL SYST, V15, P687, DOI 10.1002/1098-111X(200008)15:8<687::AID-INT1>3.0.CO;2-X; Ma Y., 1999, P 5 ACM SIGKDD INT C, P337, DOI 10.1145/312129.312274; Mannila H., 1994, AAAI WORKSH KNOWL DI, P181; Omiecinski ER, 2003, IEEE T KNOWL DATA EN, V15, P57, DOI 10.1109/TKDE.2003.1161582; Pei J, 2001, PROC INT CONF DATA, P433; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Seno M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989558; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; Srikant R., 1993, P ACM SIGMOD C MAN D, P207, DOI DOI 10.1145/170035.170072; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12; Xiong H., 2003, P 3 IEEE INT C DAT M, P387; Zheng Z., 2001, P 7 ACM SIGKDD INT C, P401, DOI 10.1145/502512.502572	25	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2006	13	2					137	166		10.1007/s10618-005-0026-2		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	082BQ	WOS:000240361900002	
J	Dubois, D; Hullermeier, E; Prade, H				Dubois, Didier; Huellermeier, Eyke; Prade, Henri			A systematic approach to the assessment of fuzzy association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	10th International-Fuzzy-Systems-Association World Congress	JUN 30-JUL 02, 2003	ISTANBUL, TURKEY	Bogazici Univ Fdn, Turkish Sci & Tech Res Council		association rules; fuzzy sets; quality measures; fuzzy partition	FREQUENT ITEMSETS; CLOSED ITEMSETS; SETS THEORY; CONNECTIVES; ALGORITHMS	In order to allow for the analysis of data sets including numerical attributes, several generalizations of association rule mining based on fuzzy sets have been proposed in the literature. While the formal specification of fuzzy associations is more or less straightforward, the assessment of such rules by means of appropriate quality measures is less obvious. Particularly, it assumes an understanding of the semantic meaning of a fuzzy rule. This aspect has been ignored by most existing proposals, which must therefore be considered as ad-hoc to some extent. In this paper, we develop a systematic approach to the assessment of fuzzy association rules. To this end, we proceed from the idea of partitioning the data stored in a database into examples of a given rule, counterexamples, and irrelevant data. Evaluation measures are then derived from the cardinalities of the corresponding subsets. The problem of finding a proper partition has a rather obvious solution for standard association rules but becomes less trivial in the fuzzy case. Our results not only provide a sound justification for commonly used measures but also suggest a means for constructing meaningful alternatives.	Univ Marburg, Dept Math & Comp Sci, D-35032 Marburg, Germany; UPS, IRIT, F-31062 Toulouse, France	Dubois, D (reprint author), Univ Marburg, Dept Math & Comp Sci, Hans Meerwein Str, D-35032 Marburg, Germany.	dubois@irit.fr; eyke@mathematik.uni-marburg.de; prade@irit.fr					Aggarwal C. C., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275490; Aggarwal R, 1994, P 20 C VLDB SANT CHI, P487; ALSINA C, 1983, J MATH ANAL APPL, V93, P15, DOI 10.1016/0022-247X(83)90216-0; ALSINA C, 1985, FUZZY SET SYST, V16, P231, DOI 10.1016/0165-0114(85)90026-0; Au W. H., 1999, P 8 IEEE INT C FUZZ, P1217; Au WH, 2005, FUZZY SET SYST, V149, P87, DOI 10.1016/j.fss.2004.07.018; Au W.H., 1998, P 7 IEEE INT C FUZZ, P1314; Au WH, 2003, IEEE T FUZZY SYST, V11, P238, DOI 10.1109/TFUZZ.2003.809901; Barber B, 2003, DATA MIN KNOWL DISC, V7, P153, DOI 10.1023/A:1022419032620; Belohlavek R, 1999, MATH LOGIC QUART, V45, P497, DOI 10.1002/malq.19990450408; BOSC P, 2001, P FUZZ IEEE 2001 10; Bosc P., 2001, P IFSA NAFIPS 2001 V; Cai CH, 1998, IDEAS 98 - INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P68; CHEN G, 1920, INF SCI, V147, P201; Chen G., 2003, P ISIS 2003 4 INT S; CHEN G, 2000, RECENT ISSUES FUZZY; CHIEN BC, 2001, P 9 INT FUZZ SYST AS, P1306; Coenen F, 2004, IEEE T KNOWL DATA EN, V16, P774, DOI 10.1109/TKDE.2004.8; Coenen F, 2004, DATA MIN KNOWL DISC, V8, P25, DOI 10.1023/B:DAMI.0000005257.93780.3b; de Graaf JM, 2001, PKDD, P140; DEFINETTI B, 1936, INT C PHIL SCI, V5, P1; Delgado M, 2003, IEEE T FUZZY SYST, V11, P214, DOI 10.1109/TFUZZ.2003.809896; DELGADO M, 2000, FUZZY LOGIC MED; DELUCA A, 1972, INFORM CONTROL, V20, P301, DOI 10.1016/S0019-9958(72)90199-4; Dougherty J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Dubois D., 2000, P 8 INT C INF PROC M, P1035; DUBOIS D, 1994, IEEE T SYST MAN CYB, V24, P1724, DOI 10.1109/21.328930; DUBOIS D, 1992, INFORM SCIENCES, V61, P103, DOI 10.1016/0020-0255(92)90035-7; Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8; Dubois D., 1980, Fuzzy Sets. Theory and Applications to Policy Analysis and Information Systems. Proceedings of the Symposium on Policy Analysis and Information Systems; Dubois D, 2005, IEEE T FUZZY SYST, V13, P250, DOI 10.1109/TFUZZ.2004.840130; DUBOIS D, 1985, FUZZY SET SYST, V16, P199, DOI 10.1016/0165-0114(85)90025-9; DUBOIS D, 2003, P 11 IFSA WORLD C IS, P111; Dubois D., 2003, LECT NOTES ARTIF INT, V2715, P677; Fodor J., 1994, FUZZY PREFERENCE MOD; Folger T.A., 1988, FUZZY SETS UNCERTAIN; Frank M.J., 1979, AEQUATIONES MATH, V19, P194, DOI DOI 10.1007/BF02189866; Fu A, 1998, IDEAL 98 1 INT S INT, P263; FU Y, 1995, KDOOD TDOOD SING, P39; Goethals B., 2003, P IEEE ICDM WORKSH F; GOETHALS B, 2004, FIMI 03 SIGKDD EXPLO, V6, P109; Goodman I.R., 1991, CONDITIONAL INFERENC; GYENESEI A, 336 TURK CTR COMP SC; GYENESEI A, 2000, 346 TURK CTR COMP SC; Gyenesei A., 2001, PRINCIPLES DATA MINI, P152; Gyenesei A., 2001, Acta Cybernetica, V15; Hamacher H., 1978, LOGISCHE AGGREGATION; Han J, 1995, P 21 INT C VER LARG, P420; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Harper W. L., 1981, IFS; HIPP J, 2000, NEWSL SPEC INT GROUP, V2, P58; Hullermeier E, 2001, LECT NOTES COMPUT SC, V2206, P380; HULLERMEIER E, 2003, INTELLIGENT SYSTEMS; Hullermeier E, 2001, P 5 EUR C PRINC PRAC, P241; Kaufmann A., 1975, INTRO THEORY FUZZY S; Kaya M, 2005, FUZZY SET SYST, V152, P587, DOI 10.1016/j.fss.2004.09.014; Klement E.P., 2000, TRIANGULAR NORMS; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; KRAUS S, 1990, ARTIF INTELL, V44, P167, DOI 10.1016/0004-3702(90)90101-5; Kuok C. M., 1998, SIGMOD REC, P41, DOI DOI 10.1145/273244.273257; LENT B, 1997, P ICDE 97 BIRM UK; LEWIS D, 1973, J PHILOS LOGIC, V3; Ling C. H., 1965, PUBL MATH-DEBRECEN, V12, P189; LUCCHESSE C, 2004, P IEEE ICDM WORKSH F; Luo JX, 2000, INT J INTELL SYST, V15, P687, DOI 10.1002/1098-111X(200008)15:8<687::AID-INT1>3.0.CO;2-X; MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2; MILLER RJ, 1999, P ACM SIGMOD INT C M, P452; Nelsen R.B., 1999, INTRO COPULAS; OHSAKI M, 2004, EVALUATION RULE INTE, P362; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; PEDRYCZ W, 1996, P BIENN C NAFIPS BER, P263, DOI 10.1109/NAFIPS.1996.534742; Pei J, 2001, PROC INT CONF DATA, P433; Prade H, 1988, REV INTELLIGENCE ART, V2, P29; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SAVASERE A, 1995, VLDB 95, P11; Scnweizer B, 1983, PROBABILISTIC METRIC; SHUYUE J, 2000, P IEEE INT C SYST MA, P1906; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Srikant R., 1995, P 21 INT C VER LARG, P407; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; STEINBACH M, 2004, P 10 ACM SIGKDD C SE; STRAUSS O, 2000, ICPR 2000 15 INT C P, P2684; STUMME G, 2001, LNCS, V2174; SUDKAMP T, 2005, FUZZY SETS SYST, V149; Tan P., 2002, P 8 ACM SIGKDD INT C, P32, DOI DOI 10.1145/775047.775053; Tao F., 2003, P 9 ACM SIGKDD INT C, P661; Uno T., 2004, P IEEE ICDM WORKSH F; WONG C, 2001, ICCBR WORKSH SOFT CO; XU B, 2003, INT C CYB SING; YAGER RR, 1979, INT J GEN SYST, V5, P221, DOI 10.1080/03081077908547452; YAHIA SB, 2000, P 8 INT C INF PROC M, P952; YAHIA SB, 2001, STUDIES FUZZINESS SO, V68, P167; YANG Y, 1999, DAT WAR KNOWL DISC P, P229; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291; Zaki MJ, 2005, IEEE T KNOWL DATA EN, V17, P462, DOI 10.1109/TKDE.2005.60; Zaki Mohammed Javeed, 1997, 651 U ROCH COMP SCI; ZHANG W, 1999, P 11 IEEE INT C TOOL	99	62	63	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2006	13	2					167	192		10.1007/s10618-005-0032-4		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	082BQ	WOS:000240361900003	
J	Wong, RCW; Fu, AWC				Wong, Raymond Chi-Wing; Fu, Ada Wai-Chee			Mining top-K frequent itemsets from data streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining algorithm; data stream; top K frequent itemset mining; sliding window; Chernoff bound; probabilistic algorithm		Frequent pattern mining on data streams is of interest recently. However, it is not easy for users to determine a proper frequency threshold. It is more reasonable to ask users to set a bound on the result size. We study the problem of mining top K frequent itemsets in data streams. We introduce a method based on the Chernoff bound with a guarantee of the output quality and also a bound on the memory usage. We also propose an algorithm based on the Lossy Counting Algorithm. In most of the experiments of the two proposed algorithms, we obtain perfect solutions and the memory space occupied by our algorithms is very small. Besides, we also propose the adapted approach of these two algorithms in order to handle the case when we are interested in mining the data in a sliding window. The experiments show that the results are accurate.	Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Wong, RCW (reprint author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Ho Sin Hang Engn Bldg, Shatin, Hong Kong, Peoples R China.	cwwong@cse.cuhk.edu.hk; adafu@cse.cuhk.edu.hk					AGRAWAL R, IBM SYNTHETIC DATA G; Babcock Brian, 2003, SIGMOD; CHANG JH, 2003, SIGKDD; CHARIKAR M, 2002, 29 INT C AUT LANG PR; CHEUNG YL, 2004, IEEE T KNOWLEDGE DAT; CHEUNG YL, 2002, SPIE C DAT MIN; DATAR M, 2002, SIAM J COMPUTING; DEMAINE E, 2002, P 10 ANN EUR S ALG; FU AWC, 2000, ISMIS; Giannella C., 2003, NEXT GENERATION DATA; Gibbons P. B., 1998, SIGMOD; GOLAB L, 2003, VLDB; HAN J, 2002, ICDM; Han J, 2000, SIGMOD; HIDBER C, 1999, SIGMOD; KOHAVI R, 2000, SIGKDD EXPLORATION, V2; LEE CH, 2001, INT C INF KNOWL MAN; Manku G., 2002, VLDB; METWALLY A, 2005, ICDT; TENG WG, 2003, VLDB; Vitter J., 1985, ACM T MATH SOFTWARE, V11; WONG RCW, 2005, SIAM INT C DAT MIN; WONG RCW, 2005, MINING TOP K FREQUEN; XU J, 2004, 5 INT C WEB AG INF M; YU JX, 2004, VLDB; MINN POP CTR U MINN	26	11	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2006	13	2					193	217		10.1007/s10618-006-0042-x		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	082BQ	WOS:000240361900004	
J	Xiong, H; Tan, PN; Kumar, V				Xiong, Hui; Tan, Pang-Ning; Kumar, Vipin			Hyperclique pattern discovery	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association analysis; hyperclique patterns; pattern Mining		Existing algorithms for mining association patterns often rely on the support-based pruning strategy to prune a combinatorial search space. However, this strategy is not effective for discovering potentially interesting patterns at low levels of support. Also, it tends to generate too many spurious patterns involving items which are from different support levels and are poorly correlated. In this paper, we present a framework for mining highly-correlated association patterns called hyperclique patterns. In this framework, an objective measure called h-confidence is applied to discover hyperclique patterns. We prove that the items in a hyperclique pattern have a guaranteed level of global pairwise similarity to one another as measured by the cosine similarity (uncentered Pearson's correlation coefficient). Also, we show that the h-confidence measure satisfies a cross-support property which can help efficiently eliminate spurious patterns involving items with substantially different support levels. Indeed, this cross-support property is not limited to h-confidence and can be generalized to some other association measures. In addition, an algorithm called hyperclique miner is proposed to exploit both cross-support and anti-monotone properties of the h-confidence measure for the efficient discovery of hyperclique patterns. Finally, our experimental results show that hyperclique miner can efficiently identify hyperclique patterns, even at extremely low levels of support.	Rutgers State Univ, Dept Management Sci & Informat Syst, Newark, NJ 07102 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Xiong, H (reprint author), Rutgers State Univ, Dept Management Sci & Informat Syst, Ackerson Hall,180 Univ Ave, Newark, NJ 07102 USA.	hui@rbs.rutgers.edu; ptan@cse.msu.edu; kumar@cs.umn.edu					Agarwal R., 2000, J PARALLEL DISTRIBUT; Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; BAYARDO R, 1998, P 1998 ACM SIGMOD IN; BAYARDO R, 1999, P INT C DAT ENG; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; BURDICK D, 2001, P 2001 INT C DAT ENG; Cohen E., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839448; FEDER T, 1995, J COMPUT SYST SCI, V51, P261, DOI 10.1006/jcss.1995.1065; GRAHNE G, 2000, P INT C DAT ENG; Han J., 2000, P ACM SIGMOD INT C M; Hastie T., 2001, ELEMENTS STAT LEARNI; LIU B, 1999, P 1999 ACM SIGKDD IN; OMIECINSKI ER, 2003, IEEE T KNOWLEDGE DAT, V15; PEI J, 2000, ACM SIGMOD WORKSH RE; Reynolds H. T., 1977, ANAL CROSS CLASSIFIC; Rijsbergen C. J. V., 1979, INFORM RETRIEVAL; TAN P, 2002, P 1999 ACM SIGKDD IN; WANG K, 2001, P 2001 ACM INT C INF; XIONG H, 2005, P PAC S BIOC PSB; Xiong H., 2003, P 3 IEEE INT C DAT M, P387; XIONG H, 2003, 03006 U MINN DEP COM; Xiong H, 2004, SIAM PROC S, P279; YANG C, 2001, P 1999 ACM SIGKDD IN; ZAKI M, 2002, P 2002 SIAM INT C DA; Zipf G K, 1949, HUMAN BEHAV PRINCIPL	26	50	59	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2006	13	2					219	242		10.1007/s10618-006-0043-9		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	082BQ	WOS:000240361900005	
J	Vanetik, N; Shimony, SE; Gudes, E				Vanetik, N.; Shimony, S. E.; Gudes, E.			Support measures for graph data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; graph mining; support measures	PATTERNS	The concept of support is central to data mining. While the definition of support in transaction databases is intuitive and simple, that is not the case in graph datasets and databases. Most mining algorithms require the support of a pattern to be no greater than that of its subpatterns, a property called anti-monotonicity, or admissibility. This paper examines the requirements for admissibility of a support measure. Support measures for mining graphs are usually based on the notion of an instance graph---a graph representing all the instances of the pattern in a database and their intersection properties. Necessary and sufficient conditions for support measure admissibility, based on operations on instance graphs, are developed and proved. The sufficient conditions are used to prove admissibility of one support measure-the size of the independent set in the instance graph. Conversely, the necessary conditions are used to quickly show that some other support measures, such as weighted count of instances, are not admissible.	Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel	Vanetik, N (reprint author), Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel.	orlovn@cs.bgu.ac.il; shimony@cs.bgu.ac.il; ehud@cs.bgu.ac.il	SHIMONY, EYAL SHLOMO/F-1940-2012; GUDES, EHUD/F-1168-2012				Agrawal R., 1994, P 20 INT C VLDB SANT; BRAY NW, 1998, PERSPECTIVES FUNDAME, V1, P3; CHAMBERLIN D, 2003, P SIGMOD C; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DEUTSCH A, 1999, IEEE DATA ENG B, V22, P27; Deutsch A., 1999, P ACM SIGMOD INT C M, P431, DOI 10.1145/304182.304220; DOMSHLAK C, 2001, P IJCAI; GOLDMAN R, 1997, P 23 VLDB C ATH GREE; HUFFMAN SB, P IJCAI 97 NAG JAP, P751; INOKUCHI A, 2000, P PKDD00; KURAMOCHI M, 2004, P 2004 SIAM DAT MIN; KURAMOCHI M, 2001, P IEEE ICDM; LIN X, 1998, P 31 INT C TECH OBJ; McKay BD, 1998, J ALGORITHM, V26, P306, DOI 10.1006/jagm.1997.0898; MEISELS A, 2001, DISCOVERING ASS XML; MILNER R, 1983, THEOR COMPUT SCI, V25, P267, DOI 10.1016/0304-3975(83)90114-7; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; OSTERGARD PRJ, 2001, NEW ALGORITHM MAXIMU; Pennec X, 1998, BIOINFORMATICS, V14, P516, DOI 10.1093/bioinformatics/14.6.516; Srikant R., 1995, P 21 INT C VER LARG; VANETIK N, 2005, FC0602 B GUR U COMP; Vanetik N., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183988; VANETIK N, 2002, THESIS B GURION U DE; VANETIK N, 2004, UNPUB COMPUTING FREQ; Vanetik N, 2004, PROC INT CONF DATA, P91, DOI 10.1109/ICDE.2004.1319987; Wang K., 1998, P SIGIR, P146, DOI 10.1145/290941.290982; Wang X, 2002, IEEE T KNOWL DATA EN, V14, P731; WASHIO T, 2003, SIGKDD EXPLORATIONS; Yan X., 2002, P 2002 IEEE INT C DA, P721; MAXIMUM WEIGHT CLIQU	31	14	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2006	13	2					243	260		10.1007/s10618-006-0044-8		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	082BQ	WOS:000240361900006	
J	Cheng, JL; Sweredoski, MJ; Baldi, P				Cheng, Jianlin; Sweredoski, Michael J.; Baldi, Pierre			DOMpro: Protein domain prediction using profiles, secondary structure, relative solvent accessibility, and recursive neural networks	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						protein structure prediction; domain; recursive neural networks	DATABASE; RECOGNITION; DICTIONARY; ALIGNMENTS; SEQUENCES; GENOMES; SERVER	Protein domains are the structural and functional units of proteins. The ability to parse protein chains into different domains is important for protein classification and for understanding protein structure, function, and evolution. Here we use machine learning algorithms, in the form of recursive neural networks, to develop a protein domain predictor called DOMpro. DOMpro predicts protein domains using a combination of evolutionary information in the form of profiles, predicted secondary structure, and predicted relative solvent accessibility. DOMpro is trained and tested on a curated dataset derived from the CATH database. DOMpro correctly predicts the number of domains for 69% of the combined dataset of single and multi-domain chains. DOMpro achieves a sensitivity of 76% and specificity of 85% with respect to the single-domain proteins and sensitivity of 59% and specificity of 38% with respect to the two-domain proteins. DOMpro also achieved a sensitivity and specificity of 71% and 71% respectively in the Critical Assessment of Fully Automated Structure Prediction 4 (CAFASP-4) (Fisher et al., 1999; Saini and Fischer, 2005) and was ranked among the top ab initio domain predictors. The DOMpro server, software, and dataset are available at http://www.igb.uci.edu/servers/psss.html.	Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA	Cheng, JL (reprint author), Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA.	jianlinc@ics.uci.edu; msweredo@ics.uci.edu; pfbaldi@ics.uci.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bryson K, 2005, NUCLEIC ACIDS RES, V33, pW36, DOI 10.1093/nar/gki410; Cheng HL, 2005, COUNS PSYCHOL, V33, P72, DOI 10.1177/0011000004270343; CHENG J, 2005, IN PRESS DATA MINING; Chivian D, 2003, PROTEINS, V53, P524, DOI 10.1002/prot.10529; Fischer D, 1999, Proteins, VSuppl 3, P209; George RA, 2002, J MOL BIOL, V316, P839, DOI 10.1006/jmbi.2001.5387; GEWEHR JE, 2005, IN PRESS BIOINFORMAT; Heger A, 2003, J MOL BIOL, V328, P749, DOI 10.1016/S0022-2836(03)00269-9; Holm L, 1998, PROTEINS, V33, P88, DOI 10.1002/(SICI)1097-0134(19981001)33:1<88::AID-PROT8>3.0.CO;2-H; Holm L, 1998, NUCLEIC ACIDS RES, V26, P316, DOI 10.1093/nar/26.1.316; HOLM L, 1994, PROTEINS, V19, P256, DOI 10.1002/prot.340190309; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; LEVITT M, 1976, NATURE, V261, P552, DOI 10.1038/261552a0; Lexa M, 2003, BIOINFORMATICS, V19, P2486, DOI 10.1093/bioinformatics/btg350; Linding R, 2003, NUCLEIC ACIDS RES, V31, P3701, DOI 10.1093/nar/gkg519; Liu JF, 2004, NUCLEIC ACIDS RES, V32, P3522, DOI 10.1093/nar/gkh684; Marchler-Bauer A, 2003, NUCLEIC ACIDS RES, V31, P383, DOI 10.1093/nar/gkg087; Marsden RL, 2002, PROTEIN SCI, V11, P2814, DOI 10.1110/ps.0209902; Mika S, 2003, NUCLEIC ACIDS RES, V31, P3789, DOI 10.1093/nar/gkg620; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Nagarajan N, 2004, BIOINFORMATICS, V20, P1335, DOI 10.1093/bioinformatics/bth086; Orengo CA, 2002, PROTEOMICS, V2, P11; Pollastri G, 2002, PROTEINS, V47, P142, DOI 10.1002/prot.10069; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Pollastri G, 2002, Bioinformatics, V18 Suppl 1, pS62; Przybylski D, 2002, PROTEINS, V46, P197, DOI 10.1002/prot.10029; Saini HK, 2005, BIOINFORMATICS, V21, P2917, DOI 10.1093/bioinformatics/bti445; von Ohsen N, 2004, BIOINFORMATICS, V20, P2228, DOI 10.1093/bioinformatics/bth232; Wheelan SJ, 2000, BIOINFORMATICS, V16, P613, DOI 10.1093/bioinformatics/16.7.613; Zdobnov EM, 2001, BIOINFORMATICS, V17, P847, DOI 10.1093/bioinformatics/17.9.847	34	34	35	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2006	13	1					1	10		10.1007/s10618-005-0023-5		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	052YG	WOS:000238269400001	
J	Bagnall, A; Ratanamahatana, CA; Keogh, E; Lonardi, S; Janacek, G				Bagnall, Anthony; Ratanamahatana, Chotirat Ann; Keogh, Eamonn; Lonardi, Stefano; Janacek, Gareth			A bit level representation for time series data mining with shape based similarity	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clipping; time series data mining; Kolmogorov complexity	NUMBER	Clipping is the process of transforming a real valued series into a sequence of bits representing whether each data is above or below the average. In this paper, we argue that clipping is a useful and flexible transformation for the exploratory analysis of large time dependent data sets. We demonstrate how time series stored as bits can be very efficiently compressed and manipulated and that, under some assumptions, the discriminatory power with clipped series is asymptotically equivalent to that achieved with the raw data. Unlike other transformations, clipped series can be compared directly to the raw data series. We show that this means we can form a tight lower bounding metric for Euclidean and Dynamic Time Warping distance and hence efficiently query by content. Clipped data can be used in conjunction with a host of algorithms and statistical tests that naturally follow from the binary nature of the data. A series of experiments illustrate how clipped series can be used in increasingly complex ways to achieve better results than other popular representations. The usefulness of the proposed representation is demonstrated by the fact that the results with clipped data are consistently better than those achieved with a Wavelet or Discrete Fourier Transformation at the same compression ratio for both clustering and query by content. The flexibility of the representation is shown by the fact that we can take advantage of a variable Run Length Encoding of clipped series to define an approximation of the Kolmogorov complexity and hence perform Kolmogorov based clustering.	Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England; Chulalongkorn Univ, Dept Comp Engn, Bangkok 10330, Thailand; Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA	Bagnall, A (reprint author), Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.	ajb@cmp.uea.ac.uk; ann@cp.eng.chula.ac.th; eamonn@cs.ucr.edu; stelo@cs.ucr.edu; G.Janacek@uea.ac.uk					Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; AGRAWAL R, 1993, P 4 INT C FDN DAT OR; Austin J, 1996, FUZZY SET SYST, V82, P223, DOI 10.1016/0165-0114(95)00258-8; AUSTIN J, 1998, P BRIT MACH VIS C; Austin J, 2005, P IEEE, V93, P496, DOI 10.1109/JPROC.2004.842746; Bagnall A, 2005, MACH LEARN, V58, P151, DOI 10.1007/s10994-005-5825-6; Bagnall A.J., 2004, 10 INT C KNOWL DISC, P49; BAGNALL AJ, 2005, P PAC AS C KNOWL DIS; Basak J, 2004, J MACH LEARN RES, V5, P239; Berndtand D., 1994, P AAAI 94 WORKSH KNO, P229; Bradley J.V, 1968, DISTRIBUTION FREE ST; Cai Y., 2004, P ACM SIGMOD INT C M, P599, DOI 10.1145/1007568.1007636; Chan K., 1999, P 15 IEEE INT C DAT; CHIU B, 2003, 9 INT C KNOWL DISC D; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117; Galan RF, 2004, NEURAL COMPUT, V16, P999, DOI 10.1162/089976604773135078; Ganti V., 1999, 5 ACM SIGKDD INT C K, P73; GE X, 2000, 6 INT C KNOWL DISC D, P81; Glaz J, 1999, SCAN STAT APPL; GLAZ J., 2001, SCAN STAT; GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907; HODGE VJ, 2003, IEEE T KNOWLEDE DATA, V15; HUANG Z, 1998, DATA MINING KNOWLEDG, V2; HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898; Kaufman L., 1990, FINDING GROUPS DATA; KEDEM B, 1980, J AM STAT ASSOC, V75, P146, DOI 10.2307/2287403; KEOGH E, 2000, P ACM SIGMOD C MAN D, P151; KEOGH E, 2003, DATA MINING KNOWLEDG, V7; Keogh E, 2004, 10 INT C KNOWL DISC, P206; Keogh E., 2002, UCR TIME SERIES DATA; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; KEOGH EJ, 2000, 4 PAC AS C KNOWL DIS; KNUTH DE, 1985, J ALGORITHM, V6, P163, DOI 10.1016/0196-6774(85)90036-7; Korn F., 1997, P ACM SIGMOD INT C M; Li M, 2003, SIAM PROC S, P863; Lin J., 2003, P 8 ACM SIGMOD WORKS; MILLIGAN GW, 1983, IEEE T PATTERN ANAL, V5, P40; Morchen F., 2003, 3 PHIL U MARB DEP MA; MORINAKA Y, 2001, P 5 PAC AS C KNOWL D; Ordonez C, 2003, P 8 ACM SIGMOD WORKS, P12; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Ratanamahatana C. A., 2005, P SIAM INT C DAT MIN; Rayner J. C. W., 2001, CONTINGENCY TABLE AP; RICE SO, 1944, BELL SYST TECH J, V23, P292; RISSANEN J, 1979, IBM J RES DEV, V23, P149; SCHWARTZ ES, 1964, INFORM CONTROL, V7, P37, DOI 10.1016/S0019-9958(64)90241-4; Vlachos M., 2005, P SIAM INT C DAT MIN; Weld D., 1990, READINGS QUALITATIVE; XIONG Y, 2002, IEEE INT C DAT MIN I; Yi B.K., 2000, P 26 INT C VER LARG, P385; Zhu Y., 2003, P ACM SIGMOD INT C M, P181	52	14	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2006	13	1					11	40		10.1007/s10618-005-0028-0		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	052YG	WOS:000238269400002	
J	Chundi, P; Rosenkrantz, DJ				Chundi, P; Rosenkrantz, DJ			Information preserving time decompositions of time stamped documents	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						measure functions; optimal information preserving decomposition; compressed interval decomposition		Extraction of sequences of events from news and other documents based on the publication times of these documents has been shown to be extremely effective in tracking past events. This paper addresses the issue of constructing an optimal information preserving decomposition of the time period associated with a given document set, i.e., a decomposition with the smallest number of subintervals, subject to no loss of information. We introduce the notion of the compressed interval decomposition, where each subinterval consists of consecutive time points having identical information content. We define optimality, and show that any optimal information preserving decomposition of the time period is a refinement of the compressed interval decomposition. We define several special classes of measure functions (functions that measure the prevalence of keywords in the document set and assign them numeric values), based on their effect on the information computed as document sets are combined. We give algorithms, appropriate for different classes of measure functions, for computing an optimal information preserving decomposition of a given document set. We studied the effectiveness of these algorithms by computing several compressed interval and information preserving decompositions for a subset of the Reuters-21578 document set. The experiments support the obvious conclusion that the temporal information gleaned from a document set is strongly dependent on the measure function used and on other user-defined parameters.	Univ Nebraska, Dept Comp Sci, Omaha, NE 68106 USA; SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA	Chundi, P (reprint author), Univ Nebraska, Dept Comp Sci, Omaha, NE 68106 USA.	pchundi@mail.unomaha.edu; djr@cs.albany.edu					AGRAWAL R, 1995, P 2U INT C VER LARG; Lent B., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Allan J., 1998, P DARPA BROADC NEWS; ALLAN J, 2000, P 3 TOP DET TRACK WO; Berndt D. J., 1996, ADV KNOWLEDGE DISCOV; CHAKRAVARTI S, 1998, P 24 INT C VER LARG; CHUNDI P, 2004, P 2004 ACM INT C INF, P437, DOI 10.1145/1031171.1031256; Cormen T. H., 2001, INTRO ALGORITHMS; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; Kleinberg J, 2002, P 8 ACM SIGKDD INT C, P91, DOI DOI 10.1023/A:1024940629314; Motoyoshi M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Rosen K. H., 2003, DISCRETE MATH ITS AP; ROY S, 2002, P TEXTM 02 WORKSH SI; SWAN R, 2000, P KDD 2000 WORKSH TE; Swan R, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P38, DOI 10.1145/319950.319956; SWAN R, 2000, P 23 ANN INT ACM SIG, P49, DOI 10.1145/345508.345546	16	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2006	13	1					41	65		10.1007/s10618-005-0035-1		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	052YG	WOS:000238269400003	
J	Maruster, L; Weijters, AJMM; Van der Aalst, WMP; Van den Bosch, A				Maruster, L; Weijters, AJMM; Van der Aalst, WMP; Van den Bosch, A			A rule-based approach for process discovery: Dealing with noise and imbalance in process logs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						rule induction; process mining; knowledge discovery; Petri nets		Effective information systems require the existence of explicit process models. A completely specified process design needs to be developed in order to enact a given business process. This development is time consuming and often subjective and incomplete. We propose a method that constructs the process model from process log data, by determining the relations between process tasks. To predict these relations, we employ machine learning technique to induce rule sets. These rule sets are induced from simulated process log data generated by varying process characteristics such as noise and log size. Tests reveal that the induced rule sets have a high predictive accuracy on new data. The effects of noise and imbalance of execution priorities during the discovery of the relations between process tasks are also discussed. Knowing the causal, exclusive, and parallel relations, a process model expressed in the Petri net formalism can be built. We illustrate our approach with real world data in a case study.	Univ Groningen, NL-9700 AV Groningen, Netherlands; Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands; Tilburg Univ, NL-5000 LE Tilburg, Netherlands	Maruster, L (reprint author), Univ Groningen, POB 800, NL-9700 AV Groningen, Netherlands.	l.maruster@rug.nl; a.j.m.m.weijters@tm.tue.nl; w.m.p.v.d.aalst@tm.tue.nl; antal.vdnbosch@uvt.nl	weijters, ton/D-1779-2010; van den Bosch, Antal/G-5072-2011; van der Aalst, Wil/G-1248-2011	van den Bosch, Antal/0000-0003-2493-656X; van der Aalst, Wil/0000-0002-0955-6940			Agrawal R., 1998, 6 INT C EXT DAT TECH, P469; Cohen W.W., 1995, P 12 INT C MACH LEAR; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Cook J.E., 1998, P 6 INT S FDN SOFTW, P35, DOI 10.1145/288195.288214; de Medeiros A., 2004, BETA WORKING PAPER S; Herbst J., 2000, P 6 EUR CONC ENG C S, P175; HERBST J, 2000, ER CONC ENG C SOC CO; Herbst J., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<67::AID-ISAF186>3.0.CO;2-7; IDS SCHEER Whitepaper, 2002, ARIS PROC PERF MAN; Keller G., 1998, SAP R 3 PROCESS ORIE; Maruster L., 2002, P ECAI WORKSH KNOWL, P32; MARUSTER L, 2002, P 5 INT C DISC SCI D, V2534, P364; MITCHELL TM, 1995, MACHINE LEARNING; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Reisig W., 1998, LECT PETRI NETS; van der Aalst W, 2004, IEEE T KNOWL DATA EN, V16, P1128, DOI 10.1109/TKDE.2004.47; Van der Aalst WMP, 1998, J CIRCUIT SYST COMP, V8, P21, DOI 10.1142/S0218126698000043; van der Aalst WMP, 2003, DATA KNOWL ENG, V47, P237, DOI 10.1016/S0169-023X(03)00066-1; van der Aalst WMP, 2004, COMPUT IND, V53, P231, DOI 10.1016/j.compind.2003.10.001; VELD A, 2002, WFM EEN LAST EEN LUS; Weijters A., 2001, P 13 BELG NETH C ART, P283; Weiss S. M., 1998, PREDICTIVE DATA MINI; WEISS SM, 1991, COMPUTER SYSTEMS THA	23	14	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2006	13	1					67	87		10.1007/s10618-005-0029-z		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	052YG	WOS:000238269400004	
J	Aggarwal, CC				Aggarwal, CC			On the use of human-computer interaction for projected nearest neighbor search	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						high dimensions; nearest neighbor search; projected clustering	HIGH-DIMENSIONAL DATA; PURSUIT	Nearest Neighbor search is an important and widely used technique in a number of important application domains. In many of these domains, the dimensionality of the data representation is often very high. Recent theoretical results have shown that the concept of proximity or nearest neighbors may not be very meaningful for the high dimensional case. Therefore, it is often a complex problem to find good quality nearest neighbors in such data sets. Furthermore, it is also difficult to judge the value and relevance of the returned results. In fact, it is hard for any fully automated system to satisfy a user about the quality of the nearest neighbors found unless he is directly involved in the process. This is especially the case for high dimensional data in which the meaningfulness of the nearest neighbors found is questionable. In this paper, we address the complex problem of high dimensional nearest neighbor search from the user perspective by designing a system which uses effective cooperation between the human and the computer. The system provides the user with visual representations of carefully chosen subspaces of the data in order to repeatedly elicit his preferences about the data patterns which are most closely related to the query point. These preferences are used in order to determine and quantify the meaningfulness of the nearest neighbors. Our system is not only able to find and quantify the meaningfulness of the nearest neighbors, but is also able to diagnose situations in which the nearest neighbors found are truly not meaningful.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Aggarwal, CC (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	charu@us.ibm.com					AGGARWAL C, 2001, ACM SIGKDD INT C KNO, P221; Aggarwal C. C., 2001, ICDT, P420; Aggarwal C. C., 2000, ACM SIGMOD INT C MAN, P70; Aggarwal CC, 2002, PROC INT CONF DATA, P593, DOI 10.1109/ICDE.2002.994777; Aggarwal CC, 2001, SIGMOD RECORD, V30, P13; AGGARWAL CC, 2000, ACM KDD C P, P119; Agrawal R., 1998, ACM SIGMOD INT C MAN, P94; ANKERST M, 2000, ACM KDD C P, P179; Bennett K.P., 1999, ACM KDD, P233; Berchtold S., 1996, VLDB, P28; Beyer K., 1999, P 7 INT C DAT THEOR, P217; BUJA A, 1997, DYNAMIC PROJECTIONS; Chakrabarti K., 2000, VLDB, P89; ESTER M, 1997, ACM KDD C P, P10; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, DOI 10.1007/BF00962238; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Gionis A., 1999, Very Large Data Bases. Proceedings of the Twenty-Fifth International Conference on Very Large Data Bases; Han JW, 1999, COMPUTER, V32, P46; Hinneburg A., 2000, P 26 INT C VER LARG, P506; Hinneburg A, 1999, IEEE COMPUT GRAPH, V19, P22, DOI 10.1109/38.788795; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Jolliffe I., 1986, PRINCIPAL COMPONENT; Katayama N, 2001, PROC INT CONF DATA, P493, DOI 10.1109/ICDE.2001.914863; KATAYAMA N, 1997, ACM SIGMOD INT C MAN, P369; KEIM DA, 1995, THESIS GERMANY; KEIM DA, 1994, ICDE C, P302; KRUSKAL J. B., 1969, STAT COMPUTATION, P427; Lin K.-I., 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; Rui Y., 1997, Proceedings. International Conference on Image Processing (Cat. No.97CB36144), DOI 10.1109/ICIP.1997.638621; Salton G, 1971, SMART RETRIEVAL SYST; Sarawagi S, 2000, VLDB C P, P307; Seidl T., 1997, VLDB J, P506; Swayne DF, 1998, J COMPUT GRAPH STAT, V7, P113, DOI 10.2307/1390772; Tung A. K. H., 2001, ICDT, P405; Weber R., 1998, VLDB, P194; Wu L., 2000, VLDB 00, P297; YANG L, 2000, ACM KDD C P, P235	38	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2006	13	1					89	117		10.1007/s10618-005-0030-6		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	052YG	WOS:000238269400005	
J	Zhang, SC; Zaki, MJ				Zhang, SC; Zaki, MJ			Mining multiple data sources: Local pattern analysis	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Beijing Univ Aeronaut & Astronaut, Dept Automat Control, Beijing 100083, Peoples R China; Univ Technol Sydney, Fac Informat Technol, Broadway, NSW 2007, Australia; Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Zhang, SC (reprint author), Beijing Univ Aeronaut & Astronaut, Dept Automat Control, Beijing 100083, Peoples R China.	zhangsc@it.uts.edu.au; zaki@cs.rpi.edu					ZHANG S, 2004, KNOWLEDGE DISCOVERY, P233	1	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					121	125		10.1007/s10618-006-0041-y		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600001	
J	Hu, J; Zhong, N				Hu, J; Zhong, N			Organizing multiple data sources for developing intelligent e-business portals	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						intelligent e-business portals; the Wisdom Web; multi-layer grid; dynamic multi-level workflows; multi-database mining	GRIDS	Enterprise applications usually involve huge, complex, and persistent data to work on, together with business rules and processes. In order to represent, integrate, and use the information coming from the huge, distributed, multiple sources, we present a conceptual model with dynamic multi-level workflows corresponding to a mining-grid centric multi-layer grid architecture, for multi-aspect analysis in building an e-business portal on the Wisdom Web. We show that this integrated model will help to dynamically organize status-based business processes that govern enterprise application integration. We also present two case studies to demonstrate the effectiveness of the proposed model in the real world. The first case study is about how to organize and mine multiple data sources for behavior-based online customer segmentation, which is the first crucial step of personalization and one-to-one marketing. The second case study is about how to evaluate and monitor data quality, which in return can optimize the knowledge discovery process for intelligent decision making. The proposed methodology attempts to orchestrate various mining agents on the mining-grid for integrating data and knowledge in a unified portal developed by a service-oriented architecture.	Maebashi Inst Technol, Dept Informat Engn, Gunma 3710816, Japan	Hu, J (reprint author), Maebashi Inst Technol, Dept Informat Engn, 460-1 Kamisadori, Gunma 3710816, Japan.	hujia@kis-lab.com; zhong@maebashi-it.ac.jp					ALONSO G, 2004, ENTERPRISE APPL INTE, P67; Berman F., 2003, GRID COMPUTING MAKIN; Buschmann Frank, 1996, PATTERN ORIENTED SOF; Cannataro M, 2004, INTELLIGENT TECHNOLOGIES FOR INFORMATION ANALYSIS, P19; Congiusta A., 2003, Web Intelligence and Agent Systems, V1; CURCIN V, 2002, P 8 ACM SIGKDD INT C, P658; DEELMAN E, 2003, GRID RESOURCE MANAGE, P99; DETLOR B, 2004, INFORM SCI KNOWLEDGE; Foster I., 1999, GRID BLUEPRINT FUTUR; Foster I., 2003, GRID, P37; Foster I, 1997, INT J SUPERCOMPUT AP, V11, P115, DOI 10.1177/109434209701100205; FOSTER I, 2001, INT J SUPERCOMPUTER, V15, P3; FOSTER I, 2003, GRID BLUEPRINT FUTUR; FOWLER M., 2003, PATTERNS ENTERPRISE; Gil Y, 2004, IEEE INTELL SYST, V19, P26, DOI 10.1109/MIS.2004.1265882; Giudici P, 2001, DATA MIN KNOWL DISC, V5, P183, DOI 10.1023/A:1011469000311; HACKATHORN RD, 1998, WEB FARMING DATA WAR; HALL M, 2001, MORE SERVLETS JAVASE; HALL M, 2001, CORE WEB PROGRAMMING; Han JW, 2002, COMPUTER, V35, P64; Hu J., 2005, Proceedings. The 2005 IEEE International Conference on e-Technology, e-Commerce and e-Service; HU J, 2004, P 2004 IEEE WIC ACM, P777; Huang J., 2003, P 2003 IEEE WIC INT, P470; Hunter J., 2001, JAVA SERVLET PROGRAM; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Liu FQ, 2004, PLANT CELL, V16, P5, DOI 10.1105/tpc.017772; Liu J, 2003, P 18 INT JOINT C ART, P1596; Maier R., 2004, KNOWLEDGE MANAGEMENT; Nabrzyski J, 2004, GRID RESOURCE MANAGE; PREUNER G, 2003, P 4 IEEE INT WORKSH, P51; Preuner G., 2000, World Wide Web, V3, DOI 10.1023/A:1019281629747; PRIEBE T, 2003, P 12 INT C INF KNOWL, P216; PYLE D., 2003, BUSINESS MODELING DA; Stork HG, 2002, J UNIVERS COMPUT SCI, V8, P848; TOMITA K, 2004, P 1 INT WORKSH SEM W, P66; Wege C, 2002, IEEE INTERNET COMPUT, V6, P73, DOI 10.1109/MIC.2002.1003134; Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353; XU M, 2003, GRID BLUEPRINT FUTUR, P179; Zhang Peilin, 2003, Mol Cancer, V2, P1, DOI 10.1186/1476-4598-2-1; ZHONG N, 2004, WAVELET ANAL ITS APP, V2, P555; ZHONG N, 2003, P WSS 03, P83; Zhong N, 2005, COMPUT INTELL, V21, P177, DOI 10.1111/j.0824-7935.2005.00270.x; Zhong N, 2004, INTELLIGENT TECHNOLOGIES FOR INFORMATION ANALYSIS, P1; Zhong N, 2003, IEEE T KNOWL DATA EN, V15, P952; Zhong N, 2004, INTELLIGENT TECHNOLOGIES FOR INFORMATION ANALYSIS, P109; Zhong N, 2001, INT J PATTERN RECOGN, V15, P451, DOI 10.1142/S0218001401000976; *OGSA DAI, OGSA DAI PROJ	47	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					127	150		10.1007/s10618-005-0018-2		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600002	
J	Kum, HC; Chang, JH; Wang, W				Kum, HC; Chang, JH; Wang, W			Sequential pattern mining in multi-databases via multiple alignment	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining algorithm; sequential patterns; approximate sequential pattern; mining local pattern; global sequential pattern; multiple alignment	ALGORITHM	To efficiently find global patterns from a multi-database, information in each local database must first be mined and summarized at the local level. Then only the summarized information is forwarded to the global mining process. However, conventional sequential pattern mining methods based on support cannot summarize the local information and is ineffective for global pattern mining from multiple data sources. In this paper, we present an alternative local mining approach for finding sequential patterns in the local databases of a multi-database. We propose the theme of approximate sequential pattern mining roughly defined as identifying patterns approximately shared by many sequences. Approximate sequential patterns can effectively summerize and represent the local databases by identifying the underlying trends in the data. We present a novel algorithm, ApproxMAP, to mine approximate sequential patterns, called consensus patterns, from large sequence databases in two steps. First, sequences are clustered by similarity. Then, consensus patterns are mined directly from each cluster through multiple alignment. We conduct an extensive and systematic performance study over synthetic and real data. The results demonstrate that ApproxMAP is effective and scalable in mining large sequences databases with long patterns. Hence, (A)pproxMAP can efficiently summarize a local database and reduce the cost for global mining. Furthremore, we present an elegant and uniform model to identify both high vote sequential patterns and exceptional sequential patterns from the collection of these consensus patterns from each local databases.	Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27514 USA; Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea	Kum, HC (reprint author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27514 USA.	kum@cs.unc.edu; jhchang@amadeus.yonsei.ac.kr; weiwang@cs.unc.edu					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Ayres J., 2002, P 8 ACM SIGKDD INT C, P429; ERTOZ L, 2003, 3 SIAM INT C DAT MIN, P47; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Gotoh O, 1999, ADV BIOPHYS, V36, P159, DOI 10.1016/S0065-227X(99)80007-0; Gusficld D., 1997, COMPUTER SCI COMPUTA; Jain A. K., 1999, ACM COMPUT SURV, V31; KOHAVI R, 2000, P SIGKDD EXPLORATION, V2, P86; KUM HC, 2003, 3 SIAM INT C DAT MIN, P311; KUM HC, 2006, IN PRESS DATA KNOWLE; KUM HC, 2005, COMPUT INTELL, V6, P45; MCPHERSON GR, 2002, APPL ECOLOGY NATURAL; Pei J, 2001, PROC INT CONF DATA, P215; Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419; Spiliopoulou M, 1999, LECT NOTES ARTIF INT, V1704, P554; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; Thompson JD, 1999, NUCLEIC ACIDS RES, V27, P2682, DOI 10.1093/nar/27.13.2682; WONG MA, 1983, J ROY STAT SOC B MET, V45, P362; Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353; Wu XD, 2005, INFORM SYST, V30, P71, DOI 10.1016/j.is.2003.10.001; YAN X, 2003, 3 SIAM INT C DAT MIN, P166; Yang J., 2002, P 2002 ACM SIGMOD IN, P406; ZAKI MJ, 1998, 7 INT C INF KNOWL MA, P68; Zhang C., 2004, IEEE COMPUT INTELL B, V3, P19; Zhang Peilin, 2003, Mol Cancer, V2, P1, DOI 10.1186/1476-4598-2-1; Zhang SC, 2004, INFORM SCIENCES, V165, P1, DOI 10.1016/j.ins.2003.10.008; Zhong N, 1999, LECT NOTES ARTIF INT, V1704, P136; *SAS I, 2000, SAS STAT US GUID SAS	28	16	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					151	180		10.1007/s10618-005-0017-3		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600003	
J	Ling, CX; Yang, Q				Ling, CX; Yang, Q			Discovering classification from data of multiple sources	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						new solutions for multiple data source mining; learning from multiple sources of data; learning classifications from unlabeled data of multiple sources		In many large e-commerce organizations, multiple data sources are often used to describe the same customers, thus it is important to consolidate data of multiple sources for intelligent business decision making. In this paper, we propose a novel method that predicts the classification of data from multiple sources without class labels in each source. We test our method on artificial and real-world datasets, and show that it can classify the data accurately. From the machine learning perspective, our method removes the fundamental assumption of providing class labels in supervised learning, and bridges the gap between supervised and unsupervised learning.	Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Ling, CX (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	cling@csd.uwo.ca; qyang@cs.ust.hk					Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Church KW, 1989, P 27 ANN M ASS COMP, P76, DOI 10.3115/981623.981633; DESA VR, 1994, PROCEEDINGS OF THE 1993 CONNECTIONIST MODELS SUMMER SCHOOL, P300; DESA VR, 1994, ADV NEURAL INFORMATI, V6, P112; DESA VR, 1998, NEURAL COMPUTATION, V10; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LU SCY, 1987, ARTIF INTELL, V1, P109; Murphy PM, 1992, UCI REPOSITORY MACHI; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354805; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Raskutti B., 2002, P 8 ACM SIGKDD INT C, P620; Reich Y., 1992, International Journal of Expert Systems Research and Applications, V5; REICH Y, 1992, ECOBWEB PRELIMINARY; REICH Y, 1991, CONCEPT FORMATION KN; SINKKONEN J, 2004, P 15 EUR C MACH LEAR, P396; Turney P.D., 1993, P EUR C MACH LEARN, P402; Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353; YAO Y, 2002, P 9 INT C NEUR INF P, P2228; Zhang Peilin, 2003, Mol Cancer, V2, P1, DOI 10.1186/1476-4598-2-1	21	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					181	201		10.1007/s10618-005-0013-7		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600004	
J	Otey, ME; Ghoting, A; Parthasarathy, S				Otey, ME; Ghoting, A; Parthasarathy, S			Fast distributed outlier detection in mixed-attribute data sets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						outlier detection; anomaly detection; distributed data mining; mining dynamic data; mixedattribute data sets; data streams		Efficiently detecting outliers or anomalies is an important problem in many areas of science, medicine and information technology. Applications range from data cleaning to clinical diagnosis, from detecting anomalous defects in materials to fraud and intrusion detection. Over the past decade, researchers in data mining and statistics have addressed the problem of outlier detection using both parametric and non-parametric approaches in a centralized setting. However, there are still several challenges that must be addressed. First, most approaches to date have focused on detecting outliers in a continuous attribute space. However, almost all real-world data sets contain a mixture of categorical and continuous attributes. Categorical attributes are typically ignored or incorrectly modeled by existing approaches, resulting in a significant loss of information. Second, there have not been any general-purpose distributed outlier detection algorithms. Most distributed detection algorithms are designed with a specific domain (e.g. sensor networks) in mind. Third, the data sets being analyzed may be streaming or otherwise dynamic in nature. Such data sets are prone to concept drift, and models of the data must be dynamic as well. To address these challenges, we present a tunable algorithm for distributed outlier detection in dynamic mixed-attribute data sets.	Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	Otey, ME (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	otey@cse.ohio-state.edu; ghoting@cse.ohio-state.edu; srini@cse.ohio-state.edu					Agrawal R., 1994, P 20 INT C VER LARG, P487; Barnett V., 1994, OUTLIERS STAT DATA; BAY SD, 2003, P ACM SIGKDD INT C K; Blake C.L., 1998, UCI MACHINE LEARNING; Bolton RJ, 2002, STAT SCI, V17, P235; Breunig M.M., 2000, P ACM SIGMOD INT C M; GAMBERGER D, 1999, P INT C MACH LEARN; GHOTING A, 2004, P IEEE INT C DAT MIN; Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3; HETTICH S, 1999, KDDCUP 1999 DATASET; Huang Y., 2003, P 1 ACM WORKSH SEC A, P135, DOI 10.1145/986858.986877; Jain A.K., 1988, ALGORITHMS CLUSTERIN; JOHNSON T, 1998, P ACM SIGKDD INT C K; KNORR E, 2000, VLDB J; Knorr E, 1998, P INT C VER LARG DAT; Lazarevic A., 2003, P SIAM INT C DAT MIN; Locasto M.E., 2004, CUCS01204 DEP COMP S; MAHONEY MV, 2002, P ACM SIGKDD INT C K; OTEY M, 2003, P 9 ANN ACM SIGKDD I; Palpanas T, 2003, SIGMOD REC, V32, P77; PAPADIMITRIOU S, 2003, P INT C DAT ENG; PENNY KI, 2001, STATISTICIAN, V50, P295; Porras P., 1997, P 20 NAT INF SYST SE, P353; Rice J, 1995, MATH STAT DATA ANAL; SEQUEIRA K, 2002, P ACM SIGKDD INT C K; VELOSO AA, 2002, P SIAM INT C DAT MIN; Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353; Zhang S., 2003, IEEE COMPUTATIONAL I, V2, P5; Zhang Y., 2000, MOBILE COMPUTING NET, P275	29	29	30	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					203	228		10.1007/s10618-005-0014-6		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600005	
J	Xue, GR; Yu, Y; Shen, D; Yang, Q; Zeng, HJ; Chen, Z				Xue, GR; Yu, Y; Shen, D; Yang, Q; Zeng, HJ; Chen, Z			Reinforcing Web-object categorization through interrelationships	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						categorization; interrelated Web objects; iterative reinforcement; clickthrough data	LOGS	Existing categorization algorithms deal with homogeneous Web objects, and consider interrelated objects as additional features when taking the interrelationships with other types of objects into account. However, focusing on any single aspect of the inter-object relationship is not sufficient to fully reveal the true categories of Web objects. In this paper, we propose a novel categorization algorithm, called the Iterative Reinforcement Categorization Algorithm (IRC), to exploit the full interrelationship between different types of Web objects on the Web, including Web pages and queries. IRC classifies the interrelated Web objects by iteratively reinforcing the individual classification results of different types of objects via their interrelationship. Experiments on a clickthrough-log dataset from the MSN search engine show that, in terms of the F-1 measure, IRC achieves a 26.4% improvement over a pure content-based classification method. It also achieves a 21% improvement over a query-metadata-based method, as well as a 16.4% improvement on F-1 measure over the well-known virtual document-based method. Our experiments show that IRC converges fast enough to be applicable to real world applications.	Shanghai Jiao Tong Univ, Shanghai 200030, Peoples R China; Hong Kong Univ Sci & Technol, Kowloon, Hong Kong, Peoples R China; Microsoft Res Asia, Sigma Ctr, Beijing 100080, Peoples R China	Xue, GR (reprint author), Shanghai Jiao Tong Univ, Shanghai 200030, Peoples R China.	grxue@sjtu.edu.cn; yyu@cs.sjtu.edu.cn; dshen@ust.hk; qyang@cs.ust.hk; hjzeng@microsoft.com; zhengc@microsoft.com					Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347176; Chakrabarti S., 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; Chuang SL, 2003, DECIS SUPPORT SYST, V35, P113, DOI 10.1016/S0167-9236(02)00099-4; Cohn D, 2001, ADV NEUR IN, V13, P430; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cortes C, 1995, MACH LEARN, V20, P1; Cui H, 2003, IEEE T KNOWL DATA EN, V15, P829; Dumais Susan, 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593; Getoor L., 2001, P 18 INT C MACH LEAR, P170; GETOOR L, 2001, IJCAI WORKSH TEXT LE; GLOVER E. J., 2002, P 11 INT WORLD WID W, P562; Grimmett GDR, 1992, PROBABILITY RANDOM P; Huang CK, 2003, J AM SOC INF SCI TEC, V54, P638, DOI 10.1002/asi.10256; Jeh G, 2002, P 8 ACM SIGKDD INT C, P538, DOI 10.1145/775047.775126; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Lu Q., 2003, P 20 INT C MACH LEAR, P496; Oh H. J., 2000, P 23 ANN INT ACM SIG, P264, DOI 10.1145/345508.345594; Platt J. C., 1999, ADV LARGE MARGIN CLA, P61; Slattery S, 2000, P 17 INT C MACH LEAR, P895; Wang J., 2003, P ACM SIGIR C RES DE, P274; Wen J.-R., 2001, P 10 INT C WORLD WID, P162, DOI 10.1145/371920.371974; Yang Y, 1997, P 14 INT C MACH LEAR, P412; Zhang Peilin, 2003, Mol Cancer, V2, P1, DOI 10.1186/1476-4598-2-1; Zhang S., 2004, KNOWLEDGE DISCOVERY; SEQUENTIAL MINIMAL O	25	3	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					229	248		10.1007/s10618-005-0015-5		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600006	
J	Yan, J; Liu, N; Yang, Q; Zhang, B; Cheng, QS; Chen, Z				Yan, J; Liu, N; Yang, Q; Zhang, B; Cheng, QS; Chen, Z			Mining adaptive ratio rules from distributed data sources	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						multiple source data mining; data stream mining; ratio rule; robust statistics; eigen system analysis	PRINCIPAL COMPONENT ANALYSIS	Different from traditional association-rule mining, a new paradigm called Ratio Rule (RR) was proposed recently. Ratio rules are aimed at capturing the quantitative association knowledge, We extend this framework to mining ratio rules from distributed and dynamic data sources. This is a novel and challenging problem. The traditional techniques used for ratio rule mining is an eigen-system analysis which can often fall victim to noise. This has limited the application of ratio rule mining greatly. The distributed data sources impose additional constraints for the mining procedure to be robust in the presence of noise, because it is difficult to clean all the data sources in real time in real-world tasks. In addition, the traditional batch methods for ratio rule mining cannot cope with dynamic data. In this paper, we propose an integrated method to mining ratio rules from distributed and changing data sources, by first mining the ratio rules from each data source separately through a novel robust and adaptive one-pass algorithm (which is called Robust and Adaptive Ratio Rule (RARR)), and then integrating the rules of each data source in a simple probabilistic model. In this way, we can acquire the global rules from all the local information sources adaptively. We show that the RARR technique can converge to a fixed point and is robust as well. Moreover, the integration of rules is efficient and effective. Both theoretical analysis and experiments illustrate that the performance of RARR and the proposed information integration procedure is satisfactory for the purpose of discovering latent associations in distributed dynamic data source.	Peking Univ, Sch Math Sci, Dept Informat Sci, LMAM, Beijing 100871, Peoples R China; Tsing Hua Univ, Dept Math Sci, Beijing 100084, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Microsoft Res Asia, Beijing 100080, Peoples R China	Yan, J (reprint author), Peking Univ, Sch Math Sci, Dept Informat Sci, LMAM, Beijing 100871, Peoples R China.	yanjun@math.pku.edu.cn; liun01@mails.tisnghua.edu.cn; qyang@cs.ust.hk; byzhang@microsoft.com; qcheng@pku.edu.cn; zhengc@microsoft.com					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AUMANN Y, 1999, P 5 ACM SIGKDD INT C, P15; Buckley C., 2000, P 23 ANN INT ACM SIG, P33, DOI [10.1145/345508.345543, DOI 10.1145/345508.345543]; CHAUDHURI S, 2003, P ACM SIGMOD INT C M, P314; Duda R. O., 2000, PATTERN CLASSIFICATI; Golub G.H., 1996, MATRIX COMPUTATIONS; HAMILTON AG, 1990, LINEAR LAGEBRA; Han J, 1995, P 21 INT C VER LARG, P420; Huber P. J., 2003, ROBUST STAT; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kallenberg O., 2002, FDN MODERN PROBABILI; Korn F, 2000, VLDB J, V8, P254, DOI 10.1007/s007780050007; Korn F., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Kushner H. J, 1978, STOCHASTIC APPROXIMA; Li YM, 2004, PATTERN RECOGN, V37, P1509, DOI 10.1016/j.patcog.2003.11.010; LIANO K, 1996, IEEE T KNOWLEDGE DAT, V7; LJUNG L, 1977, IEEE T AUTOMAT CONTR, V22, P551, DOI 10.1109/TAC.1977.1101561; OJA E, 1985, J MATH ANAL APPL, V106, P69, DOI 10.1016/0022-247X(85)90131-3; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Srikant R., 1996, ACM SIGMOD INT C MAN, P1; WANG RY, 1995, IEEE T KNOWL DATA EN, V7, P623, DOI 10.1109/69.404034; Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034; Wu XD, 2005, INFORM SYST, V30, P71, DOI 10.1016/j.is.2003.10.001; XU L, 1995, IEEE T NEURAL NETWOR, V6, P131; XU L, 1993, NEURAL NETWORKS, V6, P627, DOI 10.1016/S0893-6080(05)80107-8; YAN J, 2004, ACM SIGKDD C SEATTL, P725; Zhang Peilin, 2003, Mol Cancer, V2, P1, DOI 10.1186/1476-4598-2-1	27	3	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					249	273		10.1007/s10618-005-0027-1		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600007	
J	Zhu, XQ; Wu, XD; Chen, QJ				Zhu, XQ; Wu, XD; Chen, QJ			Bridging local and global data cleansing: Identifying class noise in large, distributed data datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data cleansing; class noise; machine learning	LEARNING ALGORITHMS; RULE	To cleanse mislabeled examples from a training dataset for efficient and effective induction, most existing approaches adopt a major set oriented scheme: the training dataset is separated into two parts (a major set and a minor set). The classifiers learned from the major set are used to identify noise in the minor set. The obvious drawbacks of such a scheme are twofold: (1) when the underlying data volume keeps growing, it would be either physically impossible or time consuming to load the major set into the memory for inductive learning; and (2) for multiple or distributed datasets, it can be either technically infeasible or factitiously forbidden to download data from other sites (for security or privacy reasons). Therefore, these approaches have severe limitations in conducting effective global data cleansing from large, distributed datasets. In this paper, we propose a solution to bridge the local and global analysis for noise cleansing. More specifically, the proposed effort tries to identify and eliminate mislabeled data items from large or distributed datasets through local analysis and global incorporation. For this purpose, we make use of distributed datasets or partition a large dataset into subsets, each of which is regarded as a local subset and is small enough to be processed by an induction algorithm at one time to construct a local model for noise identification. We construct good rules from each subset, and use the good rules to evaluate the whole dataset. For a given instance I-k , two error count variables are used to count the number of times it has been identified as noise by all data subsets. The instance with higher error values will have a higher probability of being a mislabeled example. Two threshold schemes, majority and non-objection, are used to identify and eliminate the noisy examples. Experimental results and comparative studies on both real-world and synthetic datasets are reported to evaluate the effectiveness and efficiency of the proposed approach.	Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA	Zhu, XQ (reprint author), Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA.	xqzhu@cs.uvm.edu; xwu@cs.uvm.edu; qchen@cs.uvm.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Bruha I, 1996, INT J PATTERN RECOGN, V10, P939, DOI 10.1142/S0218001496000530; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; Cestnik B., 1987, PROGR MACHINE LEARNI, P31; CHAN PK, 1996, THESIS COLUMBIA U; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; CLARK P, 1991, P 5 ECML; DIETTERICH T, 2000, LECT NOTES COMPUTER, V1867, P1; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P181; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; Gamberger D., 1999, P 16 INT C MACH LEAR, P143; Gamberger D, 2000, APPL ARTIF INTELL, V14, P205, DOI 10.1080/088395100117124; Grzymala-Busse J. W., 2000, ROUGH SETS CURRENT T, P378; HALL L, 2000, KDD 00 WORKSH DISTR, P79; Holte R. C., 1993, MACHINE LEARNING, V11; HUANG CC, 2001, P 2001 NAT COMP S TA; John G. H., 1995, P 1 INT C KNOWL DISC, P174; Kononenko I., 1984, EXPT AUTOMATIC LEARN; KUBICA J, 2003, P ICDM FL US; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; LI, 2002, P INT C DAT MIN ICDM; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; OAK N, 1993, P IEEE INT JOINT C N, P171; OAK N, 1996, P AAAI 96 WORKSH INT, P95; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SCHAEFER P, 1990, EARTH ISL J, V5, P2; SHAPIRO A, 1983, THESIS U EDINBURGH; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; SRINIVASAN A, 1992, P 2 IND LOG PROGR WO, P97; Teng C. M., 1999, P 16 INT C MACH LEAR, P239; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VERBAETEN S, 2002, P BEN ANN MACH LEARN; Weisberg S, 1980, APPL LINEAR REGRESSI; WEISS G M, 1995, P 12 INT C MACH LEAR, P558; WEISS GM, 1998, P 15 INT C MACH LEAR, P574; WHITAKER A, 1999, CSE573; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Winston P. H., 1975, PSYCHOL COMPUTER VIS; Wu X., 1995, KNOWLEDGE ACQUISITIO; Wu XD, 1998, J AM SOC INFORM SCI, V49, P435, DOI 10.1002/(SICI)1097-4571(19980415)49:5<435::AID-ASI6>3.0.CO;2-R; ZHAO Q, 1995, J ARTIF INTELL RES, V3, P119; ZHU X, 2004, P 19 NAT C ART INT A; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8; *IBM ALM RES, IBM SYNTH DAT	53	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					275	308		10.1007/s10618-005-0012-8		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600008	
J	Vlachos, M; Yu, PS; Castelli, V; Meek, C				Vlachos, M; Yu, PS; Castelli, V; Meek, C			Structural periodic measures for time-series data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						periodicity estimation; periodogram; autocorrelation; phase-invariant matching; metric index		This work motivates the need for more flexible structural similarity measures between time-series sequences, which are based on the extraction of important periodic features. Specifically, we present non-parametric methods for accurate periodicity detection and we introduce new periodic distance measures for time-series sequences. We combine these new measures with an effective metric tree index structure for efficiently answering k-Nearest-Neighbor queries. The goal of these tools and techniques are to assist in detecting, monitoring and visualizing structural periodic changes. It is our belief that these methods can be directly applicable in the manufacturing industry for preventive maintenance and in the medical sciences for accurate classification and anomaly detection.	IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA; Microsoft Corp, Res, Redmond, WA 98052 USA	Vlachos, M (reprint author), IBM Corp, TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.		Yu, Philip/A-2815-2012				BECKMANN N, 1990, P ACM SIGMOD; BOWERMAN B, 2000, FORECASTING TIME SER; CHIUEH T, 1994, P 20 VLDB; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; David BL., 1993, P 4 INT C FDN DAT OR, P69; Ebersbach G, 1999, BRAIN, V122, P1349, DOI 10.1093/brain/122.7.1349; ELFEKY MG, 2004, P EDBT; ERGUN F, 2004, LATIN; Friss-Christensen E., 1991, SCIENCE, V245, P698; FU A, 2000, VLDB J; Guttman A., 1984, P ACM SIGMOD INT C M, P47; Harris JFredric, 1978, P IEEE, V66; Ide T., 2004, P 4 DAT MIN WORKSH J; KAHN M, 1992, J STAT COMPUT SIM, V49, P111; Kalpakis K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989529; KEOGH E, 2001, P ICDM; KEOGH E, 2002, P SIGKDD; KEOGH E, 2004, P SIGKDD; Keogh E., 2002, P VLDB; Kruskal JB, 1978, MULTIDIMENSIONAL SCA; Marple L., 1987, DIGITAL SPECTRAL ANA; Mitchell J. S., 1993, INTRO MACHINERY ANAL; Oppenheim A. V., 1997, SIGNALS SYSTEMS; Papoulis A., 1977, SIGNAL ANAL; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tulen JHM, 1999, J NEUROL NEUROSUR PS, V67, P800, DOI 10.1136/jnnp.67.6.800; VLACHOS M, 2004, P SIGMOD; YIANILOS P, 1992, P 3 SIAM DISCR ALG; Zhu Y., 2002, VLDB	29	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2006	12	1					1	28		10.1007/s10618-005-0016-4		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	013ZU	WOS:000235449300001	
J	Rousseeuw, PJ; Van Driessen, K				Rousseeuw, PJ; Van Driessen, K			Computing LTS regression for large data sets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						breakdown value; linear model; outlier detection; regression; robust estimation	MULTIPLE LINEAR-REGRESSION; HIGH BREAKDOWN-POINT; SQUARES REGRESSION; ALGORITHM; ESTIMATOR; STABILITY	Data mining aims to extract previously unknown patterns or substructures from large databases. In statistics, this is what methods of robust estimation and outlier detection were constructed for, see e.g. Rousseeuw and Leroy (1987). Here we will focus on least trimmed squares (LTS) regression, which is based on the subset of h cases (out of n) whose least squares fit possesses the smallest sum of squared residuals. The coverage h may be set between n/2 and n. The computation time of existing LTS algorithms grows too much with the size of the data set, precluding their use for data mining. In this paper we develop a new algorithm called FAST-LTS. The basic ideas are an inequality involving order statistics and sums of squared residuals, and techniques which we call 'selective iteration' and nested extensions'. We also use an intercept adjustment technique to improve the precision. For small data sets FAST-LTS typically finds the exact LTS, whereas for larger data sets it gives more accurate results than existing algorithms for LTS and is faster by orders of magnitude. This allows us to apply FAST-LTS to large databases.	Univ Antwerp, Dept Math & Comp Sci, B-2020 Antwerp, Belgium; Univ Antwerp, Fac Appl Econ, B-2000 Antwerp, Belgium	Rousseeuw, PJ (reprint author), Univ Antwerp, Dept Math & Comp Sci, Middelheimlaan 1, B-2020 Antwerp, Belgium.	peter.rousseeuw@ua.ac.be; katrien.vandriessen@ua.ac.be					Agullo J, 1997, INST MATH S, V31, P133; AGULLO J, 1997, THESIS U ALICANTE SP; CHORK CJ, 1990, J GEOCHEM EXPLOR, V37, P191; COAKLEY CW, 1993, J AM STAT ASSOC, V88, P872, DOI 10.2307/2290776; HAWKINS DM, 1994, COMPUT STAT DATA AN, V17, P185, DOI 10.1016/0167-9473(92)00070-8; Hawkins DM, 1999, COMPUT STAT DATA AN, V30, P1, DOI 10.1016/S0167-9473(98)00082-6; HOSSJER O, 1994, J AM STAT ASSOC, V89, P149, DOI 10.2307/2291211; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Kaufman L., 1990, FINDING GROUPS DATA; KAUFMAN L, 1986, PATTERN RECOGN, V2, P425; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Mili L, 1996, IEEE T POWER SYST, V11, P1118, DOI 10.1109/59.496203; MILI L, 1991, IEEE T POWER SYST, V6, P511, DOI 10.1109/59.76693; Ng R, 1994, P 20 INT C VER LARG, P144; ODEWAHN S, 1998, DATA DIGITIZED PALOM; Rousseeuw P., 1985, MATH STAT APPL, V8, P283; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566; Rousseeuw PJ, 1997, INST MATH S, V31, P201; ROUSSEEUW PJ, 1990, J AM STAT ASSOC, V85, P633, DOI 10.2307/2289995; ROUSSEEUW PJ, 1997, HANDB STAT, V15, P101, DOI 10.1016/S0169-7161(97)15007-6; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SIMPSON DG, 1992, J AM STAT ASSOC, V87, P439, DOI 10.2307/2290275; STEELE JM, 1986, DISCRETE APPL MATH, V14, P93, DOI 10.1016/0166-218X(86)90009-0; STROMBERG AJ, 1993, SIAM J SCI COMPUT, V14, P1289, DOI 10.1137/0914076; Wang CM, 1997, TECHNOMETRICS, V39, P25, DOI 10.2307/1270769; WOODRUFF DL, 1994, J AM STAT ASSOC, V89, P888, DOI 10.2307/2290913; YOHAI VJ, 1987, ANN STAT, V15, P642, DOI 10.1214/aos/1176350366; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328	29	94	99	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2006	12	1					29	45		10.1007/s10618-005-0024-4		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	013ZU	WOS:000235449300002	
J	Bouchachia, A; Pedrycz, W				Bouchachia, A; Pedrycz, W			Data clustering with partial supervision	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clustering; partial supervision; classification; class discrimination; linear regression	CLASSIFICATION	Clustering with partial supervision finds its application in situations where data is neither entirely nor accurately labeled. This paper discusses a semi-supervised clustering algorithm based on a modified version of the fuzzy C-Means (FCM) algorithm. The objective function of the proposed algorithm consists of two components. The first concerns traditional unsupervised clustering while the second tracks the relationship between classes (available labels) and the clusters generated by the first component. The balance between the two components is tuned by a scaling factor. Comprehensive experimental studies are presented. First, the discrimination of the proposed algorithm is discussed before its reformulation as a classifier is addressed. The induced classifier is evaluated on completely labeled data and validated by comparison against some fully supervised classifiers, namely support vector machines and neural networks. This classifier is then evaluated and compared against three semi-supervised algorithms in the context of learning from partly labeled data. In addition, the behavior of the algorithm is discussed and the relation between classes and clusters is investigated using a linear regression model. Finally, the complexity of the algorithm is briefly discussed.	Univ Klagenfurt, Dept Informat, A-9020 Klagenfurt, Austria; Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada	Bouchachia, A (reprint author), Univ Klagenfurt, Dept Informat, Univ Str 65, A-9020 Klagenfurt, Austria.	hamid@isys.uni-klu.ac.at; pedrycz@ee.ualberta.ca					Amini MR, 2003, P 18 INT JOINT C ART, P555; Basu S, 2002, P 19 INT C MACH LEAR, P19; Bennett KP, 1999, ADV NEUR IN, V11, P368; Bezdek J., 1981, PATTERN RECOGNITION; Bishop CM, 1995, NEURAL NETWORKS PATT; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; BLUM A, 2004, P 21 INT C MACH LEAR, P92; BOUCHACHIA A, 2005, P 5 INT IEEE C INT H, P193; BOUCHACHIA A, 2005, P WORKSH LEARN PART, P10; CHAPELLE O, 2002, ADV NEURAL INFORM PR, V15, P585; Demiriz A., 1999, INTELLIGENT ENG SYST, V9, P809; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P181; Hathaway RJ, 2000, IEEE T FUZZY SYST, V8, P576, DOI 10.1109/91.873580; Jeon B, 1999, IEEE T GEOSCI REMOTE, V37, P1073; KLINKENBERG R, 2001, P WORKSH LEARN TEMP, P16; MASON R, 1983, STAT INTRO; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pedrycz W, 1997, IEEE T SYST MAN CY B, V27, P787, DOI 10.1109/3477.623232; Pizzi NJ, 1999, ARTIF INTELL MED, V16, P171, DOI 10.1016/S0933-3657(98)00071-2; Snedecor GW, 1989, STAT METHODS; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Zhu X., 2005, ADV NEURAL INFORM PR, P1641	22	16	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2006	12	1					47	78		10.1007/s10618-005-0019-1		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	013ZU	WOS:000235449300003	
J	Bouchaffra, D; Tan, J				Bouchaffra, D; Tan, J			Structural hidden Markov models using a relation of equivalence: Application to automotive designs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						hidden Markov models; relation of equivalence; local structures; statistical decoding; structural decoding	CHAINS	Standard hidden Markov models (HMM's) have been studied extensively in the last two decades. It is well known that these models assume state conditional independence of the observations. Therefore, they are inadequate for classification of complex and highly structured patterns. Nowadays, the need for new statistical models that are capable to cope with structural time series data is increasing. We propose in this paper a novel paradigm that we named "structural hidden Markov model" (SHMM). It extends traditional HMM's by partitioning the set of observation sequences into classes of equivalences. These observation sequences are related in the sense they all contribute to produce a particular local structure. We describe four basic problems that are assigned to a structural hidden Markov model: (1) probability evaluation, (2) statistical decoding, (3) local structure decoding, and (4) parameter estimation. We have applied SHMM in order to mine customers' preferences for automotive designs. The results reported in this application show that SHMM's outperform the traditional hidden Markov model with a 9% of increase in accuracy.	Oakland Univ, Dept Comp Sci & Engn, Rochester, MI 48309 USA	Bouchaffra, D (reprint author), Oakland Univ, Dept Comp Sci & Engn, 131 Dodge Hall, Rochester, MI 48309 USA.	dbouchaffra@ieee.org					ASAI K, 1993, COMPUT APPL BIOSCI, V9, P141; Bartolucci F, 2002, BIOMETRIKA, V89, P724, DOI 10.1093/biomet/89.3.724; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; BELLMAN R, 1961, COMMUNICATION ACM; BOUCHAFFRA D, 2004, CONCEPT STRUCTURAL H; BOUCHAFFRA D, 1999, IEEE T PATTERN ANAL, V21; CAI J, 1999, IEEE T PATTERN ANAL, V21; CHURCHILL GA, 1989, B MATH BIOL, V51, P79, DOI 10.1007/BF02458837; Duda R.O., 2001, PATTERN CLASSIFICATI; Eddy SR, 1998, BIOINFORMATICS, V14, P755, DOI 10.1093/bioinformatics/14.9.755; EFRON B, 1982, JACKKNIFE BOOSTRAP O; FAN G, 2001, IEEE T SIGNAL PROCES, V49; Fellbaum C., 1998, WORDNET ELECT LEXICA; FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; GALES J, 2000, IEEE T SPEECH AUDIO, V8; GEMAN S, 2004, COMPOSITIONALITY MDL; Gemignani M, 1990, ELEMENTARY TOPOLOGY; Hernandez-Hernandez D, 1999, IEEE T AUTOMAT CONTR, V44, P1093, DOI 10.1109/9.763237; KIM D, 2000, IEEE T PATTERN ANAL, V22; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Li J, 2000, IEEE T SIGNAL PROCES, V48, P517; Rabiner L., 1993, FUNDAMENTALS SPEECH; Ripley B., 1996, PATTERN RECOGNITION; SANCHES I, 2000, IEEE T SPEECH AUDIO, V8; ZHOU J, 2002, P 1 INT C MACH LEARN; ZHU W, 2004, IEEE T VEHICULAR TEC, V53	27	12	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2006	12	1					79	96		10.1007/s10618-005-0020-8		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	013ZU	WOS:000235449300004	
J	Wang, M; Leung, Y; Zhou, CH; Pei, T; Luo, JC				Wang, M; Leung, Y; Zhou, CH; Pei, T; Luo, JC			A mathematical morphology based scale space method for the mining of linear features in geographic data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						mathematical morphology; scale space theory; clustering; spatial data mining; linear belt; seismic belt	CLUSTERING-ALGORITHM; SPATIAL DATABASES; EARTHQUAKES	This paper presents a spatial data mining method MCAMMO and its extension L_MCAMMO designed for discovering linear and near linear features in spatial databases. L_MCAMMO can be divided into two basic steps: first, the most suitable re-segmenting scale is found by MCAMMO, which is a scale space method with mathematical morphology operators; second, the segmented result at this scale is re-segmented to obtain the final linear belts. These steps are essentially a multi-scale binary image segmentation process, and can also be treated as hierarchical clustering if we view the points under each connected component as one cluster. The final number of clusters is the one which survives (relatively, not absolutely) the longest scale range, and the clustering which first realizes this number of clusters is the most suitable segmentation. The advantages of MCAMMO in general and L_MCAMMO in particular, are: no need to pre-specify the number of clusters, a small number of simple inputs, capable of extracting clusters with arbitrary shapes, and robust to noise. The effectiveness of the proposed method is substantiated by the real-life experiments in the mining of seismic belts in China.	Nanjing Normal Univ, Coll Geog Sci, Nanjing, Peoples R China; Chinese Univ Hong Kong, Ctr Environm Policy & Resource Management, Dept Geog & Resource Management, Shatin, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Joint Lab Geoinformat Sci, Shatin, Hong Kong, Peoples R China; Chinese Acad Sci, State Key Lab Resources & Environm Informat Syst, Beijing, Peoples R China	Wang, M (reprint author), Nanjing Normal Univ, Coll Geog Sci, Nanjing, Peoples R China.						Acton ST, 2000, IEEE T IMAGE PROCESS, V9, P623, DOI 10.1109/83.841939; Amorese D, 1999, B SEISMOL SOC AM, V89, P742; Asano T, 1996, COMP GEOM-THEOR APPL, V6, P231, DOI 10.1016/0925-7721(95)00023-2; Ball G. H., 1965, ISODATA NOVEL METHOD; CUI Y, 2000, IMAGE PROCESSING ANA, V38, P67; DI K, 1998, J IMAGE GRAPHICS, V3, P173; Ester M., 1998, KI J, V12, P18; Ester M, 1996, P 2 INT C KNOWL DISC, P324; Fasulo D., 1999, 010302 U WASH DEP CO; FU Z, 1997, RES EARTHQUAKE ACTIV, P124; BEZDEK JC, 1981, SIAM J APPL MATH, V40, P339, DOI 10.1137/0140029; HE B, 2001, DIGITAL IMAGE PROCES, P335; Honda K, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P1444; Jones RH, 1997, J GEOPHYS RES-SOL EA, V102, P8245, DOI 10.1029/96JB03739; KOLATCH E, 2002, CLUSTERING ALGORITHM; KOPERSKI K, 1996, P ACM SIGMOD WORKSH; Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396; LINDEBERG T, 1996, P CERN SCH COMP EGM; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Marceau D.J., 1999, CANADIAN J REMOTE SE, V25, P347; Park KR, 1996, IEEE T PATTERN ANAL, V18, P1121; PENG W, 1991, COMPUTER PROCESSING, P128; POSTAIRE JG, 1993, IEEE T PATTERN ANAL, V15, P170, DOI 10.1109/34.192490; Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419; Serra JP, 1982, IMAGE ANAL MATH MORP; SONG CQ, 1982, BASIC GEOLOGY; SUN J, 1995, COMPUTER GRAPHICS, P185; Witkin A. P, 1983, P INT JOINT C ART IN, P1019; WONG YF, 1993, NEURAL COMPUT, V5, P89, DOI 10.1162/neco.1993.5.1.89; WONG YF, 1993, IEEE T GEOSCI REMOTE, V31, P634, DOI 10.1109/36.225530; Xu XW, 1999, DATA MIN KNOWL DISC, V3, P263, DOI 10.1023/A:1009884809343; ZHANG DZ, 1989, TECTONOPHYSICS, V159, P137, DOI 10.1016/0040-1951(89)90175-3; *NAT DEP EARTHQ, 1996, CONSP LAYOUT MAP CHI, P64; *SEISM AN FOR CTR, 1989, CHIN SEISM BUR SEISM; *SEISM AN FOR CTR, 1980, CHIN SEISM BUR SEISM	35	4	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2006	12	1					97	118		10.1007/s10618-005-0021-7		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	013ZU	WOS:000235449300005	
J	Pei, J; Han, JW; Lakshmanan, L				Pei, J; Han, JW; Lakshmanan, L			Pushing convertible constraints in frequent itemset mining (vol 8, pg 227, 2004)	DATA MINING AND KNOWLEDGE DISCOVERY			English	Correction									Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada; Univ Illinois, Urbana, IL 61801 USA; Univ British Columbia, Vancouver, BC V5Z 1M9, Canada	Pei, J (reprint author), Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.	jpei@cs.sfu.ca; hanj@cs.uiuc.edu; laks@cs.ubc.ca					Pei J, 2004, DATA MIN KNOWL DISC, V8, P227, DOI 10.1023/B:DAMI.0000023674.74932.4c	1	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2006	12	1					119	119		10.1007/s10618-005-0022-6		1	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	013ZU	WOS:000235449300006	
J	Cheng, JL; Sweredoski, MJ; Baldi, P				Cheng, JL; Sweredoski, MJ; Baldi, P			Accurate prediction of protein disordered regions by mining protein structure data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						protein structure prediction; disordered regions; recursive neural networks	SECONDARY STRUCTURE	Intrinsically disordered regions in proteins are relatively frequent and important for our understanding of molecular recognition and assembly, and protein structure and function. From an algorithmic standpoint, flagging large disordered regions is also important for ab initio protein structure prediction methods. Here we first extract a curated, non-redundant, data set of protein disordered regions from the Protein Data Bank and compute relevant statistics on the length and location of these regions. We then develop an ab initio predictor of disordered regions called DISpro which uses evolutionary information in the form of profiles, predicted secondary structure and relative solvent accessibility, and ensembles of 1D-recursive neural networks. DISpro is trained and cross validated using the curated data set. The experimental results show that DISpro achieves an accuracy of 92.8% with a false positive rate of 5%. DISpro is a member of the SCRATCH suite of protein data mining tools available through http://www.igb.uci.edu/servers/psss.html.	Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA	Cheng, JL (reprint author), Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA.	pfbaldi@ics.uci.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Bengio Y, 1996, IEEE T NEURAL NETWOR, V7, P1231, DOI 10.1109/72.536317; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Dunker AK, 2002, BIOCHEMISTRY-US, V41, P6573, DOI 10.1021/bi012159+; Frasconi P, 2002, P IEEE WORKSH NEUR N, P25, DOI 10.1109/NNSP.2002.1030014; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; LI X, 1999, GENOME INFORM, V42, P389; Linding R, 2003, STRUCTURE, V11, P1453, DOI 10.1016/j.str.2003.10.002; Mika S, 2003, NUCLEIC ACIDS RES, V31, P3789, DOI 10.1093/nar/gkg620; POLLASTRI G, 2001, PROTEINS, V47, P142; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; PRZYBYLSKI D, 2002, PROTEIN-STRUCT FUNCT, V46, P195; Ward JJ, 2004, J MOL BIOL, V337, P635, DOI 10.1016/j.jmb.2004.02.002; WOOTTON JC, 1994, COMPUT CHEM, V18, P269, DOI 10.1016/0097-8485(94)85023-2; Wright PE, 1999, J MOL BIOL, V293, P321, DOI 10.1006/jmbi.1999.3110	17	66	73	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2005	11	3					213	222		10.1007/s10618-005-0001-y		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	990GZ	WOS:000233732500001	
J	Gouda, K; Zaki, MJ				Gouda, K; Zaki, MJ			GenMax: An efficient algorithm for mining maximal frequent itemsets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						maximal itemsets; frequent itemsets; association rules; data mining; backtracking search		We present GenMax, a backtrack search based algorithm for mining maximal frequent itemsets. GenMax uses a number of optimizations to prune the search space. It uses a novel technique called progressive focusing to perform maximality checking, and diffset propagation to perform fast frequency computation. Systematic experimental comparison with previous work indicates that different methods have varying strengths and weaknesses based on dataset characteristics. We found GenMax to be a highly efficient method to mine the exact set of maximal patterns.	Fac Sci, Dept Math, Banha, Egypt; Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Gouda, K (reprint author), Fac Sci, Dept Math, Banha, Egypt.	karamg@hotmail.com; zaki@cs.rpi.edu					Agrawal R., 2000, 7 INT C KNOWL DISC D, P108; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bayardo R J, 1998, ACM SIGMOD INT C MAN, P85; Burdick D., 2001, ICDE, P443; GOETHALS B, 2003, SIGKDD EXPLORATIONS, V6, P109; Gouda K, 2003, 9 ACM SIGKDD INT C K, P326; Gunopulos D, 2003, ACM T DATABASE SYST, V28, P140, DOI 10.1145/777943.777945; Han J., 2000, ACM SIGMOD INT C MAN, P1; LIN DL, 1998, 6 INT C EXT DAT TECH, P105; YELLIN DM, 1994, THEOR COMPUT SCI, V129, P397, DOI 10.1016/0304-3975(94)90036-1; ZAKI MJ, 2002, 2 SIAM INT C DAT MIN, P457; Zaki M.J., 2000, 6 ACM SIGKDD INT C K, P34	12	14	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2005	11	3					223	242		10.1007/s10618-005-0002-x		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	990GZ	WOS:000233732500002	
J	Kuramochi, M; Karypis, G				Kuramochi, M; Karypis, G			Finding frequent patterns in a large sparse graph	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						pattern discovery; frequent subgraph; graph mining	EFFICIENT ALGORITHM; INDEPENDENT SETS; PROTEINS; MOTIFS	Graph-based modeling has emerged as a powerful abstraction capable of capturing in a single and unified framework many of the relational, spatial, topological, and other characteristics that are present in a variety of datasets and application areas. Computationally efficient algorithms that find patterns corresponding to frequently occurring subgraphs play an important role in developing data mining-driven methodologies for analyzing the graphs resulting from such datasets. This paper presents two algorithms, based on the horizontal and vertical pattern discovery paradigms, that find the connected subgraphs that have a sufficient number of edge-disjoint embeddings in a single large undirected labeled sparse graph. These algorithms use three different methods for determining the number of edge-disjoint embeddings of a subgraph and employ novel algorithms for candidate generation and frequency counting, which allow them to operate on datasets with different characteristics and to quickly prune unpromising subgraphs. Experimental evaluation on real datasets from various domains show that both algorithms achieve good performance, scale well to sparse input graphs with more than 120,000 vertices or 110,000 edges, and significantly outperform previously developed algorithms.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Kuramochi, M (reprint author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	kuram@cs.umn.edu; karypis@cs.umn.edu					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; BERENDT B, 2002, INT SEM WEB C ISWC, P264; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BERMAN P, 1995, P 4 WORKSH ALG DAT S, P449; Blake C, 1998, UCI REPOSITORY MACHI; Borgelt C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183885; CHEW LP, 1999, P 3 ACM RECOMB INT C, P104, DOI 10.1145/299432.299464; COHEN M, 2004, P 9 INT WORKSH DAT M, P51, DOI 10.1145/1008694.1008702; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Cook DJ, 2000, IEEE INTELL SYST APP, V15, P32, DOI 10.1109/5254.850825; COOK ER, 1995, HOLOCENE, V5, P229, DOI 10.1177/095968369500500211; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DERAEDT L, 1921, P 17 INT JOINT C ART, P853; DERAEDT L, 2001, P 17 INT JOINT C ART, P853; DESHPANDE M, 2002, P WORKSH DAT MIN BIO, P11; Deshpande M., 2003, P 3 IEEE INT C DAT M, P35; FEIGE U, 1991, PROCEEDINGS - 32ND ANNUAL SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, P2, DOI 10.1109/SFCS.1991.185341; Fortin S, 1996, TR9620 U ALB DEP COM; Garey M. R., 1979, COMPUTERS INTRACTABI; GHAZIZADEH S, 2002, CSTR4364 U MAR DEP C; GHAZIZADEH S, 2002, P 5 INT C DISC SCI, P71; GONZALEZ J, 2001, P PRED TOX CHALL WOR; Gouda K., 2003, P 9 ACM SIGKDD INT C, P326; GRINDLEY HM, 1993, J MOL BIOL, V229, P707, DOI 10.1006/jmbi.1993.1074; GURALNIK V, 2001, P 2001 IEEE INT C DA; Halldorsson MM, 1997, ALGORITHMICA, V18, P145, DOI 10.1007/BF02523693; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HOCHBAUM DS, 1983, DISCRETE APPL MATH, V6, P243, DOI 10.1016/0166-218X(83)90080-X; Holder L.B., 1994, P AAAI WORKSH KNOWL, P169; Hong MS, 2003, LECT NOTES ARTIF INT, V2637, P40; Huan J, 2003, P 3 IEEE INT C DAT M, P549; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; Inokuchi A., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); INOKUCHI A, 2002, RT0448 IBM RES TOK R; JENSEN D, 1998, ARTIFICIAL INTELLIGE; JONYER I, 2001, J MACHINE LEARNING R, V2, P19, DOI 10.1162/153244302760185234; Jonyer I., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000441; Khanna S., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), DOI 10.1109/SFCS.1994.365712; Kleinberg J. M., 1999, LECT NOTES COMPUTER, V1627, P1, DOI DOI 10.1007/3-540-48686-0_1; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; KO C, 2000, IEEE S SEC PRIV S P, P142; Koch I, 1996, J COMPUT BIOL, V3, P289, DOI 10.1089/cmb.1996.3.289; Kramer S., 2001, P 7 ACM SIGKDD INT C, P136, DOI 10.1145/502512.502533; Kuramochi M, 2004, IEEE T KNOWL DATA EN, V16, P1038, DOI 10.1109/TKDE.2004.33; Kuramochi M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989534; KURAMOCHI M, 2004, P 2004 SIAM INT C DA; Kuramochi M, 2002, 02026 U MINN DEP COM; KURAMOCHI M, 2004, IN PRESS DATA MINING, P315; Lee W., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382914; Leibowitz N, 2001, J COMPUT BIOL, V8, P93, DOI 10.1089/106652701300312896; Leibowitz N, 1999, Proc Int Conf Intell Syst Mol Biol, P169; Li W., 2001, P IEEE INT C DAT MIN, P369; Liu H, 1998, ELEC SOC S, V98, P86; MCKAY B, NAUTY USERS GUIDE; McKay B., 1981, C NUMERANTIUM, V30, P45; MITCHELL EM, 1990, J MOL BIOL, V212, P151, DOI 10.1016/0022-2836(90)90312-A; MOONEY RJ, 2004, RELATIONAL DATA MINI, P239; Muggleton S, 1999, COMMUN ACM, V42, P42, DOI 10.1145/319382.319390; Ostergard PRJ, 2002, DISCRETE APPL MATH, V120, P195; Palmer C.R., 2002, P 8 ACM SIGKDD INT C, P81; Pennec X, 1998, BIOINFORMATICS, V14, P516, DOI 10.1093/bioinformatics/14.6.516; Raymond JW, 2002, J CHEM INF COMP SCI, V42, P305, DOI 10.1021/ci010381f; READ RC, 1977, J GRAPH THEOR, V1, P339, DOI DOI 10.1002/JGT.3190010410; ROBSON JM, 1986, J ALGORITHM, V7, P425, DOI 10.1016/0196-6774(86)90032-5; Srinivasan A., 1997, LECT NOTES ARTIF INT, V1297, P273; Vanetik N., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183988; Wang X, 2002, IEEE T KNOWL DATA EN, V14, P731; Wasserman S, 1994, SOCIAL NETWORK ANAL; Yan X., 2002, P 2002 IEEE INT C DA, P721; YAN X, 2003, P 9 ACM SIGKDD INT C, P286; YOSHIDA K, 1994, APPL INTELL, V4, P297, DOI 10.1007/BF00872095; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A	74	44	52	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2005	11	3					243	271		10.1007/s10618-005-0003-9		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	990GZ	WOS:000233732500003	
J	Lee, SK; Kang, HC; Han, ST; Kim, KH				Lee, SK; Kang, HC; Han, ST; Kim, KH			Using generalized estimating equation to learn decision tree with multivariate responses	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						generalized estimating equations (GEE); multiple responses; multivariate decision tree	LONGITUDINAL DATA; CLASSIFICATION TREES; REGRESSION TREES; MODELS	Previous decision tree algorithms have used Mahalanobis distance for multiple continuous longitudinal response or generalized entropy index for multiple binary responses. However, these methods are limited to either continuous or binary responses. In this paper, we suggest a new tree-based method that can analyze any type of multiple responses by using a statistical approach, called GEE (generalized estimating equations). The value of this new technique is demonstrated with reference to an application using web-usage survey.	Korea Univ, Inst Stat, Seoul 136701, South Korea; Hoseo Univ, Dept Informat Stat, Asan 336795, South Korea; Dankuk Univ Hosp, Dept Med Record, Cheonan 330715, South Korea	Lee, SK (reprint author), Korea Univ, Inst Stat, 5-1 Anam Dong, Seoul 136701, South Korea.	sklee@grad.math.chuo-u.ac.jp; hychkang@office.hoseo.ac.kr; sthan@office.hoseo.ac.kr; dkwang@isdmc.co.kr					Agresti A, 1990, CATEGORICAL DATA ANA; Breiman L, 1984, CLASSIFICATION REGRE; CAPPELLI C, 1998, COMPSTAT 98 P COMP S, P221; CHAUDHURI P, 1995, STAT SINICA, V5, P641; COX DR, 1972, J ROY STAT SOC C-APP, V21, P113; Diggle P. J., 1994, ANAL LONGITUDINAL DA; Hand DJ, 1997, CONSTRUCTION ASSESSM; Hawkins D. M., 1982, TOPICS APPL MULTIVAR, P269; Horton NJ, 1999, AM STAT, V53, P160, DOI 10.2307/2685737; LAIRD NM, 1982, BIOMETRICS, V38, P963, DOI 10.2307/2529876; Larsen DR, 2004, BIOMETRICS, V60, P543, DOI 10.1111/j.0006-341X.2004.00202.x; LIANG KY, 1986, BIOMETRIKA, V73, P13, DOI 10.2307/2336267; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; MCCULLAGH P, 1983, GEN LINEAR MODELS; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SEGAL MR, 1992, J AM STAT ASSOC, V87, P407, DOI 10.2307/2290271; Stokes M. E., 1995, CATEGORICAL DATA ANA; TAYLOR PC, 1993, STAT COMPUT, V3, P147, DOI 10.1007/BF00141771; THALL PF, 1990, BIOMETRICS, V46, P657, DOI 10.2307/2532086; Ware M, 2001, INT J HUM-COMPUT ST, V55, P281, DOI 10.1006/ijhc.2001.0499; Yu Y, 1999, J COMPUT GRAPH STAT, V8, P749, DOI 10.2307/1390825; Zhang H., 1999, RECURSIVE PARTITIONI; Zhang HP, 1998, J AM STAT ASSOC, V93, P180, DOI 10.2307/2669615; ZHAO LP, 1990, BIOMETRIKA, V77, P642, DOI 10.1093/biomet/77.3.642; *SAS I INC, 2000, SAS MACR LANG REF VE	25	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2005	11	3					273	293		10.1007/s10618-005-0004-8		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	990GZ	WOS:000233732500004	
J	Yu, HJ; Yang, J; Han, JW; Li, XL				Yu, HJ; Yang, J; Han, JW; Li, XL			Making SVMs scalable to large data sets using hierarchical cluster indexing	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article							SUPPORT VECTOR MACHINES	Support vector machines (SVMs) have been promising methods for classification and regression analysis due to their solid mathematical foundations, which include two desirable properties: margin maximization and nonlinear classification using kernels. However, despite these prominent properties, SVMs are usually not chosen for large-scale data mining problems because their training complexity is highly dependent on the data set size. Unlike traditional pattern recognition and machine learning, real-world data mining applications often involve huge numbers of data records. Thus it is too expensive to perform multiple scans on the entire data set, and it is also infeasible to put the data set in memory. This paper presents a method, Clustering-Based SVM (CB-SVM), that maximizes the SVM performance for very large data sets given a limited amount of resource, e.g., memory. CB-SVM applies a hierarchical micro-clustering algorithm that scans the entire data set only once to provide an SVM with high quality samples. These samples carry statistical summaries of the data and maximize the benefit of learning. Our analyses show that the training complexity of CB-SVM is quadratically dependent on the number of support vectors, which is usually much less than that of the entire data set. Our experiments on synthetic and real-world data sets show that CB-SVM is highly scalable for very large data sets and very accurate in terms of classification.	Univ Iowa, Dept Comp Sci, Iowa City, IA 52242 USA; Case Western Reserve Univ, Dept Comp Sci, Cleveland, OH 44106 USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Yu, HJ (reprint author), Univ Iowa, Dept Comp Sci, Iowa City, IA 52242 USA.	hwanjoyu@cs.uiowa.edu; jiong@eecs.cwru.edu; hanj@cs.uiuc.edu; xli10@uiuc.edu					AGARWAL DK, 2002, P 8 ACM SIGKDD INT C, P173; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cauwenberghs G., 2000, P ADV NEUR INF PROC, P409; Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Devroye L, 1996, PROBABILISTIC THEORY; DOMINGOS P, 2000, P ACM SIGKDD INT C K; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI 10.1145/502512.502527; GANTI V, 1999, P INT C DAT ENG ICDE; GREINER R, 1996, P 13 INT C MACH LEAR, P207; Joachims T, 1998, ADV KERNEL METHODS S; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; KIVINEN J, 2001, P ADV NEUR INF PROC, P785; LEE YJ, 2001, SIAM INT C DAT MIN; MANGASARIAN OL, 2000, ACTIVE SUPPORT VECTO; Platt J, 1998, ADV KERNEL METHODS S; SCHEFFER T, 2002, J MACHINE LEARNING R; Schohn G., 2000, P 17 INT C MACH LEAR, P839; Scholkopf B., 2000, P ADV NEUR INF PROC, P582; SHIH L, 2002, P WORKSH TEXT LEARN; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Smola A. J., 1998, NC2TR1998030 NEUROCO; Syed N, 1999, P WORKSH SUPP VECT M; TONG S, 2000, P 17 INT C MACH LEAR, P999; Vapnik V. N., 1998, STAT LEARNING THEORY; Wang WL, 1997, ELEC SOC S, V97, P186; WATANABE O, 2001, INT C DAT MIN ICDM 0, P43; Yu H., 2002, P ACM SIGKDD INT C K, P239; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	30	11	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2005	11	3					295	321		10.1007/s10618-005-0005-7		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	990GZ	WOS:000233732500005	
J	Domingo-Ferrer, J; Torra, V				Domingo-Ferrer, J; Torra, V			Privacy in data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Univ Rovira & Virgili, Dept Comp Engn & Math, E-43007 Tarragona, Catalonia, Spain; CSIC, Inst Invest Intel Ligencia Artificial, E-08193 Bellaterra, Catalonia, Spain	Domingo-Ferrer, J (reprint author), Univ Rovira & Virgili, Dept Comp Engn & Math, Av Paisos Catalans 26, E-43007 Tarragona, Catalonia, Spain.	josep.domingo@urv.net; vtorra@iiia.csic.es					Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; DALENIUS T, 1974, STAT TIDSKRIFT, V12, P213; Denning D. E., 1979, ACM Transactions on Database Systems, V4, DOI 10.1145/320064.320069; SCHLORER J, 1975, METHOD INFORM MED, V14, P7; Willenborg L., 2001, ELEMENTS STAT DISCLO	5	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2005	11	2					117	119		10.1007/s10618-005-0009-3		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	976GM	WOS:000232721000001	
J	Bertino, E; Fovino, IN; Provenza, LP				Bertino, E; Fovino, IN; Provenza, LP			A framework for evaluating privacy preserving data mining algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article							MATHEMATICAL-THEORY; COMMUNICATION; QUALITY	Recently, a new class of data mining methods, known as privacy preserving data mining (PPDM) algorithms, has been developed by the research community working on security and knowledge discovery. The aim of these algorithms is the extraction of relevant knowledge from large amount of data, while protecting at the same time sensitive information. Several data mining techniques, incorporating privacy protection mechanisms, have been developed that allow one to hide sensitive itemsets or patterns, before the data mining process is executed. Privacy preserving classification methods, instead, prevent a miner from building a classifier which is able to predict sensitive data. Additionally, privacy preserving clustering techniques have been recently proposed, which distort sensitive numerical attributes, while preserving general features for clustering analysis. A crucial issue is to determine which ones among these privacy-preserving techniques better protect sensitive information. However, this is not the only criteria with respect to which these algorithms can be evaluated. It is also important to assess the quality of the data resulting from the modifications applied by each algorithm, as well as the performance of the algorithms. There is thus the need of identifying a comprehensive set of criteria with respect to which to assess the existing PPDM algorithms and determine which algorithm meets specific requirements. In this paper, we present a first evaluation framework for estimating and comparing different kinds of PPDM algorithms. Then, we apply our criteria to a specific set of algorithms and discuss the evaluation results we obtain. Finally, some considerations about future work and promising directions in the context of privacy preservation in data mining are discussed.	Purdue Univ, CERIAS, W Lafayette, IN 47907 USA; Purdue Univ, CS Dept, W Lafayette, IN 47907 USA; Univ Milan, Dipartimento Informat & Comunicaz, I-20122 Milan, Italy	Bertino, E (reprint author), Purdue Univ, CERIAS, W Lafayette, IN 47907 USA.	bertino@cerias.purdue.edu; nai@dico.unimi.it; parasiliti@dico.unimi.it					Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; BALLOU DP, 1985, MANAGE SCI, V31, P150, DOI 10.1287/mnsc.31.2.150; Domingo-Ferrer J, 2002, CONFIDENTIALITY DISC, P113; Duncan G. T., 2001, 121 NAT I STAT SCI; DWORK C, 2004, CRYPTO, V3152, P528; Evfimievski A, 2002, SIGKDD EXPLORATIONS, V4, P43; Evfimievski A., 2002, 8 ACM SIGKDD INT C K, P217; Kantarcioglu M., 2002, ACM SIGMOD WORKSH RE, P24; OLIVEIRA SRM, 2004, ACM SIGKDD 3 WORKSH, P7; Oliveira SRM, 2002, IEEE ICDM WORKSH PRI, P43; RIZVI S, 2002, 28 INT C VER LARG DA, P682; SCHOEMAN FD, 1984, PHILOS DIMENSIONS PR; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHANNON CE, 1948, AT&T TECH J, V27, P623; SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P571, DOI 10.1142/S021848850200165X; Tayi GK, 1998, COMMUN ACM, V41, P54, DOI 10.1145/269012.269021; Trottini M., 2001, RES OFFICIAL STAT, V4, P7; TROTTINI M, 2003, DECISION MODELS DATA; Vaidya J., 2002, 8 ACM SIGKDD INT C K, P639, DOI [10.1145/775047.775142, DOI 10.1145/775047.775142]; Verykios VS, 2004, SIGMOD REC, V33, P50; WALTERS GJ, 2001, HUMAN RIGHTS INFORM, pCH5; WANG RY, 1996, J MANAGEMENT INFORMA, V15, P5; WILLENNBORG L, 2001, ELEMENTS STAT DISCLO, V155; *SAB U, 2003, MOD ALG PRIV PRES DA; *U MIL, 2002, CODMINE I PROJ	27	31	33	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2005	11	2					121	154		10.1007/s10618-005-0006-6		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	976GM	WOS:000232721000002	
J	Fienberg, SE; Slavkovic, AB				Fienberg, SE; Slavkovic, AB			Preserving the confidentiality of categorical statistical data bases when releasing information for association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						algebraic geometry; association rules; conditional tables; contingency tables; disclosure limitation; marginal tables; privacy preservation	CONTINGENCY-TABLES; CELL ENTRIES; BOUNDS	In the statistical literature, there has been considerable development of methods of data releases for multivariate categorical data sets, where the releases come in the form of marginal tables corresponding to subsets of the categorical variables. Very recently some of the ideas have been extended to allow for the release of combinations of mixtures of marginal tables and conditional tables for subsets of variables. Association rules can be viewed as conditional tables. In this paper we consider possible inferences an intruder can make about confidential categorical data following the release of information on one or more association rules. We illustrate this with several examples.	Carnegie Mellon Univ, Dept Stat, Cylab, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Ctr Automated Learning & Discovery, Pittsburgh, PA 15213 USA; Penn State Univ, Dept Stat, University Pk, PA 16802 USA	Fienberg, SE (reprint author), Carnegie Mellon Univ, Dept Stat, Cylab, Pittsburgh, PA 15213 USA.	fienberg@stat.cmu.edu; sesa@stat.psu.edu					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agresti A., 2002, CATEGORICAL DATA ANA; ANDERSON B, 1998, KNOWL DISC DAT C KDD, P134; Arnold B., 1999, CONDITIONAL SPECIFIC; ARNOLD BC, 1998, J AM STAT ASSOC, V405, P152; Atallah M, 1999, P 1999 IEEE KNOWL DA, P45; Bishop Y.M.M., 1975, DISCRETE MULTIVARIAT; Chang CK, 2001, ANN SOFTW ENG, V11, P11, DOI 10.1023/A:1012579501037; DALENIUS T, 1982, J STAT PLAN INFER, V6, P73, DOI 10.1016/0378-3758(82)90058-1; De Loera J.A., 2003, USERS GUIDE LATTE V1; Diaconis P, 1998, ANN STAT, V26, P363; Dobra A., 2001, STAT J UN ECE, V18, P363; Dobra A, 2000, P NATL ACAD SCI USA, V97, P11885, DOI 10.1073/pnas.97.22.11885; Dobra A, 2003, CONTR STAT, P3; Domingo-Ferrer J., 2004, LECT NOTES COMPUTER, V3050; DuMouchel W., 2001, P 7 ACM SIGKDD INT C, P67, DOI 10.1145/502512.502526; Duncan G.T., 2001, CONFIDENTIALITY DISC, P135; Duncan GT, 2004, CHANCE, V17, P16; EDWARDS D, 1985, BIOMETRIKA, V72, P339, DOI 10.1093/biomet/72.2.339; Estivill-Castro V., 1999, LECT NOTES COMPUTER, V1676, P389; EVFIMIEVSKI A, 2000, P 8 ACM SIGKDD INT C, P217; Fienberg S. E., 1980, ANAL CROSS CLASSIFIE; Fienberg S. E, 2004, P WORKSH PRIV SEC AS, P1; Fienberg SE, 2004, ANN NY ACAD SCI, V3050, P14; Fienberg S.E., 1998, J OFF STAT, V14, P485; FIENBERG SE, 2004, CHANCE, V17, P5; FIENBERG SE, 2001, DATA ANAL STAT FDN F, P145; GELMAN A, 1993, J ROY STAT SOC B MET, V55, P185; Gelman A, 1999, J ROY STAT SOC B, V61, P483, DOI 10.1111/1467-9868.00189; GOLDENBERG A, 2004, ICML 04, P345; Gouweleeuw J.M., 1998, J OFF STAT, V14, P463; HEMMECKE R, 2003, 4TI2 VERSION 1 1 COM; Jordan M., 1998, LEARNING GRAPHICAL M; KANTARCIOGLU M, 2004, T KNOWLEDGE DATA ENG, P1026; Kantarcioglu M., 2004, P 10 ACM SIGKDD INT, P599; Kargupta H., 2003, P 3 IEEE INT C DAT M, P99; Koch G., 1983, SAS SUGI, V8, P785; Komarek P, 2000, P 17 INT C MACH LEAR, P495; LAURITZEN S, GRAPHICAL MODELS; MOORE A, 2002, P 18 C UNC ART INT S, P360; Oliveira S. R. M., 2003, Proceedings International Database Engineering and Applications Symposium; Pavlov D, 2003, IEEE T KNOWL DATA EN, V15, P1409, DOI 10.1109/TKDE.2003.1245281; PELLEG D, 2003, ADV NEURAL INFORMATI, V15, P801; PISTONE J, 2001, ALGEBRAIC STAT COMPU; PONTIKAKIS ED, 2004, ACM WORKSH PRIV EL S, P29; PONTIKAKIS ED, 2004, HELL DAT MAN S ATH G; PONTIKAKIS ED, 2004, C DAT SEC SITG SPAIN, P325; Rizvi S. J., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; Silverstein C, 2000, DATA MIN KNOWL DISC, V4, P163, DOI 10.1023/A:1009891813863; Slavkovic A.B., 2004, THESIS CARNEGIE MELL; Slavkovic AB, 2004, ANN NY ACAD SCI, V3050, P30; Srikant R., 1995, P 21 INT C VER LARG, P407; STURMFELS B, 2003, J VONNEUMANN LECT MU; Trottini M., 2003, THESIS CARNEGIE MELL; Trottini M, 2002, INT J UNCERTAIN FUZZ, V10, P511, DOI 10.1142/S0218488502001612; VAIDYA J, 2002, 8 ACM SIGKDD INT C K; Willenborg L. C. R. J., 2000, LECT NOTES STAT, V155; Witten IH, 2000, DATA MINING PRACTICA; Wu X., 2003, P ACM SIGKDD INT C K, P276; Zaki MJ, 2004, DATA MIN KNOWL DISC, V9, P223, DOI 10.1023/B:DAMI.0000040429.96086.c7	63	21	21	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2005	11	2					155	180		10.1007/s10618-005-0010-x		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	976GM	WOS:000232721000003	
J	Mateo-Sanz, JM; Domingo-Ferrer, J; Sebe, F				Mateo-Sanz, JM; Domingo-Ferrer, J; Sebe, F			Probabilistic information loss measures in confidentiality protection of continuous microdata	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						database security; privacy; statistical disclosure control; microdata protection; information loss measures		Inference control for protecting the privacy of microdata (individual data) should try to optimize the tradeoff between data utility (low information loss) and protection against disclosure (low disclosure risk). Whereas risk measures are bounded between 0 and 1, information loss measures proposed in the literature for continuous data are unbounded, which makes it awkward to trade off information loss for disclosure risk. We propose in this paper to use probabilities to define bounded information loss measures for continuous microdata.	Univ Rovira & Virgili, Dept Comp Engn & Math, E-43007 Tarragona, Catalonia, Spain	Mateo-Sanz, JM (reprint author), Univ Rovira & Virgili, Dept Comp Engn & Math, Av Paisos Catalans 26, E-43007 Tarragona, Catalonia, Spain.	josepmaria.mateo@urv.net; josep.domingo@urv.net; francesc.sebe@urv.net					Agrawal D., 2001, P 20 S PRINC DAT SYS; Dandekar R., 2002, LECT NOTES COMPUTER, V2316, P153; Domingo-Ferrer J, 2001, PREPROCEEDINGS ETK N, V2, P807; Domingo-Ferrer J, 2002, IEEE T KNOWL DATA EN, V14, P189, DOI 10.1109/69.979982; Hardle W., 1991, SMOOTHING TECHNIQUES; Kendall M, 1994, KENDALLS ADV THEORY, V1; MOORE R, 1996, UNPUB CONTROLLED DAT; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Rosenblatt M., 1956, ANN MATH STAT, V27, P642; Sebe F., 2002, LNCS, V2316, P163; SILVERMAN BW, 1982, APPL STAT-J ROY ST C, V31, P93, DOI 10.2307/2347084; Torra V., 2001, CONFIDENTIALITY DISC, P91; Trottini M., 2003, THESIS CARNEGIE MELL; Yancey W. E., 2002, LECT NOTES COMPUTER, V2316, P135	14	25	26	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2005	11	2					181	193		10.1007/s10618-005-0011-9		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	976GM	WOS:000232721000004	
J	Domingo-Ferrer, J; Torra, V				Domingo-Ferrer, J; Torra, V			Ordinal, continuous and heterogeneous k-anonymity through microaggregation	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						k-anonymity; microdata privacy; database security; microaggregation	MICRODATA; PRIVACY	k-Anonymity is a useful concept to solve the tension between data utility and respondent privacy in individual data (microdata) protection. However, the generalization and suppression approach proposed in the literature to achieve k-anonymity is not equally suited for all types of attributes: (i) generalization/suppression is one of the few possibilities for nominal categorical attributes; (ii) it is just one possibility for ordinal categorical attributes which does not always preserve ordinality; (iii) and it is completely unsuitable for continuous attributes, as it causes them to lose their numerical meaning. Since attributes leading to disclosure (and thus needing k-anonymization) may be nominal, ordinal and also continuous, it is important to devise k-anonymization procedures which preserve the semantics of each attribute type as much as possible. We propose in this paper to use categorical microaggregation as an alternative to generalization/suppression for nominal and ordinal k-anonymization; we also propose continuous microaggregation as the method for continuous k-anonymization.	Univ Rovira & Virgili, Dept Comp Engn & Math, E-43007 Tarragona, Catalonia, Spain; CSIC, Inst Invest Intel Ligencia Artificial, E-08193 Barcelona, Catalonia, Spain	Domingo-Ferrer, J (reprint author), Univ Rovira & Virgili, Dept Comp Engn & Math, Av Paisos Catalans 26, E-43007 Tarragona, Catalonia, Spain.	josep.domingo@urv.net; vtorra@iiia.csic.es					AGGARWAL G, 2004, KAPPA ANONYMITY ALGO; Dalenius T., 1986, J OFF STAT, V2, P329; Defays D., 1993, P 92 S DES AN LONG S, P195; Domingo-Ferrer J, 2001, PREPROCEEDINGS ETK N, V2, P807; DOMINGOFERRER J, 2005, PRIVACY STAT DATABAS; Doming-Ferrer J., 2001, CONFIDENTIALITY DISC, P111; Domingo-Ferrer J, 2002, IEEE T KNOWL DATA EN, V14, P189, DOI 10.1109/69.979982; Duncan G.T., 2001, CONFIDENTIALITY DISC, P135; DUNCAN GT, 2001, DISCLOSURE RISK DATA; HUNDEPOOL A, 2003, UTA ARGUS VERSION 3; Oganian A, 2001, STAT J UN EC COMMISS, V18, P345; REITER JP, 2004, IN PRESS J ROYAL S A; Samarati P., 1998, PROTECTING PRIVACY D; Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193; Sebe F., 2002, LNCS, V2316, P163; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P571, DOI 10.1142/S021848850200165X; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Torra V., 2001, CONFIDENTIALITY DISC, P91; Torra V, 2004, ANN NY ACAD SCI, V3050, P162; Willenborg L., 2001, ELEMENTS STAT DISCLO; Winkler WE, 2004, ANN NY ACAD SCI, V3050, P216; Yancey W. E., 2002, LECT NOTES COMPUTER, V2316, P135	22	114	114	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2005	11	2					195	212		10.1007/s10618-005-0007-5		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	976GM	WOS:000232721000005	
J	Agrawal, R; Gehrke, J; Gunopulos, D; Raghavan, P				Agrawal, R; Gehrke, J; Gunopulos, D; Raghavan, P			Automatic subspace clustering of high dimensional data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						subspace clustering; clustering; dimensionality reduction		Data mining applications place special requirements on clustering algorithms including: the ability to find clusters embedded in subspaces of high dimensional data, scalability, end-user comprehensibility of the results, non-presumption of any canonical data distribution, and insensitivity to the order of input records. We present CLIQUE, a clustering algorithm that satisfies each of these requirements. CLIQUE identifies dense clusters in subspaces of maximum dimensionality. It generates cluster descriptions in the form of DNF expressions that are minimized for ease of comprehension. It produces identical results irrespective of the order in which input records are presented and does not presume any specific mathematical form for data distribution. Through experiments, we show that CLIQUE efficiently finds accurate clusters in large high dimensional datasets.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA; Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Ver Inc, Sunnyvale, CA 94089 USA	Agrawal, R (reprint author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.	ragrawal@almaden.ibm.com; johannes@cs.cornell.edu; dg@cs.ucr.edu; pragh@verity.com					Aggarwal C. C., 2000, P ACM SIGMOD INT C M, P70, DOI 10.1145/342009.335383; AGGRAWAL C, 1999, P 1999 ACM SIGMOD IN; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Arabie P., 1996, CLUSTERING CLASSIFIC, P5; BAYARDO R, 1998, P ACM SIGMOD C MAN D; Berchtold S., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263671; BERGER M, 1991, IEEE T SYST MAN CYB, V21, P1278, DOI 10.1109/21.120081; Brin S., 1997, P ACM SIGMOD C MAN D; Bronnimann H., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, DOI 10.1145/177424.178029; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHHIKARA RS, 1979, TECHNOMETRICS, V21, P531, DOI 10.2307/1268293; DOMENICONI C, 2004, SIAM INT C DAT MIN S; Duda R., 1973, PATTERN CLASSIFICATI; EARLE RJ, 1994, Patent No. [5359724, 05359724]; Ester M., 1996, P 2 INT C KNOWL DISC; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FEIGE U, 1976, P 28 ANN ACM S THEOR, P314; FRANZBLAU DS, 1984, P 6 ANN S THEOR COMP, P268; FRANZBLAU DS, 1989, SIAM J DISCRETE MATH, V2, P307, DOI 10.1137/0402027; FRIEDMAN J, 1997, UW MSR SUMMER RES I; Fukunaga K., 1990, INTRO STAT PATTERN R; Gunopulos D., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263684; HO CT, 1997, P ACM SIGMOD C MAN D; HONG SJ, 1987, SELECTED PAPERS LOGI; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kaufman L., 1990, FINDING GROUPS DATA; LIN DI, 1998, P 6 INT C EXT DAT TE; LOVASZ L, 1975, DISCRETE MATH, V13, P383, DOI 10.1016/0012-365X(75)90058-8; Lund C., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167172; MAEK W, 1978, THESIS MIT; Mehta M., 1996, P 5 INT C EXT DAT TE; MICHALSKI RS, 1983, MACHINE LEARNING AI, V1, P331; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; NG RT, 1994, P VLDB C SANT CHIL; PROCOPIUC CM, 2002, SIGMOD; Reckhow R.A., 1987, P ACM 3 ANN COMP GEO, P268, DOI 10.1145/41958.41987; Rissanen J, 1989, STOCHASTIC COMPLEXIT; SCHROETER P, 1995, PATTERN RECOGN, V28, P695, DOI 10.1016/0031-3203(94)00133-7; Shafer J., 1996, P 22 INT C VER LARG; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; SHOSHANI A, 1997, COMMUNICATION; Sneath P.H.A., 1973, NUMERICAL TAXONOMY; Soltan V., 1992, Proceedings of the Eighth Annual Symposium on Computational Geometry, DOI 10.1145/142675.142735; Srikant R, 1996, P ACM SIGMOD C MAN D; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Ullman J. D., 1974, DESIGN ANAL COMPUTER; WHARTON SW, 1983, PATTERN RECOGN, V16, P193, DOI 10.1016/0031-3203(83)90022-5; Xu X., 1995, P 1 INT C KNOWL DISC; Zait M, 1997, FUTURE GENER COMP SY, V13, P149, DOI 10.1016/S0167-739X(97)00018-6; ZHANG D, 1986, P 2 ANN ACM S COMP, P314; Zhang T., 1996, P ACM SIGMOD C MAN D; *ARB SOFTW CORP, APPL MAN US GUID ESS; *INT BUS MACH, 1996, IBM INT MIN US GUID	54	55	67	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2005	11	1					5	33		10.1007/s10618-005-1396-1		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	951LQ	WOS:000230932200001	
J	Becerra, VM; Galvao, RKH; Abou-Seada, M				Becerra, VM; Galvao, RKH; Abou-Seada, M			Neural and wavelet network models for financial distress classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						financial distress; neural networks; wavelets; finance; classification	DISCRIMINANT-ANALYSIS; ALGORITHM; SELECTION; FAILURE	This work analyzes the use of linear discriminant models, multi-layer perceptron neural networks and wavelet networks for corporate financial distress prediction. Although simple and easy to interpret, linear models require statistical assumptions that may be unrealistic. Neural networks are able to discriminate patterns that are not linearly separable, but the large number of parameters involved in a neural model often causes generalization problems. Wavelet networks are classification models that implement nonlinear discriminant surfaces as the superposition of dilated and translated versions of a single "mother wavelet" function. In this paper, an algorithm is proposed to select dilation and translation parameters that yield a wavelet network classifier with good parsimony characteristics. The models are compared in a case study involving failed and continuing British firms in the period 1997-2000. Problems associated with over-parameterized neural networks are illustrated and the Optimal Brain Damage pruning technique is employed to obtain a parsimonious neural model. The results, supported by a re-sampling study, show that both neural and wavelet networks may be a valid alternative to classical linear discriminant models.	Univ Reading, Dept Cybernet, Reading RG6 6AY, Berks, England; Inst Tecnol Aeronaut, Div Engn Eletron, BR-12228900 Sao Jose Dos Campos, SP, Brazil; Middlesex Univ, Sch Business, London NW4 4BT, England	Becerra, VM (reprint author), Univ Reading, Dept Cybernet, Reading RG6 6AY, Berks, England.	v.m.becerra@reading.ac.uk; kawakami@ele.ita.br; m.abou-seada@mdx.ac.uk	Galvao, Roberto/D-1985-2013				ALICI Y, 1996, NEURAL NETWORKS FINA; ALTMAN EI, 1994, J BANK FINANC, V18, P505, DOI 10.1016/0378-4266(94)90007-8; ALTMAN EI, 1968, J FINANC, V23, P4; Ash T., 1989, Connection Science, V1, DOI 10.1080/09540098908915647; BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171; BJORCK A, 1994, LINEAR ALGEBRA APPL, V197; Cannon M, 1995, NEUROCOMPUTING, V9, P293, DOI 10.1016/0925-2312(95)00036-1; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; COATS PK, 1993, FINANC MANAGE, V22, P142, DOI 10.2307/3665934; Cristianini N., 2004, KERNEL METHODS PATTE; DAUBECHIES I, 1992, 19 LECT WAVELETS; Ezekiel M, 1959, METHODS CORRELATION; Foster G., 1986, FINANCIAL STATEMENT; Galvao RKH, 2004, DATA MIN KNOWL DISC, V8, P151, DOI 10.1023/B:DAMI.0000015913.38787.b3; Galvão R K, 1999, Int J Neural Syst, V9, P167, DOI 10.1142/S0129065799000150; Gill P.E., 1981, PRACTICAL OPTIMIZATI; Gomm JB, 2000, IEEE T NEURAL NETWOR, V11, P306, DOI 10.1109/72.839002; Hassibi B., 1993, IEEE INT C NEUR NETW, P293, DOI 10.1109/ICNN.1993.298572; Haykin S., 1999, NEURAL NETWORKS COMP; SETIONO R, 1995, IEEE T NEURAL NETWOR, V6, P273, DOI 10.1109/72.363426; Kohonen Teuvo, 1995, SELF ORG MAPS; KUN YL, 1990, ADV NEURAL INFORMATI, P598; Lawson C. L., 1974, SOLVING LEAST SQUARE; Mao KZ, 2002, IEEE T NEURAL NETWOR, V13, P1211, DOI 10.1109/TNN.2002.1031953; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Morrison D. F., 1990, MULTIVARIATE STAT ME; Naes T, 2001, J CHEMOMETR, V15, P413; Norgaard M., 2000, 00E891 U DENM DEP AU; Odom M.D., 1990, INT JOINT C NEUR NET, V2, P163; Pedrycz W, 1998, IEEE T NEURAL NETWOR, V9, P601, DOI 10.1109/72.701174; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; Sherstinsky A, 1996, IEEE T NEURAL NETWOR, V7, P195, DOI 10.1109/72.478404; SZU HH, 1992, OPT ENG, V31, P1907, DOI 10.1117/12.59918; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Tam K.Y, 1990, APPL ARTIF INTELL, P265, DOI 10.1080/08839519008927951; Trigueiros D, 1996, ACCOUNTING BUSINESS, V26, P347; Tyree E. W, 1996, NEURAL NETWORKS FINA; WILSON RL, 1994, DECIS SUPPORT SYST, V11, P545, DOI 10.1016/0167-9236(94)90024-8; Yao X, 1999, P IEEE, V87, P1423; Zhang QH, 1997, IEEE T NEURAL NETWOR, V8, P227; ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591; *MATHW, 2004, STAT TOOLB US GUID V	42	13	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2005	11	1					35	55		10.1007/s10618-005-1360-0		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	951LQ	WOS:000230932200002	
J	Wang, K; Zhou, SQ; Yang, Q; Yeung, JMS				Wang, K; Zhou, SQ; Yang, Q; Yeung, JMS			Mining customer value: From association rules to direct marketing	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association rule; classification; direct marketing; regression		Direct marketing is a modern business activity with an aim to maximize the profit generated from marketing to a selected group of customers. A key to direct marketing is to select a subset of customers so as to maximize the profit return while minimizing the cost. Achieving this goal is difficult due to the extremely imbalanced data and the inverse correlation between the probability that a customer responds and the dollar amount generated by a response. We present a solution to this problem based on a creative use of association rules. Association rule mining searches for all rules above an interestingness threshold, as opposed to some rules in a heuristic-based search. Promising association rules are then selected based on the observed value of the customers they summarize. Selected association rules are used to build a model for predicting the value of a future customer. On the challenging KDD-CUP-98 dataset, this approach generates 41% more profit than the KDD-CUP winner and 35% more profit than the best result published thereafter, with 57.7% recall on responders and 78.0% recall on non-responders. The average profit per mail is 3.3 times that of the KDD-CUP winner.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Wang, K (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	wangk@cs.sfu.ca; szhoua@cs.sfu.ca; qyang@cs.ust.hk; yeung@cs.sfu.ca	WANG, Ke/H-6830-2013				Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bitran GR, 1996, MANAGE SCI, V42, P1364, DOI 10.1287/mnsc.42.9.1364; BRIJS T, 1999, P 5 ACM SIGKDD INT C; Bult JR, 1995, MARKET SCI, V14, P378, DOI 10.1287/mksc.14.4.378; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Clopper CJ, 1934, BIOMETRIKA, V26, P404, DOI 10.2307/2331986; Desarbo W. S., 1994, J DIRECT MARKETING, V8, P7, DOI 10.1002/dir.4000080304; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Domingos P., 1996, P 13 INT C MACH LEAR, P105; JOSHI MV, 2001, P ACM SIGMOD C SANT, P91, DOI 10.1145/375663.375673; Levin N., 1996, J DIRECT MARKETING, V10, P28, DOI 10.1002/(SICI)1522-7138(199622)10:3<28::AID-DIR3>3.3.CO;2-G; Lingjaerde O, 1998, ACTA PSYCHIAT SCAND, V98, P73, DOI 10.1111/j.1600-0447.1998.tb10045.x; MASAND B, 1996, P 2 INT C KNOWL DISC, P195; MICHALSKI RS, 1969, 5TH P INT S INF PROC, V3, P125; POTHARST R, 2002, NEURAL NETWORKS BUSI, P89; Quinlan J., 1983, MACHINE LEARNING ART, V1, P463; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rigoutsos I, 1998, BIOINFORMATICS, V14, P55, DOI 10.1093/bioinformatics/14.1.55; Savasere A, 1998, PROC INT CONF DATA, P494, DOI 10.1109/ICDE.1998.655812; TAN PN, 2000, 4 EUR C PRINC PRACT, P632; Wang K., 2002, P ACM SIGKDD, P652; WANG K, 2002, P EDBT, P70; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540; *KDD98, 1998, KDD CUP 98 RES; *KDD98, 1998, KDD CUP 98 DAT; *KDNUGGETS, 2001, KDNUGGETS POLL RES D	28	19	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2005	11	1					57	79		10.1007/s10618-005-1355-x		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	951LQ	WOS:000230932200003	
J	Wong, RCW; Fu, AWC; Wang, K				Wong, RCW; Fu, AWC; Wang, K			Data mining for inventory item selection with cross-selling considerations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining algorithm; cross-selling; item selection; association rule; quadratic programming; genetic algorithm		Association rule mining, studied for over ten years in the literature of data mining, aims to help enterprises with sophisticated decision making, but the resulting rules typically cannot be directly applied and require further processing. In this paper, we propose a method for actionable recommendations from itemset analysis and investigate an application of the concepts of association rules-maximal-profit item selection with cross-selling effect (MPIS). This problem is about choosing a subset of items which can give the maximal profit with the consideration of cross-selling effect. A simple approach to this problem is shown to be NP-hard. A new approach is proposed with consideration of the loss rule-a rule similar to the association rule-to model the cross-selling effect. We show that MPIS can be approximated by a quadratic programming problem. We also propose a greedy approach and a genetic algorithm to deal with this problem. Experiments are conducted, which show that our proposed approaches are highly effective and efficient.	Chinese Univ Hong Kong, Dept Comp Sci & Engn, Sha Tin 100083, Peoples R China; Simon Fraser Univ, Dept Comp Sci, Burnaby, BC V5A 1S6, Canada	Wong, RCW (reprint author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Sha Tin 100083, Peoples R China.	cwwong@cse.cuhk.edu.hk; adafu@cse.cuhk.edu.hk; wangk@cs.sfu.ca					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 2004, IBM SYNTHETIC DATA G; Agrawal R., 1994, P 20 INT C VER LARG, P487; Beasley J., 1998, HEURISTIC ALGORITHMS; BLISCHOK TJ, 1995, CHAIN STORE AGE EXEC, V71, P50; Brijs T., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347156; Brijs T, 1999, P 5 INT C KNOWL DISC, P254, DOI 10.1145/312129.312241; Campo K, 2003, INT J RES MARK, V20, P273, DOI 10.1016/S0167-8116(03)00037-5; Cavicchio Jr D. J., 1970, THESIS U MICHIGAN; Garey M. R., 1979, COMPUTERS INTRACTABI; GRUEN T, 2002, REATIL OUT OF STOCKS; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HEDBERG SR, 1995, BYTE             OCT, P83; HILLER, 2001, INTRO OPERATIONS RES; HOHENBALKEN B, 1975, MATH PROGRAMMING, V8; Horst R., 2000, INTRO GLOBAL OPTIMIZ; Hull J. C., 1997, OPTIONS FUTURES OTHE; Iasemidis LD, 2001, J COMB OPTIM, V5, P9, DOI 10.1023/A:1009877331765; Kleinberg J, 1998, DATA MIN KNOWL DISC, V2, P311, DOI 10.1023/A:1009726428407; KLEINBERG J, 1998, P ACM SIAM S DISCR A; KLEINBERG J. M., 1999, JACM, V46, P5; KOK AG, 2004, DEMAND ESTIMATION AS; Leon S, 1998, LINEAR ALGEBRA APPL; LUO J, 2001, P IEEE SYST MAN CYB, P3140; Mahfoud S. W., 1992, PARALLEL PROBLEM SOL, V2, P27; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; MANNILA H, 1997, P INT C DAT THEOR, P41; SAFRONOV V, 2002, WORLD WIDE WEB, V5, P165; Sahni S., 1974, SIAM Journal on Computing, V3, DOI 10.1137/0203021; SYSWERDA G, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P2; TAYLOR B, 2001, INTRO MANAGEMENT SCI, pCH16; ULLMAN J, 2003, LECT NOTES; Urban TL, 1998, J RETAILING, V74, P15, DOI 10.1016/S0022-4359(99)80086-4; Wang K., 2002, P ACM SIGKDD, P652; Wong R, 2003, P IEEE ICDM, P371	35	12	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2005	11	1					81	112		10.1007/s10618-005-1359-6		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	951LQ	WOS:000230932200004	
J	Girolami, M; Kaban, A				Girolami, M; Kaban, A			Sequential activity profiling: Latent dirichlet allocation of Markov chains	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Markov chains; mixture models; user profiling	MODELS	To provide a parsimonious generative representation of the sequential activity of a number of individuals within a population there is a necessary tradeoff between the definition of individual specific and global representations. A linear-time algorithm is proposed that defines a distributed predictive model for finite state symbolic sequences which represent the traces of the activity of a number of individuals within a group. The algorithm is based on a straightforward generalization of latent Dirichlet allocation to time-invariant Markov chains of arbitrary order. The modelling assumption made is that the possibly heterogeneous behavior of individuals may be represented by a relatively small number of simple and common behavioral traits which may interleave randomly according to an individual-specific distribution. The results of an empirical study on three different application domains indicate that this modelling approach provides an efficient low-complexity and intuitively interpretable representation scheme which is reflected by improved prediction performance over comparable models.	Univ Glasgow, Dept Comp Sci, Bioinformat Res Ctr, Glasgow G12 8QQ, Lanark, Scotland; Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England	Girolami, M (reprint author), Univ Glasgow, Dept Comp Sci, Bioinformat Res Ctr, Glasgow G12 8QQ, Lanark, Scotland.	girolami@dcs.gla.ac.uk; a.kaban@cs.bham.ac.uk					Anderson C.R., 2001, P 17 INT JOINT C ART, P879; ATTIAS H, 2001, P AI STAT; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BORGES J, 1999, DATA MINING USER NAV, P92; Cadez I, 2003, DATA MIN KNOWL DISC, V7, P399, DOI 10.1023/A:1024992613384; Cover T. M., 1991, ELEMENTS INFORMATION; DESHPANDE M, IN PRESS ACM T INTER; FRYDMAN H, 1984, J AM STAT ASSOC, V79, P632, DOI 10.2307/2288410; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; HOFMANN T, 2001, EUR C MACH LEARN, P214; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Lappalainen H, 2000, PERSP NEURAL COMP, P75; Lee DD, 2001, ADV NEUR IN, V13, P556; LINTON F, 2000, ED TECHNOLOGY SOC, P3; MANNILA H, 2001, 1 SIAM C DAT MIN; Manning C. D., 1999, FDN STAT NATURAL LAN; Minka T., 2002, P 18 C UNC ART INT; Mitchell T., 1996, MACHINE LEARNING; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAFTERY AE, 1985, J ROY STAT SOC B MET, V47, P528; Ronning G, 1989, J STAT COMPUT SIM, V32, P215, DOI 10.1080/00949658908811178; ROSS DA, 2003, ADV NEURAL INFORMATI, V15, P1017; Sarukkai RR, 2000, COMPUT NETW, V33, P377, DOI 10.1016/S1389-1286(00)00044-X; Saul L., 1997, P 2 C EMP METH NAT L, P81; Saul LK, 1999, MACH LEARN, V37, P75, DOI 10.1023/A:1007649326333; Tino P, 2001, MACH LEARN, V45, P187, DOI 10.1023/A:1010972803901	26	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2005	10	3					175	196		10.1007/s10618-005-0362-2		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	940VW	WOS:000230175000001	
J	Seno, M; Karypis, G				Seno, M; Karypis, G			Finding frequent patterns using length-decreasing support constraints	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						frequent pattern discovery; data-mining; association rules; scalability		Finding prevalent patterns in large amount of data has been one of the major problems in the area of data mining. Particularly, the problem of finding frequent itemset or sequential patterns in very large databases has been studied extensively over the years, and a variety of algorithms have been developed for each problem. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of these two problems. In general, patterns that contain only a few items will tend to be interesting if they have a high support, whereas long patterns can still be interesting even if their support is relatively small. Ideally, we want to find all the frequent patterns whose support decreases as a function of their length without having to find many uninteresting infrequent short patterns. Developing such algorithms is particularly challenging because the downward closure property of the constant support constraint cannot be used to prune short infrequent patterns. In this paper we present two algorithms, LPMiner and SLPMiner. Given a length-decreasing support constraint, LPMiner finds all the frequent itemset patterns from an itemset database, and SLPMiner finds all the frequent sequential patterns from a sequential database. Each of these two algorithms combines a well-studied efficient algorithm for constant-support-based pattern discovery with three effective database pruning methods that dramatically reduce the runtime. Our experimental evaluations show that both LPMiner and SLPMiner, by effectively exploiting the length-decreasing support constraint, are up to two orders of magnitude faster, and their runtime increases gradually as the average length of the input patterns increases.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Seno, M (reprint author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	seno@cs.umn.edu; karypis@cs.umn.edu					AGARWAL RC, 1998, RC21341 IBM; Agarwal R.C., 2000, KDD 00, P108; Agrawal R., 1994, P 20 INT C VER LARG; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; BRIN S, 1997, P 1997 ACM SIGMOD IN; COHEN E, 2000, ICDE, P489; Guralnik V., 2001, Euro-Par 2001 Parallel Processing. 7th International Euro-Par Conference. Proceedings (Lecture Notes in Computer Science Vol.2150); GUSFIELD D, 1993, B MATH BIOL, V55, P141, DOI 10.1007/BF02460299; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HAN J, 2002, IEEE INT C DAT MIN; KOHAVI R., 2000, SIGKDD EXPLORATIONS, V2, P86; KURAMOCHI M, 2003, PAFI PATTERN FINDING; LIN DI, 1998, P 6 INT C EXT DAT TE; LIU B, 1999, SIGKDD 1999; Mount D. M., 2001, BIOINFORMATICS SEQUE; MUELLER A, 1995, CSTR3515; Park J., 1995, P 4 INT C INF KNOWL; PARK JS, 1995, P 1995 ACM SIGMOD IN; PASQUIER N, 1999, 7 INT C DAT THEOR, P398; PEI J, 2000, P ACM SIGKDD INT C K; PEI J, 2000, P 2000 ACM SIGMOD IN; Pei J., 2001, ICDE, P215; Savasere A, 1995, P 21 INT C VER LARG, P432; Srikant R., 1996, P 5 INT C EXT DAT TE; SRIKANT R, 1995, 11 INT C DAT ENG; WANG K, 2000, VLDB, P43; YAN Z, 2003, SIAM DAT MIN C; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315; ZAKI MJ, 2001, 011 RPI; ZAKI MJ, 1997, 668 RENSS POL I DEP; Zaki M.J., 2000, 6 ACM SIGKDD INT C K, P34; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291; Zheng Z., 2001, P 7 ACM SIGKDD INT C, P401, DOI 10.1145/502512.502572	33	10	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2005	10	3					197	228		10.1007/s10618-005-0364-0		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	940VW	WOS:000230175000002	
J	Artail, HA				Artail, HA			HIL-Tree: A hierarchical structure for guiding search into test and measurement data archives	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						index trees; multilevel queries; discontinuity detection; data segmentation	POINTS; JUMP	This paper describes a novel algorithm that uses discontinuity detection to discover index vectors in test and measurement data archives containing multidimensional data. The index vectors are generated from individual data series in the archive and hold location information about jumps and changes in trends (discontinuities). They are related in a hierarchical manner to form a tree-like structure based on the alignment of the location information across the vectors. We call such trees Hierarchical Index Locations trees (HIL-trees), which are useful in guiding navigation into the raw data and in speeding up the process of retrieving data subsets based on given criteria. To demonstrate the practical value of the algorithm, we present a case study through which the algorithm is applied to real automotive emission test data archives, and show how it works. We also compare the HIL-tree to the well-known R-tree index structure and show how HIL-trees are advantageous in many aspects.	Amer Univ Beirut, Dept Elect & Comp Engn, Beirut 11072020, Lebanon	Artail, HA (reprint author), Amer Univ Beirut, Dept Elect & Comp Engn, Riad El Solh,POB 11-0236, Beirut 11072020, Lebanon.	hartail@aub.edu.lb					ARGE L, 2004, P ACM SIGMOD C; ARNING A, 1996, P KNOWL DISC DAT MIN; Artail HA, 2001, INTEGR COMPUT-AID E, V8, P119; Beckmann N., 1990, P ACM SIGMOD INT C M, V19, P322; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Bettini C, 1998, IEEE T KNOWL DATA EN, V10, P222, DOI 10.1109/69.683754; Chau T, 1999, IEEE T KNOWL DATA EN, V11, P833, DOI 10.1109/69.824592; Donoho D., 1993, P S APPL MATH, V47, P173; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Fawcett T., 1999, P 5 ACM SIGKDD INT C, P53, DOI 10.1145/312129.312195; Guttman A, 1984, ACM SIGMOD, V14, P47, DOI [10.1145/971697.602266, DOI 10.1145/971697.602266], DOI 10.1145/971697.602266]; HADJIELEFTHERIO.M, 1999, R TREE VISUALIZATION; Katayama N., 1997, P ACM SIGMOD INT C M, V26, P369; Keogh E., 2002, P 8 ACM SIGKDD INT C, P550; Keogh E.J., 2001, P IEEE INT C DAT MIN; Lin K.-I., 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; Mallat S., 1992, IEEE T PATTERN ANAL, V11, P674; MULLER HG, 1992, ANN STAT, V20, P737, DOI 10.1214/aos/1176348654; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Ogden RT, 1997, ESSENTIAL WAVELETS S; SHAHABI C, 2000, P SCI STAT DAT MAN C; Srivastava A, 1999, DATA MIN KNOWL DISC, V3, P237, DOI 10.1023/A:1009832825273; Strang G., 1996, WAVELETS FILTER BANK; WANG YZ, 1995, BIOMETRIKA, V82, P385; White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202; WU JS, 1993, ANN STAT, V21, P1545, DOI 10.1214/aos/1176349271; YI B, 2000, P VLDB C CAIR EG; YI B, 1998, P DAT ENG C ORL FL	28	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2005	10	3					229	250		10.1007/s10618-005-0388-5		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	940VW	WOS:000230175000003	
J	Aggarwal, CC; Han, JW; Wang, JY; Yu, PS				Aggarwal, CC; Han, JW; Wang, JY; Yu, PS			On high dimensional projected clustering of data streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						high dimensional; projected clustering; data streams		The data stream problem has been studied extensively in recent years, because of the great ease in collection of stream data. The nature of stream data makes it essential to use algorithms which require only one pass over the data. Recently, single-scan, stream analysis methods have been proposed in this context. However, a lot of stream data is high-dimensional in nature. High-dimensional data is inherently more complex in clustering, classification, and similarity search. Recent research discusses methods for projected clustering over high-dimensional data sets. This method is however difficult to generalize to data streams because of the complexity of the method and the large volume of the data streams. In this paper, we propose a new, high-dimensional, projected data stream clustering method, called HPStream. The method incorporates a fading cluster structure, and the projection based clustering methodology. It is incrementally updatable and is highly scalable on both the number of dimensions and the size of the data streams, and it achieves better clustering quality in comparison with the previous stream clustering methods. Our performance study with both real and synthetic data sets demonstrates the efficiency and effectiveness of our proposed framework and implementation methods.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Tsing Hua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; IBM Corp, Thomas J Watson Res Ctr, Hawthorne, NY USA	Aggarwal, CC (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY USA.	charu@us.ibm.com; hanj@cs.uiuc.edu; jianyong@cs.umn.edu; psyu@us.ibm.com	Yu, Philip/A-2815-2012				AGGARWAL C, 2003, VLDB C; Aggarwal C. C., 1999, ACM SIGMOD C; Aggarwal CC, 2004, IEEE T KNOWL DATA EN, V16, P448, DOI 10.1109/TKDE.2004.1269669; AGGARWAL CC, 2003, ACM SIGMOD C, P575; AGGARWAL CC, 2002, ICDE C; AGRAWAL R, 1998, ACM SIGMOD C; BABCOCK B, 2002, ACM PODS C; DOMINGOS P, 2000, ACM SIGKDD C; Farnstrom F, 2000, SIGKDD EXPLORATIONS, V2, P51; FEIGENBAUM J, 2000, ACM SODA C; Guha S., 1998, ACM SIGMOD C; GUHA S, 2000, IEEE FOCS C; Jain AK, 1998, ALGORITHMS CLUSTERIN; NG R, 1994, VER LARG DAT BAS C; OCALLAGHAN J, 2002, ICDE C; ZHANG T, 1996, ACM SIGMOD C	16	6	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2005	10	3					251	273		10.1007/s10618-005-0645-7		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	940VW	WOS:000230175000004	
J	Kao, B; Zhang, MH; Yip, CL; Cheung, DW				Kao, B; Zhang, MH; Yip, CL; Cheung, DW			Efficient algorithms for mining and incremental update of maximal frequent sequences	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; sequence; incremental update	DISCOVERED ASSOCIATION RULES; MAINTENANCE	We study two problems: (1) mining frequent sequences from a transactional database, and (2) incremental update of frequent sequences when the underlying database changes over time. We review existing sequence mining algorithms including GSP, PrefixSpan, SPADE, and ISM. We point out the large memory requirement of PrefixSpan, SPADE, and ISM, and evaluate the performance of GSP. We discuss the high I/O cost of GSP, particularly when the database contains long frequent sequences. To reduce the I/O requirement, we propose an algorithm MFS, which could be considered as a generalization of GSP. The general strategy of MFS is to first find an approximate solution to the set of frequent sequences and then perform successive refinement until the exact set of frequent sequences is obtained. We show that this successive refinement approach results in a significant improvement in I/O cost. We discuss how MFS can be applied to the incremental update problem. In particular, the result of a previous mining exercise can be used (by MFS) as a good initial approximate solution for the mining of an updated database. This results in an I/O efficient algorithm. To improve processing efficiency, we devise pruning techniques that, when coupled with GSP or MFS, result in algorithms that are both CPU and I/O efficient.	Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Kao, B (reprint author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	kao@cs.hku.hk; mhzhang@cs.hku.hk; clyip@cs.hku.hk; dcheung@cs.hku.hk					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AYAN NF, 1999, P 5 ACM SIGKDD INT C, P287, DOI 10.1145/312129.312252; Cheung D., 1996, P 2 INT C KNOWL DISC, P307; Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094; Cheung DW, 1997, P 5 INT C DAT SYST A, P185; Garofalakis MN, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P223; Lee SD, 1998, DATA MIN KNOWL DISC, V2, P233, DOI 10.1023/A:1009703019684; LEE SD, 1997, P 1997 ACM SIGMOD WO; OMIECINSKI E, 1998, P BRIT NAT C DAT, P49; Parthasarathy S, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P251, DOI 10.1145/319950.320010; PEL J, 2001, P 17 IEEE INT C DAT, P215; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Sarda N. L., 1998, Proceedings Ninth International Workshop on Database and Expert Systems Applications (Cat. No.98EX130), DOI 10.1109/DEXA.1998.707409; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; Thomas S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; WANG K., 1997, J INTELL INF SYST, V9, P33, DOI DOI 10.1023/A:1008689103430; ZAKI MJ, 2000, MACH LEARN, P31; ZHANG M, 2001, P IC AI 2001 LAS VEG, P497; Zhang M., 2002, P 6 PAC AS C KNOWL D, P186	20	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2005	10	2					87	116		10.1007/s10618-005-0268-z		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	924HV	WOS:000228970700001	
J	Aggarwal, CC				Aggarwal, CC			On the use of wavelet decomposition for string classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						strings; classification; wavelets		In recent years, the technological advances in mapping genes have made it increasingly easy to store and use a wide variety of biological data. Such data are usually in the form of very long strings for which it is difficult to determine the most relevant features for a classification task. For example, a typical DNA string may be millions of characters long, and there may be thousands of such strings in a database. In many cases, the classification behavior of the data may be hidden in the compositional behavior of certain segments of the string which cannot be easily determined apriori. Another problem which complicates the classification task is that in some cases the classification behavior is reflected in global be havior of the string, whereas in others it is reflected in local patterns. Given the enormous variation in the behavior of the strings over different data sets, it is useful to develop an approach which is sensitive to both the global and local behavior of the strings for the purpose of classification. For this purpose, we will exploit the multi-resolution property of wavelet decomposition in order to create a scheme which can mine classification characteristics at different levels of granularity. The resulting scheme turns out to be very effective in practice on a wide range of problems.	IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA	Aggarwal, CC (reprint author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.	charu@us.ibm.com					AGGARWAL CC, 2002, KDD C, P163; Agrawal R., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases; Agrawal R., 1994, VLDB, P487; Agrawal R, 1995, INT C DAT ENG, P3; Boggess A, 2001, 1 COURSE WAVELETS FO; Chui C. K., 1992, INTRO WAVELETS; DESHPANDE M, 2001, 0133 TR U MINN; DUDA R, 1973, PATTERN ANAL SCENE A; GEHRKE J, 1998, VLDB 98 NEW YORK NY, P416; GEHRKE J, 1999, ACM SIGKDD C TUR; Gehrke J, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P169; Guralnik V., 1999, KDD 99, P33; GURALNIK V, 2001, ICDM C, P179; Gusfield D., 1997, ALGORITHMS STRINGS T; HAN J, 1999, INT C DAT ENG, P106; JAGADISH HV, 2000, SIGMOD, P403; Jagadish H. V., 1999, Very Large Data Bases. Proceedings of the Twenty-Fifth International Conference on Very Large Data Bases; James M., 1985, CLASSIFICATION ALGOR; KEIM DA, 2001, WAVELETS THEIR APPL; Keogh E., 1998, KNOWLEDGE DISCOVERY, P239; KEOGH E, 1997, KDD 97, P24; KEOGH EJ, 2001, SCALING DYNAMIC TIME, P1; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; MANGANARIS S, 1995, TRCS9510 VAND U; OATES T, 1999, KDD C, P322; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Struzik Z. R., 1999, 3 EUR C PRINC KNOWL, P12; WU Y, 2002, ACM CIKM C, P488	28	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2005	10	2					117	139		10.1007/s10618-005-0306-x		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	924HV	WOS:000228970700002	
J	Zhao, Y; Karypis, G				Zhao, Y; Karypis, G			Hierarchical clustering algorithms for document datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						hierarchical clustering; criterion function; constrained agglomerative clustering; data mining		Fast and high-quality document clustering algorithms play an important role in providing intuitive navigation and browsing mechanisms by organizing large amounts of information into a small number of meaningful clusters. In particular, clustering algorithms that build meaningful hierarchies out of large document collections are ideal tools for their interactive visualization and exploration as they provide data-views that are consistent, predictable, and at different levels of granularity. This paper focuses on document clustering algorithms that build such hierarchical solutions and (i) presents a comprehensive study of partitional and agglomerative algorithms that use different criterion functions and merging schemes, and (ii) presents a new class of clustering algorithms called constrained agglomerative algorithms, which combine features from both partitional and agglomerative approaches that allows them to reduce the early-stage errors made by agglomerative methods and hence improve the quality of clustering solutions. The experimental evaluation shows that, contrary to the common belief, partitional algorithms always lead to better solutions than agglomerative algorithms; making them ideal for clustering large document collections due to not only their relatively low computational requirements, but also higher clustering quality. Furthermore, the constrained agglomerative methods consistently lead to better solutions than agglomerative methods alone and for many cases they outperform partitional methods, as well.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; Digital Technol Ctr, Minneapolis, MN 55455 USA; Army HPC Res Ctr, Minneapolis, MN 55455 USA	Zhao, Y (reprint author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	yzhao@cs.umn.edu; karypis@cs.umn.edu					Aggarwal C., 1999, P 5 ACM SIGKDD INT C, P352, DOI 10.1145/312129.312279; Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347176; Boley D, 1999, DECIS SUPPORT SYST, V27, P329, DOI 10.1016/S0167-9236(99)00055-X; Boley D, 1998, DATA MIN KNOWL DISC, V2, P325, DOI 10.1023/A:1009740529316; BOLEY D, 1999, AI REV, V11, P365; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHENG CK, 1991, IEEE T COMPUT AID D, V10, P1502, DOI 10.1109/43.103500; CUTTING DR, 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; Devore J., 1997, STAT EXPLORATION ANA; Dhillon I. S., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183895; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; DING C, 2001, LBNL47937 U CAL; Duda R.O., 2001, PATTERN CLASSIFICATI; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Hagen L., 1991, P IEEE INT C COMP AI, P10; Han E.-H., 1998, P 2 INT C AUT AG, P408, DOI 10.1145/280765.280872; Han E.-H., 1998, B TECHNICAL COMMITTE, V21, P15; Jain A.K., 1988, ALGORITHMS CLUSTERIN; KARYPIS G, 1999, IEEE COMPUT, V32, P68, DOI DOI 10.1109/2.781637; Karypis G., 2002, 02017 U MINN DEP COM; King B., 1967, J AM STAT ASSOC, V69, P86; Kohavi R., 1995, P 1 INT C KNOWL DISC, P192; Larsen B, 1999, P 5 ACM SIGKDD INT C, DOI 10.1145/312129.312186; LEOUSKI A, 1996, IR76 U MASS DEP COMP; Lewis D. D., 1999, REUTERS 21578 TEXT C; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Moore J., 1997, 7 WORKSH INF TECHN S; Ng R, 1994, P 20 INT C VER LARG, P144; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Puzicha J, 2000, PATTERN RECOGN, V33, P617, DOI 10.1016/S0031-3203(99)00076-X; Salton G., 1989, AUTOMATIC TEXT PROCE; SAVARESI S, 2001, 1 SIAM INT C DAT MIN; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Sneath P.H.A., 1973, NUMERICAL TAXONOMY; Steinbach M, 2000, KDD WORKSH TEXT MIN; Strehl A., 2000, P 17 INT C HIGH PERF, P525; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zha H., 2001, CIKM 01, P25; ZHANG B, 1999, HPL1999119; Zhao Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6; 1999, TEXT RETRIEVAL C	46	98	105	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2005	10	2					141	168		10.1007/s10618-005-0361-3		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	924HV	WOS:000228970700003	
J	Ezeife, CI; Lu, Y				Ezeife, CI; Lu, Y			Mining web log sequential patterns with position coded pre-order linked WAP-tree	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						sequential patterns; Web usage mining; WAP-tree mining; pre-order linkage; position codes; apriori techniques		Sequential mining is the process of applying data mining techniques to a sequential database for the purposes of discovering the correlation relationships that exist among an ordered list of events. An important application of sequential mining techniques is web usage mining, for mining web log accesses, where the sequences of web page accesses made by different web users over a period of time, through a server, are recorded. Web access pattern tree (WAP-tree) mining is a sequential pattern mining technique for web log access sequences, which first stores the original web access sequence database on a prefix tree, similar to the frequent pattern tree (FP-tree) for storing non-sequential data. WAP-tree algorithm then, mines the frequent sequences from the WAP-tree by recursively re-constructing intermediate trees, starting with suffix sequences and ending with prefix sequences. This paper proposes a more efficient approach for using the WAP-tree to mine frequent sequences, which totally eliminates the need to engage in numerous re-construction of intermediate WAP-trees during mining. The proposed algorithm builds the frequent header node links of the original WAP-tree in a pre-order fashion and uses the position code of each node to identify the ancestor/descendant relationships between nodes of the tree. It then, finds each frequent sequential pattern, through progressive prefix sequence search, starting with its first prefix subsequence event. Experiments show huge performance gain over the WAP-tree technique.	Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada	Ezeife, CI (reprint author), Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.	cezeife@uwindsor.ca					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Berendt B, 2000, VLDB J, V9, P56, DOI 10.1007/s007780050083; Borges J., 1999, P WORKSH WEB US AN U, P31; Etzioni O, 1996, COMMUN ACM, V39, P65, DOI 10.1145/240455.240473; Han J., 2000, P 6 ACM SIGKDD INT C, P355, DOI 10.1145/347090.347167; Han J., 2000, DATA MINING CONCEPTS; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Madria S. K., 1999, P 1 INT C DAT WAR KN, P303; MANNILA M, 1995, 1 INT C KNOWL DISC D, P144; Masseglia F, 1998, LECT NOTES ARTIF INT, V1510, P176; Masseglia F., 1999, NETWORKING INFORMATI, V2, P571; Nanopoulos A, 2001, DATA KNOWL ENG, V37, P243, DOI 10.1016/S0169-023X(01)00008-8; Park JS, 1997, IEEE T KNOWL DATA EN, V9, P813; Pei J, 2001, PROC INT CONF DATA, P215; PEI J, 2000, P PAC AS C KNOWL DIS; Shaffer C. A., 2000, PRACTICAL INTRO DATA; SPILIOPOULOU M, 1999, SPECIAL ISSUE SEMANT, V14, P113; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1	20	29	33	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2005	10	1					5	38		10.1007/s10618-005-0248-3		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	899YV	WOS:000227182600001	
J	Webb, GI; Zhang, SM				Webb, GI; Zhang, SM			K-optimal rule discovery	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						exploratory rule discovery; association rules; classification rules; rule search; search space pruning	SEARCH	K-optimal rule discovery finds the k rules that optimize a user-specified measure of rule value with respect to a set of sample data and user-specified constraints. This approach avoids many limitations of the frequent itemset approach of association rule discovery. This paper presents a scalable algorithm applicable to a wide range of k-optimal rule discovery tasks and demonstrates its efficiency.	Monash Univ, Sch Comp Sci & Software Engn, Melbourne, Vic 3800, Australia; US Natl Lib Med, LHC CgSB, NIH, Bethesda, MD 20894 USA	Webb, GI (reprint author), Monash Univ, Sch Comp Sci & Software Engn, POB 75, Melbourne, Vic 3800, Australia.	webb@infotech.monash.edu.au; szhang@nlm.nih.gov	Webb, Geoffrey/A-1347-2008				Agarwal R. C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347114; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; BAY SD, 2001, UCI KDD ARCH; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; BLAKE C, 2001, UCI REPOSITORY MACHI; BORGELT C, 2000, APRIORI; BUCHANAN BG, 1978, ARTIF INTELL, V11, P5, DOI 10.1016/0004-3702(78)90010-3; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; CLEARWATER SH, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P24, DOI 10.1109/TAI.1990.130305; Cohen E., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839448; Cohen W., 1995, P 12 INT C MACH LEAR, P115; HAN J, P 2000 ACM SIGMOD IN, P1; KOHAVI R, 2000, KDD CUP 2000 ORG REP, V2, P86; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Ma Y., 1999, P 5 ACM SIGKDD INT C, P337, DOI 10.1145/312129.312274; MICHALSKI RS, 1977, P 1975 INT S MULT VA, P76; Morishita S, 2000, LECT NOTES ARTIF INT, V1759, P127, DOI 10.1007/3-540-46502-2_6; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J., 2000, P ACM SIGMOD WORKSH, P21; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; PROVOST F, 1999, 99012 IS STERN SCHOO; Rymon R., 1992, P KR 92, P268; Savasere A, 1995, P 21 INT C VER LARG, P432; SEGAL R, 1994, AAAI 94; Todorovski L., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Webb GI, 1995, J ARTIF INTELL RES, V3, P431; Webb G. I., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347112; Zaki M. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347101; Zheng Z., 2001, P 7 ACM SIGKDD INT C, P401, DOI 10.1145/502512.502572	34	44	44	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2005	10	1					39	79		10.1007/s10618-005-0255-4		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	899YV	WOS:000227182600002	
J	Zaki, MJ				Zaki, MJ			Mining non-redundant association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association rule mining; frequent closed itemsets; formal concept analysis	LATTICES	The traditional association rule mining framework produces many redundant rules. The extent of redundancy is a lot larger than previously suspected. We present a new framework for associations based on the concept of closed frequent itemsets. The number of non-redundant rules produced by the new approach is exponentially (in the length of the longest frequent itemset) smaller than the rule set from the traditional approach. Experiments using several "hard" as well as "easy" real and synthetic databases confirm the utility of our framework in terms of reduction in the number of rules presented to the user, and in terms of time.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Zaki, MJ (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.	zaki@cs.rpi.edu					Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; BASTIDE Y, 2000, SIGKDD EXPLORATIONS, V2; BASTIDE Y, 2000, 1 INT C COMP LOG; Bayardo Jr Roberto J., 1998, ACM SIGMOD C MAN DAT; BAYARDO RJ, 1999, 5 ACM SIGKDD INT C K; Brin Sergey, 1997, ACM SIGMOD C MAN DAT; BURDICK D, 2001, INT C DAT ENG; Davey B. A., 1990, INTRO LATTICES ORDER; Ganter B., 1999, FORMAL CONCEPT ANAL; GODIN R, 1995, COMPUT INTELL, V11, P246, DOI 10.1111/j.1467-8640.1995.tb00031.x; Guigues J.-L, 1986, MATH SCI HUMAINES, V95, P5; Klemettinen M., 1994, 3 INT C INF KNOWL MA, P401; LIN D, 1998, 6 INT C EXT DAT TECH; LIU B, 1999, 5 ACM SIGKDD INT C K; Luxenburger M., 1991, MATH INFORMATIQUE SC, V29, P35; NG RT, 1998, ACM SIGMOD INT C MAN; PASQUIER N, 1999, 7 INT C DAT THEOR; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; PEI J, 2000, SIGMOD INT WORKSH DA; TAOUIL R, 2000, 16 IEEE INT C DAT EN; TOIVONEN H, 1995, MLNET WKSHP STAT MAC; Zaki M., 1998, 3 ACM SIGMOD WORKSH; Zaki M. J., 2002, 2 SIAM INT C DAT MIN; Zaki M. J., 1997, 3 INT C KNOWL DISC D; ZAKI MJ, 2003, 034 RENSS POL I COMP	25	116	120	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2004	9	3					223	248		10.1023/B:DAMI.0000040429.96086.c7		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	865AY	WOS:000224676100001	
J	Liu, GM; Lu, HJ; Lou, WW				Liu, GM; Lu, HJ; Lou, WW			Efficient mining of frequent patterns using ascending frequency ordered prefix-tree	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						frequent pattern; frequent itemset; association rule		Mining frequent patterns, including mining frequent closed patterns or maximal patterns, is a fundamental and important problem in data mining area. Many algorithms adopt the pattern growth approach, which is shown to be superior to the candidate generate-and-test approach, especially when long patterns exist in the datasets. In this paper, we identify the key factors that influence the performance of the pattern growth approach, and optimize them to further improve the performance. Our algorithm uses a simple while compact data structure-ascending frequency ordered prefix-tree (AFOPT) to store the conditional databases, in which we use arrays to store single branches to further save space. The AFOPT structure is traversed in top-down depth-first order. Our analysis and experiment results show that the combination of the top-down traversal strategy and the ascending frequency order achieves significant performance improvement over previous works.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China	Liu, GM (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	cslgm@cs.ust.hk; luhj@cs.ust.hk; wwlou@cs.ust.hk					AGARWAL R, 2001, J PARALLEL DISTRIBUT; Agarwal R., 1994, P 20 VLDB C; Agarwal R. C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347114; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Burdick D, 2001, PROC INT CONF DATA, P443, DOI 10.1109/ICDE.2001.914857; Gouda K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989514; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J., 2000, ACM SIGMOD WORKSH RE, P21; Liu J, 2002, P 8 ACM SIGKDD INT C, P229; Meretakis D., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354768; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J, 2001, P IEEE INT C DAT MIN, P441; RAYMON R, 1992, P INT C PRINC KNOWL; Savasere A, 1995, P 21 INT C VER LARG, P432; Srikant R., 1993, P ACM SIGMOD C MAN D, P207, DOI DOI 10.1145/170035.170072; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zaki M.J., 2002, P 2 SIAM INT C DAT M; Zheng Z., 2001, P 7 ACM SIGKDD INT C, P401, DOI 10.1145/502512.502572	20	21	26	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2004	9	3					249	274		10.1023/B:DAMI.0000040905.52966.1a		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	865AY	WOS:000224676100002	
J	Grohman, W				Grohman, W			Using convex sets for exploratory data analysis and visualization	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data visualization; pattern recognition; pattern classification; neural networks	NEURAL NETWORKS	In this paper a new, abstract method for analysis and visualization of multidimensional data sets in pattern recognition problems is introduced. It can be used to determine the properties of an unknown, complex data set and to assist in finding the most appropriate recognition algorithm. Additionally, it can be employed to design layers of a feedforward artificial neural network or to visualize the higher-dimensional problems in 2-D and 3-D without losing relevant data set information. The method is derived from the convex set theory and works by considering convex subsets within the data and analyzing their respective positions in the original dimension. Its ability to describe certain set features that cannot be explicitly projected into lower dimensions sets it apart from many other visualization techniques. Two classical multidimensional problems are analyzed and the results show the usefulness of the presented method and underline its strengths and weaknesses.	Wavecrest Labs, Dulles, VA USA	Grohman, W (reprint author), Wavecrest Labs, Dulles, VA USA.						BENTLEY JL, 1980, APPROXIMATION ALGORI, P64; CESTNIK G, 1987, PROGR MACHINE LEARNI, V1, P31; Cios KJ, 1995, KYBERNETES, V24, P24, DOI 10.1108/03684929510147029; CLARK P, 1987, PROGR MACHINE LEARNI, P11; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Duda R., 1973, PATTERN CLASSIFICATI; FAHLMAN SE, 1990, ADV NEURAL INFORMATI, V2; Fausett L. V., 1994, FUNDAMENTALS NEURAL; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1972, INTRO STAT PATTERN R; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; GROHMAN W, 1999, THESIS U TOLEDO; Grohman WM, 2001, PATTERN RECOGN, V34, P1469, DOI 10.1016/S0031-3203(00)00085-6; Hiriart-Urruty J.-B., 1993, CONVEX ANAL MINIMIZA; Hoaglin DC, 1985, EXPLORING DATA TABLE; KLEE VICTOR, 1966, P IBM SCI COMP S COM, P123; Leung Y, 1997, IEEE T NEURAL NETWOR, V8, P601; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MIRCHANDANI G, 1989, IEEE T CIRCUITS SYST, V36; Nadal J.-P., 1989, International Journal of Neural Systems, V1, DOI 10.1142/S0129065789000463; NILSSON N. J., 1990, MATH FDN LEARNING MA; Preparata FP, 1985, COMPUTATIONAL GEOMET; Sirat JA, 1990, NETWORK-COMP NEURAL, V1, P423, DOI 10.1088/0954-898X/1/4/003; STRANG G, 1988, LINEAR ALGEBRA ITS A; TAN M, 1988, P 5 INT C MACH LEARN, P121; Tukey J.W., 1977, EXPLORATORY DATA ANA; Valentine FA, 1964, CONVEX SETS; ZURADA J M, 1992, INTRO ARTIFICIAL NEU	28	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2004	9	3					275	295		10.1023/B:DAMI.0000040906.82842.b5		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	865AY	WOS:000224676100003	
J	Aggarwal, CC				Aggarwal, CC			On leveraging user access patterns for topic specific crawling	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						world wide web; crawling; querying		In recent years, there has been considerable research on constructing crawlers which find resources satisfying specific conditions called predicates. Such a predicate could be a keyword query, a topical query, or some arbitrary contraint on the internal structure of the web page. Several techniques such as focussed crawling and intelligent crawling have recently been proposed for performing the topic specific resource discovery process. All these crawlers are linkage based, since they use the hyperlink behavior in order to perform resource discovery. Recent studies have shown that the topical correlations in hyperlinks are quite noisy and may not always show the consistency necessary for a reliable resource discovery process. In this paper, we will approach the problem of resource discovery from an entirely different perspective; we will mine the significant browsing patterns of world wide web users in order to model the likelihood of web pages belonging to a specified predicate. This user behavior can be mined from the freely available traces of large public domain proxies on the world wide web. For example, proxy caches such as Squid are hierarchical proxies which make their logs publically available. As we shall see in this paper, such traces are a rich source of information which can be mined in order to find the users that are most relevant to the topic of a given crawl. We refer to this technique as collaborative crawling because it mines the collective user experiences in order to find topical resources. Such a strategy turns out to be extremely effective because the topical consistency in world wide web browsing patterns turns out to very high compared to the noisy linkage information. In addition, the user-centered crawling system can be combined with linkage based systems to create an overall system which works more effectively than a system based purely on either user behavior or hyperlinks.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Aggarwal, CC (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	charu@us.ibm.com					AGGARWAL CC, 1999, P ACM SIGKDD C; AGGARWAL CC, 2002, P KDD C; AGGARWAL CC, 2001, P WWW C; BARYOSSEF Z, 2000, P VLDB C; BHARAT K, 1998, P ACM SIGIR C; CARRIERE J, P WORLD WID WEB C, P701; CHAKRABARTI S, 1999, P VLDB C; CHAKRABARTI S, 1998, 7 WORLD WID WEB C, V30; Chakrabarti S, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL WORLD WIDE WEB CONFERENCE, P545; CHAKRABARTI S, 2001, P WWW C; Chakrabarti S, 1999, COMPUTER, V32, P60, DOI 10.1109/2.781636; CHEN MS, 1996, ICDCS C; CHO J, 2000, P VLDB C; DILIGENTI M, 2000, P VLDB C; DING J, 2000, P VLDB C; EDWARDS J, 2001, P WORLD WID WEB C; KLEINBERG J, 1998, P ACM SIAM S DISCR A; KUMAR R, 1999, P WORLD WID WEB C; LEMPEL R, 2000, WWW9 C, P387; MUKHERJEA S, 2000, P WORLD WID WEB C; NAJORK M, 2001, P WORLD WID WEB C; RAGHAVAN S, 2001, P VLDB C; ROUSSKOV A, PERFORMANCE CACHING; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; SRIKANT R, 2001, ACM KDD C	25	3	3	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2004	9	2					123	145		10.1023/B:DAMI.0000031633.76754.d3		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	828FX	WOS:000221960300001	
J	Demiriz, A				Demiriz, A			Enhancing product recommender systems on sparse binary data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						recommender systems; association mining; dependency networks; e-commerce; collaborative filtering; customer relationship management		Commercial recommender systems use various data mining techniques to make appropriate recommendations to users during online, real-time sessions. Published algorithms focus more on the discrete user ratings instead of binary results, which hampers their predictive capabilities when usage data is sparse. The system proposed in this paper, e-VZpro, is an association mining-based recommender tool designed to overcome these problems through a two-phase approach. In the first phase, batches of customer historical data are analyzed through association mining in order to determine the association rules for the second phase. During the second phase, a scoring algorithm is used to rank the recommendations online for the customer. The second phase differs from the traditional approach and an empirical comparison between the methods used in e-VZpro and other collaborative filtering methods including dependency networks, item-based, and association mining is provided in this paper. This comparison evaluates the algorithms used in each of the above methods using two internal customer datasets and a benchmark dataset. The results of this comparison clearly show that e-VZpro performs well compared to dependency networks and association mining. In general, item-based algorithms with cosine similarity measures have the best performance.	Verizon Inc, Informat Technol, Irving, TX 75038 USA	Demiriz, A (reprint author), Verizon Inc, Informat Technol, 919 Hidden Ridge, Irving, TX 75038 USA.	ayhan.demiriz@verizon.com					Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; BILLSUS D, 1998, P 1998 WORKSH REC SY; Breese JS, 1998, P 14 C UNC ART INT, P43; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Heckerman D, 2000, J MACHINE LEARNING R, V1, P49; Hettich S., 1999, UCI KDD ARCH; Karypis G., 2001, P 10 INT C INF KNOWL; Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126; PENNOCK D. M., 2000, P 16 C UNC ART INT S, P473; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Rucker J, 1997, COMMUN ACM, V40, P73, DOI 10.1145/245108.245125; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; SARWAR BM, 2000, P 2 ACM E COMM C EC; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; UNGAR LH, 1998, P 1998 WORKSH REC SY; *MICR CORP, 2000, INTRO OL DB DAT MIN	16	14	15	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2004	9	2					147	170		10.1023/B:DAMI.0000031629.31935.ac		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	828FX	WOS:000221960300002	
J	Limas, MC; Mere, JBO; Ascacibar, FJMD; Gonzalez, EPV				Limas, MC; Mere, JBO; Ascacibar, FJMD; Gonzalez, EPV			Outlier detection and data cleaning in multivariate non-normal samples: The PAELLA algorithm	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						outlier; multivariate; non-normal; data cleaning; EM algorithm; cluster analysis; mixture model	CLUSTER-ANALYSIS; ROBUST ESTIMATION; REGRESSION; NUMBER	A new method of outlier detection and data cleaning for both normal and non-normal multivariate data sets is proposed. It is based on an iterated local fit without a priori metric assumptions. We propose a new approach supported by finite mixture clustering which provides good results with large data sets. A multi-step structure, consisting of three phases, is developed. The importance of outlier detection in industrial modeling for open-loop control prediction is also described. The described algorithm gives good results both in simulations runs with artificial data sets and with experimental data sets recorded in a rubber factory. Finally, some discussion about this methodology is exposed.	Univ Leon, Dept Ingn Elect, E-24071 Leon, Spain; Univ La Rioja, Dept Ingn Mecan, Logrono, Spain	Limas, MC (reprint author), Univ Leon, Dept Ingn Elect, E-24071 Leon, Spain.	joaquin.ordieres@dim.unirioja.es	Castejon Limas, Manuel/B-4456-2009; ordieres, joaquin/B-9677-2011; Martinez-De-Pison, F.J./H-1502-2012	ordieres, joaquin/0000-0002-9677-6764; Martinez-De-Pison, F.J./0000-0002-3063-7374			BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Billor N, 2000, COMPUT STAT DATA AN, V34, P279, DOI 10.1016/S0167-9473(99)00101-2; BILMES JA, 1998, GENTLE TUTORIAL EM A; BRADLEY PS, 1999, MSRTR9835; Campbell N. A., 1980, Applied Statistics, V29, DOI 10.2307/2346896; Coleman D, 1999, COMPUT STAT DATA AN, V31, P1, DOI 10.1016/S0167-9473(99)00009-2; Cuevas A, 2001, COMPUT STAT DATA AN, V36, P441, DOI 10.1016/S0167-9473(00)00052-9; Cuevas A, 2000, CAN J STAT, V28, P367, DOI 10.2307/3315985; DEAMORIM SG, 1992, J CLASSIF, V9, P17; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DEVEAUX RD, 1990, STAT PROBABIL LETT, V10, P1, DOI 10.1016/0167-7152(90)90104-F; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Fraley C, 1999, J CLASSIF, V16, P297, DOI 10.1007/s003579900058; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; GALLEGOS MT, 2000, MIP0013 U PASS FM IN; Hardy A, 1996, COMPUT STAT DATA AN, V23, P83, DOI 10.1016/S0167-9473(96)00022-9; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hawkins D., 1980, IDENTIFICATIONS OUTL; Ihaka R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; LIMAS MC, 2001, CONTROL CALIDAD METO; MARKATOU M, 1998, MIXTURE MODELS ROBUS; McLachlan G. J., 1998, LECT NOTES COMPUTER, V1451, P658; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; MCLACHLAN GJ, 1988, STATISTICIAN, V37, P417, DOI 10.2307/2348768; MCLACHLAN GJ, 2000, P AM STAT ASS BAYES; MULLER D, 1991, FRONTIERS STAT SCI T, V26, P355; Rocke DM, 1996, J AM STAT ASSOC, V91, P1047, DOI 10.2307/2291724; Rocke DM, 1997, J STAT PLAN INFER, V57, P245, DOI 10.1016/S0378-3758(96)00047-X; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Srivastava MS, 1998, J MULTIVARIATE ANAL, V65, P195, DOI 10.1006/jmva.1997.1729; STANFORD D, 1997, 317 U WASH DEP STAT; THIESSON B, 2000, MSRTR9931; Wang X. Z., 1999, DATA MINING KNOWLEDG	33	4	4	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2004	9	2					171	187		10.1023/B:DAMI.0000031630.50685.7c		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	828FX	WOS:000221960300003	
J	Yang, J; Wang, W; Yu, PS				Yang, J; Wang, W; Yu, PS			Mining surprising periodic patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						sequential patterns; statistical significant patterns	EFFICIENT ALGORITHM; SEQUENTIAL PATTERNS; TIME SEQUENCES; DISCOVERY	In this paper, we focus on mining surprising periodic patterns in a sequence of events. In many applications, e. g., computational biology, an infrequent pattern is still considered very significant if its actual occurrence frequency exceeds the prior expectation by a large margin. The traditional metric, such as support, is not necessarily the ideal model to measure this kind of surprising patterns because it treats all patterns equally in the sense that every occurrence carries the same weight towards the assessment of the significance of a pattern regardless of the probability of occurrence. A more suitable measurement, information, is introduced to naturally value the degree of surprise of each occurrence of a pattern as a continuous and monotonically decreasing function of its probability of occurrence. This would allow patterns with vastly different occurrence probabilities to be handled seamlessly. As the accumulated degree of surprise of all repetitions of a pattern, the concept of information gain is proposed to measure the overall degree of surprise of the pattern within a data sequence. The bounded information gain property is identified to tackle the predicament caused by the violation of the downward closure property by the information gain measure and in turn provides an efficient solution to this problem. Furthermore, the user has a choice between specifying a minimum information gain threshold and choosing the number of surprising patterns wanted. Empirical tests demonstrate the efficiency and the usefulness of the proposed model.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA; IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Yang, J (reprint author), Univ Illinois, Dept Comp Sci, 201 N Goodwin Ave, Urbana, IL 61801 USA.	jioyang@cs.uiuc.edu; weiwang@cs.unc.edu; psyu@us.ibm.com	Yu, Philip/A-2815-2012				AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; BERGER G, 1998, LECT NOTES COMPUTER, V1399, P281; Berndt D. J., 1996, ADV KNOWLEDGE DISCOV, P229; Bettini C, 1998, IEEE T KNOWL DATA EN, V10, P222, DOI 10.1109/69.683754; Blahut Richard E, 1987, PRINCIPLES PRACTICE; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; CALIFANO A, 1999, ANAL GENE EXPRESSION; Chakrabarti S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Cohen E., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839448; Das G, 1997, LECT NOTES ARTIF INT, V1263, P88; Das G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Fayyad U., 1996, P 2 INT C KNOWL DISC, P351; Feldman R., 1997, P ACM SIGMOD WORKSH, P59; Fujiwara S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839449; Garofalakis MN, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P223; Ge X., 2000, P 6 ACM SIGKDD INT C, P81, DOI 10.1145/347090.347109; GUNOPULOS G, 1997, P 6 INT C DAT THEOR, P215; Guralnik V, 1999, P 5 ACM SIGKDD INT C, P33, DOI 10.1145/312129.312190; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J, 1998, P 4 INT C KNOWL DISC, P214; HAN J, 2000, P INT C KNOWL DISC D; Han JW, 1999, PROC INT CONF DATA, P106; Huhtala Y, 1999, COMPUT J, V42, P100, DOI 10.1093/comjnl/42.2.100; Keogh E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; KLEMETINEN M, 1994, P CIKM; LIU B, 2000, P 6 ACM SIGKDD INT C, P208, DOI 10.1145/347090.347128; Liu B., 1999, P 5 ACM SIGKDD INT C, P125, DOI 10.1145/312129.312216; Ma Y., 1999, P 5 ACM SIGKDD INT C, P337, DOI 10.1145/312129.312274; Mannila H., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347122; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; MANNILA H, 1999, P 5 ACM SIGKDD INT C, P357, DOI 10.1145/312129.312281; Oates T., 1999, P 5 INT C KNOWL DISC, P322, DOI 10.1145/312129.312268; Oates T., 1999, P 16 IJCAI, P794; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; Padmanabhan B., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347103; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J., 2000, P ACM SIGMOD WORKSH, P21; Pei J, 2001, PROC INT CONF DATA, P215; Piatetsky-Shapiro G., 1994, P AAAI 94 WORKSH KNO, P25; Guralnik V., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; QU Y, 1998, P ACM CIKM, P251, DOI 10.1145/288627.288664; Rafiei D, 1999, PROC INT CONF DATA, P410, DOI 10.1109/ICDE.1999.754957; Ramaswamy S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Zaki M. J., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354849; Sahar S, 1999, P 5 ACM SIGKDD INT C, P332, DOI 10.1145/312129.312272; Shah D., 1999, P ACM SIGMOD WORKSH; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Spiliopoulou M, 1999, LECT NOTES ARTIF INT, V1704, P554; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; THOMAS S, 4 INT C KNOWL DISC D, P344; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; WANG K, 2000, P INT C VER LARG DAT; YANG J, 2000, P ACM SIGKDD INT C K, P275, DOI 10.1145/347090.347150; Yi BK, 1998, PROC INT CONF DATA, P201; Zaki M. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347101; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315	59	6	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2004	9	2					189	216		10.1023/B:DAMI.0000031631.84034.af		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	828FX	WOS:000221960300004	
J	Loh, WK; Kim, SW; Whang, KY				Loh, WK; Kim, SW; Whang, KY			A subsequence matching algorithm that supports normalization transform in time-series databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						subsequence matching; normalization transform; index interpolation; time-series databases		In this paper, an algorithm is proposed for subsequence matching that supports normalization transform in time-series databases. Normalization transform enables finding sequences with similar fluctuation patterns even though they are not close to each other before the normalization transform. Simple application of existing subsequence matching algorithms to support normalization transform is not feasible since the algorithms do not have information for normalization transform of subsequences of arbitrary lengths. Application of the existing whole matching algorithm supporting normalization transform to the subsequence matching is feasible, but requires an index for every possible length of the query sequence causing serious overhead on both storage space and update time. The proposed algorithm generates indexes only for a small number of different lengths of query sequences. For subsequence matching it selects the most appropriate index among them. Better search performance can be obtained by using more indexes. In this paper, the approach is called index interpolation. It is formally proved that the proposed algorithm does not cause false dismissal. The search performance can be traded off with storage space by adjusting the number of indexes. For performance evaluation, a series of experiments is conducted using the indexes for only five different lengths out of lengths 256similar to512 of the query sequence. The results show that the proposed algorithm outperforms the sequential scan by up to 2.4 times on the average when the selectivity of the query is 10(-2) and up to 14.6 times when it is 10(-5). Since the proposed algorithm performs better with smaller selectivities, it is suitable for practical situations, where the queries with smaller selectivities are much more frequent.	Korea Adv Inst Sci & Technol, Dept Comp Sci, Seoul, South Korea; Korea Adv Inst Sci & Technol, Adv Informat Technol Res Ctr, Seoul, South Korea; Hanyang Univ, Coll Informat & Commun, Seoul, South Korea		wkloh@tmax.co.kr; wook@ihanyang.ac.kr; kywhang@mozart.kaist.ac.kr	Whang, Kyu-Young/C-2009-2011				Agrawal R., 1995, P 21 INT C VER LARG, P490; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Chan KP, 1999, PROC INT CONF DATA, P126; Chatfield C., 1984, ANAL TIME SERIES INT; Chu K. K. W., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, DOI 10.1145/303976.304000; David BL., 1993, P 4 INT C FDN DAT OR, P69; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; Goldin D. Q., 1995, Principles and Practice of Constraint Programming - CP '95. First International Conference, CP'95. Proceedings; Gonzalez R., 1993, DIGITAL IMAGE PROCES; Guttman A., 1984, P ACM SIGMOD INT C M, P47; HART JM, 1997, WIN3I SYSTEM PROGRAM; Kendall M., 1976, TIME SERIES; Loh WK, 2001, IEICE T INF SYST, VE84D, P76; MOON Y, 2002, P INT C MAN DAT MAD; Moon YS, 2001, PROC INT CONF DATA, P263; Oppenheim A. V., 1975, DIGITAL SIGNAL PROCE; Press WH, 1992, NUMERICAL RECIPES C; REYSZIG E, 1993, ADV ENG MATH; RFIEI D, 1997, P INT C MAN DAT TUCS, P13; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Yi BK, 1998, PROC INT CONF DATA, P201	23	16	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2004	9	1					5	28		10.1023/B:DAMI.0000026902.89522.a3		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	818WD	WOS:000221274300001	
J	Ozdal, MM; Aykanat, C				Ozdal, MM; Aykanat, C			Hypergraph models and algorithms for data-pattern-based clustering	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; clustering; hypergraph models; data patterns	RETRIEVAL	In traditional approaches for clustering market basket type data, relations among transactions are modeled according to the items occurring in these transactions. However, an individual item might induce different relations in different contexts. Since such contexts might be captured by interesting patterns in the overall data, we represent each transaction as a set of patterns through modifying the conventional pattern semantics. By clustering the patterns in the dataset, we infer a clustering of the transactions represented this way. For this, we propose a novel hypergraph model to represent the relations among the patterns. Instead of a local measure that depends only on common items among patterns, we propose a global measure that is based on the cooccurences of these patterns in the overall data. The success of existing hypergraph partitioning based algorithms in other domains depends on sparsity of the hypergraph and explicit objective metrics. For this, we propose a two-phase clustering approach for the above hypergraph, which is expected to be dense. In the first phase, the vertices of the hypergraph are merged in a multilevel algorithm to obtain large number of high quality clusters. Here, we propose new quality metrics for merging decisions in hypergraph clustering specifically for this domain. In order to enable the use of existing metrics in the second phase, we introduce a vertex-to-cluster affinity concept to devise a method for constructing a sparse hypergraph based on the obtained clustering. The experiments we have performed show the effectiveness of the proposed framework.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Bilkent Univ, Dept Comp Engn, Bilkent, Turkey	Ozdal, MM (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	ozdal@uiuc.edu; aykanat@cs.bilkent.edu.tr					Aggarwal C., 1999, P 1999 ACM SIGMOD IN, P61, DOI 10.1145/304182.304188; AGGARWAL CC, 2000, SIGMOD C; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; BAKER D, 1998, P 21 ANN INT ACM SIG, P96; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; Berge Claude, 1976, GRAPHS HYPERGRAPHS; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Catalyurek UV, 1999, IEEE T PARALL DISTR, V10, P673, DOI 10.1109/71.780863; Cheng C.H., 1999, ENTROPY BASED SUBSPA, P84; CHIU T, 2001, ROBUST SCALABLE CLUS, P263; Faloutsos C., 1995, SIGMOD, P163; Fasulo D., 1999, ANAL RECENT WORK CLU; FELDMAN R, 1997, 2 SIGMOD WORKSH RES; Ganti V., 1999, P 5 ACM SIGKDD INT C, P73, DOI 10.1145/312129.312201; Ganti V, 1999, PROC INT CONF DATA, P502, DOI 10.1109/ICDE.1999.754966; Guha S., 1999, P 15 INT C DAT ENG; HAN EH, 1997, CLUSTERING HIGH DIME, P97; HUANG Z, 1997, P SIGMOD WORKSH RES; Jain A. K., 1999, ACM COMPUT SURV, V31; Jolliffe I., 1986, PRINCIPAL COMPONENT; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; KARYPIS G, 1997, P ACM IEEE DES AUT C; Kaufman L., 1990, FINDING GROUPS DATA; King B., 1967, J AM STAT ASSOC, V69, P86; Lengauer T., 1990, COMBINATORIAL ALGORI; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; Nagesh H, 1999, 9906010 NW U; Ng R, 1994, P 20 INT C VER LARG, P144; PARK JS, 1996, P 1995 ACM SIGMOD C, P175; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; SILVA SS, 1998, POLIMEROS CIENCIA TE, V2, P1; Sneath P.H.A., 1973, NUMERICAL TAXONOMY; VOORHEES EM, 1986, INFORM PROCESS MANAG, V22, P465, DOI 10.1016/0306-4573(86)90097-X; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Zait M, 1997, FUTURE GENER COMP SY, V13, P149, DOI 10.1016/S0167-739X(97)00018-6; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	42	18	19	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2004	9	1					29	57		10.1023/B:DAMI.0000026903.59233.2a		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	818WD	WOS:000221274300002	
J	Schroedl, S; Wagstaff, K; Rogers, S; Langley, P; Wilson, C				Schroedl, S; Wagstaff, K; Rogers, S; Langley, P; Wilson, C			Mining GPS traces for map refinement	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						digital maps; spatial data mining; GPS; floating car data		Despite the increasing popularity of route guidance systems, current digital maps are still inadequate for many advanced applications in automotive safety and convenience. Among the drawbacks are the insufficient accuracy of road geometry and the lack of fine-grained information, such as lane positions and intersection structure. In this paper, we present an approach to induce high-precision maps from traces of vehicles equipped with differential GPS receivers. Since the cost of these systems is rapidly decreasing and wireless technology is advancing to provide the communication infrastructure, we expect that in the next few years large amounts of car data will be available inexpensively. Our approach consists of successive processing steps: individual vehicle trajectories are divided into road segments and intersections; a road centerline is derived for each segment; lane positions are determined by clustering the perpendicular offsets from it; and the transitions of traces between segments are utilized in the generation of intersection models. This paper describes an approach to this complex data-mining task in a contiguous manner. Among the new contributions are a spatial clustering algorithm for inferring the connectivity structure, more powerful lane finding algorithms that are able to handle lane splits and merges, and an approach to inferring detailed intersection models.	DaimlerChrysler Res & Technol N Amer, Palo Alto, CA 94304 USA	Schroedl, S (reprint author), DaimlerChrysler Res & Technol N Amer, 1510 Page Mill Rd, Palo Alto, CA 94304 USA.	schroedl@rtna.daimlerchrysler.com; wagstaff@rtna.daimlerchrysler.com; rogers@rtna.daimlerchrysler.com; langley@rtna.daimlerchrysler.com; wilson@rtna.daimlerchrysler.com					Harvey A., 1990, FORECASTING STRUCTUR; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LAVOIE P, 1999, NURBS LIB REFERENCE; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; Parkinson B. W., 1996, GLOBAL POSITIONING S; Piegl L., 1997, NURBS BOOK; ROGERS S, P 5 INT C KNOWL DISC, P104; SCHROEDL S, 2000, 62000 RTC DAIML CHRY; Wagstaff K., 2001, P 18 INT C MACH LEAR, P577; WANG J, 2001, P ION TECHN M 2001 L; Wilson C.K.H., 1998, P IEEE INT C INT VEH, P419; *ERT, 2002, NEXTMAP PROJ; *NAVTECH, 1996, SOFTW DEV TOOLK	13	24	25	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2004	9	1					59	87		10.1023/B:DAMI.0000026904.74892.89		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	818WD	WOS:000221274300003	
J	Li, JY; Manoukian, T; Dong, GZ; Ramamohanarao, K				Li, JY; Manoukian, T; Dong, GZ; Ramamohanarao, K			Incremental maintenance on the border of the space of emerging patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						incremental maintenance algorithms; emerging patterns (EPs); borders	ACUTE LYMPHOBLASTIC-LEUKEMIA; GENE-EXPRESSION PROFILES; VERSION SPACES; CLASSIFICATION; DISCOVERY; SEARCH	Emerging patterns (EPs) are useful knowledge patterns with many applications. In recent studies on bio-medical profiling data, we have successfully used such patterns to solve difficult cancer diagnosis problems and produced higher classification accuracy when compared to alternative methods. However, the discovery of EPs is a challenging and computationally expensive problem. In this paper, we study how to incrementally modify and maintain the concise boundary descriptions of the space of all emerging patterns when small changes occur to the data. As EP spaces are convex, the maintenance on the bounds guarantees that no desired patterns are lost. We introduce algorithms to handle four types of changes: insertion of new data, deletion of old data, addition of new attributes, and deletion of old attributes. We compare these incremental algorithms, on six benchmark data sets, against an efficient algorithm that computes from scratch. The results show that the incremental algorithms are much faster than the From-Scratch method, often with tremendous speed-up rates.	Inst Infocomm Res, Singapore 119613, Singapore; Univ Melbourne, Dept CSSE, Parkville, Vic 3052, Australia; Wright State Univ, Dept CSE, Dayton, OH 45435 USA	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@i2r.a-star.edu.sg; tcm@cs.mu.oz.au; gdong@cs.wright.edu; rao@cs.mu.oz.au					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Blake C.L., 1998, UCI MACHINE LEARNING; Cai Y., 1991, Knowledge discovery in databases; Dong G., 1999, P 2 INT C DISC SCI, P30; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Gunter CA, 1997, ARTIF INTELL, V95, P357, DOI 10.1016/S0004-3702(97)00033-7; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J., 1996, ADV KNOWLEDGE DISCOV, P399; HIRSH H, 1994, MACH LEARN, V17, P5, DOI 10.1007/BF00993863; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1994, MLC MACHINE LEARNING, P740; LI J, 2001, THESIS U MELBOURNE; Li J, 2002, SER INF MANAGE SCI, V1, P325; Li J, 2000, P 4 EUR C PRINC PRAC, P191; LI J, 2000, P 17 INT C MACH LEAR, P551; Li J., 2001, KNOWL INF SYST, V3, P131, DOI 10.1007/PL00011662; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Mitchell T. M., 1977, P 5 INT JOINT C ART, P305; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; NORTON SW, 1993, MACH LEARN, P220; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Sebag M., 1996, P 13 INT C MACH LEAR, P444; SMIRNOV EN, 1998, P 13 EUR C ART INT, P460; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	31	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2004	9	1					89	116		10.1023/B:DAMI.0000026901.85057.58		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	818WD	WOS:000221274300004	
J	Corchado, E; MacDonald, D; Fyfe, C				Corchado, E; MacDonald, D; Fyfe, C			Maximum and minimum likelihood Hebbian learning for exploratory projection pursuit	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						exploratory projection pursuit; artificial neural networks	NETWORKS	In this paper, we review an extension of the learning rules in a Principal Component Analysis network which has been derived to be optimal for a specific probability density function. We note that this probability density function is one of a family of pdfs and investigate the learning rules formed in order to be optimal for several members of this family. We show that, whereas we have previously (Lai et al., 2000; Fyfe and MacDonald, 2002) viewed the single member of the family as an extension of PCA, it is more appropriate to view the whole family of learning rules as methods of performing Exploratory Projection Pursuit. We illustrate this on both artificial and real data sets.	Univ Paisley, Appl Computat Intelligence Res Unit, Paisley PA1 2BE, Renfrew, Scotland; Univ Burgos, Burgos, Spain	Corchado, E (reprint author), Univ Paisley, Appl Computat Intelligence Res Unit, Paisley PA1 2BE, Renfrew, Scotland.	emilio.corchado@paisley.ac.uk; donald.mcdonald@paisley.ac.uk; colin.fyfe@paisley.ac.uk					Bell J.F., 1988, LUNAR PLANET SCI, VXIX, P57; Bishop CM, 1995, NEURAL NETWORKS PATT; DIACONIS P, 1984, ANN STAT, V12, P793, DOI 10.1214/aos/1176346703; FYFE C, 2002, IN PRESS NEUROCOMPUT; FYFE C, 1995, BIOL CYBERN, V72, P533, DOI 10.1007/BF00199896; FYFE C, 1995, THESIS STRATHCLYDE U; FYFE C, 1993, P INT C ART ART NEUR, P183; HOWELL ES, 1994, J GEOPHYS RES-PLANET, V99, P10847, DOI 10.1029/93JE03575; Hyvarinen A., 2002, INDEPENDENT COMPONEN; Hyvarinen A, 2001, NEURAL COMPUT, V13, P883, DOI 10.1162/089976601300014394; KARHUNEN J, 1994, NEURAL NETWORKS, V7, P113, DOI 10.1016/0893-6080(94)90060-4; Kashyap R. L., 1994, PRELUDE NEURAL NETWO; Lai P. L., 2000, DEV ARTIFICIAL NEURA; MACDONALD D, 1999, EUR S ART NEUR NETW, P117; OJA E, 1992, IEICE T INF SYST, VE75D, P366; Oja E., 1989, International Journal of Neural Systems, V1, DOI 10.1142/S0129065789000475; Smola A. J., 1998, NEUROCOLT2 TECHNICAL; THOLEN D, 1994, THESIS U ARIZONA; XU L, 1993, NEURAL NETWORKS, V6, P627, DOI 10.1016/S0893-6080(05)80107-8; ZELLNER B, 1985, ICARUS, V61, P355, DOI 10.1016/0019-1035(85)90133-2	20	60	60	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2004	8	3					203	225		10.1023/B:DAMI.0000023673.23078.a3		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	812CQ	WOS:000220818000001	
J	Pei, J; Han, JW; Lakshmanan, LVS				Pei, J; Han, JW; Lakshmanan, LVS			Pushing convertible constraints in frequent itemset mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						frequent itemset mining; constraint; convertible constraint; algorithm; pruning		Recent work has highlighted the importance of the constraint-based mining paradigm in the context of frequent itemsets, associations, correlations, sequential patterns, and many other interesting patterns in large databases. Constraint pushing techniques have been developed for mining frequent patterns and associations with antimonotonic, monotonic, and succinct constraints. In this paper, we study constraints which cannot be handled with existing theory and techniques in frequent pattern mining. For example, avg(S)thetav, median(S)thetav, sum(S)thetav (S can contain items of arbitrary values, thetais an element of {>, <,&LE;, &GE;} and v is a real number.) are customarily regarded as "tough" constraints in that they cannot be pushed inside an algorithm such as A priori. We develop a notion of convertible constraints and systematically analyze, classify, and characterize this class. We also develop techniques which enable them to be readily pushed deep inside the recently developed FP-growth algorithm for frequent itemset mining. Results from our detailed experiments show the effectiveness of the techniques developed.	SUNY Buffalo, Buffalo, NY 14260 USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ British Columbia, Vancouver, BC V6T 1Z4, Canada	Pei, J (reprint author), SUNY Buffalo, 201 Bell Hall, Buffalo, NY 14260 USA.	jianpei@cse.buffalo.edu; hanj@cs.uiuc.edu; laks@cs.ubc.ca					Agarwal R., 1994, P 20 INT C VER LARG, P487; Agarwal R., 1995, P 1995 INT C DAT ENG, P3; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo RJ, 1999, PROC INT CONF DATA, P188, DOI 10.1109/ICDE.1999.754924; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Garofalakis MN, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P223; Grahne G., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839450; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han JW, 1999, PROC INT CONF DATA, P106; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; LAKSHMANAN LVS, 1999, P 1999 ACM SIGMOD IN, P157, DOI 10.1145/304182.304196; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Pei J, 2001, PROC INT CONF DATA, P433; Pei J., 2000, P 6 ACM SIGKDD INT C, P350, DOI 10.1145/347090.347166; PEI J, 2002, P 2002 INT C INF KNO; Pei J., 2000, P 2000 ACM SIGMOD IN, P11; RYMON R, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P539; Silverstein C., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Webb GI, 1995, J ARTIF INTELL RES, V3, P431	24	22	22	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2004	8	3					227	252		10.1023/B:DAMI.0000023674.74932.4c		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	812CQ	WOS:000220818000002	
J	Yang, Q; Li, TY; Wang, K				Yang, Q; Li, TY; Wang, K			Building association-rule based sequential classifiers for web-document prediction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						web log mining; sequential classifiers; presending web documents	PATTERNS	Web servers keep track of web users' browsing behavior in web logs. From these logs, one can build statistical models that predict the users' next requests based on their current behavior. These data are complex due to their large size and sequential nature. In the past, researchers have proposed different methods for building association-rule based prediction models using the web logs, but there has been no systematic study on the relative merits of these methods. In this paper, we provide a comparative study on different kinds of sequential association rules for web document prediction. We show that the existing approaches can be cast under two important dimensions, namely the type of antecedents of rules and the criterion for selecting prediction rules. From this comparison we propose a best overall method and empirically test the proposed model on real web logs.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Yang, Q (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clearwater Bay, Hong Kong, Hong Kong, Peoples R China.	qyang@cs.sfu.ca; tlie@cs.sfu.ca; wangk@cs.sfu.ca	WANG, Ke/H-6830-2013				AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Breiman L, 1984, CLASSIFICATION REGRE; Liu H, 1998, ELEC SOC S, V98, P86; MANNILA H, 1998, P 1 INT C KNOWL DISC, P210; Pei J, 2001, PROC INT CONF DATA, P215; PITKOW JE, 1999, 2 USENIX S INT TECHN; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SCHECHTER S, 1998, P 7 INT WORLD WID WE, P457; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12; Su Z., 2000, P 1 INT C WEB INF SY, P200; SU Z, 2000, P 2000 INT ACM C MUL; Zhou S., 2000, P 6 ACM SIGKDD INT C, P265, DOI 10.1145/347090.347147	14	11	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2004	8	3					253	273		10.1023/B:DAMI.0000023675.04946.f1		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	812CQ	WOS:000220818000003	
J	Yamanishi, K; Takeuchi, JI; Williams, G; Milne, P				Yamanishi, K; Takeuchi, JI; Williams, G; Milne, P			On-line unsupervised outlier detection using finite mixtures with discounting learning algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						outlier detection; intrusion detection; anomaly detection; fraud detection; finite mixture model; EM algorithm		Outlier detection is a fundamental issue in data mining, specifically in fraud detection, network intrusion detection, network monitoring, etc. SmartSifter is an outlier detection engine addressing this problem from the viewpoint of statistical learning theory. This paper provides a theoretical basis for SmartSifter and empirically demonstrates its effectiveness. SmartSifter detects outliers in an on-line process through the on-line unsupervised learning of a probabilistic model ( using a finite mixture model) of the information source. Each time a datum is input SmartSifter employs an on-line discounting learning algorithm to learn the probabilistic model. A score is given to the datum based on the learned model with a high score indicating a high possibility of being a statistical outlier. The novel features of SmartSifter are: ( 1) it is adaptive to non-stationary sources of data; ( 2) a score has a clear statistical/information-theoretic meaning; ( 3) it is computationally inexpensive; and ( 4) it can handle both categorical and continuous variables. An experimental application to network intrusion detection shows that SmartSifter was able to identify data with high scores that corresponded to attacks, with low computational costs. Further experimental application has identified a number of meaningful rare cases in actual health insurance pathology data from Australia's Health Insurance Commission.	NEC Corp Ltd, Internet Syst Res Labs, Kanagawa 2168555, Japan; CSIRO Math & Informat Sci, Data Min Grp, Canberra, ACT 2601, Australia	Yamanishi, K (reprint author), NEC Corp Ltd, Internet Syst Res Labs, 4-1-1 Miyazaki, Kanagawa 2168555, Japan.	k-yamanishi@cw.jp.nec.com; tak@ap.jp.nec.com; Graham.Williams@cmis.csiro.au; Peter.Milne@cmis.csiro.au					Allan J., 1998, P DARPA BROADC NEWS, P194; Barnett V., 1994, OUTLIERS STAT DATA; Bonchi F., 1999, P 5 ACM SIGKDD INT C, P175, DOI 10.1145/312129.312224; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Cover T. M., 1991, ELEMENTS INFORMATION; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Fawcett T., 1999, P 5 ACM SIGKDD INT C, P53, DOI 10.1145/312129.312195; FAWCETT T, 1997, P AI APPR FRAUD DET, P14; GRABEC I, 1990, BIOL CYBERN, V63, P403, DOI 10.1007/BF00202757; Guralnik V, 1999, P 5 ACM SIGKDD INT C, P33, DOI 10.1145/312129.312190; Hawkins D. M., 1980, IDENTIFICATION OUTLI; Hunt L.A., 1999, AUST NZ J STAT, V40, P153; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211; KRICHEVSKY RE, 1981, IEEE T INFORM THEORY, V27, P199, DOI 10.1109/TIT.1981.1056331; LANE T, 1998, P KDD 98, P66; Lee W., 1999, P 5 ACM SIGKDD INT C, P114, DOI 10.1145/312129.312212; LEE W, 1998, P KDD 98; MARRON JS, 1992, ANN STAT, V20, P712, DOI 10.1214/aos/1176348653; MCLACHLAN G., 2000, WILEY SERIES PROBABI; MOREAU Y, DETECTION MOBILE PHO; NEAL R, 1993, VIEW EM ALGORITHM JU; NG SK, 2002, IN PRESS STAT COMPUT; P Burge, 1997, P AI APPR FRAUD DET, P9; Rocke DM, 1996, ANN STAT, V24, P1327, DOI 10.1214/aos/1032526972; ROSSET S, 1999, P 5 ACM SIGKDD INT C, P409, DOI 10.1145/312129.312303; WILLIAMS GJ, 1997, ADV TOPICS ARTIFICIA, V1342, P340, DOI 10.1007/3-540-63797-4_87; Yamanishi K., 2000, P 6 ACM SIGKDD INT C, P250	28	40	41	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2004	8	3					275	300		10.1023/B:DAMI.0000023676.72185.7c		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	812CQ	WOS:000220818000004	
J	Elomaa, T; Rousu, J				Elomaa, T; Rousu, J			Efficient multisplitting revisited: Optima-preserving elimination of partition candidates	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						numerical attributes; optimal partitions; convex functions; boundary points	VALUED ATTRIBUTES; DISCRETIZATION; SELECTION	We consider multisplitting of numerical value ranges, a task that is encountered as a discretization step preceding induction and also embedded into learning algorithms. We are interested in finding the partition that optimizes the value of a given attribute evaluation function. For most commonly used evaluation functions this task takes quadratic time in the number of potential cut points in the numerical range. Hence, it is a potential bottleneck in data mining algorithms. We present two techniques that speed up the optimal multisplitting task. The first one aims at discarding cut point candidates in a quick linear-time preprocessing scan before embarking on the actual search. We generalize the definition of boundary points by Fayyad and Irani to allow us to merge adjacent example blocks that have the same relative class distribution. We prove for several commonly used evaluation functions that this processing removes only suboptimal cut points. Hence, the algorithm does not lose optimality. Our second technique tackles the quadratic-time dynamic programming algorithm, which is the best schema for optimizing many well-known evaluation functions. We present a technique that dynamically - i.e., during the search - prunes partitions of prefixes of the sorted data from the search space of the algorithm. The method works for all convex and cumulative evaluation functions. Together the use of these two techniques speeds up the multisplitting process considerably. Compared to the baseline dynamic programming algorithm the speed-up is around 50 percent on the average and up to 90 percent in some cases. We conclude that optimal multisplitting is fully feasible on all benchmark data sets we have encountered.	Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland	Elomaa, T (reprint author), Univ Helsinki, Dept Comp Sci, POB 26, FIN-00014 Helsinki, Finland.	elomaa@cs.helsinki.fi; rousu@cs.helsinki.fi	Rousu, Juho/E-8195-2012	Rousu, Juho/0000-0002-0705-4314			Ankerst M., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347124; AUER P, 1997, UNPUB OPTIMAL SPLITS; AUER P, 1995, P 12 INT C MACH LEAR, P21; BIRKENDORF A, 1997, LECT NOTES ARTIF INT, V1208, P198; Blake C, 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P41, DOI 10.1023/A:1018094028462; CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164; Cerquides J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; CODRINGTON C, 1997, 975 PURD U SCH EL CO; Coppersmith D, 1999, DATA MIN KNOWL DISC, V3, P197, DOI 10.1023/A:1009869804967; Cover T. M., 1991, ELEMENTS INFORMATION; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; Elomaa T, 2001, FUND INFORM, V47, P35; Elomaa T, 1999, MACH LEARN, V36, P201, DOI 10.1023/A:1007674919412; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; Fulton T., 1995, P 12 INT C MACH LEAR, P244; Hardy G. H., 1934, INEQUALITIES; Hickey RJ, 1996, ARTIF INTELL, V82, P157, DOI 10.1016/0004-3702(94)00094-8; Ho K. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; Maass W., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181016; MEYER B, 1984, MATH COMPUT, V42, P193, DOI 10.2307/2007569; Pfahringer B, 1995, P 12 INT C MACH LEAR, P456; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1988, MACH INTELL, V11, P305; Elomaa T., 2003, Knowledge and Information Systems, V5, DOI 10.1007/s10115-003-0099-4; ROUSU J, 2001, A20011 U HELS DEP CO; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; Wu XD, 1996, COMPUT J, V39, P688, DOI 10.1093/comjnl/39.8.688; Zighed D. A., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	38	19	19	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2004	8	2					97	126		10.1023/B:DAMI.0000015868.85039.e6		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	773KN	WOS:000188923100001	
J	Estivill-Castro, V; Yang, J				Estivill-Castro, V; Yang, J			Fast and robust general purpose clustering algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clustering; k-MEANS; medoids; 1-median problem; combinatorial optimization; EXPECTATION MAXIMIZATION	SPATIAL DATA; EM ALGORITHM	General purpose and highly applicable clustering methods are usually required during the early stages of knowledge discovery exercises. k-MEANS has been adopted as the prototype of iterative model-based clustering because of its speed, simplicity and capability to work within the format of very large databases. However, k-MEANS has several disadvantages derived from its statistical simplicity. We propose an algorithm that remains very efficient, generally applicable, multidimensional but is more robust to noise and outliers. We achieve this by using medians rather than means as estimators for the centers of clusters. Comparison with k-MEANS, EXPECTATION MAXIMIZATION and GIBBS sampling demonstrates the advantages of our algorithm.	Griffith Univ, Sch Comp & Informat Technol, Nathan, Qld 4111, Australia; Univ Western Sydney Macarthur, Sch Comp & Informat Technol, Campbelltown, NSW 2560, Australia	Estivill-Castro, V (reprint author), Griffith Univ, Sch Comp & Informat Technol, Nathan, Qld 4111, Australia.	v.estivill-castro@griffith.edu.au					Aldenderfer M. S., 1984, CLUSTER ANAL; Apostol T. M., 1969, CALCULUS, V2; Arnold S. F., 1993, HDB STAT, P599, DOI 10.1016/S0169-7161(05)80142-7; Arora S., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276718; BAJAJ C, 1986, J SYMB COMPUT, V2, P99, DOI 10.1016/S0747-7171(86)80015-3; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Berry M. R. J., 1997, DATA MINING TECHNIQU; Bezdek J., 1981, PATTERN RECOGNITION; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Bradley PS, 1997, ADV NEUR IN, V9, P368; Bulmer M. G., 1979, PRINCIPLES STAT; CASELA G., 1990, STAT INFERENCE; CELEUX G, 1995, PATTERN RECOGN, V28, P781, DOI 10.1016/0031-3203(94)00125-6; Cherkassky V., 1998, LEARNING DATA CONCEP; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dowe DL, 1998, LECT NOTES ARTIF INT, V1394, P87; Duda R., 1973, PATTERN CLASSIFICATI; Estivill-Castro V, 1998, LECT NOTES ARTIF INT, V1394, P110; Estivill-Castro V., 2002, SIGKDD EXPLORATIONS, V4, P65; Estivill-Castro V, 2001, ALGORITHMICA, V30, P216, DOI 10.1007/s00453-001-0010-1; EVERITT B., 1980, CLUSTER ANAL; Fayyad U., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Francis R., 1974, FACILITY LAYOUT LOCA; Gelman A., 1995, BAYESIAN DATA ANAL; Graham RL, 1989, CONCRETE MATH; GUPTA SK, 1999, SPRINGER VERLAG LECT, V1676, P203; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; JORDAN MI, 1993, P 10 INT C MACH LEAR, P159; Kaufman L., 1990, FINDING GROUPS DATA; Kuhn HW, 1973, MATH PROGRAM, V4, P98, DOI 10.1007/BF01584648; KUHN HW, 1962, J REGIONAL SCI, V4, P21; KUHN HW, 1967, NONLINEAR PROGRAMMIN, pCH3; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; MASSA S, 1999, SPRINGER VERLAG LECT, V1676, P331; MEILIJSON I, 1989, J ROY STAT SOC B MET, V51, P127; Murray AT, 1998, INT J GEOGR INF SCI, V12, P431; Ng R, 1994, P 20 INT C VER LARG, P144; Oliver J., 1996, P 13 INT C MACH LEAR, P364; OVERTON ML, 1983, MATH PROGRAM, V27, P34, DOI 10.1007/BF02591963; ROGERS GW, 1997, P 28 S INT COMP SCI, P492; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; SMITH WD, 1993, RES VET SCI, V55, P1, DOI 10.1016/0034-5288(93)90025-B; Tanner M. A., 1993, TOOLS STAT INFERENCE; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; Wesolowsky G. O., 1993, Location Science, V1; ZHANG B, 1907, SPRINGER VERLAG LECT, P31	50	17	18	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2004	8	2					127	150		10.1023/B:DAMI.0000015869.08323.b3		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	773KN	WOS:000188923100002	
J	Galvao, RKH; Becerra, VM; Abou-Seada, M				Galvao, RKH; Becerra, VM; Abou-Seada, M			Ratio selection for classification models	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						ratio selection; multivariate analysis; discriminant analysis; genetic algorithm; distress prediction; finance	SUCCESSIVE PROJECTIONS ALGORITHM; MATRIX CONDITION NUMBER; MULTIVARIATE CALIBRATION; WAVELENGTH SELECTION; MULTICOMPONENT ANALYSIS; BANKRUPTCY PREDICTION; DISCRIMINANT-ANALYSIS; GENETIC ALGORITHMS; VARIABLE SELECTION; FINANCIAL RATIOS	This paper is concerned with the selection of inputs for classification models based on ratios of measured quantities. For this purpose, all possible ratios are built from the quantities involved and variable selection techniques are used to choose a convenient subset of ratios. In this context, two selection techniques are proposed: one based on a pre-selection procedure and another based on a genetic algorithm. In an example involving the financial distress prediction of companies, the models obtained from ratios selected by the proposed techniques compare favorably to a model using ratios usually found in the financial distress literature.	Inst Tecnol Aeronaut, Div Engn Eletron, BR-12228900 Sao Jose Dos Campos, Brazil; Univ Reading, Dept Cybernet, Reading RG6 6AY, Berks, England; Middlesex Univ, Sch Business, London NW4 4BT, England	Galvao, RKH (reprint author), Inst Tecnol Aeronaut, Div Engn Eletron, BR-12228900 Sao Jose Dos Campos, Brazil.	kawakami@ele.ita.br; v.m.becerra@reading.ac.uk; m.abou-seada@mdx.ac.uk	Galvao, Roberto/D-1985-2013				ALICI Y, 1996, NEURAL NETWORKS FINA; Altman E.I., 1993, CORPORATE FINANCIAL; ALTMAN EI, 1968, J FINANC, V23, P505; Araujo MCU, 2001, CHEMOMETR INTELL LAB, V57, P65, DOI 10.1016/S0169-7439(01)00119-8; Atiya AF, 2001, IEEE T NEURAL NETWOR, V12, P929, DOI 10.1109/72.935101; BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171; Becerra V. M., 2001, Proceedings of the IASTED International Conference. Artificial Intelligence and Applications; Centner V, 1996, ANAL CHEM, V68, P3851, DOI 10.1021/ac960321m; Chen K., 1981, FINANCIAL MANAGE SPR, P51; Ezekiel M, 1959, METHODS CORRELATION; Foster G., 1986, FINANCIAL STATEMENT; Galvao RKH, 2001, ANAL CHIM ACTA, V443, P107; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Han CZ, 2001, BIOL TRACE ELEM RES, V83, P133, DOI 10.1385/BTER:83:2:133; Hirashima M, 1998, J CANCER RES CLIN, V124, P329, DOI 10.1007/s004320050178; HUGHES WB, 1995, GEOCHIM COSMOCHIM AC, V59, P3581, DOI 10.1016/0016-7037(95)00225-O; JOHNSON WB, 1979, J FINANC QUANT ANAL, V14, P1035, DOI 10.2307/2330305; Jones F.L., 1987, J ACCOUNTING LIT, V6, P131; JOUANRIMBAUD D, 1995, ANAL CHEM, V67, P4295, DOI 10.1021/ac00119a015; JUHL LL, 1986, ANAL CHIM ACTA, V187, P347, DOI 10.1016/S0003-2670(00)82930-X; KALIVAS JH, 1986, ANAL CHEM, V58, P989, DOI 10.1021/ac00295a074; Kim M, 2000, COMPUT CHEM ENG, V24, P513, DOI 10.1016/S0098-1354(00)00522-6; Letellier S, 1999, MELANOMA RES, V9, P389, DOI 10.1097/00008390-199908000-00008; LUCASIUS CB, 1994, ANAL CHIM ACTA, V286, P135, DOI 10.1016/0003-2670(94)80155-X; Lugger K, 1998, MED BIOL ENG COMPUT, V36, P309, DOI 10.1007/BF02522476; Malope BI, 2001, BRIT J HAEMATOL, V115, P84, DOI 10.1046/j.1365-2141.2001.03063.x; Marchant JA, 2001, COMPUT ELECTRON AGR, V32, P101, DOI 10.1016/S0168-1699(01)00158-2; Morrison D. F., 1990, MULTIVARIATE STAT ME; Naes T, 2001, J CHEMOMETR, V15, P413; PEREZARRIBAS LV, 1993, J CHEMOMETR, V7, P267; PINCHES GE, 1975, J BUS RES, V3, P295, DOI 10.1016/0148-2963(75)90011-9; Sheth SG, 1998, AM J GASTROENTEROL, V93, P44; Spiegelman CH, 1998, ANAL CHEM, V70, P35, DOI 10.1021/ac9705733; Tabachnick B. G., 2001, USING MULTIVARIATE S; TAFFLER RJ, 1982, J ROY STAT SOC A STA, V145, P342, DOI 10.2307/2981867; THOMPSON KFM, 1994, ORG GEOCHEM, V21, P877, DOI 10.1016/0146-6380(94)90047-7; VILLOSLADA FN, 1995, ANAL CHIM ACTA, V313, P93; WILSON RL, 1994, DECIS SUPPORT SYST, V11, P545, DOI 10.1016/0167-9236(94)90024-8	38	6	6	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2004	8	2					151	170		10.1023/B:DAMI.0000015913.38787.b3		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	773KN	WOS:000188923100003	
J	Schuster, A; Wolff, R				Schuster, A; Wolff, R			Communication-efficient distributed mining of association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association Rules; data mining; distributed algorithms; communication-efficient		Mining for associations between items in large transactional databases is a central problem in the field of knowledge discovery. When the database is partitioned among several share-nothing machines, the problem can be addressed using distributed data mining algorithms. One such algorithm, called CD, was proposed by Agrawal and Shafer and was later enhanced by the FDM algorithm of Cheung, Han et al. The main problem with these algorithms is that they do not scale well with the number of partitions. They are thus impractical for use in modern distributed environments such as peer-to-peer systems, in which hundreds or thousands of computers may interact. In this paper we present a set of new algorithms that solve the Distributed Association Rule Mining problem using far less communication. In addition to being very efficient, the new algorithms are also extremely robust. Unlike existing algorithms, they continue to be efficient even when the data is skewed or the partition sizes are imbalanced. We present both experimental and theoretical results concerning the behavior of these algorithms and explain how they can be implemented in different settings.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Wolff, R (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	assaf@cs.technion.ac.il; ranw@cs.technion.ac.il					Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Brin S., 1997, SIGMOD Record, V26; CHEUNG D, 1998, 12 PAC AS C KNOWL DI, P48; Cheung DW, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P31, DOI 10.1109/PDIS.1996.568665; Han E.H.S., 2000, IEEE T KNOWL DATA EN, V12, P352; HAN J, 1999, 9912 S FRAS U; Han J, 1995, P 21 INT C VER LARG, P420; JARAI Z, 1998, WORKSH HIGH PERF DAT; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Schuster A, 2001, P 2001 ACM SIGMOD IN, P473, DOI 10.1145/375663.375728; SRIKANT R, SYNTHETIC DATA GENER; SRIKANT R, 1994, P 20 INT C VER LARG, P407; TOIVONEN H, 1996, VLDB, P134; ZAKI MJ, 1996, P SUP 96 PITTSB PA, P17	16	8	8	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2004	8	2					171	196		10.1023/B:DAMI.0000015870.80026.6a		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	773KN	WOS:000188923100004	
J	Brijs, T; Swinnen, G; Vanhoof, K; Wets, G				Brijs, T; Swinnen, G; Vanhoof, K; Wets, G			Building an association rules framework to improve product assortment decisions	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association rules; frequent itemset; product assortment decisions	KNOWLEDGE DISCOVERY	It has been claimed that the discovery of association rules is well suited for applications of market basket analysis to reveal regularities in the purchase behaviour of customers. However today, one disadvantage of associations discovery is that there is no provision for taking into account the business value of an association. Therefore, recent work indicates that the discovery of interesting rules can in fact best be addressed within a microeconomic framework. This study integrates the discovery of frequent itemsets with a (microeconomic) model for product selection (PROFSET). The model enables the integration of both quantitative and qualitative (domain knowledge) criteria. Sales transaction data from a fully automated convenience store are used to demonstrate the effectiveness of the model against a heuristic for product selection based on product-specific profitability. We show that with the use of frequent itemsets we are able to identify the cross-sales potential of product items and use this information for better product selection. Furthermore, we demonstrate that the impact of product assortment decisions on overall assortment profitability can easily be evaluated by means of sensitivity analysis.	Limburgs Univ Ctr, Dept Appl Econ Sci, B-3590 Diepenbeek, Belgium	Brijs, T (reprint author), Limburgs Univ Ctr, Dept Appl Econ Sci, Univ Campus,Gebouw D, B-3590 Diepenbeek, Belgium.	tom.brijs@luc.ac.be; gilbert.swinnen@luc.ac.be; koen.vanhoof@luc.ac.be; geert.wets@luc.ac.be					Adomavicius G., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Ahmed K. M., 2000, SIGKDD EXPLORATIONS, V1, P46; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Anand S. S., 1997, Proceedings of the First Pacific-Asia Conference on Knowledge Discovery and Data Mining. KDD: Techniques and Applications; BIXBY R, 1999, MIP THEORY PRACTICE; BLISCHOK TJ, 1995, CHAIN STORE AGE EXEC, V71, P50; BOCKER F, 1978, SCHRIFTEN MARKETING, V7; BRIJS T, 2000, IN PRESS INTELLIGENT; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Cabena P., 1997, DISCOVERING DATA MIN; Guillaume S, 1998, LECT NOTES ARTIF INT, V1510, P318; HEDBERG SR, 1995, BYTE             OCT, P83; Hruschka H, 1999, J RETAILING CONSUMER, V6, P99, DOI 10.1016/S0969-6989(98)00026-5; Kendall M, 1979, ADV THEORY STAT INFE; Kleinberg J, 1998, DATA MIN KNOWL DISC, V2, P311, DOI 10.1023/A:1009726428407; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; Liu B., 1999, P 5 ACM SIGKDD INT C, P125, DOI 10.1145/312129.312216; MANNILA H, 1997, P INT C DAT THEOR, P41; MERKLE E, 1981, SCHIRFTEN MARKETING, V11; Padmanabhan B, 1999, DECIS SUPPORT SYST, V27, P303, DOI 10.1016/S0167-9236(99)00053-6; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Pessemier E.A., 1980, RETAIL ASSORTMENTS S; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; SILVA SS, 1998, POLIMEROS CIENCIA TE, V2, P1; TOIVONEN H, 1995, MLNET WORKSH STAT MA; VANDERSTER W, 1993, MARKETING DETAILHAND; Viveros MS, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P286; Wang K., 1998, P 4 INT C KNOWL DISC, P121; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	33	20	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2004	8	1					7	23		10.1023/B:DAMI.0000005256.79013.69		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	746RB	WOS:000186759800001	
J	Coenen, F; Goulbourne, G; Leng, P				Coenen, F; Goulbourne, G; Leng, P			Tree structures for mining association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association rules; set-enumeration tree		A well-known approach to Knowledge Discovery in Databases involves the identification of association rules linking database attributes. Extracting all possible association rules from a database, however, is a computationally intractable problem, because of the combinatorial explosion in the number of sets of attributes for which incidence-counts must be computed. Existing methods for dealing with this may involve multiple passes of the database, and tend still to cope badly with densely-packed database records. We describe here a class of methods we have introduced that begin by using a single database pass to perform a partial computation of the totals required, storing these in the form of a set enumeration tree, which is created in time linear to the size of the database. Algorithms for using this structure to complete the count summations are discussed, and a method is described, derived from the well-known Apriori algorithm. Results are presented demonstrating the performance advantage to be gained from the use of this approach. Finally, we discuss possible further applications of the method.	Univ Liverpool, Dept Comp Sci, Liverpool L69 7ZF, Merseyside, England	Coenen, F (reprint author), Univ Liverpool, Dept Comp Sci, Liverpool L69 7ZF, Merseyside, England.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; BAYARDO RJ, 1999, P 15 INT C DAT ENG; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Goulbourne G, 2000, KNOWL-BASED SYST, V13, P141, DOI 10.1016/S0950-7051(00)00055-1; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Houtsma M., 1993, 9567 RJ IBM ALM RES; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; RYMON R, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P539; Savasere A, 1995, P 21 INT C VER LARG, P432; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Zaki Mohammed Javeed, 1997, 651 U ROCH COMP SCI	14	50	52	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2004	8	1					25	51		10.1023/B:DAMI.0000005257.93780.3b		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	746RB	WOS:000186759800002	
J	Han, JW; Pei, J; Yin, YW; Mao, RY				Han, JW; Pei, J; Yin, YW; Mao, RY			Mining frequent patterns without candidate generation: A frequent-pattern tree approach	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						frequent pattern mining; association mining; algorithm; performance improvements; data structure	SEQUENTIAL PATTERNS	Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist a large number of patterns and/or long patterns. In this study, we propose a novel frequent-pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a condensed, smaller data structure, FP-tree which avoids costly, repeated database scans, (2) our FP-tree-based mining adopts a pattern-fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space. Our performance study shows that the FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent-pattern mining methods.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; SUNY Buffalo, Buffalo, NY 14260 USA; Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada; Microsoft Corp, SQL Server Grp, Redmond, WA 98052 USA; China Telecom, Beijing, Peoples R China	Pei, J (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	hanj@cs.uiuc.edu; jianpei@cse.buffalo.edu; yiweny@cs.sfu.ca; runyingm@microsoft.com	Yan, Caspar/A-3130-2012				Agarwal RC, 2001, J PARALLEL DISTR COM, V61, P350, DOI 10.1006/jpdc.2000.1693; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Grahne G., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839450; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han JW, 1999, PROC INT CONF DATA, P106; Kamber M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J, 2001, PROC INT CONF DATA, P433; Pei J, 2001, PROC INT CONF DATA, P215; Pei J, 2001, P IEEE INT C DAT MIN, P441; Pei J., 2000, P 2000 ACM SIGMOD IN, P11; Sarawagi S, 1998, P ACM SIGMOD INT C M, P343, DOI 10.1145/276304.276335; Savasere A, 1995, P 21 INT C VER LARG, P432; Silverstein C., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zaki MJ, 2002, SIAM PROC S, P457	28	363	425	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2004	8	1					53	87		10.1023/B:DAMI.0000005258.31418.83		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	746RB	WOS:000186759800003	
J	Keogh, E; Kasetty, S				Keogh, E; Kasetty, S			On the need for time series data mining benchmarks: A survey and empirical demonstration	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th International Conference on Knowledge Discovery and Data Mining (KDD 2002)	JUL 23-26, 2002	EDMONTON, CANADA	ACM, SIGKDD		time series; data mining; experimental evaluation	SIMILARITY SEARCH; SEQUENCES; WAVELETS; QUERIES; DATABASES	In the last decade there has been an explosion of interest in mining time series data. Literally hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we make the following claim. Much of this work has very little utility because the contribution made ( speed in the case of indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an amount of "improvement" that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details. To illustrate our point, we have undertaken the most exhaustive set of time series experiments ever attempted, re-implementing the contribution of more than two dozen papers, and testing them on 50 real world, highly diverse datasets. Our empirical results strongly support our assertion, and suggest the need for a set of time series benchmarks and more careful empirical evaluation in the data mining community.	Univ Calif Riverside, Riverside, CA 92521 USA	Keogh, E (reprint author), Univ Calif Riverside, Riverside, CA 92521 USA.	eamonn@cs.ucr.edu; skasetty@cs.ucr.edu					Agrawal R., 1995, P 21 INT C VER LARG, P490; Andre-Jonsson H, 1997, LECT NOTES ARTIF INT, V1263, P211; Bailey D. H., 1991, SUPERCOMPUTING REV, P54; BAY S, 1999, UCI REPOSITORY KDD D; Berndt D. J., 1996, ADV KNOWLEDGE DISCOV, P229; Bozkaya T., 1997, Proceedings of the Sixth International Conference on Information and Knowledge Management. CIKM'97, DOI 10.1145/266714.266880; Caraca-Valente J. P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347192; Chan KP, 1999, PROC INT CONF DATA, P126; Chu K. K. W., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, DOI 10.1145/303976.304000; Chu W.W., 2001, P 16 ACM S APPL COMP, P248, DOI 10.1145/372202.372334; Cohen W. W., 1993, P 13 INT JOINT C ART, P988; Das G, 1997, LECT NOTES ARTIF INT, V1263, P88; DAS G, P 4 INT C KNOWL DISC, P16; David BL., 1993, P 4 INT C FDN DAT OR, P69; Debregeas A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; FALOUTSOS C, 1997, P INT C COMPR COMPL; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; Ferhatosmanoglu H, 2001, PROC INT CONF DATA, P503, DOI 10.1109/ICDE.2001.914864; GAVRILOV M, 2000, KDD 00, P487; Ge X., 2000, P 6 ACM SIGKDD INT C, P81, DOI 10.1145/347090.347109; Geurts P., 2001, P 5 EUR C PRINC DAT, P115; Goldin D. Q., 1995, Principles and Practice of Constraint Programming - CP '95. First International Conference, CP'95. Proceedings; Guralnik V, 1999, P 5 ACM SIGKDD INT C, P33, DOI 10.1145/312129.312190; Huang YW, 1999, P 5 INT C KNOWL DISC, P282, DOI 10.1145/312129.318357; Huhtala Y, 1999, PROC SPIE, V3695, P150, DOI 10.1117/12.339977; Indyk P., 2000, P 26 INT C VER LARG, P363; Kahveci T, 2001, PROC INT CONF DATA, P273, DOI 10.1109/ICDE.2001.914838; Kahveci T, 2002, PROC INT CONF DATA, P266, DOI 10.1109/ICDE.2002.994720; Kalpakis K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989529; KAWAGOE K, 2002, P 9 INT S TEMP REPR; Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; Keogh E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Kibler D., 1988, P 3 EUR WORK SESS LE, P81; KIM E, 2000, P DAT WAR KNOWL DISC, P347; Kim SW, 2001, PROC INT CONF DATA, P607; Korn F., 1997, P ACM SIGMOD INT C M, P289, DOI DOI 10.1145/253260.253332; Lam SK, 1998, DATA KNOWL ENG, V28, P321, DOI 10.1016/S0169-023X(98)00023-8; Lavrenko V., 2000, P 6 ACM SIGKDD INT C, P37; Lee S.-L., 2000, P ICDE, P599; LI C., 1998, P 7 INT C INF KNOWL, P267, DOI 10.1145/288627.288666; LOH WK, 2000, P ACM INT C INF KNOW, P480, DOI 10.1145/354756.354856; Park S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839384; PARK S, 2001, COMMUNICATION; PARK S, 1999, P 3 IEEE KNOWL DAT E; POLLY WPM, 2001, P 2001 ACM CIKM INT, P271; Popivanov I, 2002, PROC INT CONF DATA, P212, DOI 10.1109/ICDE.2002.994711; PRATT KB, 2002, INT J IMAGE GRAPHICS, V2, P86; PRECHELT L, 1995, P 4 INT C ART NEUR N, P223; QU Y, 1998, P ACM CIKM, P251, DOI 10.1145/288627.288664; RAFIEI D, 1998, P 5 INT C FDN DAT OR; Rafiei D, 1999, PROC INT CONF DATA, P410, DOI 10.1109/ICDE.1999.754957; Shahabi C., 2000, Proceedings. 12th International Conference on Scientific and Statistica Database Management, DOI 10.1109/SSDM.2000.869778; Shatkay H, 1996, PROC INT CONF DATA, P536, DOI 10.1109/ICDE.1996.492204; SIMON JL, 1994, AM STAT, V48, P1; Struzik ZR, 1999, LECT NOTES ARTIF INT, V1704, P12; WALKER J, 2001, HOTBITS GENUINE RAND; WANG C, 2000, P 9 ACM CIKM INT C I, P314, DOI 10.1145/354756.354834; WANG C, 2000, P 12 INT C SCI STAT, P69; WANG C, 2000, P 82 ANN M TOR ONT E, P37; Wu L., 2000, P 26 INT C VER LARG, P297; Wu Y. L., 2000, P 9 ACM CIKM INT C I, P488, DOI 10.1145/354756.354857; Yi BK, 1998, PROC INT CONF DATA, P201; Yi B.K., 2000, P 26 INT C VER LARG, P385; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680	65	94	108	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2003	7	4					349	371		10.1023/A:1024988512476		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	704UM	WOS:000184358900002	
J	Kleinberg, J				Kleinberg, J			Bursty and hierarchical structure in streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th ACM/SIGKDD International Conference on Knowledge Discovery and Data Mining	JUL, 2002	EDMONTON, CANADA	ACM, SIGKDD		data stream algorithms; text mining; Markov source models		A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time. E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale. Underlying much of the text mining work in this area is the following intuitive premise-that the appearance of a topic in a document stream is signaled by a "burst of activity," with certain features rising sharply in frequency as the topic emerges. The goal of the present work is to develop a formal approach for modeling such " bursts," in such a way that they can be robustly and efficiently identified, and can provide an organizational framework for analyzing the underlying content. The approach is based on modeling the stream using an infinite-state automaton, in which bursts appear naturally as state transitions; it can be viewed as drawing an analogy with models from queueing theory for bursty network traffic. The resulting algorithms are highly efficient, and yield a nested representation of the set of bursts that imposes a hierarchical structure on the overall stream. Experiments with e-mail and research paper archives suggest that the resulting structures have a natural meaning in terms of the content that gave rise to them.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Kleinberg, J (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Agrawal R., 1995, P INT C DAT ENG; AIGRAIN P, 1996, MULTIMEDIA TOOLS APP, V3; Allan J., 1998, P DARPA BROADC NEWS; ALLAN J, 1998, P SIGIR INT C INF RE; ANICK D, 1982, BELL SYST TECH J, V61; BECKER K, 2000, P 15 BRAZ S DAT; Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214; Berghel H, 1997, COMMUN ACM, V40, P11, DOI 10.1145/256175.256176; BIRRELL A, 1997, PACHYDERM E MAIL SYS; BLANTON T, 1995, WHITE HOUSE E MAIL; BOONE G, 1998, P 2 INT C AUT AG; CHARIKAR M, 2002, P 29 INT C AUT LANG; Chatfield C., 1996, ANAL TIME SERIES INT; Chatman Seymour, 1978, STORY DISCOURSE NARR; CHUDOVA D, 2001, KDD WORKSH TEMP DAT; COHEN WW, 1996, P AAAI SPRING S MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EHRICH R, 1976, IEEE T COMPUT, V25, P7; ELWALID A, 1993, IEEE ACM T NETWORKIN, V1; FINE S, 1998, MACHINE LEARNING, V32; Forster E. M., 1927, ASPECTS NOVEL; GAROFALAKIS M, 2002, ACM SIGMOD INT C MAN; GAY G, 2001, ED TECHNOLOGY SOC, V4; Genette Gerard, 1980, NARRATIVE DISCOURSE; Genette Gerard, 1988, NARRATIVE DISCOURSE; GROSZ BJ, 1986, COMPUTATIONAL LINGUI, V12; GRUBER T, HYPERMAIL; GURALNIK V, 1999, INT C KNOWL DISC DAT; HAN J, 1998, P INT C KNOWL DISC D; Hand D. J., 2001, PRINCIPLES DATA MINI; HAVRE S, 2000, P IEEE S INF VIS; HAWKINS D, 1976, APPL STAT, V25; HECKEL B, 1997, P WORKSH NEW PAR INF; HELFMAN J, 1995, ISHMAIL IMMEDIATE ID; Horvitz E., 1999, P ACM C HUM FACT COM; HUDSON DJ, 1966, J AM STAT ASSOC, V61, P1097, DOI 10.2307/2283203; Kelly F., 1996, STOCHASTIC NETWORKS; KEOGH E, 1997, P INT C KNOWL DISC D; LAST M, 2001, IEEE T SYSTEMS MAN B, V31; LAVRENKO V, 2000, KDD 2000 WORKSH TEXT; LEWIS DD, 1997, INF P MANAGEMENT, V33; LUKESH SS, 1999, 1 MONDAY, V4; Maes P., 1994, Communications of the ACM, V37, DOI 10.1145/176789.176792; MANNILA H, 2001, P INT C KNOWL DISC D; MARKUS ML, 1994, ACM T INFORM SYST, V12, P119, DOI 10.1145/196734.196738; MARTIN R, 2001, KDD WKSHP TEMP DAT M; MILLER N, 1998, P IEEE VISUALIZATION; Moore R. W., 2000, D LIB MAGAZINE, V6; MURPHY K, 2001, ADV NEURAL INFORMATI, V14; OLSEN F, 1999, CHRONICLE HIGHE 0824; Payne TR, 1997, APPL ARTIF INTELL, V11, P1, DOI 10.1080/088395197118325; POLLOCK S, 1988, ACM T INFORM SYST, V6, P232, DOI 10.1145/45945.214327; Rabiner L., 1989, P IEEE, V77; REDMOND M, 1998, P AAAI WORKSH CAS BA; RENNIE J, 2000, P KDD WORKSH TEXT MI; Sahami M., 1998, P AAAI WORKSH LEARN; Schneier B., 1996, APPL CRYPTOGRAPHY; SCOTT S, 1998, THESIS HARVARD U; SCOTT SL, 2002, MARKOV MODULATED POI; SEGAL R, 1999, P INT C AUT AG; SEGAL R, 2000, P INT C MACH LEARN; SHAW S, 1990, IEEE T ACOUSTICS SPE, V38, P2; SWAN R, 2000, P SIGIR INT C INF RE; SWAN R, 2000, KDD 2000 WORKSH TEXT; Swan R, 1999, P 8 INT C INF KNOWL; WHITTAKER S, 1996, P ACM SIGCHI C HUM F; WONG P, 2000, P IEEE INFORMATION V; YANG Y, 2000, P SIGIR INT C INF RE; YANG Y, 1998, P SIGIR INT C INF RE; GOGGLE ZEITGEIST SEA	70	55	58	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2003	7	4					373	397		10.1023/A:1024940629314		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	704UM	WOS:000184358900003	
J	Cadez, I; Heckerman, D; Meek, C; Smyth, P; White, S				Cadez, I; Heckerman, D; Meek, C; Smyth, P; White, S			Model-based clustering and visualization of navigation patterns on a web site	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th International Conference on Knowledge Discovery and Data Mining (KDD 2002)	JUL 23-26, 2002	EDMONTON, CANADA	ACM, SIGKDD		model-based clustering; sequence clustering; data visualization; Internet; web	HIDDEN MARKOV-MODELS; ACCESS PATTERNS; INFORMATION	We present a new methodology for exploring and analyzing navigation patterns on a web site. The patterns that can be analyzed consist of sequences of URL categories traversed by users. In our approach, we first partition site users into clusters such that users with similar navigation paths through the site are placed into the same cluster. Then, for each cluster, we display these paths for users within that cluster. The clustering approach we employ is model-based ( as opposed to distance-based) and partitions users according to the order in which they request web pages. In particular, we cluster users by learning a mixture of first-order Markov models using the Expectation-Maximization algorithm. The runtime of our algorithm scales linearly with the number of clusters and with the size of the data; and our implementation easily handles hundreds of thousands of user sessions in memory. In the paper, we describe the details of our method and a visualization tool based on it called WebCANVAS. We illustrate the use of our approach on user-traffic data from msnbc.com.	Sparta Syst Inc, Laguna Hills, CA 92653 USA; Microsoft Res, Redmond, WA 98052 USA; Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA	Heckerman, D (reprint author), Sparta Syst Inc, 23382 Mill Creek Dr 100, Laguna Hills, CA 92653 USA.	igor_cadez@sparta.com; heckerma@microsoft.com; meek@microsoft.com; smyth@ics.uci.edu; stevewh@microsoft.com					Anderson C.R., 2001, P 17 INT JOINT C ART, P879; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Bernardo J, 1994, BAYESIAN THEORY; BERNARDO JM, 1979, ANN STAT, V7, P686, DOI 10.1214/aos/1176344689; Bestavros A, 1996, PROC INT CONF DATA, P180, DOI 10.1109/ICDE.1996.492104; Borges J, 2000, LECT NOTES COMPUT SC, V1836, P92; CADEZ I, 1999, 9916 U CAL; Cheeseman P, 1995, ADV KNOWLEDGE DISCOV, P153; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; Cooley R, 2000, LECT NOTES COMPUT SC, V1836, P163; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DESHPANDE M, 2003, IN PRESS ACM T INTER; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Fu YJ, 2000, LECT NOTES COMPUT SC, V1836, P21; Good I. J., 1965, ESTIMATION PROBABILI; HUBERMAN B, 1997, SCIENCE, V280, P95; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; McLachlan GJ, 1988, MIXTURE MODELS INFER; MINAR N, 1999, C HUM FACT COMP SYST, P186; Padmanabhan V, 1996, ACM SIGCOMM COMPUTER, V26, P22, DOI 10.1145/235160.235164; Pirolli P. L. T., 1999, World Wide Web, V2, DOI 10.1023/A:1019288403823; Poulsen Carsten S., 1990, INT J RES MARK, V7, P5, DOI 10.1016/0167-8116(90)90028-L; Rabiner L. R., 1989, P INT C AC SPEECH SI, P405; Ridgeway G, 1998, P SECT PHYS ENG SCI, P228; Sarukkai RR, 2000, COMPUT NETW, V33, P377, DOI 10.1016/S1389-1286(00)00044-X; Sen R, 2003, J COMPUT GRAPH STAT, V12, P143, DOI 10.1198/1061860031275; Smyth P, 1999, J ATMOS SCI, V56, P3704, DOI 10.1175/1520-0469(1999)056<3704:MRINHH>2.0.CO;2; Smyth P., 1999, P 7 INT WORKSH AI ST, P299; Smyth P, 1997, ADV NEUR IN, V9, P648; Spiliopoulou M, 2000, LECT NOTES COMPUT SC, V1836, P142; Thiesson B., 1999, BAYESIAN STAT, V6, P631; Wedel M., 1998, MARKET SEGMENTATION; Wexelblat A., 1999, P SIGCHI C HUM FACT, P270, DOI 10.1145/302979.303060; Yan TW, 1996, COMPUT NETWORKS ISDN, V28, P1007; Zaiane OR, 1998, P IEEE INT FORUM RES, P19, DOI 10.1109/ADL.1998.670376; Zuckerman I, 1999, P 7 INT C US MOD, P275	36	59	64	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2003	7	4					399	424		10.1023/A:1024992613384		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	704UM	WOS:000184358900004	
J	Hand, DJ; Keim, DA; Ng, R				Hand, DJ; Keim, DA; Ng, R			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material																	0	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2003	7	4					347	348		10.1023/A:1024906028406		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	704UM	WOS:000184358900001	
J	Bucila, C; Gehrke, J; Kifer, D; White, W				Bucila, C; Gehrke, J; Kifer, D; White, W			DualMiner: A dual-pruning algorithm for itemsets with constraints	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th ACM/SIGKDD International Conference on Knowledge Discovery and Data Mining	JUL, 2002	EDMONTON, CANADA	ACM, SIGKDD		data mining; association rules; market basket analysis; constraints in data mining; constrained frequent itemsets		Recently, constraint-based mining of itemsets for questions like "find all frequent itemsets whose total price is at least $50" has attracted much attention. Two classes of constraints, monotone and antimonotone, have been very useful in this area. There exist algorithms that efficiently take advantage of either one of these two classes, but no previous algorithms can efficiently handle both types of constraints simultaneously. In this paper, we present DualMiner, the first algorithm that efficiently prunes its search space using both monotone and antimonotone constraints. We complement a theoretical analysis and proof of correctness of DualMiner with an experimental study that shows the efficacy of DualMiner compared to previous work.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Univ Dallas, Dept Math, Irving, TX 75062 USA; Cornell Univ, Intelligent Informat Syst Inst, Ithaca, NY 14853 USA	Bucila, C (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, VLDB, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bayardo R.J., 1998, SIGMOD, P85; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; BOULICAUT J, 2000, USING CONSTRAINTS SE; BOULICAUT JF, 2001, INT DAT ENG APPL S, P322; BURDICK D, 2001, ICDE 2001; DELIS A, 1999, SIGMOD 1999; Gunopulos D., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263684; HAAS LM, 1998, SIGMOD 1998; HAN J, 2001, SIGMOD C; Hipp J, 2002, SIGKDD EXPLORATIONS, V4, P50; Lakshmanan LVS, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P157; LEUNG CKS, 2002, SIGKDD EXPLORATIONS, V4, P31; NG R, 1998, SIGMOD, P13; Ng R, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P556; Pei J, 2000, ACM SIGKDD C, P350; PEI J, 2001, ICDE, P433; Pei J., 2002, SIGKDD EXPLORATIONS, V4, P31; PERNG CS, 2002, SIGKDD EXPLORATIONS, V4, P56; RAEDT LD, 2001, P 17 INT JOINT C ART, P853; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	23	21	21	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2003	7	3					241	272		10.1023/A:1024076020895		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	686PD	WOS:000183329400002	
J	Chudova, D; Smyth, P				Chudova, D; Smyth, P			Analysis of pattern discovery in sequences using a Bayes error framework	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th ACM/SIGKDD International Conference on Knowledge Discovery and Data Mining	JUL, 2002	EDMONTON, CANADA	ACM, SIGKDD		Hidden Markov model; motif discovery; Bayes error rate	HIDDEN MARKOV-MODELS; MOTIFS; ALIGNMENT; SITE	In this paper we investigate the general problem of discovering recurrent patterns that are embedded in categorical sequences. An important real-world problem of this nature is motif discovery in DNA sequences. There are a number of fundamental aspects of this data mining problem that can make discovery "easy" or "hard" we characterize the difficulty of this problem using an analysis based on the Bayes error rate under a Markov assumption. The Bayes error framework demonstrates why certain patterns are much harder to discover than others. It also explains the role of different parameters such as pattern length and pattern frequency in sequential discovery. We demonstrate how the Bayes error can be used to calibrate existing discovery algorithms, providing a lower bound on achievable performance. We discuss a number of fundamental issues that characterize sequential pattern discovery in this context, present a variety of empirical results to complement and verify the theoretical analysis, and apply our methodology to real-world motif-discovery problems in computational biology.	Univ Calif Irvine, Irvine, CA 92697 USA	Chudova, D (reprint author), Univ Calif Irvine, Irvine, CA 92697 USA.						BAILEY TL, 1995, MACH LEARN, V21, P51, DOI 10.1023/A:1022617714621; BALDI P, 1994, P NATL ACAD SCI USA, V91, P1059, DOI 10.1073/pnas.91.3.1059; Buhler J, 2001, P 5 ANN INT C COMP M, P69, DOI 10.1145/369133.369172; Chen SF, 2001, J MOL BIOL, V314, P75, DOI 10.1006/jmbi.2001.5090; Chow C.K., 1962, Institute of Radio Engineers Transactions on Electronic Computers, VEC-11; CHU JT, 1971, IEEE T COMPUT, VC 20, P1203, DOI 10.1109/T-C.1971.223106; CHUDOVA D, 2002, 0208 UCIICS; Duda R.O., 2001, PATTERN CLASSIFICATI; Eddy S. R, 1995, P 3 INT C INT SYST M, P114; Fukunaga K., 1990, INTRO STAT PATTERN R; Helden J, 1998, J MOL BIOL, V281, P827; HU Y, 1999, P 16 INT C MACH LEAR, P181; Keich U, 2002, BIOINFORMATICS, V18, P1374, DOI 10.1093/bioinformatics/18.10.1374; Keich U, 2002, BIOINFORMATICS, V18, P1382, DOI 10.1093/bioinformatics/18.10.1382; LAWRENCE CE, 1993, SCIENCE, V262, P208, DOI 10.1126/science.8211139; LEE E, 1974, P INT C CYB SOC, P324; Liu JS, 1995, J AM STAT ASSOC, V90, P1156, DOI 10.2307/2291508; Liu X, 2001, Pac Symp Biocomput, P127; McLachlan G., 1992, DISCRIMINANT ANAL ST; Pevzner P. A., 2000, COMPUTATIONAL MOL BI; Pevzner P.A., 2000, ISMB, P269; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAVIV J., 1967, IEEE T INFORMATION T, V3, P536; Regnier M, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P253; Ripley B., 1996, PATTERN RECOGNITION; Robison K, 1998, J MOL BIOL, V284, P241, DOI 10.1006/jmbi.1998.2160; STEFFEN N, 2002, BIOINFORMATICS, V1, P1; STORMO GD, 1989, P NATL ACAD SCI USA, V86, P1183, DOI 10.1073/pnas.86.4.1183; Sze S H, 2002, Pac Symp Biocomput, P235	29	1	1	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2003	7	3					273	299		10.1023/A:1024032204965		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	686PD	WOS:000183329400003	
J	Ridgeway, G; Madigan, D				Ridgeway, G; Madigan, D			A sequential Monte Carlo method for Bayesian analysis of massive datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th ACM/SIGKDD International Conference on Knowledge Discovery and Data Mining	JUL, 2002	EDMONTON, CANADA	ACM, SIGKDD		Bayesian inference; massive datasets; Markov chain Monte Carlo; importance sampling; particle filter; mixture model	MODELS	Markov chain Monte Carlo (MCMC) techniques revolutionized statistical practice in the 1990s by providing an essential toolkit for making the rigor and flexibility of Bayesian analysis computationally practical. At the same time the increasing prevalence of massive datasets and the expansion of the field of data mining has created the need for statistically sound methods that scale to these large problems. Except for the most trivial examples, current MCMC methods require a complete scan of the dataset for each iteration eliminating their candidacy as feasible data mining techniques. In this article we present a method for making Bayesian analysis of massive datasets computationally feasible. The algorithm simulates from a posterior distribution that conditions on a smaller, more manageable portion of the dataset. The remainder of the dataset may be incorporated by reweighting the initial draws using importance sampling. Computation of the importance weights requires a single scan of the remaining observations. While importance sampling increases efficiency in data access, it comes at the expense of estimation efficiency. A simple modification, based on the "rejuvenation" step used in particle filters for dynamic systems models, sidesteps the loss of efficiency with only a slight increase in the number of data accesses. To show proof-of-concept, we demonstrate the method on two examples. The first is a mixture of transition models that has been used to model web traffic and robotics. For this example we show that estimation efficiency is not affected while offering a 99% reduction in data accesses. The second example applies the method to Bayesian logistic regression and yields a 98% reduction in data accesses.	RAND Corp, Santa Monica, CA 90407 USA; Rutgers State Univ, Dept Stat, Hill Ctr 477, Piscataway, NJ 08855 USA	Ridgeway, G (reprint author), RAND Corp, POB 2138, Santa Monica, CA 90407 USA.						ANDRIEU C, 2003, MACHINE LEARNING, V50; BESAG J, 1995, STAT SCI, V10, P3, DOI 10.1214/ss/1177010123; Cadez I., 2000, MSRTR0018; CARLIN B.P., 2000, BAYES EMPIRICAL BAYE; Chopin N, 2002, BIOMETRIKA, V89, P539, DOI 10.1093/biomet/89.3.539; DeGroot M. H., 1970, OPTIMAL STAT DECISIO; Doucet A, 2001, SEQUENTIAL MONTE CAR; DuMouchel W, 1999, AM STAT, V53, P177, DOI 10.2307/2686093; ELDER J, 1996, ADV KNOWLEDGE DISCOV, pCH4; FIGUEIREDO M, 2001, ADAPTIVE SPARSENESS; FIGUEIREDO M, 2001, P IEEE COMP SOC C CO; Friedman N., 1999, P 15 C UNC ART INT, p[206, 523]; Gelman A., 1995, BAYESIAN DATA ANAL; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Gilks W., 1996, MARKOV CHAIN MONTE C; Gilks WR, 2001, J ROY STAT SOC B, V63, P127, DOI 10.1111/1467-9868.00280; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Glymour C, 1997, DATA MIN KNOWL DISC, V1, P11, DOI 10.1023/A:1009773905005; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97; JU WH, 2002, BAYESIAN LEARNING SP; LeCam L., 1990, ASYMPTOTICS STAT SOM, DOI 10.1007/978-1-4684-0377-0; Madigan D, 2002, DATA MIN KNOWL DISC, V6, P173, DOI 10.1023/A:1014095614948; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Posse C, 2001, J COMPUT GRAPH STAT, V10, P464, DOI 10.1198/106186001317115072; Ramoni M, 2002, MACH LEARN, V47, P91, DOI 10.1023/A:1013635829250; RIDGEWAY G, 1997, MSRTR9724; Ripley B.D., 1987, STOCHASTIC SIMULATIO; ROSS SM, 1993, PROBABILITY MODELS; Tibshirani R., 1995, J ROYAL STAT SOC B, V57, P267; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; KONG A, 1994, J AM STAT ASSOC, V89, P278, DOI 10.2307/2291224; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	32	18	18	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2003	7	3					301	319		10.1023/A:1024084221803		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	686PD	WOS:000183329400004	
J	Rosset, S; Neumann, E; Eick, U; Vatnik, N				Rosset, S; Neumann, E; Eick, U; Vatnik, N			Customer lifetime value models for decision support	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th International Conference on Knowledge Discovery and Data Mining (KDD 2002)	JUL 23-26, 2002	EDMONTON, CANADA	ACM, SIGKDD		lifetime value; length of service; churn modeling; retention		We present and discuss the important business problem of estimating the effect of marketing activities on the Lifetime Value of a customer in the Telecommunications industry. We discuss the components of this problem, in particular customer value and length of service ( or tenure) modeling, and present a novel segment-based approach, motivated by the segment-level view marketing analysts usually employ. We describe in detail how we build on this approach to estimate the effects of retention campaigns on Lifetime Value, and also discuss its application in other situations. Our solution has been successfully implemented by the Business Insight (BI) Professional Services.	Amdocs Ltd, IL-43000 Raanana, Israel; Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Rosset, S (reprint author), Amdocs Ltd, 8 Hapnina St, IL-43000 Raanana, Israel.	saharonr@amdocs.com; einatn@amdocs.com; urieick@amdocs.com; nuritv@amdocs.com					COX DR, 1972, J ROY STAT SOC B, V34, P187; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Helsen K., 1993, MARKET SCI, V11, P395; INGER A, 2000, SIGKDD EXPLORATIONS, V2, P94; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; MANI DR, 1999, P 5 ACM SIGKDD INT C, P94, DOI 10.1145/312129.312205; Murad U, 1999, LECT NOTES ARTIF INT, V1704, P251; NEUMANN E, 2000, SIGKDD EXPLORATIONS, V2, P98; NOVO J, 2001, MAXIMIZING MARKETING; ROSSET S, 1999, P 5 ACM SIGKDD INT C, P409, DOI 10.1145/312129.312303; Rosset S., 2001, P 7 ACM SIGKDD INT C, P456, DOI 10.1145/502512.502581; ROSSET S, 2000, SIGKDD EXPLORATIONS, V1, P85; Venables W. N., 1999, MODERN APPL STAT S P	13	24	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2003	7	3					321	339		10.1023/A:1024036305874		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	686PD	WOS:000183329400005	
J	Hand, DJ; Keim, DA; Ng, R				Hand, DJ; Keim, DA; Ng, R			Special issue: Selected papers from the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - Part I	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material																	0	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2003	7	3					239	240		10.1023/A:1024041103148		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	686PD	WOS:000183329400001	
J	Barbara, D; Chen, P				Barbara, D; Chen, P			Using self-similarity to cluster large data sets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clustering; self-similarity; scalability	DIMENSIONS	Clustering is a widely used knowledge discovery technique. It helps uncovering structures in data that were not previously known. The clustering of large data sets has received a lot of attention in recent years, however, clustering is a still a challenging task since many published algorithms fail to do well in scaling with the size of the data set and the number of dimensions that describe the points, or in finding arbitrary shapes of clusters, or dealing effectively with the presence of noise. In this paper, we present a new clustering algorithm, based in self-similarity properties of the data sets. Self-similarity is the property of being invariant with respect to the scale used to look at the data set. While fractals are self-similar at every scale used to look at them, many data sets exhibit self-similarity over a range of scales. Self-similarity can be measured using the fractal dimension. The new algorithm which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same cluster have a great degree of self-similarity among them (and much less self-similarity with respect to points in other clusters). FC requires one scan of the data, is suspendable at will, providing the best answer possible at that point, and is incremental. We show via experiments that FC effectively deals with large data sets, high-dimensionality and noise and is capable of recognizing clusters of arbitrary shape.	George Mason Univ, ISE Dept, Fairfax, VA 22030 USA; Univ Houston Downtown, Dept Math & Comp Sci, Houston, TX 77002 USA	Barbara, D (reprint author), George Mason Univ, ISE Dept, MSN 4A4, Fairfax, VA 22030 USA.	dbarbara@gmu.edu; Chenp@zeus.dt.uh.edu					Backer E., 1995, COMPUTER ASSISTED RE; BELUSSI A., 1995, P 21 INT C VER LARG, P299; Bradley P. S., 1998, P 4 INT C KNOWL DISC; BRADLEY PS, 1998, P ACM SIGMOD WORKSH; CHERNOFF H, 1952, ANN MATH STAT, V23, P493, DOI 10.1214/aoms/1177729330; DOMINGO C, 2000, DISCOVERY SCI, P172; DOMINGO C, 1998, P 1 INT C DISC SCI; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347107; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Faloutsos C, 1997, J COMPUT SYST SCI, V55, P229, DOI 10.1006/jcss.1997.1522; Faloutsos C, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P40; Faloutsos C, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P307; Fisher D, 1996, J ARTIF INTELL RES, V4, P147; Fukunaga K., 1990, INTRO STAT PATTERN R; Gluck M.A., 1985, P 7 ANN C COGN SCI S; GRASSBERGER P, 1983, PHYS REV LETT, V50, P5; GRASSBERGER P, 1983, PHYS LETT A, V97, P227, DOI 10.1016/0375-9601(83)90753-3; HINNEBURG A, 1999, ACM SIGKDD INT C KNO; Jain A.K., 1988, ALGORITHMS CLUSTERIN; LAURITZEN SL, 1995, COMPUTATIONAL STAT D, V19, P101; LI YF, 1990, GLOBAL POPULATION DI; LIEBOVITCH LS, 1989, PHYS LETT A, V141, P386, DOI 10.1016/0375-9601(89)90854-2; LIPTON RJ, 1993, THEOR COMPUT SCI, V116, P195, DOI 10.1016/0304-3975(93)90224-H; LIPTON RJ, 1995, J COMPUT SYST SCI, V51, P18, DOI 10.1006/jcss.1995.1050; Mandelbrot B. B., 1983, FRACTAL GEOMETRY NAT; Ng R, 1994, P 20 INT C VER LARG, P144; Samet H, 1990, APPL SPATIAL DATA ST; SARRAILLE J, FD3; Schikuta E., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.546732; Schroeder M., 1991, FRACTALS CHAOS POWER; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; WANG W, 1997, P 23 VER LARG DAT BA, P186; WATANABE O, 2000, IEICE T INFORMATION; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	36	11	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2003	7	2					123	152		10.1023/A:1022493416690		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	646MT	WOS:000181039400001	
J	Barber, B; Hamilton, HJ				Barber, B; Hamilton, HJ			Extracting share frequent itemsets with infrequent subsets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						frequent itemsets; share measure; share frequent itemsets; heuristic data mining; quantitative itemsets; association rules	ASSOCIATION RULES; DATABASES	Itemset share has been proposed as an additional measure of the importance of itemsets in association rule mining (Carter et al., 1997). We compare the share and support measures to illustrate that the share measure can provide useful information about numerical values that are typically associated with transaction items, which the support measure cannot. We define the problem of finding share frequent itemsets, and show that share frequency does not have the property of downward closure when it is defined in terms of the itemset as a whole. We present algorithms that do not rely on the property of downward closure, and thus are able to find share frequent itemsets that have infrequent subsets. The algorithms use heuristic methods to generate candidate itemsets. They supplement the information contained in the set of frequent itemsets from a previous pass, with other information that is available at no additional processing cost. They count only those generated itemsets that are predicted to be frequent. The algorithms are applied to a large commercial database and their effectiveness is examined using principles of classifier evaluation from machine learning.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Hamilton, HJ (reprint author), Univ Regina, Dept Comp Sci, 3737 Wascana Pkwy, Regina, SK S4S 0A2, Canada.	hamilton@cs.uregina.ca					AGRAWAL A, 1994, P 20 INT C VER LARG, P487; Agrawal A., 1993, P ACM SIGMOD C MAN D, P207; Agrawal A, 1996, ADV KNOWLEDGE DISCOV, P307; Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Barber B, 2001, J INTELL INF SYST, V16, P277, DOI 10.1023/A:1011276003319; Barber B., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Bayardo RJ, 1999, PROC INT CONF DATA, P188, DOI 10.1109/ICDE.1999.754924; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; BUCHTER O, 1998, P 2 PAC AS C KNOWL D, P36; Cai C. H., 1998, Proceedings. IDEAS'98. International Database Engineering and Applications Symposium (Cat. No.98EX156), DOI 10.1109/IDEAS.1998.694360; Carter CL, 1997, LECT NOTES ARTIF INT, V1263, P14; Cheung DW, 1996, IEEE T KNOWL DATA EN, V8, P911, DOI 10.1109/69.553158; Frawley W. J., 1991, Knowledge discovery in databases; Han J, 1995, P 21 INT C VER LARG, P420; HIDBER C, 1999, P ACM SIGMOD INT C M, P145, DOI 10.1145/304182.304195; Hilderman R. J., 1998, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V7, DOI 10.1142/S0218213098000111; HIPP M, 1998, P 2 EUR S PRINC DAT, P74; Kohavi R., 1998, MACH LEARN, V30, P271, DOI DOI 10.1023/A:1017181826899; KOPERSKI K., 1995, P 4 INT S LARG SPAT, P47; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Lewis DD, 1994, P 17 ANN INT ACM SIG, P3; Lin T. Y., 2002, P PAKDD, P328; Lu S., 2001, INTELL DATA ANAL, V5, P211; MANNILA H, 1994, P AAAI WORKSH KNOWL, P144; MASAND B, 1996, P 2 INT C KNOWL DISC, P195; Megiddo N., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Pei J, 2001, PROC INT CONF DATA, P433; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; SILVA SS, 1998, POLIMEROS CIENCIA TE, V2, P1; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	36	25	25	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2003	7	2					153	185		10.1023/A:1022419032620		33	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	646MT	WOS:000181039400002	
J	Garofalakis, M; Hyun, DJ; Rastogi, R; Shim, K				Garofalakis, M; Hyun, DJ; Rastogi, R; Shim, K			Building decision trees with constraints	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; classification; decision tree; branch-and-bound algorithm; constraint	PERFORMANCE	Classification is an important problem in data mining. Given a database of records, each with a class label, a classifier generates a concise and meaningful description for each class that can be used to classify subsequent records. A number of popular classifiers construct decision trees to generate class models. Frequently, however, the constructed trees are complex with hundreds of nodes and thus difficult to comprehend, a fact that calls into question an often-cited benefit that decision trees are easy to interpret. In this paper, we address the problem of constructing "simple" decision trees with few nodes that are easy for humans to interpret. By permitting users to specify constraints on tree size or accuracy, and then building the "best" tree that satisfies the constraints, we ensure that the final tree is both easy to understand and has good accuracy. We develop novel branch-and-bound algorithms for pushing the constraints into the building phase of classifiers, and pruning early tree nodes that cannot possibly satisfy the constraints. Our experimental results with real-life and synthetic data sets demonstrate that significant performance speedups and reductions in the number of nodes expanded can be achieved as a result of incorporating knowledge of the constraints into the building step as opposed to applying the constraints after the entire tree is built.	Seoul Natl Univ, Seoul, South Korea; Bell Labs, Lucent Technol, Murray Hill, NJ 07974 USA; Korea Adv Inst Sci & Technol, Taejon 305701, South Korea; Adv Informat Technol Res Ctr, Taejon, South Korea; Adv Informat Technol Ctr, Seoul, South Korea	Shim, K (reprint author), Seoul Natl Univ, Seoul, South Korea.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; ALMUALLIM H, 1996, ARTIF INTELL, V83, P346; Bishop CM, 1995, NEURAL NETWORKS PATT; BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1007/BF00993345; Breiman L, 1984, CLASSIFICATION REGRE; CHEESEMAN P, 1988, AUTOCLASS BAYESIAN C; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FAYYAD UM, 1991, THESIS U MICHIGAN; FUKUDA T, 1996, P 22 INT C VER LARG; GEHRKE J, 1998, P 24 INT C VER LARG; GEHRKE J, 1999, P 1999 ACM SIGMOD IN; Goldberg D.E., 1989, GENETIC ALGORITHMS S; HUNT E, 1996, EXPT INDUCTION; KRICHEVSKY RE, 1981, IEEE T INFORM THEORY, V27, P199, DOI 10.1109/TIT.1981.1056331; Mehta M., 1995, P 1 INT C KNOWL DISC; Mehta M., 1996, P 5 INT C EXT DAT TE; Mitchie D., 1994, MACHINE LEARNING NEU; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rastogi R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ripley B., 1996, PATTERN RECOGNITION; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rissanen J, 1989, STOCHASTIC COMPLEXIT; Shafer J., 1996, P 22 INT C VER LARG; WALLACE CS, 1993, MACH LEARN, V11, P7, DOI 10.1023/A:1022646101185; ZIHED DA, 1997, P 3 INT C KNOWL DISC	30	17	17	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2003	7	2					187	214		10.1023/A:1022445500761		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	646MT	WOS:000181039400003	
J	Rocke, DM; Dai, J				Rocke, DM; Dai, J			Sampling and subsampling for cluster analysis in data mining: With applications to sky survey data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clustering algorithm; mixture likelihood; sampling; star/galaxy classification	MULTIVARIATE LOCATION; HIGH DIMENSION; EM ALGORITHM; LIKELIHOOD; ESTIMATORS; SHAPE	This paper describes a clustering method for unsupervised classification of objects in large data sets. The new methodology combines the mixture likelihood approach with a sampling and subsampling strategy in order to cluster large data sets efficiently. This sampling strategy can be applied to a large variety of data mining methods to allow them to be used on very large data sets. The method is applied to the problem of automated star/galaxy classification for digital sky data and is tested using a sample from the Digitized Palomar Sky Survey (DPOSS) data. The method is quick and reliable and produces classifications comparable to previous work on these data using supervised clustering.	Univ Calif Davis, Ctr Image Proc & Integrated Computing, Davis, CA 95616 USA	Rocke, DM (reprint author), Univ Calif Davis, Ctr Image Proc & Integrated Computing, Davis, CA 95616 USA.		Rocke, David/I-7044-2013	Rocke, David/0000-0002-3958-7318			BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Battiti R., 1994, ORSA Journal on Computing, V6; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; DASGUPTA A, 1995, 195 U WASH DEP STAT; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Everitt B, 1981, MONOGRAPHS APPL PROB; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P471; Fayyad UM, 1997, DATA MIN KNOWL DISC, V1, P5, DOI 10.1023/A:1009715820935; FAYYAD UM, 1998, P 4 INT C KNOWL DISC, P193; FAYYAD UM, 1991, THESIS U MICHIGAN; Fraley C, 1998, 329 U WASH DEP STAT; Hawkins D.M., 1982, TOPICS APPL MULTIVAR, P303; HAWKINS DM, 1981, TECHNOMETRICS, V23, P105, DOI 10.2307/1267983; Kaufman L., 1990, FINDING GROUPS DATA; KENDALL MG, 1963, ADV THEORY STAT, V3; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; MCLACHLAN GJ, 1987, APPL STAT-J ROY ST C, V36, P318, DOI 10.2307/2347790; McLachlan GJ, 1988, MIXTURE MODELS INFER; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; MCLACHLAN GJ, 1998, MIXFIT ALGORITHM AUT; ODEWAHN S, 1998, DATA DIGITIZED PALOM; Rocke DM, 1996, J AM STAT ASSOC, V91, P1047, DOI 10.2307/2291724; Rocke DM, 1996, ANN STAT, V24, P1327, DOI 10.1214/aos/1032526972; ROCKE DM, 1998, CONSTRUCTIVE STAT ES; Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566; SMYTH P, 1996, P 2 INT C KNOWL DISC; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; WEIR N, 1995, ASTRON J, V109, P2401, DOI 10.1086/117459; WHITE RL, 1997, STAT CHALLENGES MODE, V2, P135; WOLF J, 1971, 722 STB US NAV PERS; WOODRUFF DL, 1994, J AM STAT ASSOC, V89, P888, DOI 10.2307/2290913; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060	33	8	9	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2003	7	2					215	232		10.1023/A:1022497517599		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	646MT	WOS:000181039400004	
J	Boulicaut, JF; Bykowski, A; Rigotti, C				Boulicaut, JF; Bykowski, A; Rigotti, C			Free-sets: A condensed representation of Boolean data for the approximation of frequency queries	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						condensed representations; frequent pattern discovery; association rules		Given a large collection of transactions containing items, a basic common data mining problem is to extract the so-called frequent itemsets (i.e., sets of items appearing in at least a given number of transactions). In this paper, we propose a structure called free-sets, from which we can approximate any itemset support (i.e., the number of transactions containing the itemset) and we formalize this notion in the framework of epsilon-adequate representations (H. Mannila and H. Toivonen, 1996. In Proc. of the Second International Conference on Knowledge Discovery and Data Mining (KDD'96), pp. 189-194). We show that frequent free-sets can be efficiently extracted using pruning strategies developed for frequent itemset discovery, and that they can be used to approximate the support of any frequent itemset. Experiments on real dense data sets show a significant reduction of the size of the output when compared with standard frequent itemset extraction. Furthermore, the experiments show that the extraction of frequent free-sets is still possible when the extraction of frequent itemsets becomes intractable, and that the supports of the frequent free-sets can be used to approximate very closely the supports of the frequent itemsets. Finally, we consider the effect of this approximation on association rules ( a popular kind of patterns that can be derived from frequent itemsets) and show that the corresponding errors remain very low in practice.	Inst Natl Sci Appl, Lab Ingn Syst Informat, F-69621 Villeurbanne, France	Boulicaut, JF (reprint author), Inst Natl Sci Appl, Lab Ingn Syst Informat, Batiment 501, F-69621 Villeurbanne, France.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo R. J.  Jr., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; BOULICAUT JF, IN PRESS P 4 EUR C P; Boulicaut JF, 2000, LECT NOTES ARTIF INT, V1805, P62; BYKOWSKI A, 2000, P 2000 INT WORKSH WE, P27; Fujiwara S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839449; Mannila H., 1996, P 2 INT C KNOWL DISC, P189; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; PAVLOV D, 2000, 200007 U CAL DEP INF; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases	15	94	95	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2003	7	1					5	22		10.1023/A:1021571501451		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	623LU	WOS:000179705200001	
J	Garofalakis, M; Gionis, A; Rastogi, R; Seshadri, S; Shim, K				Garofalakis, M; Gionis, A; Rastogi, R; Seshadri, S; Shim, K			XTRACT: Learning Document Type Descriptors from XML document collections	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Extensible Markup Language (XML); Document Type Descriptor (DTD); regular expressions; MDL principle	COMPLEXITY; INFERENCE	XML is rapidly emerging as the new standard for data representation and exchange on the Web. Unlike HTML, tags in XML documents describe the semantics of the data and not how it is to be displayed. In addition, an XML document can be accompanied by a Document Type Descriptor (DTD) which plays the role of a schema for an XML data collection. DTDs contain valuable information on the structure of documents and thus have a crucial role in the efficient storage of XML data, as well as the effective formulation and optimization of XML queries. Despite their importance, however, DTDs are not mandatory, and it is frequently possible that documents in XML databases will not have accompanying DTDs. In this paper, we propose XTRACT, a novel system for inferring a DTD schema for a database of XML documents. Since the DTD syntax incorporates the full expressive power of regular expressions, naive approaches typically fail to produce concise and intuitive DTDs. Instead, the XTRACT inference algorithms employ a sequence of sophisticated steps that involve: ( 1) finding patterns in the input sequences and replacing them with regular expressions to generate "general" candidate DTDs, (2) factoring candidate DTDs using adaptations of algorithms from the logic optimization literature, and ( 3) applying the Minimum Description Length (MDL) principle to find the best DTD among the candidates. The results of our experiments with real-life and synthetic DTDs demonstrate the effectiveness of XTRACT's approach in inferring concise and semantically meaningful DTD schemas for XML databases.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; Bell Labs, Murray Hill, NJ 07974 USA; Strand Genom, Bangalore 560080, Karnataka, India; Seoul Natl Univ, Seoul 151742, South Korea; AITrc, Seoul 151742, South Korea	Shim, K (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.		Gionis, Aristides/G-2225-2013	Gionis, Aristides/0000-0002-5211-112X			Abiteboul S., 1997, P 6 INT C DAT THEOR, P1; AHONEN H, 1996, THESIS U HELSINKI; AHONEN H, 1994, P 2 INT C GRAMM INF, P153; ANGLUIN D, 1978, INFORM CONTROL, V39, P337, DOI 10.1016/S0019-9958(78)90683-6; BRAY T, EXTENSIBLE MARKUP LA; Brayton R. K, 1982, ISCAS P INT S CIRC S, P49; BRAZMA A, 1993, COLT, P236; Charikar M., 1999, 40 ANN S FDN COMP SC; DEUTSCH A, 1999, P ACM SIGMOD C MAN D; FERNANDEZ M, 1997, P INT C DAT THEOR IC; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Goldman R., 1999, P 2 INT WORKSH WEB D, P25; GOLDMAN R, 1997, P 23 INT C VER LARG; HOCHBAUM DS, 1982, MATH PROGRAM, V22, P148, DOI 10.1007/BF01581035; HOPCROFT JE, 1979, INTRO AUTOMATION THE; KILPELAINEN P, 1995, 2 EUR C COMP LEARN T, P252; LAWLER EL, 1964, J ACM, V11, P283, DOI 10.1145/321229.321232; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; MEHTA M, 1995, INT C KNOWL DISC DAT; Nestorov S., 1998, P ACM SIGMOD INT C M, P295, DOI 10.1145/276304.276331; PITT L, 1989, P 1989 INT WORKSH AN, P18; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rissanen J, 1989, STOCHASTIC COMPLEXIT; SHAFER KE, 1995, P SGML 95 C BOST MA; SHANMUGASUNDARA.J, 1999, P INT C VER LARG DAT; WANG ARR, 1989, THESIS U CALIFORNIA; WIDOM J, 1999, IEEE DATA ENG B, V22, P44; Young-Lai M, 2000, MACH LEARN, V40, P111, DOI 10.1023/A:1007653929870	29	19	21	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2003	7	1					23	56		10.1023/A:1021560618289		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	623LU	WOS:000179705200002	
J	Kepner, J; Kim, R				Kepner, J; Kim, R			Cluster detection in databases: The adaptive matched filter algorithm and implementation	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						filtering; parallel processing; astronomy	LUMINOSITY FUNCTION; GALAXIES; CATALOG	Matched filter techniques are a staple of modern signal and image processing. They provide a firm foundation ( both theoretical and empirical) for detecting and classifying patterns in statistically described backgrounds. Application of these methods to databases has become increasingly common in certain fields ( e. g. astronomy). This paper describes an algorithm ( based on statistical signal processing methods), a software architecture ( based on a hybrid layered approach) and a parallelization scheme ( based on a client/server model) for finding clusters in large astronomical databases. The method has proved successful in identifying clusters in real and simulated data. The implementation is flexible and readily executed in parallel on a network of workstations.	Princeton Univ, Princeton, NJ 08544 USA	Kepner, J (reprint author), MIT, Lincoln Lab, 244 Wood St, Lexington, MA 02173 USA.						Abell G. O., 1958, ASTROPHYS J        S, V3, P211, DOI 10.1086/190036; ABELL GO, 1989, ASTROPHYS J SUPPL S, V70, P1, DOI 10.1086/191333; BAHCALL N, 1988, ARA A, V36, P631; BINGGELI B, 1988, ANNU REV ASTRON ASTR, V26, P509; BRAMEL DA, IN PRESS ASTROPHYSIC; Colley WN, 1996, ASTROPHYS J, V461, pL83, DOI 10.1086/310015; DALTON G, 1994, MNRAS, V269, P15; DASARATHY B, 1999, DATA MINING KNOWLEDG, V3696; DJORGOSKI S, 1997, P SPIE, V3164; Duda R. O., 2000, PATTERN CLASSIFICATI; Fadda D, 1998, ASTRON ASTROPHYS SUP, V127, P335, DOI 10.1051/aas:1998355; FANG LZ, 1997, P 5 ER CHAL SCH ASTR; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; GAL RR, IN PRESS ASTRONOMICA; KAWASAKI W, IN PRESS A AS; KEPNER J, IN PRESS J CLUSTER C; Kepner J, 1999, ASTROPHYS J, V517, P78, DOI 10.1086/307160; KIM, 2000, B AM ASTRONOMICAL SO, V195; LOVEDAY J, 1992, ASTROPHYS J, V390, P338, DOI 10.1086/171284; LUMSDEN SL, 1992, MON NOT R ASTRON SOC, V258, P1; Postman M, 1996, ASTRON J, V111, P615, DOI 10.1086/117811; RAMELLA N, 1998, ASTROPH9810124; SCHECHTER P, 1976, ASTROPHYS J, V203, P297, DOI 10.1086/154079; SZALAY AS, ADASS 99 C	24	1	1	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2003	7	1					57	79		10.1023/A:1021512702360		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	623LU	WOS:000179705200003	
J	Kim, W; Choi, BJ; Hong, EK; Kim, SK; Lee, D				Kim, W; Choi, BJ; Hong, EK; Kim, SK; Lee, D			A taxonomy of dirty data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						dirty data; data quality; data mining; data cleansing; data warehousing	MULTIDATABASE SYSTEMS; RELATIONAL DATABASES; DATA QUALITY; FUZZY; HETEROGENEITY	Today large corporations are constructing enterprise data warehouses from disparate data sources in order to run enterprise-wide data analysis applications, including decision support systems, multidimensional online analytical applications, data mining, and customer relationship management systems. A major problem that is only beginning to be recognized is that the data in data sources are often "dirty". Broadly, dirty data include missing data, wrong data, and non-standard representations of the same data. The results of analyzing a database/data warehouse of dirty data can be damaging and at best be unreliable. In this paper, a comprehensive classification of dirty data is developed for use as a framework for understanding how dirty data arise, manifest themselves, and may be cleansed to ensure proper construction of data warehouses and accurate data analysis. The impact of dirty data on data mining is also explored.	Cyber Database Solut Inc, Austin, TX USA; Ewha Inst Sci & Technol, Dept Comp Sci, Seoul, South Korea; Seoul Natl Univ, AITrc, Seoul, South Korea; Lucent Technol, Seoul, South Korea; Korea Adv Inst Sci & Technol, Dept Biosyst, Taejon, South Korea	Kim, W (reprint author), Cyber Database Solut Inc, Austin, TX USA.		Lee, Doheon/B-7303-2011				Ballou DP, 1999, COMMUN ACM, V42, P73, DOI 10.1145/291469.291471; Berry M. R. J., 1997, DATA MINING TECHNIQU; Berson A., 1997, DATA WAREHOUSING DAT; BUCKLES BP, 1982, FUZZY SET SYST, V7, P213, DOI 10.1016/0165-0114(82)90052-5; CODD EF, 1979, ACM T DATABASE SYST, V4, P4; Date C., 1998, RELATIONAL DATABASE; Date C. J., 2000, INTRO DATABASE SYSTE; DEY D, 1996, ACM T DATABASE SYSTE, V21; ENGLISH L. P., 1999, IMPROVING DATA WAREH; Etzion O., 1998, LECT NOTES COMPUTER, V1399; Galindo J, 2001, FUZZY SET SYST, V121, P471, DOI 10.1016/S0165-0114(99)00156-6; Gray J., 1993, T PROCESSING CONCEPT; Inmon W.H., 1996, BUILDING DATA WAREHO; INMON WH, 1999, DATA WAREHOUSE PERFO; KIM W, 1995, MODERN DATABASE SYST; KIM W, 1993, DISTRIB PARALLEL DAT, V1, P251, DOI 10.1007/BF01263333; Kim W, 1999, J OBJECT-ORIENT PROG, V12, P40; KIM W, 1991, COMPUTER, V24, P12, DOI 10.1109/2.116884; Kimball R., 1998, DATA WAREHOUSE LIFEC; LAURINI R, 1993, APIC SERIES, V37; Maimon O, 2001, FUZZY SET SYST, V117, P183, DOI 10.1016/S0165-0114(98)00294-2; OLSON J, DATA PROFILING; OOI B, 1990, LECT NOTES COMPUTER; Rizzi S., 1999, J COMPUTER SCI INFOR, V2; Schneider M., 1997, LECT NOTES COMPUTER, V1288; Silberschatz A., 1997, DATABASE SYSTEM CONC; Snodgrass R.T., 1995, TSQL2 TEMPORAL QUERY; Sozat MI, 2001, FUZZY SET SYST, V117, P161, DOI 10.1016/S0165-0114(98)00152-3; Stokes M. E., 1995, CATEGORICAL DATA ANA; Stonebraker M., 1996, OBJECT RELATIONAL DB; TRAIGER IL, 1982, ACM T DATABASE SYST, V7, P323, DOI 10.1145/319732.319734; WANG RY, 1995, IEEE T KNOWL DATA EN, V7, P623, DOI 10.1109/69.404034; Westphal C., 1998, DATA MINING SOLUTION; WILLIAMS J, 1997, TOOLS TRAVELING DATA; ZEMANKOVA M, 1985, INFORM SCIENCES, V37, P107, DOI 10.1016/0020-0255(85)90008-8; *1 LOG INC, CUST DAT QUAL BUILD; *APPL TECHN GROUP, 1998, BUILD SUCC CRM ENV; *CUTT INF CORP, 1998, MANAGE SCI, V31, P150; *IBM NUMA Q, 1999, MOD CUST REL; *SAS I INC, 1999, FIND SOL DAT MIN MAP; *TECHG 1, TECHN GUID SER PRACT; *TECHG 2, TECHN GUID SER ACH B; *TRILL SOFTW SYST, 1998, PRACT GUID ACH ENT D; *VAL TECHN INC, 5 LEG DAT CONT YOU W	44	31	31	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2003	7	1					81	99		10.1023/A:1021564703268		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	623LU	WOS:000179705200004	
J	Owen, A				Owen, A			Data squashing by empirical likelihood	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						credit scoring; database abstraction; MART; misclassification loss; reweighting		Data squashing was introduced by W. DuMouchel, C. Volinsky, T. Johnson, C. Cortes, and D. Pregibon, in Proceedings of the 5th International Conference on KDD (1999). The idea is to scale data sets down to smaller representative samples instead of scaling up algorithms to very large data sets. They report success in learning model coefficients on squashed data. This paper presents a form of data squashing based on empirical likelihood. This method reweights a random sample of data to match certain expected values to the population. The computation required is a relatively easy convex optimization. There is also a theoretical basis to predict when it will and won't produce large gains. In a credit scoring example, empirical likelihood weighting also accelerates the rate at which coefficients are learned. We also investigate the extent to which these benefits translate into improved accuracy, and consider reweighting in conjunction with boosted decision trees.	Stanford Univ, Dept Stat, Stanford, CA 94025 USA	Owen, A (reprint author), Stanford Univ, Dept Stat, Sequoia Hall, Stanford, CA 94025 USA.						Baggerly KA, 1998, BIOMETRIKA, V85, P535, DOI 10.1093/biomet/85.3.535; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Bratley P., 1987, GUIDE SIMULATION; Cochran W.G., 1977, SAMPLING TECHNIQUES; DAVIS PJ, 1984, METHODS NUMERICAL IN; DUMOUCHEL W, 1999, P 5 ACM SIGKDD INT C, P6, DOI 10.1145/312129.312184; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 1999, GREEDY FUNCTION APPR; FRIEDMAN J, 1999, ADDITIVE LOGISTIC RE; Friedman J.H., 1999, STOCHASTIC GRADIENT; HESTERBERG T, 1995, TECHNOMETRICS, V37, P185, DOI 10.2307/1269620; Lohr S. L., 1999, SAMPLING DESIGN ANAL; MADIGAN D, 2002, J DATA MINING KNOWLE, V6, P173; OWEN A, 1990, ANN STAT, V18, P90, DOI 10.1214/aos/1176347494; OWEN A, 1991, ANN STAT, V19, P1725, DOI 10.1214/aos/1176348368; QIN J, 1994, ANN STAT, V22, P300, DOI 10.1214/aos/1176325370; Ripley B.D., 1987, STOCHASTIC SIMULATIO; ROWE NC, 1983, THESIS STANFORD U; Wolff GJ, 1996, INT J NEURAL SYST, V7, P263, DOI 10.1142/S0129065796000245	19	10	10	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2003	7	1					101	113		10.1023/A:1021568920107		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	623LU	WOS:000179705200005	
J	Grabmeier, J; Rudolph, A				Grabmeier, J; Rudolph, A			Techniques of cluster algorithms in data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; cluster algorithm; Condorcet's criterion; demographic clustering		An overview of cluster analysis techniques from a data mining point of view is given. This is done by a strict separation of the questions of various similarity and distance measures and related optimization criteria for clusterings from the methods to create and modify clusterings themselves. In addition to this general setting and overview, the second focus is used on discussions of the essential ingredients of the demographic cluster algorithm of IBM's Intelligent Miner, based Condorcet's criterion.	Univ Appl Sci, D-94469 Deggendorf, Germany; Univ Bundeswehr Munchen, D-85579 Neubiberg, Germany	Grabmeier, J (reprint author), Univ Appl Sci, Edlmaierstr 6 & 8, D-94469 Deggendorf, Germany.						BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BALL GH, 1967, RADCTR67310 STANF RE; BALL GH, 1965, P AFIPS FALL JOINT C, V1, P533; BALL GH, 1965, ISODATA NOVEL TECHNI; Bigus J. P., 1996, DATA MINING NEURAL N; Bishop CM, 1995, NEURAL NETWORKS PATT; Bock H. H., 1974, AUTOMATISCHE KLASSIF; BRAVERMAN EM, 1996, AUTOMAT REM CONTR, V27, P1748; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FORTIER JJ, 1996, P MULT AN 66, P493; Graham R. L., 1989, CONCRETE MATH FDN CO; HARTUNG HJ, 1984, MULTIVARIATE STAT; Hoppner F., 1999, FUZZY CLUSTER ANAL; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jobson J. D., 1992, APPL MULTIVARIATE DA, V1; Jobson J. D., 1992, APPL MULTIVARIATE DA, V2; JOHNSON NL, 1990, CONTINUOUS UNIVARIAT, V1; Kaufman L., 1990, FINDING GROUPS DATA; Kohonen T., 1997, SELF ORG MAPS; KRISHNAIAH PR, P MULT AN 66; LU SY, 1978, IEEE T SYST MAN CYB, V8, P381, DOI 10.1109/TSMC.1978.4309979; MCLACHLAN GJ, MIXTURE MODELS; MESSATFA H, 1997, FUTURE GEN COMPUTER, V13, P149; MICHAUD P, 1985, F052 IBM CTR SCI; MICHAUD P, 1995, MAP010 IBM ECAM; MICHAUD P, 1987, APPL STOCH MODEL BUS, V3, P173, DOI 10.1002/asm.3150030305; MICHAUD P, 1982, F051 IBM CTR SCI; MICHAUD P, 1987, F084 IBM CTR SCI; Michaud P, 1997, FUTURE GENER COMP SY, V13, P135, DOI 10.1016/S0167-739X(97)00017-4; Rao C. R., 1973, LINEAR STAT INFERENC; RENYI A, 1962, WAHRSCHEINLICHKEITST; Ripley B., 1996, PATTERN RECOGNITION; Robins H., 1951, ANN MATH STAT, V22, P400; RUDOLPH A, 1999, DATA MINING ACTION S; Seber G.A.F., 1984, MULTIVARIATE OBSERVA; SPAETH H, 1984, CLUSTER ANAL ALGORIT; STEINHAUSEN D, 1977, CLUSTERANALYSE; TSYPKIN YZ, 1967, ENG CYBERNETICS USSR, V5, P70	38	82	100	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2002	6	4					303	360		10.1023/A:1016308404627		58	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	574AB	WOS:000176865200001	
J	Hsu, WH; Welge, M; Redman, T; Clutter, D				Hsu, WH; Welge, M; Redman, T; Clutter, D			High-performance commercial data mining: A multistrategy machine learning application	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						constructive induction; scalable high-performance computing; real-world decision support applications; relevance determination; genetic algorithms; software development environments for knowledge discovery in databases (KDD)	ALGORITHMS	We present an application of inductive concept learning and interactive visualization techniques to a large-scale commercial data mining project. This paper focuses on design and configuration of high-level optimization systems (wrappers) for relevance determination and constructive induction, and on integrating these wrappers with elicited knowledge on attribute relevance and synthesis. In particular, we discuss decision support issues for the application (cost prediction for automobile insurance markets in several states) and report experiments using D2K, a Java-based visual programming system for data mining and information visualization, and several commercial and research tools. We describe exploratory clustering, descriptive statistics, and supervised decision tree learning in this application, focusing on a parallel genetic algorithm (GA) system, Jenesis, which is used to implement relevance determination (attribute subset selection). Deployed on several high-performance network-of-workstation systems (Beowulf clusters), Jenesis achieves a linear speedup, due to a high degree of task parallelism. Its test set accuracy is significantly higher than that of decision tree inducers alone and is comparable to that of the best extant search-space based wrappers.	Kansas State Univ, Dept Comp & Informat Sci, Manhattan, KS 66506 USA; Univ Illinois, Natl Ctr Supercomp Applicat, Automated Learning Grp, Champaign, IL 61820 USA	Hsu, WH (reprint author), Kansas State Univ, Dept Comp & Informat Sci, Manhattan, KS 66506 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AUVIL L, 1999, DATA KNOWLEDGE D2K R; BENJAMIN D, 1990, CHANGE REPRESENTATIO; Brooks F. P., 1995, MYTHICAL MAN MONTH E; CHERKAUER KJ, 1996, P 2 INT C KNOWL DISC; CHESEMAN P, 1988, P 5 INT C MACH LEARN, P54; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DONOHO SK, 1996, UIUCDCSR1970; FAYYAD U, 1996, ADV KNOWLEDGE DISCOV, P82; Gersho A., 1992, VECTOR QUANTIZATION; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GREFENSTETTE JJ, 1990, GENESIS GENETIC ALGO; Haykin S., 1999, NEURAL NETWORKS COMP; HSU W, IN PRESS ACTIVITIES; Hsu WH, 2000, MACH LEARN, V38, P213, DOI 10.1023/A:1007694209216; HSU WH, 1999, P JOINT AAAI GECCO W; HSU WH, 1998, UIUCDCSR2063; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; JONSKE J, 1999, UNPUB COMMUNICATION; Kira K, 1992, P 10 NAT C ART INT, P129; KOHAVI R, 1998, MINESET V2 6; KOHAVI R, 1997, EUR C MACH LEARN ECM; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, THESIS STANFORD U; KOHAVI R, 1996, MCL PLUS PLUS MACHIN; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1996, A31 HELS U TECHN LAB; Kononenko Igor, 1994, P EUR C MACH LEARN; Koza J. R., 1992, GENETIC PROGRAMMING; KRISHNAMURTHY B, 1995, PRACTICAL REUSABLE U; Mitchell T. M, 1997, MACHINE LEARNING; Neal R. M., 1996, BAYESIAN LEARNING NE; PORTER J, 1998, UNPUB COMMUNICATION; PRINCIPE J, 1998, NEUROSOLUTIONS V3 02; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RAYMER ML, 1997, P 7 INT C GEN ALG IC, P561; Russell S., 1995, ARTIFICIAL INTELLIGE; SARLE WS, NEURAL NETWORK FAQ P; Sterling T., 1999, BUILD BEOWULF GUIDE	41	1	2	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2002	6	4					361	391		10.1023/A:1016352221465		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	574AB	WOS:000176865200002	
J	Liu, H; Hussain, F; Tan, CL; Dash, M				Liu, H; Hussain, F; Tan, CL; Dash, M			Discretization: An enabling technique	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						discretization; continuous feature; data mining; classification	ATTRIBUTES; SELECTION	Discrete values have important roles in data mining and knowledge discovery. They are about intervals of numbers which are more concise to represent and specify, easier to use and comprehend as they are closer to a knowledge-level representation than continuous values. Many studies show induction tasks can benefit from discretization: rules with discrete values are normally shorter and more understandable and discretization can lead to improved predictive accuracy. Furthermore, many induction algorithms found in the literature require discrete features. All these prompt researchers and practitioners to discretize continuous features before or during a machine learning or data mining task. There are numerous discretization methods available in the literature. It is time for us to examine these seemingly different methods for discretization and find out how different they really are, what are the key components of a discretization process, how we can improve the current level of research for new development as well as the use of existing methods. This paper aims at a systematic study of discretization methods with their history of development, effect on classification, and trade-off between speed and accuracy. Contributions of this paper are an abstract description summarizing existing discretization methods, a hierarchical framework to categorize the existing methods and pave the way for further development, concise discussions of representative discretization methods, extensive experiments and their analysis, and some guidelines as to how to choose a discretization method under various circumstances. We also identify some issues yet to solve and future research for discretization.	Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore	Liu, H (reprint author), Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.	hliu@asu.edu; farhad@comp.nus.edu.sg; tancl@comp.nus.edu.sg; manoranj@comp.nus.edu.sg					BAILEY TL, 1993, P INT JOINT C ART IN, P95; BREIMAN L, 1992, INT STAT REV, V60, P291, DOI 10.2307/1403680; Breiman L, 1984, CLASSIFICATION REGRE; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Cerquides J., 1997, KDD97, P139; Chan C.C., 1991, P IEEE C SYST MAN CY, P1719; Chiu D. K. Y., 1990, Journal of Experimental and Theoretical Artificial Intelligence, V2, DOI 10.1080/09528139008953718; Chmielewski M.R., 1994, 3 INT WORKSH ROUGH S, P294; CHOU P, 1991, IEEE T PATTERN ANAL, V4, P340; DOMINGOS B, 1996, MACH LEARN, P105; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; FAYYAD U, 1996, P 13 INT C MACH LEAR, P157; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; Fulton T., 1995, P 12 INT C MACH LEAR, P244; Ho K. M., 1997, KDD97 3 INT C KNOWL, P191; Holte RC, 1989, P 11 INT JOINT C ART, P813; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kerber R., 1992, P 10 NAT C ART INT, P123; KONTKAREN P, 1998, 4 INT C KNOWL DISC D, P254; LANGLEY P, 1994, P C UNC AI, P255; Langley P, 1992, P 10 NAT C ART INT, P223; LIU H, 1997, IEEE T KNOWL DATA EN, V9, P1; Liu H, 1995, PROC INT C TOOLS ART, P388; Maass W., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181016; MANTARAS RL, 1991, MACH LEARN, P103; Merz C. J., 1996, UCI REPOSITORY MACHI; OATES T, 1999, P 4 INT C KNOWL DISC, P294; Pfahringer B, 1995, P 12 INT C MACH LEAR, P456; PFAHRINGER B, 1995, ECML95, P331; QINLAN JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1988, MACH INTELL, V11, P305; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Richeldi M., 1995, P 8 EUR C MACH LEARN, P335; Schaffer C., 1994, MACH LEARN, P259; SHANNON C, 1949, MATH THEORY INFORMAT; Simon Herbert A., 1981, SCI ARTIFICIAL; Thornton C.J., 1992, TECHNIQUES COMPUTATI; Utogoff P, 1989, MACH LEARN, V4, P161; VANDEMERCKT T, 1990, MACH LEARN, P1016; Wang K, 1998, LECT NOTES ARTIF INT, V1531, P250; WEISS SM, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P626	45	234	250	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2002	6	4					393	423		10.1023/A:1016304305535		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	574AB	WOS:000176865200003	
J	Imielinski, T; Khachiyan, L; Abdulghani, A				Imielinski, T; Khachiyan, L; Abdulghani, A			Cubegrades: Generalizing association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						database mining; cubegrades; association rules; cube generation; OLAP	AGGREGATION	Cubegrades are a generalization of association rules which represent how a set of measures (aggregates) is affected by modifying a cube through specialization (rolldown), generalization (rollup) and mutation (which is a change in one of the cube's dimensions). Cubegrades are significantly more expressive than association rules in capturing trends and patterns in data because they can use other standard aggregate measures, in addition to COUNT. Cubegrades are atoms which can support sophisticated "what if" analysis tasks dealing with behavior of arbitrary aggregates over different database segments. As such, cubegrades can be useful in marketing, sales analysis, and other typical data mining applications in business. In this paper we introduce the concept of cubegrades. We define them and give examples of their usage. We then describe in detail an important task for computing cubegrades: generation of significant cubes which is analogous to generating frequent sets. A novel Grid Based Pruning (GBP) method is employed for this purpose. We experimentally demonstrate the practicality of the method. We conclude with a number of open questions and possible extensions of the work.	Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Imielinski, T (reprint author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.						ABDULGHANI A, UNPUB DATA MINING KN; Agarwal S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, VLDB, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; BaraaniDastjerdi A, 1997, DATA KNOWL ENG, V23, P97, DOI 10.1016/S0169-023X(96)00054-7; BASU S, 1997, FDN COMPUTER SCI FOC; BEYER K, 1999, P 1999 ACM SIGMOD IN, P359, DOI 10.1145/304182.304214; GRAY J, 1996, 12 IEEE INT C DAT EN, P152; Han J, 1995, P 21 INT C VER LARG, P420; Harinarayan V., 1996, P ACM SIGMOD INT C M, P205, DOI 10.1145/233269.233333; HEINTZ J, 1993, COMPUTER J, V36; IMIELINSKI T, 1999, DATA MINING KNOWLEDG; LAKSHMANAN LVS, 1999, P 1999 ACM SIGMOD IN, P157, DOI 10.1145/304182.304196; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Ross KA, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P116; Ross KA, 1998, THEOR COMPUT SCI, V193, P149, DOI 10.1016/S0304-3975(97)00011-X; Sarawagi S, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P42; SARAWAGI S, 1998, 6 INT C EXT DAT TECH, P168; Shukla A., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; VIRMANI A, 1998, THESIS RUTGERS U; *STATL PROJ, AUSTR CRED	22	24	27	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2002	6	3					219	257		10.1023/A:1015417610840		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	550LB	WOS:000175503600001	
J	Lin, Y				Lin, Y			Support vector machines and the Bayes rule in classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						support vector machine; classification; the Bayes rule; reproducing kernel; reproducing kernel Hilbert space; regularization methods		The Bayes rule is the optimal classification rule if the underlying distribution of the data is known. In practice we do not know the underlying distribution, and need to "learn" classification rules from the data. One way to derive classification rules in practice is to implement the Bayes rule approximately by estimating an appropriate classification function. Traditional statistical methods use estimated log odds ratio as the classification function. Support vector machines (SVMs) are one type of large margin classifier, and the relationship between SVMs and the Bayes rule was not clear. In this paper, it is shown that the asymptotic target of SVMs are some interesting classification functions that are directly related to the Bayes rule. The rate of convergence of the solutions of SVMs to their corresponding target functions is explicitly established in the case of SVMs with quadratic or higher order loss functions and spline kernels. Simulations are given to illustrate the relation between SVMs and the Bayes rule in other cases. This helps understand the success of SVMs in many classification studies, and makes it easier to compare SVMs and traditional statistical methods.	Univ Wisconsin, Dept Stat, Madison, WI 53706 USA	Lin, Y (reprint author), Univ Wisconsin, Dept Stat, 1210 W Dayton St, Madison, WI 53706 USA.						Boser B. E., 1992, P 5 ANN ACM WORKSH C; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; Evgeniou T., 1999, UNIFIED FRAMEWORK RE; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Kaufman L, 1999, ADVANCES IN KERNEL METHODS, P147; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; LIN Y, 2000, 1029 U WISC DEP STAT; Lin Y, 2000, ANN STAT, V28, P734, DOI 10.1214/aos/1015951996; LIN Y, 1998, THESIS U PENNSYLVANI; SHAWETAYLOR J, 1998, TR1998029 COLT; Vapnik V.N., 1995, NATURE STAT LEARNING; Wahba G., 1999, ADV KERNEL METHODS S; Wahba G., 2000, ADV LARGE MARGIN CLA; Wahba G, 1990, SPLINE MODELS OBSERV	16	94	97	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2002	6	3					259	275		10.1023/A:1015469627679		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	550LB	WOS:000175503600002	
J	Ramsey, J; Gazis, P; Roush, T; Spirtes, P; Glymour, C				Ramsey, J; Gazis, P; Roush, T; Spirtes, P; Glymour, C			Automated remote sensing with near infrared reflectance spectra: Carbonate recognition	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						reflectance spectroscopy; mineralogy; artificial intelligence; Bayes nets; TETRAD; carbonates; mars		Reflectance spectroscopy is a standard tool for studying the mineral composition of rock and soil samples and for remote sensing of terrestrial and extraterrestrial surfaces. We describe research on automated methods of mineral identification from reflectance spectra and give evidence that a simple algorithm, adapted from a well-known search procedure for Bayes nets, identifies the most frequently occurring classes of carbonates with reliability equal to or greater than that of human experts. We compare the reliability of the procedure to the reliability of several other automated methods adapted to the same purpose. Evidence is given that the procedure can be applied to some other mineral classes as well. Since the procedure is fast with low memory requirements, it is suitable for on-board scientific analysis by orbiters or surface rovers.	Carnegie Mellon Univ, Dept Philosophy, Pittsburgh, PA 15213 USA; NASA, Ames Res Ctr, Mt View, CA USA; Univ W Florida, Inst Human & Machine Cognit, Pensacola, FL 32514 USA; Carnegie Mellon Univ, Ctr Automated Learning & Discovery, Pittsburgh, PA 15213 USA	Ramsey, J (reprint author), Carnegie Mellon Univ, Dept Philosophy, Pittsburgh, PA 15213 USA.						GAFFEY SJ, 1987, J GEOPHYS RES-SOLID, V92, P1429, DOI 10.1029/JB092iB02p01429; GAZIS PR, 2001, J GEOPHYS RES, V106; GILMORE, 2000, J GEOPHY RES PLANETS, V105; Glymour C., 1999, CAUSATION COMPUTATIO; Grove C.I., 1992, JPL PUBLICATION; Hapke B., 1993, THEORY REFLECTANCE E; JOHNSON JR, 2001, J GEOPHYS RES, V106; Moody J., 2001, P 7 ACM SIGKDD C KNO, P347, DOI 10.1145/502512.502563; Pearl J., 1988, PROBABILISTIC REASON; PIETERS C, 1993, REMOTE GEOCHEMICAL A; ROBINS J, 1999, LIMITS CASUAL KNOWLE; SCHEINES R, 1994, TETRAD 2; Scheines R., 1993, CAUSATION PREDICTION; Spirtes P., 2000, CAUSATION PREDICTION; Stoker CR, 2001, J GEOPHYS RES-PLANET, V106, P7639, DOI 10.1029/1999JE001178	15	14	14	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2002	6	3					277	293		10.1023/A:1015421711749		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	550LB	WOS:000175503600003	
J	Liu, H; Motoda, H				Liu, H; Motoda, H			On issues of instance selection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material							ALGORITHMS		Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA; Osaka Univ, Inst Sci & Ind Res, Osaka, Japan	Liu, H (reprint author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aha D.W., 1997, LAZY LEARNING; BAEZAYATES R, 1999, MORDEN INFORMATION R; BLOEDORN E, 1998, FEATURE EXTRACTION C, P51; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; BREIMAN L, 1984, STAT SIGNAL PROCESSI, P191; Breiman L, 1984, CLASSIFICATION REGRE; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHANG C, 1974, IEEE T COMPUTERS, V23; Chaudhuri S., 1998, P ACM SIGMOD INT C M, P436, DOI 10.1145/276304.276343; Cochran W.G., 1977, SAMPLING TECHNIQUES; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devlin B., 1997, DATA WAREHOUSE ARCHI; Domingo C, 2002, DATA MIN KNOWL DISC, V6, P131, DOI 10.1023/A:1014091514039; DUMOUCHEL W, 1999, P 5 ACM C KNOWL DISC; Everitt B., 1974, CLUSTER ANAL; Fayyad U, 1996, ADV KNOWLEDGE DISCOV, P495; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; FREUND Y, 1994, AAAI FALL S SERIES, P85; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; HARRISJONES C, 1997, AMSCATWP97118; Hussain F., 1999, TRC699 NAT U SING SC; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; KIVINEN J, 1994, SIGMOD PODS 94, P77; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Langley P, 1996, ELEMENTS MACHINE LEA; Lewis DD, 1994, P 17 ANN INT ACM SIG, P3; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; Liu H., 1998, FEATURE SELECTION KN; Liu H, 1998, FEATURE EXTRACTION C; Madigan D, 2002, DATA MIN KNOWL DISC, V6, P173, DOI 10.1023/A:1014095614948; McCallum A., 1998, P 15 INT C MACH LEAR, P350; Mitchell T. M, 1997, MACHINE LEARNING; PIATETSKYSHAPIR.G, 1984, ACM SIGMOD C, P256; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; PROVOST F, 1999, P 5 ACM C KNOWL DISC; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; REINARTZ T, 1999, LNAI, V1623; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Scholkopf B., 1995, P 1 INT C KNOWL DISC, P252; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; SMITH P, 1998, INTO STAT; Syed N. A., 1999, P 5 ACM SIGKDD INT C, P317, DOI 10.1145/312129.312267; SZALAY A, 1999, SCI AM; Utogoff P, 1989, MACH LEARN, V4, P161; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V.N., 1995, NATURE STAT LEARNING; Weiss S. M., 1998, PREDICTIVE DATA MINI	57	55	58	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					115	130		10.1023/A:1014056429969		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600001	
J	Domingo, C; Gavalda, R; Watanabe, O				Domingo, C; Gavalda, R; Watanabe, O			Adaptive sampling methods for scaling up knowledge discovery algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; knowledge discovery; scalability; adaptive sampling; concentration bounds	ONLINE	Scalability is a key requirement for any KDD and data mining algorithm, and one of the biggest research challenges is to develop methods that allow to use large amounts of data. One possible approach for dealing with huge amounts of data is to take a random sample and do data mining on it, since for many data mining applications approximate answers are acceptable. However, as argued by several researchers, random sampling is difficult to use due to the difficulty of determining an appropriate sample size. In this paper, we take a sequential sampling approach for solving this difficulty, and propose an adaptive sampling method that solves a general problem covering many actual problems arising in applications of discovery science. An algorithm following this method obtains examples sequentially in an on-line fashion, and it determines from the obtained examples whether it has already seen a large enough number of examples. Thus, sample size is not fixed a priori; instead, it adaptively depends on the situation. Due to this adaptiveness, if we are not in a worst case situation as fortunately happens in many practical applications, then we can solve the problem with a number of examples much smaller than required in the worst case. We prove the correctness of our method and estimates its efficiency theoretically. For illustrating its usefulness, we consider one concrete task requiring sampling, provide an algorithm based on our method, and show its efficiency experimentally.	Tokyo Inst Technol, Dept Math & Comp Sci, Tokyo 152, Japan; Univ Politecn Catalunya, Dept LSI, Barcelona, Spain	Domingo, C (reprint author), Tokyo Inst Technol, Dept Math & Comp Sci, Tokyo 152, Japan.						Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; DOMINGO C, 1999, C138 TOK I TECHN DEP; Domingo C, 1998, LECT NOTES ARTIF INT, V1532, P150; DOMINGO C, 2000, C139 TOK I TECHN DEP; DOMINGO C, 2000, IN PRESS P 4 PAC AS; DOMINGO C, 1999, C126 TOK I TECHN DEP; Dougherty J, 1995, P 12 INT C MACH LEAR; Fayad U.M., 1993, P 13 INT JOINT C ART, P1022; Feller W, 1950, INTRO PROBABILITY TH; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; JOHN GH, 1996, P 2 ING C KNOWL DISC; Kearns M. J., 1994, INTRO COMPUTATIONAL; KEOGH E, 1998, UCI REPOSITORY MACHI; Kivinen J., 1994, Proceedings of the Thirteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1994, DOI 10.1145/182591.182601; LIPTON RJ, 1993, THEOR COMPUT SCI, V116, P195, DOI 10.1016/0304-3975(93)90224-H; LIPTON RJ, 1995, J COMPUT SYST SCI, V51, P18, DOI 10.1006/jcss.1995.1050; PROVOST F, 1999, P 5 INT C KNOWL DISC; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Wald A, 1947, WILEY MATH STAT SERI; WANG M, 1998, P ACM SIGMOD WORKSH	21	28	30	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					131	152		10.1023/A:1014091514039		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600002	
J	Brighton, H; Mellish, C				Brighton, H; Mellish, C			Advances in instance selection for instance-based learning algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						instance-based learning; instance selection; forgetting; pruning	NEAREST-NEIGHBOR RULE; CLASSIFICATION	The basic nearest neighbour classifier suffers from the indiscriminate storage of all presented training instances. With a large database of instances classification response time can be slow. When noisy instances are present classification accuracy can suffer. Drawing on the large body of relevant work carried out in the past 30 years, we review the principle approaches to solving these problems. By deleting instances, both problems can be alleviated, but the criterion used is typically assumed to be all encompassing and effective over many domains. We argue against this position and introduce an algorithm that rivals the most successful existing algorithm. When evaluated on 30 different problems, neither algorithm consistently outperforms the other: consistency is very hard. To achieve the best results, we need to develop mechanisms that provide insights into the structure of class definitions. We discuss the possibility of these mechanisms and propose some initial measures that could be useful for the data miner.	Univ Edinburgh, Dept Theoret & Appl Linguist, Language Evolut & Computat Res Unit, Edinburgh EH8 9LL, Midlothian, Scotland; Univ Edinburgh, Dept Artificial Intelligence, Edinburgh EH1 1HN, Midlothian, Scotland	Brighton, H (reprint author), Univ Edinburgh, Dept Theoret & Appl Linguist, Language Evolut & Computat Res Unit, Edinburgh EH8 9LL, Midlothian, Scotland.	henryb@ling.ed.ac.uk; chrism@dai.ed.ac.uk	Brighton, Henry/A-3504-2011				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; BRIGHTON H, 1996, THESIS U EDINBURGH S; BRIGHTON H, 1997, THESIS U EDINBURGH S; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; BRIGHTON H, 1997, UNPUB GEOMETRIC CRIT; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; Cameron-Jones R. M., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; DAELEMANS W, 1997, P 9 EUR C MACH LEARN, P29; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Holte RC, 1989, P 11 INT JOINT C ART, P813; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; Kolodner J. L., 1993, CASE BASED REASONING; MARKOVITCH S, 1993, MACH LEARN, V10, P113, DOI 10.1007/BF00993503; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Salganicoff M., 1993, P 10 INT C MACH LEAR, P276; SALZBERG S, 1991, MACH LEARN, V6, P227; Scott P. D., 1988, P 5 INT C MACH LEARN, P459; Sebban M, 1999, LECT NOTES ARTIF INT, V1704, P184; SMYTH B, 1995, INT JOINT C ART INT, V1, P377; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VANDENBOSCH A, 1998, P NEMLAP3 CONLL98, P195, DOI 10.3115/1603899.1603933; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WILSON DR, 1997, MACH LEARN P 14 INT; Zhang J., 1992, P 9 INT MACH LEARN C, P470	32	145	151	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					153	172		10.1023/A:1014043630878		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600003	
J	Madigan, D; Raghavan, N; Dumouchel, W; Nason, M; Posse, C; Ridgeway, G				Madigan, D; Raghavan, N; Dumouchel, W; Nason, M; Posse, C; Ridgeway, G			Likelihood-based data squashing: A modeling approach to instance construction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						instance construction; data compression		Squashing is a lossy data compression technique that preserves statistical information. Specifically, squashing compresses a massive dataset to a much smaller one so that outputs from statistical analyses carried out on the smaller (squashed) dataset reproduce outputs from the same statistical analyses carried out on the original dataset. Likelihood-based data squashing (LDS) differs from a previously published squashing algorithm insofar as it uses a statistical model to squash the data. The results show that LDS provides excellent squashing performance even when the target statistical analysis departs from the model used to squash the data.	Rutgers State Univ, Piscataway, NJ 08855 USA; AT&T Labs Res, Shannon Lab, Florham Pk, NJ USA; Univ Washington, Dept Biostat, Seattle, WA 98195 USA	Madigan, D (reprint author), Rutgers State Univ, Piscataway, NJ 08855 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BOX CEP, 1978, STAT EXPT INTRO DESI; Box G. E. P., 1987, EMPIRICAL MODEL BUIL; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; BREIMAN L, 1984, STAT SIGNAL PROCESSI, P191; Catlett J., 1991, P 8 INT WORKSH MACH, P596; DUMOUCHEL W, 1999, P 5 ACM SIGKDD INT C, P6, DOI 10.1145/312129.312184; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; Gibson GA, 1996, ACM COMPUT SURV, V28, P779, DOI 10.1145/242223.242300; LAWLESS JF, 1978, BIOMETRICS, V34, P318, DOI 10.2307/2530022; PROVOST F, 1989, J DATA MINING KNOWLE, V3, P131; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Syed N. A., 1999, P 5 ACM C KNOWL DISC, P272, DOI 10.1145/312129.312245; VENABLES WN, 1997, MODERN APPL STAT SPL; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	15	16	16	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					173	190		10.1023/A:1014095614948		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600004	
J	Reinartz, T				Reinartz, T			A unifying view on instance selection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data reduction; focusing; sampling; instance selection		In this paper, we consider instance selection as an important focusing task in the data preparation phase of knowledge discovery and data mining. Focusing generally covers all issues related to data reduction. First of all, we define a broader perspective on focusing tasks, choose instance selection as one particular focusing task, and outline the specification of concrete evaluation criteria to measure success of instance selection approaches. Thereafter, we present a unifying framework that covers existing approaches towards solutions for instance selection as instantiations. We describe specific examples of instantiations of this framework and discuss their strengths and weaknesses. Then, we outline an enhanced framework for instance selection, generic sampling, and summarize example evaluation results for several different instantiations of its implementation. Finally, we conclude with open issues and research challenges for instance selection as well as focusing in general.	DaimlerChrysler AG, Res & Technol, D-89013 Ulm, Germany	Reinartz, T (reprint author), DaimlerChrysler AG, Res & Technol, FT3-KL,POB 2360, D-89013 Ulm, Germany.	thomas.reinartz@daimlerchrysler.com					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aha DW, 1996, LEARNING DATA, P199; BARREIS ER, 1989, EXEMPLAR BASED KNOWL; CHAPMAN P, 1999, CRISP DM PROCESS MOD; Cochran W.G., 1977, SAMPLING TECHNIQUES; DATTA P, 1995, P 12 INT C MACH LEAR, P158; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; DUMOUCHEL W, 1999, P 5 ACM SIGKDD INT C, P6, DOI 10.1145/312129.312184; Fayyad U, 1996, P 2 INT C KNOWL DISC, P367; GENARI JH, 1989, 8938 U CAL; Hartigan J.A., 1975, CLUSTERING ALGORITHM; John G. H., 1994, P 11 INT C MACH LEAR, P121; KOHAVI R, 1996, DATA MINING USING ML; LINDE Y, 1980, IEEE T COMMUN, V28, P85; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Reinartz T, 1998, LECT NOTES ARTIF INT, V1510, P423; REINARTZ T, 1997, P ISI 97 SAT C IND S, P137; REINARTZ T, 1999, LNAI, V1623; Scheaffer RL, 1996, ELEMENTARY SURVEY SA; SEN S, 1995, P 14 INT JOINT C ART, V1, P725; Skalak D. B., 1993, P AAAI 93 CAS BAS RE, P64; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Smyth B., 1995, P INTL JOINT C ART I, V1, P377; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; WETTSCHERECK D, 1995, AIC95012 NAV CTR APP; Zhang J., 1992, P 9 INT MACH LEARN C, P470	28	28	28	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					191	210		10.1023/A:1014047731786		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600005	
J	Kohavi, R; Masand, B; Spiliopoulou, M; Srivastava, J				Kohavi, R; Masand, B; Spiliopoulou, M; Srivastava, J			Web mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Blue Martini Software, San Mateo, CA 94403 USA; Verilytics, Burlington, MA 01803 USA; Leipzig Grad Sch Management, HHL, Dept Business E, D-04109 Leipzig, Germany; Univ Minnesota, Minneapolis, MN 55455 USA	Kohavi, R (reprint author), Blue Martini Software, 2600 Campus Dr, San Mateo, CA 94403 USA.						KOHAVI R, 2001, P 7 ACM SIGKDD INT C; Kosala R., 2000, ACM SIGKDD EXPLORATI, V2; Masand B, 2000, LNAI, V1836; PINE BJ, EXPERIENCE EC; SRIVASTAVA J, 2000, ACM SIGKDD EXPLORATI, V1	5	1	2	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2002	6	1					5	8		10.1023/A:1013266218887		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	503VK	WOS:000172822000001	
J	Tan, PN; Kumar, V				Tan, PN; Kumar, V			Discovery of Web robot sessions based on their navigational patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						web usage mining; web robot detection; classification; data mining	AGENTS	Web robots are software programs that automatically traverse the hyperlink structure of the World Wide Web in order to locate and retrieve information. There are many reasons why it is important to identify visits by Web robots and distinguish them from other users. First of all, e-commerce retailers are particularly concerned about the unauthorized deployment of robots for gathering business intelligence at their Web sites. In addition, Web robots tend to consume considerable network bandwidth at the expense of other users. Sessions due to Web robots also make it more difficult to perform clickstream analysis effectively on the Web data. Conventional techniques for detecting Web robots are often based on identifying the IP address and user agent of the Web clients. While these techniques are applicable to many well-known robots, they may not be sufficient to detect camouflaged and previously unknown robots. In this paper, we propose an alternative approach that uses the navigational patterns in the click-stream data to determine if it is due to a robot. Experimental results on our Computer Science department Web server logs show that highly accurate classification models can be built using this approach. We also show that these models are able to discover many camouflaged and previously unidentified robots.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Tan, PN (reprint author), Univ Minnesota, Dept Comp Sci, 200 Union St SE, Minneapolis, MN 55455 USA.						Balabanovic M., 1995, P AAAI SPRING S INF, P13; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Clark D, 2000, COMPUTER, V33, P18, DOI 10.1109/MC.2000.820034; COOLEY R, 1999, THESIS U MINNESOTA; Cooley R., 1999, Knowledge and Information Systems, V1; EICHMANN D, 1995, COMPUT NETWORKS ISDN, V28, P127, DOI 10.1016/0169-7552(95)00107-3; Graham L, 2000, IEEE SOFTWARE, V17, P106, DOI 10.1109/52.895177; GRAY M, 1993, MEASURING GROWTH WEB; JACKSON S, 1998, BUILDING BETTER SPID; KEPHART J, 1999, AGENTS, P378; KOLAR C, 1996, ROBOT EXCLUSION STAN; KOSTER M, 1994, GUIDELINES ROBOT WRI; Koster M., 1995, ConneXions, V9; Koster MA, 1994, STANDARD ROBOT EXCLU; Lieberman H., 1995, P 14 INT JOINT C ART, P924; PIROLLO P, 1996, CHI 96 P C HUM FACT, P118; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; ROSENSTEIN M, 2000, ACM C EL COMM MINN M, P38; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; YOON M, 2000, WEB ROBOT DETECTION	20	62	72	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2002	6	1					9	35		10.1023/A:1013228602957		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	503VK	WOS:000172822000002	
J	Berendt, B				Berendt, B			Using site semantics to analyze, visualize, and support navigation	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						web usage mining; sequence mining; visualization; statistical techniques	WORLD-WIDE-WEB; PATTERNS; SYSTEMS; TOOL	To satisfy potential customers of a Web site and to lead them to the goods offered by the site, one should support them in the course of navigation they have embarked on. This paper presents the tool STRATDYN, developed as an add-on module to the Web Usage Miner WUM. WUM not only discovers frequent sequences, but it also allows the inspection of the different paths through the site. STRATDYN extends these capabilities: It tests differences between navigation patterns, described by a number of measures of success and strategy, for statistical significance. This can help to single out the relevant differences between users' behaviors, and it can determine whether a change in the site's design has had the desired effect. STRATDYN also exploits the site's semantics in the classification of navigation behavior and in the visualization of results, displaying navigation patterns as alternative paths through a strategy space. This helps to understand the Web logs, and to communicate analysis results to non-experts. Two case studies investigate search in an online catalog and interaction with an electronic shopping agent in an online store. They show how the results of analysis can lead to proposals for improving a Web site. These highlight the importance of investigating measures not only of eventual success, but also of process, to help users navigate towards the site's offers.	Humboldt Univ, Fac Econ, Inst Informat Syst, D-10178 Berlin, Germany	Berendt, B (reprint author), Humboldt Univ, Fac Econ, Inst Informat Syst, Spandauer Str 1, D-10178 Berlin, Germany.	berendt@wiwi.hu-berlin.de					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; ANNACKER D, 2001, P 14 BLED EL COMM C; BAUMGARTEN M, 2000, ADV WEB USAGE ANAL U, P74; Berendt B., 1998, HERAUSFORDERUNGEN WI, P63; Berendt B, 2000, VLDB J, V9, P56, DOI 10.1007/s007780050083; Berendt B, 2001, BEHAV RES METH INS C, V33, P243, DOI 10.3758/BF03195371; Berry M. R. J., 1997, DATA MINING TECHNIQU; Berthon P, 1996, J ADVERTISING RES, V36, P43; BORGES J, 2000, ADV WEB USAGE ANAL U, P92; Bortz J, 1993, STAT SOZIALWISSENSCH; BRESHAHA.JL, 1966, PSYCHOL BULL, V66, P252, DOI 10.1037/h0023728; BRIN S, ACM SIGMOD INT C MAN, P265; Card S. K., 1999, READINGS INFORMATION, P1; Chi E., 2000, P C HUM FACT COMP SY, P161, DOI 10.1145/332040.332423; Cooley R., 1999, J KNOWLEDGE INFORM S, V1, P5; Cooley R, 2000, THESIS U MINNESOTA; COOLEY R, 2000, ADV WEB USAGE ANAL U, P163; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; Cugini J., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, DOI 10.1109/DEXA.1999.795175; Fu WT, 2001, BEHAV RES METH INS C, V33, P149, DOI 10.3758/BF03195360; Green M, 1998, PERCEPTUAL SCI MULTI; Han J., 2001, DATA MINING CONCEPTS; Jones T., 1995, Journal of Educational Multimedia and Hypermedia, V4; MENASCE DA, 1999, P ACM C EL COMM DENV; Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169; Oberlander J, 1996, PROCEEDINGS OF THE EIGHTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P201; OLSON GM, 1994, HUM-COMPUT INTERACT, V9, P427, DOI 10.1207/s15327051hci0903&4_6; Page L., 1998, PAGERANK CITATION RA; SPIEKERMANN S, 2000, P 3 INT C TEL EL COM, P387; SPIEKERMANN S, 2001, E FINANCE INNOVATIVE, P129; Spiliopoulou M, 1999, COMPUT SYST SCI ENG, V14, P113; SPILIOPOULOU M, 2000, ADV WEB USAGE ANAL U; Spiliopoulou M, 2001, DATA MIN KNOWL DISC, V5, P85, DOI 10.1023/A:1009800113571; SPILIOPOULOU M, 2000, ADV WEB USAGE ANAL U, P142; Spiliopoulou M., 1999, P EDBT WORKSH WEBDB, P184; SPILIOPOULOU M, 2001, HDB DATA MINING MARK, P855; SRIKANT R, 1996, MINING SEQUENTIAL PA, P3; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; WANG K, 1997, INTELLIGENT INFORMAT, V9, P8	40	21	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2002	6	1					37	59		10.1023/A:1013280719795		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	503VK	WOS:000172822000003	
J	Mobasher, B; Dai, H; Luo, T; Nakagawa, M				Mobasher, B; Dai, H; Luo, T; Nakagawa, M			Discovery and evaluation of aggregate usage profiles for web personalization	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Web usage mining; clustering; personalization; collaborative filtering; data mining		Web usage mining, possibly used in conjunction with standard approaches to personalization such as collaborative filtering, can help address some of the shortcomings of these techniques, including reliance on subjective user ratings, lack of scalability, and poor performance in the face of high-dimensional and sparse data. However, the discovery of patterns from usage data by itself is not sufficient for performing the personalization tasks. The critical step is the effective derivation of good quality and useful (i.e., actionable) "aggregate usage profiles" from these patterns. In this paper we present and experimentally evaluate two techniques, based on clustering of user transactions and clustering of pageviews, in order to discover overlapping aggregate profiles that can be effectively used by recommender systems for real-time Web personalization. We evaluate these techniques both in terms of the quality of the individual profiles generated, as well as in the context of providing recommendations as an integrated part of a personalization engine. In particular, our results indicate that using the generated aggregate profiles, we can achieve effective personalization at early stages of users' visits to a site, based only on anonymous clickstream data and without the benefit of explicit input by these users or deeper knowledge about them.	Depaul Univ, Sch Comp Sci Telecommun & Informat Syst, Ctr Web Intelligence, Chicago, IL 60604 USA	Mobasher, B (reprint author), Depaul Univ, Sch Comp Sci Telecommun & Informat Syst, Ctr Web Intelligence, Chicago, IL 60604 USA.						AGARWAL R, 1999, P HIGH PERF DAT MIN; Agrawal R., 1994, P 20 INT C VER LARG; AGRAWAL R, 1995, P INT C DAT ENG ICDE; BANERJEE A, 2001, P WEB MIN WORKSH 1 S; BRIN S, 1997, P ACM SIGMOD INT C M; BUCHNER A, 1999, SIGMOD REC, V4, P27; Charniak E., 1996, STAT LANGUAGE LEARNI; COOLEY R, 1999, P WORKSH WEB US AN U; COOLEY R, 1999, J KNOWLEDGE INFORMAT, V1, P1; HAN EH, 1998, IEEE B TECHNICAL COM, V21, P1; HAN EH, 1999, J ARTIFICIAL INTELLI, V13, P365; HAN EH, 1997, P SIGMOD 97 WORKSH R; Herlocker J. L., 1999, P 1999 C RES DEV INF; KARYPIS G, 2000, 00016 U MINN DEP COM; KONSTAN J, 1997, COMMUN ACM, V40, P3; LEWIS D, 1994, P 17 ANN ACM SIGIR C, V3, P12; MOBASHER B, 1999, IEEE KNOWL DAT ENG W; MOBASHER B, 2000, COMMUN ACM, V43, P8; MOBASHER B, 1999, P 9 WORKSH INF TECHN; Nasraoui O., 1999, P 8 INT FUZZ SYST AS; OCONNER M, 1999, P ACM SIGIR WORKSH R; Perkowitz M., 1998, P 15 NAT C ART INT M; SARWAR BM, 2000, P 2 ACM E COMM C EC; Schechter S., 1998, P 7 INT WORLD WID WE; SHAHABI C, 1997, P WORKSH RES ISS DAT; SHARDANAND U, 1995, P ACM CHI C CHI95; SPILIOPOULOU M, 1999, LNCS, V1590; SPILIOPOULOU M, 1999, P WORKSH WEB US AN U; Srivastava J, 2000, SIGKDD EXPLOR NEWSL, V1, P2; YAN TW, 1996, P 5 INT WORLD WID WE; YU PS, 1999, P INT C DAT SYST ADV; ZAIANE O, 1998, ADV DIGITAL LIB, P19	32	113	119	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2002	6	1					61	82		10.1023/A:1013232803866		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	503VK	WOS:000172822000004	
J	Lin, WY; Alvarez, SA; Ruiz, C				Lin, WY; Alvarez, SA; Ruiz, C			Efficient adaptive-support association rule mining for recommender systems	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; efficient association rule mining; e-commerce; recommender systems; adaptive computation		Collaborative recommender systems allow personalization for e-commerce by exploiting similarities and dissimilarities among customers' preferences. We investigate the use of association rule mining as an underlying technology for collaborative recommender systems. Association rules have been used with success in other domains. However, most currently existing association rule mining algorithms were designed with market basket analysis in mind. Such algorithms are inefficient for collaborative recommendation because they mine many rules that are not relevant to a given user. Also, it is necessary to specify the minimum support of the mined rules in advance, often leading to either too many or too few rules; this negatively impacts the performance of the overall system. We describe a collaborative recommendation technique based on a new algorithm specifically designed to mine association rules for this purpose. Our algorithm does not require the minimum support to be specified in advance. Rather, a target range is given for the number of rules, and the algorithm adjusts the minimum support for each user in order to obtain a ruleset whose size is in the desired range. Rules are mined for a specific target user, reducing the time required for the mining process. We employ associations between users as well as associations between items in making recommendations. Experimental evaluation of a system based on our algorithm reveals performance that is significantly better than that of traditional correlation-based approaches.	Microsoft Corp, Mt View, CA 94043 USA; Boston Coll, Dept Comp Sci, Chestnut Hill, MA 02467 USA; Worcester Polytech Inst, Dept Comp Sci, Worcester, MA 01609 USA	Lin, WY (reprint author), Microsoft Corp, SVC-3 2955,1065 La Ave, Mt View, CA 94043 USA.						Agarwal R., 1994, P 20 INT C VER LARG, P487; Agarwal R. C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347114; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Billsus D, 1998, P 15 INT C MACH LEAR; Breese J, 1998, P 14 C UNC ART INT M; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; COOLEY R, 1999, P WORKSH WEB US AN U; COOLEY R, 1997, 97021 TR U MINN DEP; FU X, 2000, P 2000 INT C INT US, P106, DOI 10.1145/325737.325796; HAJEK P, 1977, INT J MAN MACH STUD, V9, P415, DOI 10.1016/S0020-7373(77)80011-4; HAJEK P, 1966, COMPUTING, V1, P293, DOI 10.1007/BF02345483; Liu B, 1998, P 4 INT C KNOWL DISC, P80; McJones P., 1997, EACHMOVIE COLLABORAT; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Sarwar B, 2001, THESIS U MINNESOTA; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Srikant R., 1993, P ACM SIGMOD C MAN D, P207, DOI DOI 10.1145/170035.170072; SRIKANT R, 1996, P 1996 ACM SIGMOD C; Srivastava J., 1997, P 9 IEEE INT C TOOLS; Webb G. I., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347112	21	103	120	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2002	6	1					83	105		10.1023/A:1013284820704		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	503VK	WOS:000172822000005	
J	Kohavi, R; Provost, F				Kohavi, R; Provost, F			Applications of data mining to electronic commerce	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Blue Martini Software, San Mateo, CA 94403 USA; NYU, New York, NY 10012 USA	Kohavi, R (reprint author), Blue Martini Software, 2600 Campus Dr, San Mateo, CA 94403 USA.						Adomavicius G, 2001, DATA MIN KNOWL DISC, V5, P33, DOI 10.1023/A:1009839827683; Provost F, 1998, MACH LEARN, V30, P127, DOI 10.1023/A:1007442505281; Langley P., 1995, Communications of the ACM, V38, DOI 10.1145/219717.219768; Lawrence RD, 2001, DATA MIN KNOWL DISC, V5, P11, DOI 10.1023/A:1009835726774; Moore G.A., 1995, CROSSING CHASM MARKE; PAZZANI MJ, 2000, IEEE INTELLIGENT MAR, P10; PIATETSKYSHAPIR. G, 1996, P 2 INT C KNOWL DISC, P89; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; Spiliopoulou M, 2001, DATA MIN KNOWL DISC, V5, P85, DOI 10.1023/A:1009800113571; Underhill P., 2000, WHY WE BUY SCI SHOPP	10	21	23	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					5	10		10.1023/A:1009840925866		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900001	
J	Lawrence, RD; Almasi, GS; Kotlyar, V; Viveros, MS; Duri, SS				Lawrence, RD; Almasi, GS; Kotlyar, V; Viveros, MS; Duri, SS			Personalization of supermarket product recommendations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						recommender systems; personalization; collaborative filtering; data mining; clustering; associations; pervasive computing		We describe a personalized recommender system designed to suggest new products to supermarket shoppers. The recommender functions in a pervasive computing environment, namely, a remote shopping system in which supermarket customers use Personal Digital Assistants (PDAs) to compost and transmit their orders to the store, which assembles them for subsequent pickup. The recommender is meant to provide an alternative source of new ideas for customers who now visit the store less frequently. Recommendations are generated by matching products to customers based on the expected appeal of the product and the previous spending of the customer. Associations mining in the product domain is used to determine relationships among product classes for use in characterizing the appeal of individual products. Clustering in the customer domain is used to identify groups of shoppers with similar spending histories. Cluster-specific lists of popular products are then used as input to the matching process. The recommender is currently being used in a pilot program with several hundred customers. Analysis of results to date have shown a 1.8% boost in program revenue as a result of purchases made directly from the list of recommended products. A substantial fraction of the accepted recommendations are from product classes new to the customer, indicating a degree of willingness to expand beyond present purchase patterns in response to reasonable suggestions.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Heights, NY 10598 USA	Lawrence, RD (reprint author), IBM Corp, Thomas J Watson Res Ctr, POB 218, Yorktown Heights, NY 10598 USA.						Aggarwal C. C., 1999, KNOWLEDGE DISCOVERY, P201; Agrawal R., 1994, P 20 INT C VER LARG; Almasi G. S., 2000, Proceedings of the Fifth International Conference on the Practical Application of Intelligent Agent and Multi Agent Technology; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Borchers A, 1998, COMPUTER, V31, P106, DOI 10.1109/2.666847; Everitt B. S., 1993, CLUSTER ANAL; Kohonen Teuvo, 1995, SELF ORG MAPS; KONSTAN J, 1997, COMMUNICATIONS ACM, V40; KOTLYAR V, 1999, P 10 INT C DAT EXP S, V1677; Lawrence RD, 1999, DATA MIN KNOWL DISC, V3, P171, DOI 10.1023/A:1009817804059; MICHAUD P, 1999, FUTURE GENERATION CO, V13; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; ROBBINS H, 1975, INTRO STAT; SALTON J, 1983, INTRO MODERN INFORMA; SALTON J, 1989, AUTOMATIC TEXT PROCE; SHARDANAND U, 1995, P CHI 95, P202; UNGAR LH, 1998, P 1988 AAAI WORKSH R	18	65	71	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					11	32		10.1023/A:1009835726774		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900002	
J	Adomavicius, G; Tuzhilin, A				Adomavicius, G; Tuzhilin, A			Expert-driven validation of rule-based user models in personalization applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						personalization; profiling; rule discovery; post-analysis; validation	KNOWLEDGE DISCOVERY; ASSOCIATION RULES	In many e-commerce applications, ranging from dynamic Web content presentation, to personalized ad targeting, to individual recommendations to the customers, it is important to build personalized profiles of individual users from their transactional histories. These profiles constitute models of individual user behavior and can be specified with sets of rules learned from user transactional histories using various data mining techniques. Since many discovered rules can be spurious, irrelevant, or trivial, one of the main problems is how to perform post-analysis of the discovered rules, i.e., how to validate user profiles by separating "good" rules from the "bad." This validation process should be done with an explicit participation of the human expert. However, complications may arise because there can be very large numbers of rules discovered in the applications that deal with many users, and the expert cannot perform the validation on a rule-by-rule basis in a reasonable period of time. This paper presents a framework for building behavioral profiles of individual users. It also introduces a new approach to expert-driven validation of a very large number of rules pertaining to these users. In particular, it presents several types of validation operators, including rule grouping, filtering, browsing, and redundant rule elimination operators, that allow a human expert validate many individual rules at a time. By iteratively applying such operators, the human expert can validate a significant part of all the initially discovered rules in an acceptable time period. These validation operators were implemented as a part of a one-to-one profiling system. The paper also presents a case study of using this system for validating individual user rules discovered in a marketing application.	NYU, Courant Inst Math Sci, Dept Comp Sci, New York, NY 10012 USA; NYU, Stern Sch Business, Dept Informat Syst, New York, NY 10012 USA	Adomavicius, G (reprint author), NYU, Courant Inst Math Sci, Dept Comp Sci, 251 Mercer St, New York, NY 10012 USA.						ADOMAVICIUS G, 1999, P 5 ACM SIGKDD INT C; ADOMAVICIUS G, 1997, P 3 INT C KNOWL DISC; AGGARWAL C, 1998, P 4 INT C KNOWL DISC; AGGARWAL CC, 1998, P 14 INT C DAT ENG; AGRAWAL R, 1996, ADV KNOWLEDGE DISCOV, pCH12; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Allen C., 1998, INTERNET WORLD GUIDE; BAUDISCH P, 1999, CHI 99 WORKSH INT RE; Bayardo R. J., 1999, P 5 ACM SIGKDD INT C; BAYARDO RJ, 1999, P 15 INT C DAT ENG; BRACHMAN RJ, 1996, ADV KNOWLEDGE DISCOV, pCH2; Breiman L, 1984, CLASSIFICATION REGRE; BRIN S, 1997, P ACM SIGMOD C; BRUNK C, 1997, P 3 INT C KNOWL DISC; CHAN PK, 1999, WORKSH WEB US AN US; Cheung DW, 1996, P 1996 INT C DAT ENG; Clearwater SH, 1990, P 2 INT IEEE C TOOLS; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; FAWCETT T, 1996, P 2 INT C KNOWL DISC; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FAYYAD UM, 1996, ADV KNOWLEDGE DISCOV, pCH1; FELDMAN R, 1997, P WORKSH RES ISS DAT; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; GOETHALS B, 1999, P 1999 ACM SIGMOD WO; Hagel J., 1999, NET WORTH SHAPING MA; HAGEL J, 1999, COMMUNICATION   1116; HAN J, 1996, P SIGMOD WORKSH RES; Imielinski T, 1999, DATA MIN KNOWL DISC, V3, P373, DOI 10.1023/A:1009816913055; KAUTZ H, 1998, 1988 WORKSHOP TECH R; KLEMETTINEN M, 1994, P 3 INT C INF KNOWL; Lee Y, 1998, MACH LEARN, V30, P217, DOI 10.1023/A:1007404308006; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Liu B., 1999, P 5 ACM SIGKDD INT C; LIU B, 1997, P 3 INT C KNOWL DISC; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; Meo R, 1998, DATA MIN KNOWL DISC, V2, P195, DOI 10.1023/A:1009774406717; Morimoto Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; MORISHITA S, 1998, P 1 INT C DISC SCI; PADMANABHAN B, 1998, P 4 INT C KNOWL DISC; Padmanabhan B, 1999, DECIS SUPPORT SYST, V27, P303, DOI 10.1016/S0167-9236(99)00053-6; PEPPERS D, 1993, ONE ONE FUTURE; PIATETSKYSHAPIR.G, 1994, P AAAI 94 WORKSH KNO; PROVOST F, 1998, TUTORIAL 4 INT C KNO; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SAHAR S, 1999, P 5 ACM SIGKDD INT C; SHEN WM, 1996, ADV KNOWLEDGE DISCOV, pCH15; SILBERSCHATZ A, 1996, P SIGMOD WORKSH RES; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; SOBOROFF I, 1999, ACM SIGIR 99 WORKSH; Srikant R., 1996, THESIS U WISCONSIN M; Srikant R., 1995, P 21 INT C VER LARG; SRIKANT R, 1997, P 3 INT C KNOWL DISC; STEDMAN C, 1997, COMPUTERWORLD, V31; SUZUKI E, 1997, P 3 INT C KNOWL DISC; THOMAS S, 1997, P 3 INT C KNOWL DISC; TOIVONEN H, 1995, ECML 95 WORKSH STAT; TUZHILIN A, 1996, IS9626 NEW YORK U ST; TUZHILIN A, 1999, CHI 99 WORKSH INT RE; WANG K, 1998, P 4 INT C KNOWL DISC; *CACM, 1997, COMMUN ACM, V40, P56; 1999, PERS SUMM SAN FRANC	61	43	49	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					33	58		10.1023/A:1009839827683		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900003	
J	Lee, J; Podlaseck, M; Schonberg, E; Hoch, R				Lee, J; Podlaseck, M; Schonberg, E; Hoch, R			Visualization and analysis of clickstream data of online stores for understanding Web merchandising	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						e-commerce; business intelligence; visualization; merchandising; marketing		Clickstreams are visitors' paths through a Web site. Analysis of clickstreams shows how a Web site is navigated and used by its visitors. Clickstream data of online stores contains information useful for understanding the effectiveness of marketing and merchandising efforts, such as how customers find the store, what products they see, and what products they purchase. In this paper, we present an interactive visualization system that provides users with greater abilities to interpret and explore clickstream data of online stores. This system visualizes the effectiveness of Web merchandising from two different points of view by using two different visualization techniques: visualization of sessions by using parallel coordinates and visualization of product performance by using starfield graphs. Furthermore, this system provides facilities for zooming, filtering, color-coding, dynamic querying and data sampling. It also provides summary information along with visualizations, and by maintaining a connection between visualizations and the source database, it dynamically updates the summary information. To demonstrate how the presented visualization system provides capabilities for examining online store clickstreams, we present a series of parallel coordinates and starfield visualizations that display clickstream data from an operating online retail store. A framework for understanding Web merchandising is briefly explained. A set of metrics referred to as micro-conversion rates, which are defined for Web merchandising analysis in our previous work (Lee et al., Electronic Markets, 2000), is also explained and used for the visualizations of online store effectiveness.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Heights, NY 10598 USA	Lee, J (reprint author), IBM Corp, Thomas J Watson Res Ctr, POB 218, Yorktown Heights, NY 10598 USA.						AGGRAWAL C, 1999, P 5 ACM SIGKDD INT C; ALHBERG C, 1994, ACM CHI C HUM FACT C; Becker B., 1997, P KDD WORKSH ISS INT; BERMAN B, 1998, RETAIL MANAGEMENT ST; Brieman L, 1984, CLASSIFICATION REGRE; BRIJS T, 1999, P 5 ACM SIGKDD INT C; BRUNK C, 1997, P 3 ACM SIGKDD INT C; Buchner A. G., 1998, SIGMOD REC, V27, P54, DOI 10.1145/306101.306124; CHAKRABARI S, 1998, P SIGMOD C; CHEN MS, 1996, P 16 INT C DISTR COM; CHI E, 1998, ACM CHI C HUM FACT C, P400; COOLEY R, 1999, J KNOWLEDGE INFORMAT, V1; HOCHHEISER HS, 1999, CSTR3989 U MAR DEP C; INSELBERG A, 1991, HUMAN MACHINE INTERA, P199; LEE J, ELECT MARKETS, V10, P20; PAPADAKAKIS N, 1998, INET 98 P; PITKOW JE, 1994, P 1 INT C WORLD WID; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RABENHORST D, 1994, P SPIE S EL IM, P277; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Shafer J., 1996, P 22 INT C VER LARG; Tauscher L., 1997, P CHI 97 HUM FACT CO, P399, DOI 10.1145/258549.258816; WILSON T, 1999, INTERNETWEEK    0329	23	30	33	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					59	84		10.1023/A:1009843912662		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900004	
J	Spiliopoulou, M; Pohle, C				Spiliopoulou, M; Pohle, C			Data mining for measuring and improving the success of web sites	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						web usage mining; contact efficiency; conversion efficiency; web merchandizing; web site analysis; data mining; e-commerce	TOOL	For many companies, competitiveness in e-commerce requires a successful presence on the web. Web sites are used to establish the company's image, to promote and sell goods and to provide customer support. The success of a web site affects and reflects directly the success of the company in the electronic market. In this study, we propose a methodology to improve the "success" of web sites. based on the exploitation of navigation pattern discovery. In particular, we present a theory, in which success is modelled on the basis of the navigation behaviour of the site's users. We then exploit WUM, a navigation pattern discovery miner, to study how the success of a site is reflected in the users' behaviour. With WUM we measure the success of a site's components and obtain concrete indications of how the site should be improved. We report on our first experiment!; with an online catalog, the success of which we have studied. Our mining analysis has shown very promising results, on the basis of which the site is currently undergoing concrete improvements.	Humboldt Univ, Inst Informat Syst, D-10178 Berlin, Germany	Spiliopoulou, M (reprint author), Humboldt Univ, Inst Informat Syst, Spandauer Str 1, D-10178 Berlin, Germany.						AGRAWAL R, 1995, P INT C DAT ENG TAIP; Agrawal R., 1993, SIGMOD, P207; ALPAR P, 1999, 4 INT TAG WIRTSCH 19; Berendt B, 2000, VLDB J, V9, P56, DOI 10.1007/s007780050083; Berthon P, 1996, J ADVERTISING RES, V36, P43; BUCHNER AG, 1998, ACM SIGMOD RECOR DEC; BUCHNER AG, 1999, NAVIGATION PATTERN D; Chen MS, 1996, INT CON DISTR COMP S, P385; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Cooley R., 1999, J KNOWLEDGE INFORM S, V1, P5; COOLEY R, 1997, 9 IEEE INT C TOOLS A; Dreze X, 1997, J ADVERTISING RES, V37, P77; Eighmey J, 1997, J ADVERTISING RES, V37, P59; GREEN PE, 1978, J CONSUM RES, V5, P103, DOI 10.1086/208721; Ho J., 1997, J COMPUTER MEDIATED, V3; Joachims T., 1997, P 15 INT JOINT C ART, P770; MARTIN D, 1999, WEBKDD 99; Masand B, 2000, LNAI, V1836; PARTHASARATHY S, 1999, P C INF KNOWL MAN; Perkowitz M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Spiliopoulou M, 1999, COMPUT SYST SCI ENG, V14, P113; SPILIOPOULOU M, 1999, P WORKSH MACH LEARN; SPILIOPOULOU M, 2000, HDB DATA MINING MARK; Spiliopoulou M, 1999, LECT NOTES COMPUT SC, V1590, P184; SULLIVAN T, 1997, P WEB C 97; WEXELBLAT A, 1996, P AAAI SPRING S ACQ; Wu KL, 1998, IBM SYST J, V37, P89; ZAIANE O, 1998, ADV DIGITAL LIB, P19; Zamir O., 1997, KDD 97, P287	29	46	47	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					85	114		10.1023/A:1009800113571		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900005	
J	Ben Schafer, J; Konstan, JA; Riedl, J				Ben Schafer, J; Konstan, JA; Riedl, J			E-commerce recommendation applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						electronic commerce; recommender systems; personalization; customer loyalty; cross-sell; up-sell; mass customization; privacy; data mining; database marketing; user interface		Recommender systems are being used by an ever-increasing number of E-commerce sites to help consumers find products to purchase. What started as a novelty has turned into a serious business tool. Recommender systems use product knowledge-either hand-coded knowledge provided by experts or "mined" knowledge learned from the behavior of consumers-to guide consumers through the often-overwhelming task of locating products they will like. In this article we present an explanation of how recommender systems are related to some traditional database analysis techniques. We examine how recommender systems help E-commerce sites increase sales and analyze the recommender systems at six market-leading sites. Based on these tramples, we create a taxonomy of recommender systems, including the inputs required from the consumers, the additional knowledge required from the database, the ways the recommendations are presented to consumers, the technologies used to create the recommendations, and the level of personalization of the recommendations. We identify five commonly used E-commerce recommender application models, describe several open research problems in the held of recommender systems, and examine privacy implications of recommender systems technology.	Univ Minnesota, Dept Comp Sci & Engn, GroupLens Res Project, Minneapolis, MN 55455 USA	Ben Schafer, J (reprint author), Univ Minnesota, Dept Comp Sci & Engn, GroupLens Res Project, Minneapolis, MN 55455 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Avery C, 1999, AM ECON REV, V89, P564, DOI 10.1257/aer.89.3.564; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Breese JS, 1998, P 14 C UNC ART INT, P43; Chaudhuri A., 2001, HARVARD BUSINESS MAR; Gilmore James H., 1999, EXPERIENCE EC; Good N., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Herlocker J. L., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312682; Hill W., 1995, HUMAN FACTORS COMPUT, P194; Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126; MANI DR, 1999, P 5 ACM SIGKDD INT C, P94, DOI 10.1145/312129.312205; PEPPERS D, 1997, 1 1 FUTURE BUILDING; Pine B. J., 1993, MASS CUSTOMIZATION; PINE BJ, 1995, HARVARD BUSINESS MAR, P103; Reichheld F., 1990, HARVARD BUSINESS SEP, P105; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; SALTON G, 1968, AUTOMATIC INFORMATIO; SARWAR B, 1998, P 1998 C COMP SUPP C; Schafer J. B., 1999, ACM C EL COMM, P158; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Shneiderman B., 1997, P 2 INT C INT US INT, P33, DOI 10.1145/238218.238281; Wolf J., 1999, P ACM SIGKDD INT C K	23	21	21	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					115	153				39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900006	
J	Giudici, P; Heckerman, D; Whittaker, J				Giudici, P; Heckerman, D; Whittaker, J			Statistical models for data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; knowledge discovery; statistical modelling of large databases		We review the background to the papers presented in this special issue and give a short introduction to each. We also briefly describe the workshop on "Statistical models for data mining", held in Pavia (Italy), in October 2000, where the papers were presented.	Univ Pavia, I-27100 Pavia, Italy; Microsoft Corp, Seattle, WA USA; Univ Lancaster, Lancaster LA1 4YW, England	Giudici, P (reprint author), Univ Pavia, I-27100 Pavia, Italy.							0	3	3	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	3					163	165		10.1023/A:1011452614423		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	443EK	WOS:000169327200001	
J	Cortes, C; Pregibon, D				Cortes, C; Pregibon, D			Signature-based methods for data streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						transactional data streams; signatures; large scale data mining		We have been developing signature-based methods in the telecommunications industry for the past 5 years. In this paper, we describe our work as it evolved due to improvements in technology and our aggressive attitude toward scale. We discuss the types of features that our signatures contain, nuances of how these are updated through time, our treatment of outliers, and the trade-off between time-driven and event-driven processing. We provide a number of examples, all drawn from the application of signatures to toll fraud detection.	AT&T Labs Res, Shannon Lab, Florham Park, NJ 07932 USA	Pregibon, D (reprint author), AT&T Labs Res, Shannon Lab, 180 Pk Ave, Florham Park, NJ 07932 USA.						CORTES C, 1999, P KDD99; Cortes C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347094; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; DuMouchel W, 1999, AM STAT, V53, P177, DOI 10.2307/2686093; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Lunt T. F., 1993, Computers & Security, V12, DOI 10.1016/0167-4048(93)90029-5; P Burge, 1997, P AI APPR FRAUD DET, P9	8	22	22	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	3					167	182		10.1023/A:1011464915332		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	443EK	WOS:000169327200002	
J	Giudici, P; Castelo, R				Giudici, P; Castelo, R			Association models for web mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Bayesian inference; data mining; graphical models; Markov chain Monte Carlo methods; model selection		We describe how statistical association models and, specifically, graphical models, can be usefully employed to model web mining data. We describe some methodological problems related to the implementation of discrete graphical models for web mining data. In particular, we discuss model selection procedures.	Univ Pavia, Dipartimento Econ Polit & Metodi Quantitat, Fac Econ, I-27100 Pavia, Italy; Univ Utrecht, NL-3508 TC Utrecht, Netherlands	Giudici, P (reprint author), Univ Pavia, Dipartimento Econ Polit & Metodi Quantitat, Fac Econ, Via San Felice 5, I-27100 Pavia, Italy.		Castelo, Robert/A-4679-2010				Breese J. S., 1998, P 14 C UNC ART INT; Brooks SP, 1998, J ROY STAT SOC D-STA, V47, P69; GIUDICI P, 2001, UNPUB IMPROVING MARK; Giudici P, 1999, BIOMETRIKA, V86, P785, DOI 10.1093/biomet/86.4.785; Heckerman D, 2000, J MACHINE LEARNING R, V1, P49; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Lauritzen SL, 1996, GRAPHICAL MODELS; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; Whittaker J., 1990, GRAPHICAL MODELS APP	9	10	10	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	3					183	196		10.1023/A:1011469000311		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	443EK	WOS:000169327200003	
J	Tresp, V				Tresp, V			Scaling kernel-based systems to large data sets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						kernel-based systems; support vector machine; Gaussian processes; committee machines; massive data sets		In the form of the support vector machine and Gaussian processes, kernel-based systems are currently very popular approaches to supervised learning. Unfortunately, the computational load for training kernel-based systems increases drastically with the size of the training data set, such that these systems are not ideal candidates for applications with large data sets. Nevertheless, research in this direction is very active. In this paper, I review some of the current approaches toward scaling kernel-based systems to large data sets.	Siemens AG, Corp Technol, Cent Res & Dev Unit, D-81730 Munich, Germany	Tresp, V (reprint author), Siemens AG, Corp Technol, Cent Res & Dev Unit, Otto Hahn Ring 6, D-81730 Munich, Germany.						Christianini N., 2000, SUPPORT VECTOR MACHI; CSATO L, 2001, ADV NEURAL INFORMATI, V13; Fahrmeir L, 1994, MULTIVARIATE STAT MO; Gibbs M, 1997, EFFICIENT IMPLEMENTA; Joachims T., 1998, ADV KERNEL METHODS; Lee Y, 2000, 0007 U WISC DAT MIN; MACKAY DJC, 1997, NATO ASI SERIES F, V168; MANGASARIAN OL, 2001, ADV NEURAL INFORMATI, V13; MANGASARIAN OL, 1999, 9901 U WISC DAT MIN; MANGASARIAN OL, 2000, 0006 U WISC DAT MIN; MULLER KR, 2001, IEEE T NEURAL NE MAY; OSUNA E, 1997, NEURAL NETWORKS SIGN, V7; PAVLOV D, 2000, P 6 ACM SIGKDD INT C; PAVLOV D, 2000, P ICPR; PEREZCRUZ F, 2001, ADV NEURAL INFORMATI, V13; Platt J., 1998, ADV KERNEL METHODS; POGGIO T, 1990, P IEEE, P78; Press WH, 1992, NUMERICAL RECIPES C; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Scholkopf B., 1999, ADV KERNEL METHODS; SCHWAIGHOFER A, 2001, P 11 INT C ART NEUR; SMOLA AJ, 2001, ADV NEURAL INFORMATI, V13; Smola A.J., 2000, P 17 INT C MACH LEAR; TIPPING ME, 2000, ADV NEURAL INFORMATI, V12; TRECATE GF, 1998, ADV NEURAL INFORMATI, V11; TRESP V, 2000, NEURAL COMPUTATION, V12; TRESP V, 2001, P 11 INT C ART NEUR; TRESP V, 2000, P 6 ACM SIGKDD INT C; Vapnik V. N., 1998, STAT LEARNING THEORY; Wahba G, 1990, SPLINE MODELS OBSERV; WILLIAMS CKI, 2001, ADV NEURAL INFORMATI, V13; WILLIAMS CKI, 1998, IEEE T PATT AN MACH, V20; ZHU H, 1998, NATO ASI SERIES F, V168	33	11	12	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	3					197	211		10.1023/A:1011425201219		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	443EK	WOS:000169327200004	
J	Bay, SD; Pazzani, MJ				Bay, SD; Pazzani, MJ			Detecting group differences: Mining contrast sets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; contrast sets; change detection; association rules	KNOWLEDGE DISCOVERY	A fundamental task in data analysis is understanding the differences between several contrasting groups. These groups can represent different classes of objects, such as male or female students, or the same group over time, e.g. freshman students in 1993 through 1998. We present the problem of mining contrast sets: conjunctions of attributes and values that differ meaningfully in their distribution across groups. We provide a search algorithm for mining contrast sets with pruning rules that drastically reduce the computational complexity. Once the contrast sets are found, we post-process the results to present a subset that are surprising to the user given what we have already shown. We explicitly control the probability of Type I error (false positives) and guarantee a maximum error rate for the entire analysis by using Bonferroni corrections.	Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA	Bay, SD (reprint author), Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA.						Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1995, P 21 INT C VER LARG; Agresti A, 1990, CATEGORICAL DATA ANA; Bay S., 1999, P 5 ACM SIGKDD INT C, P302, DOI 10.1145/312129.312263; BAY SD, 1999, UCI KDD ARCH; BAYARDO R, 1998, P ACM SIGMOD C MAN D; BAYARDO RJ, 1999, P 15 INT C DAT ENG; Bazaraa M. S., 1979, NONLINEAR PROGRAMMIN; Bishop Y.M.M., 1975, DISCRETE MULTIVARIAT; BLAKE C, 1998, UCI REPOSITORY MACH; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; CHAKRABARTI S, 1998, P 24 INT C VER LARG; COHEN J, 1990, AM PSYCHOL, V45, P1304, DOI 10.1037//0003-066X.45.12.1304; Darity WA, 1998, SOUTHERN ECON J, V64, P805, DOI 10.2307/1061206; DAVIES J, 1996, P 18 ANN C COGN SCI, P750; Dong G., 1999, P 5 ACM SIGKDD INT C; Everitt BS, 1992, ANAL CONTINGENCY TAB; GANTI V, 1999, P 18 ACM SIGMOD SIGA; Glenn ND, 1977, COHORT ANAL; Hoschka P., 1991, Knowledge discovery in databases; Keogh E., 1998, P 4 INT C KNOWL DISC; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; KLOSGEN W, 1993, EXPLORA USER DOCUMEN; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, P249; Knoke D., 1980, LOG LINEAR MODELS; LEWONTIN RC, 1965, BIOMETRICS, V21, P19, DOI 10.2307/2528349; LIN D, 1998, P 6 EUR C EXT DAT TH; Lincoff G, 1981, AUDUBON SOC FIELD GU; Liu B., 1997, P 3 INT C KNOWL DISC, P31; Liu B., 1999, P 5 ACM SIGKDD INT C; Liu B, 1999, IEEE T KNOWL DATA EN, V11, P817; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; MEGIDDO N, 1998, P 4 INT C KNOWL DISC; Menard S., 1991, LONGITUDINAL RES; MICHELL TM, 1977, P 5 INT JOINT C ART; NG R, 1998, P ACM SIGMOD C MAN D; PADMANABHAN B, 1998, P 4 INT C KNOWL DISC; RIDDLE P, 1994, APPL ARTIF INTELL, V8, P125, DOI 10.1080/08839519408945435; Ruggles S, 1997, DEMOGRAPHY, V34, P455, DOI 10.2307/3038300; Ruggles S., 1997, INTEGRATED PUBLIC US; RUGGLES S, 1995, HIST METHOD, V28, P40; RYMON R, 1992, 3 INT C PRINC KNOWL; SHAFFER JP, 1995, ANNU REV PSYCHOL, V46, P561, DOI 10.1146/annurev.psych.46.1.561; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; SRIKANT R, 1997, P 3 INT C KNOWL DISC; Srikant R, 1996, P ACM SIGMOD C MAN D; Tamhane AC, 1987, MULTIPLE COMPARISON; Zaki M.J., 1997, P 3 INT C KNOWL DISC	51	91	96	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	3					213	246		10.1023/A:1011429418057		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	443EK	WOS:000169327200005	
J	Sarawagi, S				Sarawagi, S			iDiff: Informative summarization of differences in multidimensional aggregates	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						multidimensional databases; OLAP; OLAP-mining integration; difference mining; data summarization; advanced aggregates		Multidimensional OLAP products provide an excellent opportunity for integrating mining functionality because of their widespread acceptance as a decision support tool and their existing heavy reliance on manual, user-driven analysis. Most OLAP products are rather simplistic and rely heavily on the user's intuition to manually drive the discovery process. Such ad hoc user-driven exploration gets tedious and error-prone as data dimensionality and size increases. Our goal is to automate these manual discovery processes. In this paper we present an example of such automation through a iDiff operator that in a single step returns summarized reasons for drops or increases observed at an aggregated level. We formulate this as a problem of summarizing the difference between two multidimensional arrays of real numbers. We develop a general framework for such summarization and propose a specific formulation for the case of OLAP aggregates. We develop an information theoretic formulation for expressing the reasons that is compact and easy to interpret. We design an efficient dynamic programming algorithm that requires only one pass of the data and uses a small amount of memory independent of the data size. This allows easy integration with existing OLAP products. Our prototype has been tested on the Microsoft OLAP server, DB2/UDB and Oracle 8i. Experiments using the OLAP benchmark demonstrate (1) scalability of our algorithm as the size and dimensionality of the cube increases and (2) feasibility of getting interactive answers with modest hardware resources.	Indian Inst Technol, Bombay 400076, Maharashtra, India	Sarawagi, S (reprint author), Indian Inst Technol, Bombay 400076, Maharashtra, India.						Chaudhuri S., 1997, ACM SIGMOD RECORD; CODD E, 1993, PROVIDING OLAP ON LI; Cover T. M., 1991, ELEMENTS INFORMATION; FLAJOLET P, 1985, J COMPUT SYST SCI, V31, P182, DOI 10.1016/0022-0000(85)90041-8; GERBER C, 1996, DATAMATION      0501; HAN J, 1995, P 21 INT C VER LARG; HAN JW, 1998, ON LINE ANAL MINING; Microsoft Corporation, 1998, OLE DB OLAP VERS 1 0; SARAWAGI S, 2000, P ACM SIGMOD INT C M; SARAWAGI S, 1999, P 25 INT C VER LARG; Shukla A, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P522; THOMSEN E, 1998, OLAP DATA MINING CRE; *ARB SOFTW CORP, MULT AN CONV CORP DA; *COGN SOFTW CORP, 1997, POW PLAY 5; *DBMS, 1998, DBMS MAGAZINE    APR; *INF DISC INC, 1996, OL DAT BRIDG GAP; *INT DAT AN GROUP, 1999, OL VEND INCR SEE DAT; *OLAP COUNC, OLAP BENCHM	18	4	5	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	4					255	276		10.1023/A:1011494927464		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	458ZK	WOS:000170225200001	
J	Shek, EC; Muntz, RR; Mesrobian, E				Shek, EC; Muntz, RR; Mesrobian, E			Extensible parallel query processing for exploratory geoscientific data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						parallel query processing; extensible user-defined operations; geoscientific data mining; cyclone; blocking events; upward wave-energy propagation	ANOMALIES	Exploratory data mining and analysis requires a computing environment which provides facilities for the user-friendly expression and rapid execution of "scientific queries." In this paper, we address research issues in the parallelization of scientific queries containing complex user-defined operations. In a parallel query execution environment, parallelizing a query execution plan involves determining how input data streams to evaluators implementing logical operations can be divided to be processed by clones of the same evaluator in parallel. We introduced the concept of "relevance window" that characterizes data lineage and data partitioning opportunities available for an user-defined evaluator. In addition, we developed a query parallelization framework by extending relational parallel query optimization algorithms to allow the parallelization characteristics of user-defined evaluators to guide the process of query parallelization in an extensible query processing environment. We demonstrated the utility of our system by performing experiments mining cyclonic activity, blocking events, and the upward wave-energy propagation features from several observational and model simulation datasets.	HRL Labs LLC, Informat Sci Lab, Malibu, CA 90265 USA; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA; Disney Online, Burbank, CA 91521 USA	Shek, EC (reprint author), HRL Labs LLC, Informat Sci Lab, Malibu, CA 90265 USA.						Agrawal R., 1995, P 11 INT C DAT ENG; DEWITT D, 1996, P 4 INT C PAR DISTR; Dole R. M., 1983, LARGE SCALE DYNAMICA; Freytag J.-C., 1987, P ACM SIGMOD INT C M, P173, DOI 10.1145/38713.38735; GRAEFE G, 1994, IEEE T KNOWL DATA EN, V6, P120, DOI 10.1109/69.273032; HASAN W, 1996, SIGMOD RECORD, V25; HONG W, 1993, DISTRIB PARALLEL DAT, V1, P9, DOI 10.1007/BF01277518; Karpovich J. F., 1993, Proceedings the 2nd International Symposium on High Performance Distributed Computing (Cat. No.93TH0550-4), DOI 10.1109/HPDC.1993.263860; LANZELOTTE R, 1993, P C VER LARG DAT BAS, P493; LEUNG TYC, 1990, PROCEEDINGS : 6TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING, P200; LEUNG TYC, 1992, PROC INT CONF VERY L, P383; LIBKIN L, 1996, P ACM SIGMOD INT C M, P228, DOI 10.1145/233269.233335; Marathe AP, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P46; MECHOSO CR, 1990, J CLIMATE, V3, P812, DOI 10.1175/1520-0442(1990)003<0812:TIOSST>2.0.CO;2; Mehta M, 1995, P 21 INT C VER LARG, P382; Mesrobian E., 1996, Proceedings. Sixth International Workshop on Research Issues in Data Engineering. Interoperability of Nontraditional Database Systems (Cat. No.96TB100021), DOI 10.1109/RIDE.1996.492248; Mesrobian E., 1994, Proceeding IEEE Workshop on Visualization and Machine Vision (Cat. No.94TH0636-1), DOI 10.1109/VMV.1994.324983; NAKAMURA H, 1990, J ATMOS SCI, V47, P1100, DOI 10.1175/1520-0469(1990)047<1100:OCIBWA>2.0.CO;2; RAHM E, 1993, P 19 INT C VER LARG; RITTER GX, 1990, COMPUT VISION GRAPH, V49, P297, DOI 10.1016/0734-189X(90)90106-6; Seshadri P, 1994, P ACM SIGMOD INT C M, P430, DOI 10.1145/191839.191926; Shek E. C., 1996, Proceedings. Sixth International Workshop on Research Issues in Data Engineering. Interoperability of Nontraditional Database Systems (Cat. No.96TB100021), DOI 10.1109/RIDE.1996.492247; SHEK EC, 1996, P 2 INT C KNOWL DISC; TOMLIN CD, 1990, GEOGRAPHIC INFORMATI; Woodruff A, 1997, PROC INT CONF DATA, P91, DOI 10.1109/ICDE.1997.581742	25	1	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	4					277	304		10.1023/A:1011401111535		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	458ZK	WOS:000170225200002	
J	Wallis, S; Nelson, G				Wallis, S; Nelson, G			Knowledge discovery in grammatically analysed corpora	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						linguistics; grammar; structured datasets; Text Corpora; redescription; cyclic knowledge discovery		Collections of grammatically annotated texts (corpora), and in particular, parsed corpora, present a challenge to current methods of analysis. Such corpora are large and highly structured heterogeneous data sources. In this paper we briefly describe the parsed one-million word ICE-GB corpus, and the ICECUP query system. We then consider the application of knowledge discovery in databases (KDD) to text corpora. Following Cupit and Shadbolt (Proceedings 9th European Knowledge Acquisition Workshop, EKAW '96; Berlin: Springer Verlag, pp. 245-261, 1996), we argue that effective linguistic knowledge discovery must be based on a process of redescription or, more precisely, abstraction, based on the research question to be investigated. Abstraction maps relevant elements from the corpus to an abstract model of the research topic. This mapping may be implemented using a grammatical query representation such as ICECUP's Fuzzy Tree Fragments (FTFs). Since this abstractive process must be both experimental and expert-guided, ultimately a workbench is necessary to maintain, evaluate and refine the abstract model. We conclude with a pilot study, employing our approach, into aspects of noun phrase postmodifying clause structure. The data is analysed using the UNIT machine learning algorithm to search for significant interactions between domain variables. We show that our results are commensurable with those published in the linguistics literature, and discuss how the methodology may be improved.	Univ Hong Kong, Dept English, Hong Kong, Hong Kong, Peoples R China; UCL, Survey English Usage, London, England	Wallis, S (reprint author), Univ Hong Kong, Dept English, Hong Kong, Hong Kong, Peoples R China.	s.wallis@ucl.ac.uk; ganelson@hkucc.hk					AARTS B, 1998, ENGLISH TODAY, V14, P52, DOI 10.1017/S0266078400010373; ABEILLE, 1999, JOURN ATALA CORP ANN; Biber D., 1988, VARIATION SPEECH WRI; Brill E., 1992, P 3 C APPL NAT LANG, P152, DOI 10.3115/974499.974526; BRISCOE T, 1996, SURVEY STATE ART HUM; BURNAGE G, 1992, ENGLISH LANGUAGE COR; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; CORBRIDGE C, 1994, KNOWL ACQUIS, V6, P315, DOI 10.1006/knac.1994.1016; Cupit J, 1996, LECT NOTES ARTIF INT, V1076, P245; DEHAAN P, 1986, CORPUS LINGUISTICS, P151; FANG AC, 1996, SYNCHRONIC CORPUS LI, P131; Fayyad UM, 1997, DATA MIN KNOWL DISC, V1, P5, DOI 10.1023/A:1009715820935; Greenbaum Sidney, 1996, COMP ENGLISH WORLDWI; Haberman S.J., 1978, ANAL QUALITATIVE DAT, V1; Huddleston R., 1984, INTRO GRAMMAR ENGLIS; KONDOPOULOU P, 1997, THESIS U E LONDON; Lakatos I., 1981, SCI REVOLUTIONS, P107; MARCUS M, 1994, P HUM LANG TECHN WOR; McEnery A., 1996, CORPUS LINGUISTICS; Michie Donald, 1986, MACHINE INTELLIGENCE; MOONEY RJ, 1995, J ARTIF INTELL RES, V3, P1; MOONEY RJ, 1997, P 6 INT WORKSH IND L, P3; MUGGLETON S, 1998, P 13 EUR C ART INT E, P697; NELSON G, IN PRESS EXPLORING N; Niblett T, 1986, RES DEV EXPERT SYSTE, P25; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Quirk R., 1985, COMPREHENSIVE GRAMMA; SHAW MLG, 1987, KNOWLEDGE ACQUISITIO; Wallis S, 1997, LECT NOTES ARTIF INT, V1319, P285; Wallis S., 2000, Literary & Linguistic Computing, V15, DOI 10.1093/llc/15.3.339; WALLIS SA, 1993, P MLNET WORKSH SCI D, P123; WALLIS SA, 1999, THESIS U NOTTINGHAM; WALLIS SA, 1999, CORPORA GALORE, P335; Wu X., 1995, KNOWLEDGE ACQUISITIO; Zadeh LA, 1965, INFORM CONTR, V8, P353	35	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	4					305	335		10.1023/A:1011453128373		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	458ZK	WOS:000170225200003	
J	Westerdijk, M; Barber, D; Wiegerinck, W				Westerdijk, M; Barber, D; Wiegerinck, W			Deterministic generative models for fast feature discovery	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						vector quantisation; feature discovery; generative models; mean-field methods; message passing algorithms; handwritten digits analysis; image compression	INDEX ASSIGNMENTS; VECTOR QUANTIZERS; BELIEF NETWORKS	We propose a vector quantisation method which does not only provide a compact description of data vectors in terms codebook vectors, but also gives an explanation of codebook vectors as binary combinations of elementary features. This corresponds to the intuitive notion that, in the real world, patterns can be usefully thought of as being constructed by compositions from simpler features. The model can be understood as a generative model, in which the codebook vector is generated by a hidden binary state vector. The model is non-probabilistic in the sense that it assigns each data vector to a single codebook vector. We describe exact and approximate learning algorithms for learning deterministic feature representations. In contrast to probabilistic models, the deterministic approach allows the use of message propagation algorithms within the learning scheme. These are compared with standard mean-field/Gibbs sampling learning. We show that Generative Vector Quantisation gives a good performance in large scale real world tasks like image compression and handwritten digit analysis with up to 400 data dimensions.	Univ Nijmegen, Dept Med Phys & Biophys, Nijmegen, Netherlands	Westerdijk, M (reprint author), Univ Nijmegen, Dept Med Phys & Biophys, Nijmegen, Netherlands.	machiel@mbfys.kun.nl; barberd@aston.ac.uk; wimw@mbfys.kun.nl	Wiegerinck, Wim/J-2510-2012				Attias H, 1999, NEURAL COMPUT, V11, P803, DOI 10.1162/089976699300016458; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; BARNES CF, 1993, IEEE T INFORM THEORY, V39, P565, DOI 10.1109/18.212286; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; GHAHRAMANI Z, 1998, ADV NEURAL INFORMATI, V10; GHAHRAMANI Z, 1995, ADV NEURAL INFORMATI, V7; GRAY RM, 1989, IEEE ASSP MAGAZINE, P4; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Knagenhjelm P, 1996, IEEE T INFORM THEORY, V42, P1139, DOI 10.1109/18.508837; McEliece R. J., 1995, Proceedings. Thirty-Third Annual Allerton Conference on Communication, Control, and Computing; McLaughlin SW, 1995, IEEE T INFORM THEORY, V41, P2031, DOI 10.1109/18.476331; Mehes A, 1998, IEEE T INFORM THEORY, V44, P79, DOI 10.1109/18.650990; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pearl J., 1988, PROBABILISTIC REASON; Press WH, 1992, NUMERICAL RECIPES C; Sallans B., 1998, Neural Networks and Machine Learning. Proceedings; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; SAUND E, 1995, NEURAL COMPUT, V7, P51, DOI 10.1162/neco.1995.7.1.51; WEISS Y, 1997, AIM1616 MITAILAB; ZEMEL RS, 1994, CRGTR932 U TOR	23	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	4					337	363		10.1023/A:1011405212443		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	458ZK	WOS:000170225200004	
J	Dhar, V; Chou, D; Provost, F				Dhar, V; Chou, D; Provost, F			Discovering interesting patterns for investment decision making with GLOWER - A genetic learner overlaid with entropy reduction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; knowledge discovery; machine learning; genetic algorithms; financial prediction; rule learning; investment decision making; systematic trading	ALGORITHM	Prediction in financial domains is notoriously difficult for a number of reasons. First, theories tend to be weak or non-existent, which makes problem formulation open ended by forcing us to consider a large number of independent variables and thereby increasing the dimensionality of the search space. Second, the weak relationships among variables tend to be nonlinear, and may hold only in limited areas of the search space. Third, in financial practice, where analysts conduct extensive manual analysis of historically well performing indicators, a key is to find the hidden interactions among variables that perform well in combination. Unfortunately, these are exactly the patterns that the greedy search biases incorporated by many standard rule learning algorithms will miss. In this paper, we describe and evaluate several variations of a new genetic learning algorithm (GLOWER) on a variety of data sets. The design of GLOWER has been motivated by financial prediction problems, but incorporates successful ideas from tree induction and rule learning. We examine the performance of several GLOWER variants on two UCI data sets as well as on a standard financial prediction problem (S&P500 stock returns), using the results to identify one of the better variants for further comparisons. We introduce a new (to KDD) financial prediction problem (predicting positive and negative earnings surprises), and experiment with GLOWER, contrasting it with tree- and rule-induction approaches. Our results are encouraging, showing that GLOWER has the ability to uncover effective patterns for difficult problems that have weak structure and significant nonlinearities.	NYU, Stern Sch Business, New York, NY 10012 USA	Dhar, V (reprint author), NYU, Stern Sch Business, 44 W 4th St,Room 9-75, New York, NY 10012 USA.						ACHELIS SB, 1995, TECHNICAL ANAL A Z; ATIYA A, 1995, P 3 INT C NEUR NETW; BARR D, 1994, AI EXPERT        FEB; Bauer R. J., 1994, GENETIC ALGORITHMS I; Beasley D, 1993, EVOL COMPUT, V1, P101, DOI 10.1162/evco.1993.1.2.101; BLAKE CL, 1998, REPOSITORY MACH LEAR; Breiman L, 1984, CLASSIFICATION REGRE; CARTWRIGHT HM, 1991, P 4 INT C GEN ALG; CHOU D, 1999, THESIS NEW YORK U; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; CLEARWATER SH, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P24, DOI 10.1109/TAI.1990.130305; COHEN WW, 1990, P 16 NAT C ART INT A, P335; Deb K., 1989, P 3 INT C GEN ALG; De Jong KA, 1999, COMMUN ACM, V42, P51, DOI 10.1145/319382.319392; Dhar V, 1997, 7 METHODS TRANSFORMI; Domingos P., 1996, P 2 INT C KNOWL DISC, P96; Domingos P, 1996, MACH LEARN, V24, P141; FORGY CL, 1982, ARTIF INTELL, V19, P17, DOI 10.1016/0004-3702(82)90020-0; FRIEDMAN J. H., 1996, LOCAL LEARNING BASED; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; GEORGE EI, 1996, P COMP SCI STAT 28 S; Goldberg D, 1987, P 2 INT C GEN ALG; Goldberg D. E., 1992, PARALLEL PROBLEM SOL, V2; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GRAHAM B, 1936, SECURITY ANAL; Grefenstette J. J., 1987, GENETIC ALGORITHMS S; HEKANAHO J, 1996, P 13 INT C MACH LEAR; HOLLAND JH, 1972, INTR ANAL APPL BIOL; HOLLAND JH, 1975, ADAPTATION NATURAL A; HONG J, 1991, KNOWLEDGE DISCOVERY; JANIKOW CZ, 1993, MACH LEARN, V13, P189, DOI 10.1023/A:1022669929488; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; MADDEN B, 1996, J INVESTING, V5; Mahfoud S., 1995, P 6 INT C GEN ALG; MAHFOUD S. W., 1995, NICHING METHODS GENE; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHIE D, 1994, MACH LEARNING NEURAL; MITCHELL T, 1980, CBMTR117 RUTG U COMP; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Oei C.K., 1991, TOURNAMENT SELECTION; PACKARD N, 1989, GENETIC LEARNING ALG; PROVOST F, 1992, LECT NOTES ARTIFICIA, V642; PROVOST F, 1999, 99012 IS NYU STERN S; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; QUINLAN J, 1996, MACH LEARNING ID3; SIKORA R, 1994, ORSA J COMPUTING, V6, P334; SMYTHE P, 1991, KNOWLEDGE DISCOVERY; *UCI, 1995, RESP MACH LEARN DAT	49	33	34	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2000	4	4					251	280		10.1023/A:1009848126475		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	352VZ	WOS:000089241200001	
J	Hellerstein, JM; Avnur, R; Raman, V				Hellerstein, JM; Avnur, R; Raman, V			Informix under CONTROL: Online query processing	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						online query processing; interactive; informix; control; data analysis; ripple joins; online reoredering	DATABASE	The goal of the CONTROL project at Berkeley is to develop systems for interactive analysis of large data sets. We focus on systems that provide users with iteratively refining answers to requests and online control of processing, thereby tightening the loop in the data analysis process. This paper presents the database-centric subproject of CONTROL: a complete online query processing facility, implemented in a commercial Object-Relational DBMS from Informix. We describe the algorithms at the core of the system, and detail the end-to-end issues required to bring the algorithms together and deliver a complete system.	Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA	Hellerstein, JM (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.						AGRAWAL R, 1997, COMMUNICATION; Agrawal R., 1994, P 20 INT C VER LARG; AIKEN A, 1996, P 12 IEEE INT C DAT; Antoshenkov G., 1996, VLDB Journal, V5, DOI 10.1007/s007780050026; ANTOSHENKOV G, 1992, P 18 INT C VER LARG; AOKI PM, 1998, IEEE INT C DAT ENG O; Astrahan M. M., 1976, ACM Transactions on Database Systems, V1, DOI 10.1145/320455.320457; AVNUR R, 2000, P ACM SIGMOD INT C M; BAYARDO RJ, 1996, 5 INT C INF KNOWL MA; CAREY MJ, 1998, P 24 INT C VER LARG; CAREY MJ, 1997, P ACM SIGMOD INT C M; CHAUDHURI S, 1996, P ACM SIGMOD INT C M; CHAUDHURI S, 1996, P 24 INT C VER LARG; CHAUDHURI S, 1999, P INT C VER LARG DAT; CHAUDHURI S, 1998, P ACM SIGMOD INT C M; CHERNIACK M, 1998, THESIS BROWN U; DEWITT DJ, 1984, P ACM SIGMOD INT C M; DONJERKOVIC D, 1999, P INT C VER LARG DAT; FAGIN R, 1998, P ACM SIGACT SIGMOD; Fayyad Usama, 1996, COMMUNICATIONS ACM, V39; FUSHIMI S, 1986, P 24 INT C VER LARG; GIBBONS P, 1998, P ACM SIGMOD INT C M; GIBBONS PB, 1998, AQUA SYSTEM TECHNIQU; GRAEFE G, 1993, COMPUT SURV, V25, P73; GRAY J, 1997, SIGMOD RECORD, V26; HAAS PJ, 1996, 10040 RJ IBM ALM RES; Haas PJ, 1996, J COMPUT SYST SCI, V52, P550, DOI 10.1006/jcss.1996.0041; HAAS PJ, 1999, P ACM SIGMOD INT C M; HARINARYAN V, 1996, P ACM SIGMOD INT C M; HASS PJ, 1997, P 9 INT C SCI STAT D; Heller S., 1998, Cutter IT Journal, V11; HELLERSTEIN JM, 1997, CSD97958 U CAL; HELLERSTEIN JM, 1997, IEEE DATA ENG B, V20; HELLERSTEIN JM, 1997, P ACM SIGMOD INT C M; Hellerstein JM, 1999, COMPUTER, V32, P51, DOI 10.1109/2.781635; HELLERSTEIN JM, 1998, ACM T DATABASE SYSTE, V23; HELLERSTEIN JM, 1996, P ACM SIGMOD INT C M; HIDBER C, 1997, P ACM SIGMOD INT C M; Hoeffding W., 1963, J AM STAT ASS, V58; HOU W, 1989, P ACM SIGMOD INT C M; HOU WC, 1998, P 7 ACM SIGACT SIGMO; Knuth D, 1973, ART COMPUTER PROGRAM, V3; LEUNG TYC, 1998, READING DATABASE SYS; LIPTON RJ, 1993, THEOR COMPUT SCI, V116, P195, DOI 10.1016/0304-3975(93)90224-H; LIVNY M, 1997, P ACM SIGMOD INT C M; LYNCH C, 1998, P 14 INT C VER LARG; MAIER D, 1986, P 1 WORKSH OBJ OR DA; MORGENSTEIN JP, 1980, THESIS UC BERKELEY; ODAY V, 1993, INTERCHI; OHNO P, 1998, INFORMIX MAGAZINE; Olken F, 1993, THESIS U CALIFORNIA; PAPADOPOULOS G, 1997, BERKELEY NOW RET JUL; Perlin K., 1993, P 20 ANN C COMP GRAP, P57, DOI 10.1145/166117.166125; RAMAN V, 1999, DMKD WORKSH; RAMAN V, 1999, P INT C VER LARG DAT; RAO J, 1998, P ACM SIGMOD INT C M; SESHADRI P, 1995, P 11 IEEE INT C DAT; Shneiderman B., 1982, Behaviour and Information Technology, V1; Shukla A., 1998, P 24 INT C VER LARG; SILBERSCHATZ A, 1992, P 18 INT C VER LARG; Stonebraker M., 1989, SIGMOD Record, V18; STONEBRAKER M, 1991, COMMUN ACM, V34, P78, DOI 10.1145/125223.125262; TAN K, 1999, P INT C VER LARG DAT; VRBSKY SV, 1993, IEEE T KNOWL DATA EN, V5, P1056, DOI 10.1109/69.250091; WALDSPURGER CA, 1995, 1 S OP SYST DES IMPL; WALTER T, 1998, NSF DAT SYST IND AC; Wilschut A. N., 1991, Proceedings of the First International Conference on Parallel and Distributed Information Systems (Cat. No.91TH0393-4), DOI 10.1109/PDIS.1991.183069; WINTER R, 1998, DATABASE PROGRAMMING; Zilberstein S, 1996, ARTIF INTELL, V82, P181, DOI 10.1016/0004-3702(94)00074-3; *ILL INF TECHN INC, 1994, ULL US GUID; *INF CORP, 1998, INF DYN SERV UN DAT; *INF CORP, 1998, C ISAM VERS 7 24 UNI; *INF CORP, 1998, 0002168170 INF CORP; *QL, 1998, SERV 7 0 OLAP SERV; *RED BRICK SYST IN, 1998, RED BRICK WAR	75	3	3	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2000	4	4					281	314		10.1023/A:1009835310546		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	352VZ	WOS:000089241200002	
J	Rastogi, R; Shim, K				Rastogi, R; Shim, K			PUBLIC: A decision tree classifier that integrates building and pruning	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; classification; decision tree	PERFORMANCE	Classification is an important problem in data mining. Given a database of records, each with a class label, a classifier generates a concise and meaningful description for each class that can be used to classify subsequent records. A number of popular classifiers construct decision trees to generate class models. These classifiers first build a decision tree and then prune subtrees from the decision tree in a subsequent pruning phase to improve accuracy and prevent "overfitting". Generating the decision tree in two distinct phases could result in a substantial amount of wasted effort since an entire subtree constructed in the first phase may later be pruned in the next phase. In this paper, we propose PUBLIC, an improved decision tree classifier that integrates the second "pruning" phase with the initial "building" phase. In PUBLIC, a node is not expanded during the building phase, if it is determined that it will be pruned during the subsequent pruning phase. In order to make this determination for a node, before it is expanded, PUBLIC computes a lower bound on the minimum cost subtree rooted at the node. This estimate is then used by PUBLIC to identify the nodes that are certain to be pruned, and for such nodes, not expend effort on splitting them. Experimental results with real-life as well as synthetic data sets demonstrate the effectiveness of PUBLIC's integrated approach which has the ability to deliver substantial performance improvements.	Bell Labs, Murray Hill, NJ 07974 USA; Korea Adv Inst Sci & Technol, Taejon 305701, South Korea; Adv Informat Technol Res Ctr, Taejon 305701, South Korea	Rastogi, R (reprint author), Bell Labs, 600 Mt Ave, Murray Hill, NJ 07974 USA.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; Bishop CM, 1995, NEURAL NETWORKS PATT; Breiman L, 1984, CLASSIFICATION REGRE; CHEESEMAN P, 1988, 5 INT C MACH LEARN J; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FAYYAD UM, 1991, THESIS U MICHIGAN; FUKUDA T, 1996, P INT C VER LARG DAT; GEHRKE J, 1998, P VLDB C AUG NEW YOR; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Hunt EB, 1966, EXPT INDUCTION; KRICHEVSKY RE, 1981, IEEE T INFORM THEORY, V27, P199, DOI 10.1109/TIT.1981.1056331; MEHTA M, 1995, INT C KNOWL DISC DAT; MEHTA MP, 1996, EDBT 96 MAR AV FRANC; MITCHIE D, 1994, MACH LEARNING NEURAL; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Ripley B., 1996, PATTERN RECOGNITION; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rissanen J, 1989, STOCHASTIC COMPLEXIT; SHAFER J, 1996, P VLDB C SEPT BOMB I; WALLACE CS, 1993, MACH LEARN, V11, P7, DOI 10.1023/A:1022646101185; ZIHED DA, 1997, INT C KNOWL DISC DAT	25	27	29	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2000	4	4					315	344		10.1023/A:1009887311454		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	352VZ	WOS:000089241200003	
J	Chaudhuri, S				Chaudhuri, S			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Microsoft Res, Database Grp, Redmond, WA 98052 USA	Chaudhuri, S (reprint author), Microsoft Res, Database Grp, Redmond, WA 98052 USA.							0	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2000	4	2-3					87	88		10.1023/A:1009832828884		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	325ZA	WOS:000087706100001	
J	Sarawagi, S; Thomas, S; Agrawal, R				Sarawagi, S; Thomas, S; Agrawal, R			Integrating association rule mining with relational database systems: Alternatives and implications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						mining system architecture; association rule mining; database mining; mining algorithms in SQL		Data mining on large data warehouses is becoming increasingly important. In support of this trend, we consider a spectrum of architectural alternatives for coupling mining with database systems. These alternatives include: loose-coupling through a SQL cursor interface; encapsulation of a mining algorithm in a stored procedure; caching the data to a file system on-the-fly and mining; tight-coupling using primarily user-defined functions; and SQL implementations for processing in the DBMS. We comprehensively study the option of expressing the mining algorithm in the form of SQL queries using Association rule mining as a case in point. We consider four options in SQL-92 and six options in SQL enhanced with object-relational extensions (SQL-OR). Our evaluation of the different architectural alternatives shows that from a performance perspective, the Cache option is superior, although the performance of the SQL-OR option is within a factor of two. Both the Cache and the SQL-OR approaches incur a higher storage penalty than the loose-coupling approach which performance-wise is a factor of 3 to 4 worse than Cache. The SQL-92 implementations were too slow to qualify as a competitive option. We also compare these alternatives on the basis of qualitative factors like automatic parallelization, development ease, portability and inter-operability. As a byproduct of this study, we identify some primitives for native support in database systems for decision-support applications.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Sarawagi, S (reprint author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.						Agrawal R., 1996, P 2 INT C KNOWL DISC; Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Brin S., 1997, P ACM SIGMOD C MAN D; CHAMBERLIN D, 1996, USING NEW DB2 IBMS O; CHAUDHURI S, 1998, B TECHNICAL COMMITTE, V21, P4; GRAEFE G, 1998, 4 INT C KNOWL DISC D; Han J., 1996, P 1996 SIGMOD WORKSH; HOUTSMA M, 1995, INT C DAT ENG TAIP T; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; IMIELINSKI T, 1996, P 2 INT C KNOWL DISC; Mehta M., 1996, P 5 INT C EXT DAT TE; MELTON J, 1992, UNDERSTANDING NEW SQ; MELTON J, 1996, 22 INT C VER LARG DA; Meo R., 1996, P 22 INT C VER LARG; PIRAHESH H, 1998, SIGMOD; RAJAMANI K, 1997, TR03690 IBM CORP SAN; SARAWAGI S, 1998, P ACM SIGMOD INT C M; SAVASERE A, 1995, P VLDB C ZUR SWITZ; SIEBES A, 1997, P 3 INT C KNOWL DISC; Srikant R., 1995, P 21 INT C VER LARG; Srikant R., 1996, P 5 INT C EXT DAT TE; STONEBRAKER M, 1991, COMMUN ACM, V34, P78, DOI 10.1145/125223.125262; THOMAS S, 1998, 4 INT C KNOWL DISC D; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; TSUR D, 1998, P ACM SIGMOD INT C M; VITTER JS, 1998, IDEAS, P58; Zaki M.J., 1997, P 3 INT C KNOWL DISC; *IBM CORP, 1997, DB2 UN DAT APPL PROG; *INT BUS MACH, 1996, IBM INT MIN US GUID; 1992, ORACLE RDBMS DATABAS, V1; 1992, ORACLE RDBMS DATABAS, V2	33	20	22	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2000	4	2-3					89	125		10.1023/A:1009887712954		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	325ZA	WOS:000087706100002	
J	Gehrke, J; Ramakrishnan, R; Ganti, V				Gehrke, J; Ramakrishnan, R; Ganti, V			RainForest - A framework for fast decision tree construction of large datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; decision trees; classification; scalability	DISCRIMINANT-ANALYSIS; CLASSIFICATION; ALGORITHMS; KNAPSACK	Classification of large datasets is an important data mining problem. Many classification algorithms have been proposed in the literature, but studies have shown that so far no algorithm uniformly outperforms all other algorithms in terms of quality. In this paper, we present a unifying framework called Rain Forest for classification tree construction that separates the scalability aspects of algorithms for constructing a tree from the central features that determine the quality of the tree. The generic algorithm is easy to instantiate with specific split selection methods from the literature (including C4.5, CART, CHAID, FACT, ID3 and extensions, SLIQ, SPRINT and QUEST). In addition to its generality, in that it yields scalable versions of a wide range of classification algorithms, our approach also offers performance improvements of over a factor of three over the SPRINT algorithm, the fastest scalable classification algorithm proposed previously. In contrast to SPRINT, however, our generic algorithm requires a certain minimum amount of main memory, proportional to the set of distinct values in a column of the input relation. Given current main memory costs, this requirement is readily met in most if not all workloads.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	Gehrke, J (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; Agresti A, 1990, CATEGORICAL DATA ANA; ASTRAHAN MM, 1987, INFORM SYST, V12, P11, DOI 10.1016/0306-4379(87)90014-7; Bishop CM, 1995, NEURAL NETWORKS PATT; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Breiman L, 1984, CLASSIFICATION REGRE; BRODLEY CE, 1992, 8 U MASS DEP COMP SC; CATLETT J, 1991, P EUR WORK SESS LEAR, V482, P164; Catlett J., 1991, THESIS U SYDNEY; Chan P., 1993, P 2 INT C INF KNOWL, P314; Chan P. K., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); CHEESEMAN P, 1988, P 5 INT C MACH LEARN; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHIRSTENSEN R, 1997, LOG LINEAR MODELS LO; CURRAM SP, 1994, J OPER RES SOC, V45, P440, DOI 10.1057/jors.1994.62; Dougherty J., 1995, MACHINE LEARNING; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FAYYAD UM, 1991, THESIS U MICHIGAN; Fayyad Usama, 1996, COMMUNICATIONS ACM, V39; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; FUKUDA T, 1996, P 22 VLDB C MUMB IND; Garey M.R., 1979, COMPUTER INTRACTABIL; GILLO MW, 1972, BEHAV SCI, V17, P251; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Graefe G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Haas P., 1995, P VLDB C, P311; Hand DJ, 1997, CONSTRUCTION ASSESSM; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; INMAN WH, 1996, COMMUNICATIONS ACM, V39; James M., 1985, CLASSIFICATION ALGOR; KERBER R, 1991, P 10 INT C ART INT, P123; IBARRA OH, 1975, J ACM, V22, P463, DOI 10.1145/321906.321909; KOHAVI R, 1995, LECT NOTES COMPUTER, V912; Kohonen Teuvo, 1995, SELF ORG MAPS; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Lim T.-S., 1997, 979 U WISC DEP STAT; LIU H, 1996, P IEEE TOOLS AI; Loh WY, 1997, STAT SINICA, V7, P815; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Maass W., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181016; MAGIDSON J, 1993, J DATABASE MARKETING, V1; MAGIDSON J, 1993, HDB MARKETING RES; MAGIDSON J, 1989, 11130 MARKT INF SYST; Mehta M., 1995, P 1 INT C KNOWL DISC; Mehta M., 1996, P 5 INT C EXT DAT TE; MORGAN JN, 1973, THAID SEQUANTIAL SEA; MORIMOTO Y, 1998, P 24 INT C VER LARG; MURPHY OJ, 1991, IEEE T COMPUT, V40, P315, DOI 10.1109/12.76408; MURTHY SK, 1995, THESIS J HOPKINS U B; Naumov G. E., 1991, Soviet Physics - Doklady, V36; BROWN DE, 1993, PATTERN RECOGN, V26, P953, DOI 10.1016/0031-3203(93)90060-A; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1983, MACHINE LEARNING ART; Rastogi R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ripley B., 1996, PATTERN RECOGNITION; Rissanen J, 1989, STOCHASTIC COMPLEXIT; SAHNI S, 1975, J ACM, V22, P115, DOI 10.1145/321864.321873; Sarle W., 1994, P 19 ANN SAS US GROU, P1538; Shafer J., 1996, P 22 INT C VER LARG; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; Sonquist J, 1971, SEARCHING STRUCTURE; Taylor C.C., 1994, MACHINE LEARNING NEU; Zighed D. A., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	67	48	51	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2000	4	2-3					127	162		10.1023/A:1009839829793		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	325ZA	WOS:000087706100003	
J	Silverstein, C; Brin, S; Motwani, R; Ullman, J				Silverstein, C; Brin, S; Motwani, R; Ullman, J			Scalable techniques for mining causal structures	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; text mining; market basket; association rules; causality	NETWORKS	Mining for association rules in market basket data has proved a fruitful area of research. Measures such as conditional probability (confidence) and correlation have been used to infer rules of the form "the existence of item A implies the existence of item B." However, such rules indicate only a statistical relationship between A and B. They do not specify the nature of the relationship: whether the presence of A causes the presence of B, or the converse, or some other attribute or phenomenon causes both to appear together. In applications, knowing such causal relationships is extremely useful for enhancing understanding and effecting change. While distinguishing causality from correlation is a truly difficult problem, recent work in statistics and Bayesian learning provide some avenues of attack. In these fields, the goal has generally been to learn complete causal models, which are essentially impossible to learn in large-scale data mining applications with a large number of variables. In this paper, we consider the problem of determining casual relationships, instead of mere associations, when mining market basket data. We identify some problems with the direct application of Bayesian learning ideas to mining large databases, concerning both the scalability of algorithms and the appropriateness of the statistical techniques, and introduce some initial ideas for dealing with these problems. We present experimental results from applying our algorithms on several large, real-world data sets. The results indicate that the approach proposed here is both computationally feasible and successful in identifying interesting causal structures. An interesting outcome is that it is perhaps easier to infer the lack of causality than to infer causality, information that is useful in preventing erroneous decision making.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Silverstein, C (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agresti A, 1990, CATEGORICAL DATA ANA; Balke A. A., 1994, P 10 C UNC ART INT S, P46; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; COOPER G, 1997, DATA MIN KNOWL DISC, V2, P203; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Heckerman D., 1995, P 11 C UNC ART INT, P285; Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752; HECKERMAN D, 1997, MSRTR9705 MICR RES; Heckerman David, 1994, P 10 C UNC ART INT, P293; PEARL J, 1993, P AD COMP INF PROC S, P25; PEARL J, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P441; Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.1093/biomet/82.4.669; Scheaffer Richard, 1986, MATH STAT APPL; Scheines R., 1993, CAUSATION PREDICTION	15	31	31	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2000	4	2-3					163	192		10.1023/A:1009891813863		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	325ZA	WOS:000087706100004	
J	Ester, M; Frommelt, A; Kriegel, HP; Sander, J				Ester, M; Frommelt, A; Kriegel, HP; Sander, J			Spatial data mining: Database primitives, algorithms and efficient DBMS support	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						mining spatial data; database primitives for KDD		Spatial data mining algorithms heavily depend on the efficient processing of neighborhood relations since the neighbors of many objects have to be investigated in a single run of a typical algorithm. Therefore, providing general concepts for neighborhood relations as well as an efficient implementation of these concepts will allow a tight integration of spatial data mining algorithms with a spatial database management system. This will speed up both, the development and the execution of spatial data mining algorithms. In this paper, we define neighborhood graphs and paths and a small set of database primitives for their manipulation. We show that typical spatial data mining algorithms are well supported by the proposed basic operations. For finding significant spatial patterns, only certain classes of paths "leading away" from a starting object are relevant. We discuss filters allowing only such neighborhood paths which will significantly reduce the search space for spatial data mining algorithms. Furthermore, we introduce neighborhood indices to speed up the processing of our database primitives. We implemented the database primitives on top of a commercial spatial database management system. The effectiveness and efficiency of the proposed approach was evaluated by using an analytical cost model and an extensive experimental study on a geographic database.	Univ Munich, Inst Comp Sci, D-80538 Munich, Germany	Ester, M (reprint author), Univ Munich, Inst Comp Sci, Oettingenstr 67, D-80538 Munich, Germany.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; BILL F, 1909, FUNDAMENTALS GEOGRAP; EGENHOFER MJ, 1991, P SSD 91, P143; Ester M., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; ESTER M, 1997, P 5 INT S LARG SPAT, P47; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; GUETING R, 1994, VLDB J, V3; Guttman A., 1984, P ACM SIGMOD INT C M, P47; KOPERSKI K, 1998, P S SPAT DAT HANDL S; KOPERSKI K, 1996, P SIGMOD WORKSH RES; KOPERSKI K., 1995, P 4 INT S LARG SPAT, P47; LU W, 1992, P 8 INT C DAT ENG PH, P284; Ng R, 1994, P 20 INT C VER LARG, P144; Rotem D., 1991, Proceedings. Seventh International Conference on Data Engineering (Cat. No.91CH2968-6), DOI 10.1109/ICDE.1991.131499; SANDER J, 1998, DATA MINING KNOWLEDG, V2; VALDURIEZ P, 1987, ACM T DATABASE SYST, V12, P218, DOI 10.1145/22952.22955	16	24	29	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2000	4	2-3					193	216		10.1023/A:1009843930701		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	325ZA	WOS:000087706100005	
J	Bayardo, RJ; Agrawal, R; Gunopulos, D				Bayardo, RJ; Agrawal, R; Gunopulos, D			Constraint-based rule mining in large, dense databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; association rules; rule induction		Constraint-based rule miners find all rules in a given data-set meeting user-specified constraints such as minimum support and confidence. We describe a new algorithm that directly exploits all user-specified constraints including minimum support, minimum confidence, and a new constraint that ensures every mined rule offers a predictive advantage over any of its simplifications. Our algorithm maintains efficiency even at low supports on data that is dense (e.g. relational tables). Previous approaches such as Apriori and its variants exploit only the minimum support constraint, and as a result are ineffective on dense data due to a combinatorial explosion of "frequent itemsets".	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Bayardo, RJ (reprint author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.						AGARWAL RC, 1998, RC21341 IBM; AGRAWAL R, 1994, RJ9839 IBM ALM RES C; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo R. J.  Jr., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Berry M. R. J., 1997, DATA MINING TECHNIQU; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; CLEARWATER SH, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P24, DOI 10.1109/TAI.1990.130305; Cohen W., 1995, P 12 INT C MACH LEAR, P115; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; GUNOPULOS G, 1997, P 6 INT C DAT THEOR, P215; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Lin DI, 1998, P 6 INT C EXT DAT TE, P105; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Murphy M A, 1994, J Clin Neurosci, V1, P257, DOI 10.1016/0967-5868(94)90066-3; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; PARK JS, 1996, P 1995 ACM SIGMOD C, P175; RYMON R, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P539; RYMON R, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P181; Savasere A, 1995, P 21 INT C VER LARG, P432; Schlimmer J.C., 1993, P 10 INT C MACH LEAR, P284; SEGAL R, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P619; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Webb GI, 1995, J ARTIF INTELL RES, V3, P431; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; *INT BUS MACH, 1996, IBM INT MIN US GUID	31	57	60	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2000	4	2-3					217	240				24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	325ZA	WOS:000087706100006	
J	Brown, TJ; Mielke, PW				Brown, TJ; Mielke, PW			Statistical mining and data visualization in atmospheric sciences	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Desert Res Inst, Reno, NV 89506 USA; Univ Nevada, Atmospher Sci Program, Reno, NV 89557 USA; Colorado State Univ, Ft Collins, CO 80523 USA	Brown, TJ (reprint author), Desert Res Inst, Reno, NV 89506 USA.							0	4	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2000	4	1					5	6		10.1023/A:1009856215038		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289HY	WOS:000085615500001	
J	Mielke, PW; Berry, KJ				Mielke, PW; Berry, KJ			Euclidean distance based permutation methods in atmospheric science	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						agreement; autoregressive patterns; cyclic data; distribution-free; experimental designs; inference; multivariate; nonparametric; permutation; prediction; regression; residual analyses	ABSOLUTE DEVIATIONS REGRESSION; ATLANTIC HURRICANE ACTIVITY; MODEL PERFORMANCE; LEAST SUM; TESTS; DISTRIBUTIONS; PROBABILITY; VALIDATION; STATISTICS; SKILL	The majority of existing statistical methods inherently involve complex nonmetric analysis spaces due to their least squares regression origin; consequently, the analysis space of such statistical methods is not consistent with the simple metric Euclidean geometry of the data space in question. The statistical methods presented in this paper are consistent with the data spaces in question. These alternative methods depend on exact and approximate permutation procedures for univariate and multivariate data involving cyclic phenomena, autoregressive patterns, covariate residual analyses including most linear model based experimental designs, and linear and nonlinear prediction model evaluations. Specific atmospheric science applications include climate change, Atlantic basin seasonal tropical cyclone predictions, analyses of weather modification experiments, and numerical model evaluations for phenomena such as cumulus clouds, clear-sky surface energy budgets, and mesoscale atmospheric predictions.	Colorado State Univ, Dept Stat, Ft Collins, CO 80523 USA; Colorado State Univ, Dept Sociol, Ft Collins, CO 80523 USA	Mielke, PW (reprint author), Colorado State Univ, Dept Stat, Ft Collins, CO 80523 USA.						ARABIE P, 1991, PSYCHOMETRIKA, V56, P567, DOI 10.1007/BF02294491; BARRODAL.I, 1974, COMMUN ACM, V17, P319, DOI 10.1145/355616.361024; BARRODAL.I, 1973, SIAM J NUMER ANAL, V10, P839, DOI 10.1137/0710069; BERRY KJ, 1983, BRIT J MATH STAT PSY, V36, P202; BERRY KJ, 1992, EDUC PSYCHOL MEAS, V52, P41, DOI 10.1177/001316449205200104; BERRY KJ, 1984, COMMUN STAT-SIMUL C, V13, P417, DOI 10.1080/03610918408812386; BERRY KJ, 1988, EDUC PSYCHOL MEAS, V48, P921, DOI 10.1177/0013164488484007; Berry KJ, 1998, PERCEPT MOTOR SKILL, V86, P1063; BOSCOVICH RJ, 1757, COMMENTARII, V4, P353; BOWDITCH N, 1809, MEM AM ACAD ARTS, V3, P1, DOI 10.2307/25057874; BROCKWELL PJ, 1984, AUSTR J STAT, V26, P30; BROCKWELL PJ, 1982, AUSTR J STAT, V24, P33; BROWN BM, 1982, BIOMETRIKA, V69, P619; COTTON WR, 1994, B AM METEOROL SOC, V75, P349, DOI 10.1175/1520-0477(1994)075<0349:RTMPOW>2.0.CO;2; DENKER M, 1988, ADV APPL MATH, V9, P200, DOI 10.1016/0196-8858(88)90013-9; DURBIN J, 1950, BIOMETRIKA, V37, P409, DOI 10.2307/2332391; ELSNER JB, 1994, WEATHER FORECAST, V9, P619, DOI 10.1175/1520-0434(1994)009<0619:AFSTCV>2.0.CO;2; ELSNER JB, 1993, WEATHER FORECAST, V8, P345, DOI 10.1175/1520-0434(1993)008<0345:IERSPO>2.0.CO;2; Fisher R, 1935, DESIGN EXPT; Gauss CF, 1809, THEORIA MOTUS CORPOR; GRAY WM, 1992, WEATHER FORECAST, V7, P440, DOI 10.1175/1520-0434(1992)007<0440:PASHAM>2.0.CO;2; HESS JC, 1994, GEOPHYS RES LETT, V21, P365, DOI 10.1029/94GL00008; Kelley TL, 1935, P NATL ACAD SCI USA, V21, P554, DOI 10.1073/pnas.21.9.554; Kelly F. P., 1989, Journal of Atmospheric and Oceanic Technology, V6, DOI 10.1175/1520-0426(1989)006<0671:IRBAAT>2.0.CO;2; LAPLACE PS, 1789, OEUVRES COMPLETE LAP, V11, P477; Lee TJ, 1995, J GEOPHYS RES-ATMOS, V100, P25585, DOI 10.1029/95JD00725; MICHAELSEN J, 1987, J CLIM APPL METEOROL, V26, P1589, DOI 10.1175/1520-0450(1987)026<1589:CVISCF>2.0.CO;2; MIELKE HW, 1983, AM J PUBLIC HEALTH, V73, P1366, DOI 10.2105/AJPH.73.12.1366; Mielke Jr PW, 1984, HDB STATISTICS, V4, P813, DOI 10.1016/S0169-7161(84)04036-0; MIELKE PW, 1985, J ATMOS SCI, V42, P1209, DOI 10.1175/1520-0469(1985)042<1209:GCPTAO>2.0.CO;2; MIELKE PW, 1991, EARTH-SCI REV, V31, P55, DOI 10.1016/0012-8252(91)90042-E; Mielke PW, 1999, J EDUC BEHAV STAT, V24, P109, DOI 10.2307/1165197; MIELKE PW, 1986, J STAT PLAN INFER, V13, P377, DOI 10.1016/0378-3758(86)90147-3; Mielke PW, 1997, PSYCHOL REP, V81, P795; MIELKE PW, 1978, BIOMETRICS, V34, P277, DOI 10.2307/2530017; Mielke PW, 1997, ANN OPER RES, V74, P259, DOI 10.1023/A:1018926522359; Mielke PW, 1996, WEATHER FORECAST, V11, P153, DOI 10.1175/1520-0434(1996)011<0153:ASAVIM>2.0.CO;2; MIELKE PW, 1982, COMMUN STAT A-THEOR, V11, P1197, DOI 10.1080/03610928208828305; MIELKE PW, 1981, MON WEATHER REV, V109, P120, DOI 10.1175/1520-0493(1981)109<0120:AOMRPP>2.0.CO;2; MIELKE PW, 1982, COMMUN STAT A-THEOR, V11, P1427; Mielke PW, 1997, WEATHER FORECAST, V12, P847, DOI 10.1175/1520-0434(1997)012<0847:ASSEOS>2.0.CO;2; MIELKE PW, 1982, J APPL METEOROL, V21, P788, DOI 10.1175/1520-0450(1982)021<0788:CIAIDR>2.0.CO;2; MIELKE PW, 1981, J APPL METEOROL, V20, P643, DOI 10.1175/1520-0450(1981)020<0643:ASROTR>2.0.CO;2; MIELKE PW, 1976, COMMUN STAT A-THEOR, V5, P1409, DOI 10.1080/03610927608827451; MIELKE PW, 1994, J EDUC BEHAV STAT, V19, P217, DOI 10.3102/10769986019003217; MIELKE PW, 1987, J STAT PLANNING INFE, V13, P430; MIELKE PW, 1979, COMMUN STAT A-THEOR, V8, P1541, DOI 10.1080/03610927908827850; OREILLY FJ, 1980, COMMUN STAT A-THEOR, V9, P629, DOI 10.1080/03610928008827907; Portnoy S, 1997, STAT SCI, V12, P279; Robinson J., 1983, AUSTR J STAT, V25, P358; Rudin W., 1966, REAL COMPLEX ANAL; SHEYNIN OB, 1973, ARCH HIST EXACT SCI, V9, P306; SIMMONS G. F., 1963, INTRO TOPOLOGY MODER; Smith PL, 1997, J APPL METEOROL, V36, P463, DOI 10.1175/1520-0450(1997)036<0463:AEAOCH>2.0.CO;2; TUCKER DF, 1989, METEOROL ATMOS PHYS, V40, P181, DOI 10.1007/BF01032458; Walker DD, 1997, MATH GEOL, V29, P1011, DOI 10.1023/A:1022309619605; Watterson IG, 1996, INT J CLIMATOL, V16, P379, DOI 10.1002/(SICI)1097-0088(199604)16:4<379::AID-JOC18>3.0.CO;2-U; WILLMOTT CJ, 1982, B AM METEOROL SOC, V63, P1309, DOI 10.1175/1520-0477(1982)063<1309:SCOTEO>2.0.CO;2; WILLMOTT CJ, 1995, J APPL METEOROL, V34, P2577, DOI 10.1175/1520-0450(1995)034<2577:SIOAAA>2.0.CO;2; WILLMOTT CJ, 1985, J GEOPHYS RES-OCEANS, V90, P8995, DOI 10.1029/JC090iC05p08995; Willmott C.J, PHYS GEOG, V2, P184; Willmott CJ, 1996, INT J CLIMATOL, V16, P1103, DOI 10.1002/(SICI)1097-0088(199610)16:10<1103::AID-JOC78>3.0.CO;2-P; WONG RKW, 1983, ATMOS OCEAN, V21, P1	63	4	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2000	4	1					7	27				21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289HY	WOS:000085615500002	
J	Rao, JS				Rao, JS			Bootstrapping to assess and improve atmospheric prediction models	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						bootstrap; CART; classification; hurricanes; instability; supervised learning; weather data	JACKKNIFE	Bootstrapping is a simple technique typically used to assess accuracy of estimates of model parameters by using simple plug-in principles and replacing sometimes unwieldy theory by computer simulation. Common uses include variance estimation and confidence interval construction of model parameters. It also provides a way to estimate prediction accuracy of continuous and class-valued outcomes regression models. In this paper we will overview some of these applications of the bootstrap focusing on bootstrap estimates of prediction error, and also explore how the bootstrap can be used to improve prediction accuracy of unstable models like tree-structured classifiers through aggregation. The improvements can typically be attributed to variance reduction in the classical regression setting and more generally a smoothing of decision boundaries for the classification setting. These advancements have important implications in the way that atmospheric prediction models can be improved, and illustrations of this will be shown. For class-valued outcomes, an interesting graphic known as the CAT scan can be constructed to help understand the aggregated decision boundary. This will be illustrated using simulated data.	Case Western Reserve Univ, Dept Biostat, Cleveland, OH 44106 USA	Rao, JS (reprint author), Case Western Reserve Univ, Dept Biostat, Cleveland, OH 44106 USA.						Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHAMBERS JM, 1991, STAT MODELS S PACIFI; CHIPMAN H, 1998, MAKING SENSE FOREST; Davison AV, 1997, BOOTSTRAP METHODS TH; Efron B., 1993, INTRO BOOTSTRAP; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Efron B, 1982, JACKNIFE BOOTSTRAP O; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Efron B., 1982, JACKKNIFE BOOTSTRAP; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GRAY WM, 1992, WEATHER FORECAST, V7, P440, DOI 10.1175/1520-0434(1992)007<0440:PASHAM>2.0.CO;2; LEGER C, 1992, TECHNOMETRICS, V34, P378, DOI 10.2307/1268938; QUINLAN R, 1996, P AAAI NAT C ART INT; Rao J., 1997, OUT BOOTSTRAP METHOD; RAO JS, IN PRESS J COMPUTATI; Ripley B., 1996, PATTERN RECOGNITION; Shao J., 1995, SPRINGER SERIES STAT; Shao J, 1996, J AM STAT ASSOC, V91, P655, DOI 10.2307/2291661; Tibshirani R, 1996, NEURAL COMPUT, V8, P152, DOI 10.1162/neco.1996.8.1.152; Tibshirani Robert, 1996, BIAS VARIANCE PREDIC; WU CFJ, 1986, ANN STAT, V14, P1261, DOI 10.1214/aos/1176350142	24	6	6	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2000	4	1					29	41		10.1023/A:1009876615946		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289HY	WOS:000085615500003	
J	Carr, DB; Olsen, AR; Pierson, SM; Courbois, JYP				Carr, DB; Olsen, AR; Pierson, SM; Courbois, JYP			Using linked micromap plots to characterize Omernik ecoregions	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						statistical graphics; LM plots; multivariate; spatial data; Omernik ecoregions; row plots; boxplots; line-height plots	UNITED-STATES	The paper introduces linked micromap (LM) plots for presenting environmental summaries. The LM template includes parallel sequences of micromap, label, and statistical summary graphics panels with attention paid to perceptual grouping, sorting and linking of the summary components. The applications show LM plots for Omernik Level II Ecoregions. The summarized United States continental data includes USGS digital elevation, 30-year normal precipitation and temperature, and 8 million AVHRR pixels classified into 159 types of land cover. One LM plot uses a line-height glyph to represent all 159 land cover percentages per ecoregion. LM plots represent new visualization methodology that is useful in the data and knowledge based pattern representation and knowledge discovery process. The LM plots focus on providing an orienting overview. The overview provides a starting place for subsequent drilling down to what could otherwise be viewed as an overwhelming mass of data. The overview also provides a starting place to learn about the intellectual structure that lies behind the notion of ecoregions and begins to connect this abstract structure to quantitative methods.	George Mason Univ, Ctr Computat Stat, Fairfax, VA 22030 USA; US EPA, NHEERL Western Ecol Div, Corvallis, OR 97333 USA; US EPA, OAO, Corvallis, OR 97333 USA; Oregon State Univ, Dept Stat, Corvallis, OR 97331 USA	Carr, DB (reprint author), George Mason Univ, Ctr Computat Stat, Fairfax, VA 22030 USA.						Bailey RG, 1995, ECOSYSTEM GEOGRAPHY; BAILEY R.G, 1995, USDA MISC PUBL; BAILEY RG, 1998, USDA MISC PUBL, V1548; BECKER RA, 1993, J COMPUT GRAPH STAT, V2, P41, DOI 10.2307/1390953; Bertin J., 1983, SEMIOLOGY GRAPHICS D; BREWER CA, 1997, CARTOGR GEOGR INF SC, V24, P203, DOI 10.1559/152304097782439231; CARR D, 1996, STAT COMPUTING GRAPH, V7, P19; Carr D. B., 1997, STAT COMPUTING GRAPH, V7, p[20, 584]; CARR D. B., 1991, COMPUTING GRAPHICS S, P7; CARR DB, 1997, US BUREAU LABOR STAT, V42; CARR DB, 1994, STAT COMPUTING GRAPH, V5, P11; CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444; CARR DB, 1996, COMPUTING SCI STAT, V27, P410; CARR DB, 1996, STAT COMPUTING GRAPH, V7, P10; CARR DB, 1980, PNLSA8781; CARR DB, 1996, STAT COMPUTING GRAPH, V7, P16; CARR DB, 1992, CARTOGR GEOGR INFORM, V19, P228, DOI 10.1559/152304092783721231; CARR DB, 1994, 101 G MAS U CTR COMP; CARR DB, 1998, ENCY BIOSTATISTICS, V4, P2864; CARR DB, 1995, STAT COMPUTING STAT, V6, P11; Carrano AV, 1998, HUM GENOME NEWS, V9, P1; Chambers J. M., 1983, GRAPHICAL METHODS DA; CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400; Cleveland W. S., 1993, VISUALIZING DATA; Cleveland W. S., 1994, ELEMENTS GRAPHING DA; CLEVELAND WS, 1993, J COMPUTATIONAL GRAP, V2, P322; DALY C, 1994, J APPL METEOROL, V33, P140, DOI 10.1175/1520-0450(1994)033<0140:ASTMFM>2.0.CO;2; DENT B. D., 1990, CARTOGRAPHY THEMATIC; Dorling D, 1995, NEW SOCIAL ATLAS BRI; EDDY WF, 1996, J COMPUTATIONAL GRAP, V5, P101; EICK SG, 1996, MASS DAT SETS P WORK; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; FRIGGE M, 1989, AM STAT, V43, P50, DOI 10.2307/2685173; Goodchild M. F., 1989, ACCURACY SPATIAL DAT; Grant J., 1993, STATE WORLDS CHILDRE; GREEN S, 1997, 9720 U MAR HUM COMP; GREEN S, 1997, 9716 U MAR HUM COMP; HALL DL, 1980, PNLSA8781; HUBER P, 1994, COMPSTAT 1994; JULESZ B, 1986, BIOL CYBERN, V54, P245, DOI 10.1007/BF00318420; Kosslyn S. M., 1994, ELEMENTS GRAPH DESIG; LOVELAND TR, 1995, ANN ASSOC AM GEOGR, V85, P339, DOI 10.1111/j.1467-8306.1995.tb01798.x; MacEachren A. M., 1994, SOME TRUTH MAPS PRIM; MacEachren A.M., 1995, MAPS WORK REPRESENTA; MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468; MONMONIER M, 1988, P STAT GRAPH SECT AM, P1; Monmonier Mark, 1993, MAPPING IT OUT; OLSEN AR, 1996, 1996 JOINT STAT M CH; Omernik J.M., 1995, BIOL ASSESSMENT CRIT, P49; OMERNIK JM, 1987, ANN ASSOC AM GEOGR, V77, P118, DOI 10.1111/j.1467-8306.1987.tb00149.x; Perez Carrion R, 1994, ANN ONCOL S7, V5, P19; PICKLE LW, 1997, ATLAS US MORTALITY; PLAISANT C, 1998, 9880 U MAR HUM COMP; Scott D.W., 1992, MULTIVARIATE DENSITY; Tufte E. R., 1997, VISUAL EXPLANATIONS; TUFTE ER, 1990, ENVISIONING INFORMAT; Tufte E.R., 1983, VISUAL DISPLAY QUANT; Tukey J. W., 1993, J COMPUTATIONAL GRAP, V2, P1, DOI 10.2307/1390951; Wahlstrom E., 1996, FUTURE FINNISH ENV; Wiken E. B, 1986, ECOLOGICAL LAND CLAS, V19; WOODS D, 1992, POWER MAPS; ZAWITZ MW, 1983, REPORT NATION CRIME; *ART MON ASS PROGR, 1997, ARCT POLL ISS STAT A; *CATS, 1996, P WORKSH COMM APPL T	64	7	7	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2000	4	1					43	67		10.1023/A:1009828700017		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289HY	WOS:000085615500004	
J	Macedo, M; Cook, D; Brown, TJ				Macedo, M; Cook, D; Brown, TJ			Visual data mining in atmospheric science data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						multivariate analysis; statistical graphics; exploratory data analysis; high-dimensional data; interactive graphics; linked brushing; grand tour	EXPLORATORY ANALYSIS; SCATTERPLOT MATRIX; DYNAMIC GRAPHICS; LINKED SOFTWARE; GIS	This paper discusses the use of simple visual tools to explore multivariate spatially-referenced data. It describes interactive approaches such as linked brushing, and dynamic methods such as the grand tour, applied to studying the Comprehensive Ocean-Atmosphere Data Set (COADS). This visual approach provides an alternative way to gain understanding of high-dimensional data. It also provides cross-validation and visual adjuncts to the more computationally intensive data mining techniques.	Iowa State Univ, Dept Stat, Ames, IA 50011 USA; Desert Res Inst, Reno, NV 89512 USA	Macedo, M (reprint author), Iowa State Univ, Dept Stat, 102 Snedecor Hall, Ames, IA 50011 USA.						ASIMOV D, 1985, SIAM J SCI STAT COMP, V6, P128, DOI 10.1137/0906011; BAO S, 1997, ASA P SECT STAT GRAP, P61; BUJA A, 1986, P 17 S INT COMP SCI, P63; Buja A, 1988, DYNAMIC GRAPHICS STA, P277; BUJA A, 1997, DYNAMIC PROJECTIONS; Buja A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), DOI 10.1109/VISUAL.1991.175794; Buja A., 1996, J COMPUTATIONAL GRAP, V5, P78, DOI 10.2307/1390754; CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444; CARR DB, 1996, 129 G MAS U CTR COMP; Cook D, 1997, COMPUT GEOSCI, V23, P371, DOI 10.1016/S0098-3004(97)00015-0; Cook D, 1998, ENVIRON MONIT ASSESS, V51, P441, DOI 10.1023/A:1005909420690; Cook D., 1995, J COMPUTATIONAL GRAP, V4, P155, DOI 10.2307/1390844; COOK D, 1997, J STAT SOFTWARE; Cook D, 1997, J COMPUT GRAPH STAT, V6, P464, DOI 10.2307/1390747; Cook D, 1996, COMPUTATION STAT, V11, P467; DYKES J, 1996, INNOVATIONS GIS, V3, P177; ELMS JD, 1993, DIGITIZING HIST RECO, P4; Haining R, 1996, COMPUTATION STAT, V11, P449; HASLETT J, 1991, AM STAT, V45, P234, DOI 10.2307/2684298; MACDOUGALL EB, 1992, CARTOGR GEOGR INFORM, V19, P237, DOI 10.1559/152304092783721268; MACEDO M, 1998, EXPLORATORY DATA ANA; MAJURE JJ, 1995, SPATIAL CDF ESTIMATI; MCDONALD JA, 1987, USE GRAND TOUR REMOT; MCDONALD JA, 1982, INTERACTIVE GRAPHICS; MONMONIER M, 1989, GEOGR ANAL, V21, P81; NEWTON CM, 1978, GRAPHICAL REPRESENTA, P59; Swayne DF, 1998, J COMPUT GRAPH STAT, V7, P113, DOI 10.2307/1390772; SYMANZIK J, 1997, ASA P SECT STAT GRAP; SYMANZIK J, 1999, IN PRESS J COMPUTATI; Unwin A, 1990, ASA P SECT STAT GRAP, P36; WILKS DS, 1995, STAT METHODS ATMOSPH; WOODRUFF SD, 1993, EARTH SYSTEM MONITOR, V1, P1	32	6	6	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2000	4	1					69	80		10.1023/A:1009880716855		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	289HY	WOS:000085615500005	
S	Miyahara, T; Shoudai, T; Uchida, T; Takahashi, K; Ueda, H		Terano, T; Liu, H; Chen, ALP		Miyahara, T; Shoudai, T; Uchida, T; Takahashi, K; Ueda, H			Polynomial time matching algorithms for tree-like structured patterns in Knowledge Discovery	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Graphs have enough richness and flexibility to express discrete structures hidden in a large amount of data. Some searching methods utilizing graph algorithmic techniques have been developed in Knowledge Discovery. A term graph, which is one of expressions for graph-structured data, is a hypergraph whose hyperedges are regarded as variables. Although term graphs can represent complicated patterns found from structured data, it is hard to do pattern match and pattern search in them. We have been studying subclasses of term graphs, called regular term trees, which are suited for expressing tree-like structured data. In this paper, we consider a matching problem for a regular term tree T and a standard tree T, which decides whether or not there exists a tree T ' such that T ' is isomorphic to T and T ' is obtained by replacing variables in t with some trees. First we show that the matching problem for a regular term tree and a tree is NP-complete even if each variable in the regular term tree contains only 4 vertices. Next we give a polynomial time algorithm for solving the matching problem for a regular term tree and a tree of bounded degree such that the regular term tree has only variables consisting the constant number of vertices greater than one. We also report some computational experiments and compare our algorithm with a naive algorithm.	Hiroshima City Univ, Fac Informat Sci, Hiroshima 7333194, Japan; Kyushu Univ, Dept Informat, Kasuga, Fukuoka 8168580, Japan	Miyahara, T (reprint author), Hiroshima City Univ, Fac Informat Sci, Hiroshima 7333194, Japan.						Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Dehaspe L, 1999, DATA MIN KNOWL DISC, V3, P7, DOI 10.1023/A:1009863704807; Dzeroski S., 1998, LECT NOTES ARTIF INT, V1446, P281; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P118; Garey M. R., 1979, COMPUTERS INTRACTABI; Matsumoto S, 1997, LECT NOTES ARTIF INT, V1316, P212; MIYAHARA T, 1999, LECT NOTES ARTIF INT, V1574, P438; Miyahara T, 1999, LECT NOTES ARTIF INT, V1634, P222; MUKOUCHI Y, 1995, THEOR COMPUT SCI, V137, P53, DOI 10.1016/0304-3975(95)91135-D; TOIVONEN H, 1999, P PAKDD WORKSH KNOWL; UCHIDA T, 1995, IEICE T INF SYST, VE78D, P99	11	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						5	16				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400001	
S	Vucetic, S; Obradovic, Z		Terano, T; Liu, H; Chen, ALP		Vucetic, S; Obradovic, Z			Performance controlled data reduction for knowledge discovery in distributed databases	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		data reduction; data compression; sensitivity analysis; distributed databases; neural networks; learning curve		The objective of data reduction is to obtain a compact representation of a large data set to facilitate repeated use of non-redundant information with complex and slow learning algorithms and to allow efficient data transfer and storage. For a user-controllable allowed accuracy loss we propose an effective data reduction procedure based on guided sampling for identifying a minimal size representative subset, followed by a model-sensitivity analysis for determining an appropriate compression level for each attribute. Experiments were performed on 3 large data sets and, depending on an allowed accuracy loss margin ranging from 1% to 5% of the ideal generalization, the achieved compression rates ranged between 95 and 12,500 times. These results indicate that transferring reduced data sets from multiple locations to a centralized site for an efficient and accurate knowledge discovery might often be possible in practice.	Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA	Vucetic, S (reprint author), Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA.						BLACKARD JA, 1998, THESIS COLORADO STAT; Breiman L, 1984, CLASSIFICATION REGRE; Cressie N.A.C., 1993, STAT SPATIAL DATA; Davidson R., 1993, ESTIMATION INFERENCE; HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898; Judge G. G., 1988, INTRO THEORY PRACTIC; MURPHY PM, 1999, UCI REPOSITORY MACHI; OATES T, 1998, P 4 INT C KNOWL DISC; PROVOST F, 1999, P 5 INT C KNOWL DISC; Sayood K., 1996, INTRO DATA COMPRESSI; Stolfo S, 1997, P 3 INT C KNOWL DISC; VUCETIC S, 1999, P IEEE INNS INT C NE	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						29	39				11	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400003	
S	Rumantir, GW		Terano, T; Liu, H; Chen, ALP		Rumantir, GW			Minimum Message Length criterion for second-order polynomial model discovery	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		scientific discovery; automated modelling; second-order polynomial regression		This paper proposes a method based on the Minimum Message Length (MML) Principle for the task of discovering polynomial models up to the second order. The method is compared with a number of other selection criteria in the ability to, in an automated manner, discover a model given the generated data. Of particular interest is the ability of the methods to discover (1) second-order independent variables, (2) independent variables with weak causal relationships with the target variable given a small sample size, and (3) independent variables with weak links to the target variable but strong links from other variables which are not directly linked with the target variable. A common non-backtracking search strategy has been developed and is used with all of the model selection criteria.	Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3168, Australia	Rumantir, GW (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3168, Australia.						Akaike H., 1973, INT S INFORMATION TH, P267; BAXTER R, 1996, 276 MON U SCH COMP S; BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361; Conway J. H., 1988, SPHERE PACKINGS LATT; Ezekiel M., 1930, METHODS CORRELATION; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Miller AJ, 1990, SUBSET SELECTION REG; RISSANEN J, 1987, J ROY STAT SOC B MET, V49, P223; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Ryan T. P., 1997, MODERN REGRESSION ME; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Vapnik V.N., 1995, NATURE STAT LEARNING; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; WALLACE CS, 1997, UNPUB SELECTION ORDE	14	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						40	48				9	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400004	
S	Jensen, VC; Soparkar, N		Terano, T; Liu, H; Chen, ALP		Jensen, VC; Soparkar, N			Frequent itemset counting across multiple tables	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Available technology for mining data usually applies to centrally stored data (i.e., homogeneous, and in one single repository and schema). The few extensions to mining algorithms for decentralized data have largely been for load balancing. In this paper, we examine mining decentralized data for the task of finding frequent itemsets. In contrast to current techniques where data is first joined to form a single table, we exploit the inter-table foreign key relationships to obtain decentralized algorithms that execute concurrently on the separate tables, and thereafter, merge the results. In particular, for typical warehouse schema designs, our approach adapts standard algorithms, and works efficiently. We provide analyses and empirical validation for important cases to exhibit how our approach performs well. In doing so, we also compare two of our approaches in merging results from individual tables, and thereby, we exhibit certain memory vs I/O trade-offs that are inherent in merging of decentralized partial results.	Univ Michigan, Ann Arbor, MI 48109 USA	Jensen, VC (reprint author), Univ Michigan, Ann Arbor, MI 48109 USA.						AGARWAL RC, 1998, 21246 IBM RJ RES DIV; Agrawal R., 1993, P ACM SIGMOD INT C M; Agrawal R., 1994, P 20 INT C VER LARG; BRIN S, 1997, P ACM SIGMOD INT C M; CHEUNG D, 1996, IEEE T KNOWL DAT ENG; CRESTANA V, 1999, CSETR38599 U MICH; DUNKEL B, 1999, P 15 IEEE INT C DAT; JENSEN VC, 1999, CSETR41899 U MICH; Liu B., 1998, P 4 INT C KNOWL DISC; Park J.S., 1995, P ACM SIGMOD INT C M; SAVASERE A, 1995, P 21 INT C VER LARG; SILBERSCHATZ A, 1996, DATABASE SYSTEMS CON; Srikant R., 1996, P ACM SIGMOD INT C M; *STAR SCHEM STARJ, 1995, RED BRICK SYST WHIT	14	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						49	61				13	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400005	
S	Boulicaut, JF; Bykowski, A		Terano, T; Liu, H; Chen, ALP		Boulicaut, JF; Bykowski, A			Frequent closures as a concise representation for binary data mining	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Frequent set discovery from binary data is an important problem in data mining. It concerns the discovery of a concise representation of large tables from which descriptive rules can be derived, e.g., the popular association rules. Our work concerns the study of two representations, namely frequent sets and frequent closures. N. Pasquier and colleagues designed the close algorithm that provides frequent sets via the discovery of frequent closures. When one mines highly correlated data, apriori-based algorithms clearly fail while close remains tractable. We discuss our implementation of close and the experimental evidence we got from two real-life binary data mining processes. Then, we introduce the concept of almost-closure (generation of every frequent set from frequent almost-closures remains possible but with a bounded error on frequency). To the best of our knowledge, this is a new concept and, here again, we provide some experimental evidence of its add-value.	Inst Natl Sci Appl, Lab Ingn Syst Informat, F-69621 Villeurbanne, France	Boulicaut, JF (reprint author), Inst Natl Sci Appl, Lab Ingn Syst Informat, Batiment 501, F-69621 Villeurbanne, France.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; BOULICAUT JF, 2000, MINING ALMOST CLOSUR; BYKOWSKI A, 1999, THESIS INSA LYON; Klemettinen M., 1999, LNCS, V1676, P293; MANNILA H, 1997, P INT LOG PROGR S, P21; Mannila H., 1996, P 2 INT C KNOWL DISC, P189; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; PASQUIER N, 1999, P BDA 99 BORD OCT, P53; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Zaki M., 1998, P 3 ACM SIGMOD 98 WO, P85	13	26	26	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						62	73				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400006	
S	Hung, E; Cheung, DW; Kao, B; Liang, YL		Terano, T; Liu, H; Chen, ALP		Hung, E; Cheung, DW; Kao, B; Liang, YL			An optimization problem in data cube system design	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				In an CLAP system, we can use data cubes (precomputed multidimensional views of data) to support real-time queries. To reduce the maintenance cost, which is related to the number of cubes materialized, some cubes can be merged, but the resulting larger cubes will increase the response time of answering some queries. In order to satisfy the maintenance bound and response time bound given by the user, we may have to sacrifice some of the queries and not to take them into our consideration. The optimization problem in the data cube system design is to optimize an initial set of cubes such that the system can answer a maximum number of queries and satisfy the bounds. This is an NP-complete problem. Approximate algorithms Greedy Removing and 2-Greedy Merging are proposed. Experiments have been done on a census database and the results show that our approach is both effective and efficient.	Univ Hong Kong, Dept Comp Sci & Informat Syst, Hong Kong, Hong Kong, Peoples R China	Hung, E (reprint author), Univ Hong Kong, Dept Comp Sci & Informat Syst, Hong Kong, Hong Kong, Peoples R China.	ehung@csis.hku.hk; dcheung@csis.hku.hk; kao@csis.hku.hk; ylliang@csis.hku.hk					CHAURET N, 1997, DRUG METAB DISPOS, V26, P1; CHEUNG DW, 1999, P 8 INT C INF KNOWL; Gray J, 1996, PROC INT CONF DATA, P152, DOI 10.1109/ICDE.1996.492099; Harinarayan V., 1996, P ACM SIGMOD INT C M, P205, DOI 10.1145/233269.233333; HUNG E, OPTIMIZATION DATA CU; O'Neil P., 1997, P ACM SIGMOD INT C M, P38, DOI 10.1145/253260.253268; ONEILL P, 1995, SIGMOD RECORD    SEP, P8; Shukla A., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases	8	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						74	85				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400007	
S	Hussain, F; Liu, H; Suzuki, E; Lu, HJ		Terano, T; Liu, H; Chen, ALP		Hussain, F; Liu, H; Suzuki, E; Lu, HJ			Exception rule mining with a relative interestingness measure	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				This paper presents a method for mining exception rules based on a novel measure which estimates interestingness relative to its corresponding common sense rule and reference rule. Mining interesting rules is one of the important data mining tasks. Interesting rules bring novel knowledge that helps decision makers for advantageous actions. It is true that interestingness is a relative issue that depends on the other prior knowledge. However, this estimation can be biased due to the incomplete or inaccurate knowledge about the domain. Even if possible to estimate interestingness, it is not so trivial to judge the interestingness from a huge set of mined rules. Therefore, an automated system is required that can exploit the knowledge extractacted from the data in measuring interestingness. Since the extracted knowledge comes from the data, so it is possible to find a measure that is unbiased from the user's own belief. An unbiased measure that can estimate the interestingness of a rule with respect to the extractacted rules can be more acceptable to the user. In this work we try to show through the experiments, how our proposed relative measure can give an unbiased estimate of relative interestingness in a rule considering already mined rules.	Natl Univ Singapore, PRIS, Sch Comp, Singapore 117548, Singapore; Yokohama Natl Univ, Yokohama, Kanagawa 240, Japan; Hong Kong Univ Sci & Technol, Hong Kong, Hong Kong, Peoples R China	Hussain, F (reprint author), Natl Univ Singapore, PRIS, Sch Comp, Singapore 117548, Singapore.	farhad@comp.nus.edu.sg; liuh@comp.nus.edu.sg; suzuki@dnj.ynu.ac.jp; luhj@cs.ust.hk; liuh@comp.nus.edu.sg					Agrawal R., 1994, P 20 INT C VER LARG, P478; Chakrabarti S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; HSU W, 1997, P 3 INT C KNOWL DISC, P31; LIU H, 1999, P 3 PAC AS C KNOWL D, P194; MANNILA H, 1994, 3 INT C INF KNOWL MA; Merz C. J., 1996, UCI REPOSITORY MACHI; PADMANABHAN B, 1998, P 4 INT C KNOWL DISC, P27; PIATETSKYSHAPIR.G, 1996, SELECTING REPORTING; SHANNON C, 1949, MATH THEORY INFORMAT; Smyth P., 1991, Knowledge discovery in databases; SUZUKI E, 1996, P 2 INT C KNOWL DISC, P295; SUZUKI E, 1996, P 4 INT WORKSH ROUGH, P225; Suzuki E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; SUZUKI E, 1998, P 2 PAC AS C KNOWL D; THOMAS C, 1996, ELEMENTS INFORMATION; TUZHILIN A, 1996, IEEE T KNOWLEDGE DIS, P970	16	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						86	97				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400008	
S	Dash, M; Liu, H; Motoda, H		Terano, T; Liu, H; Chen, ALP		Dash, M; Liu, H; Motoda, H			Consistency based feature selection	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Feature selection is an effective technique in dealing with dimensionality reduction for classification task, a main component of data mining. It searches for an "optimal" subset of features. The search strategies under consideration are one of the three: complete, heuristic, and probabilistic. Existing algorithms adopt various measures to evaluate the goodness of feature subsets. This work focuses on one measure called consistency. We study its properties in comparison with other major measures and different ways of using this measure in search of feature subsets. We conduct an empirical study to examine the pros and cons of these different search methods using consistency. Through this extensive exercise, we aim to provide a comprehensive view of this measure and its relations with other measures and a guideline of the use of this measure with different search strategies facing a new application.	Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore; Osaka Univ, Div Intelligent Sys Sci, Ibaraki, Osaka 567, Japan	Dash, M (reprint author), Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.						ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Ben-Bassat M., 1982, HDB STATISTICS, V2, P773, DOI 10.1016/S0169-7161(82)02038-0; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Blumer A., 1990, READINGS MACHINE LEA, P201; Brassard G., 1996, FUNDAMENTALS ALGORIT; Dash M., 1997, Proceedings. 1997 IEEE Knowledge and Data Engineering Exchange Workshop (Cat. No.97TB100208), DOI 10.1109/KDEX.1997.629862; DASH M, 1997, INTELLIGENT DATA ANA, V1; Devijver PA, 1982, PATTERN RECOGNITION; John G. H., 1994, P 11 INT C MACH LEAR, P121; JOHNSON DS, 1974, J COMPUT SYST SCI, V9, P256; Kira K, 1992, P 10 NAT C ART INT, P129; KOHAVI R, 1995, THESIS STANFORD U CA; LIU H, 1996, P 9 INT C IND ENG AP; Liu H, 1998, P EUR C MACH LEARN, P101; Merz C. J., 1996, UCI REPOSITORY MACHI; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RAUBER TW, 1994, THESIS U NOVA LISBOA; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; Watanabe S., 1985, PATTERN RECOGNITION; Zell A., 1995, STUTTGART NEURAL NET	21	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						98	109				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400009	
S	Dash, M; Liu, H		Terano, T; Liu, H; Chen, ALP		Dash, M; Liu, H			Feature selection for clustering	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Clustering is an important data mining task. Data mining often concerns large and high-dimensional data but unfortunately most of the clustering algorithms in the literature are sensitive to largeness or high-dimensionality or both. Different features affect clusters differently, some are important for clusters while others may hinder the clustering task. An efficient way of handling it is by selecting a subset of important features. It helps in finding clusters efficiently, understanding the data better and reducing data size for efficient storage, collection and processing. The task of finding original important features for unsupervised data is largely untouched. Traditional feature selection algorithms work only for supervised data where class information is available. For unsupervised data, without class information, often principal components (PCs) are used, but PCs still require all features and they may be difficult to understand. Our approach: first features are ranked according to their importance on clustering and then a subset of important features are selected. For large data we use a scalable method using sampling. Empirical evaluation shows the effectiveness and scalability of our approach for benchmark and synthetic data sets.	Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore	Dash, M (reprint author), Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.						Aggarwal C., 1999, P 1999 ACM SIGMOD IN, P61, DOI 10.1145/304182.304188; AGRAWAL R, 1998, P ACM SIGMOD C MAN D; Agrawal R., 1994, P 20 VLDB C SANT CHI; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; CHENG C., 1999, P INT C KNOWL DISC D; Dash M., 1997, INT J INTELLIGENT DA, V1; Devore J. L., 1995, PROBABILITY STAT ENG; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; GANTI V, 1999, P INT C KNOWL DIS DA; Jain AK, 1988, PRENTICE HALL ADV RE; KOHAVI R, 1995, THESIS STANFORD U ST; Merz C. J., 1996, UCI REPOSITORY MACHI	13	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						110	121				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400010	
S	Keogh, EJ; Pazzani, MJ		Terano, T; Liu, H; Chen, ALP		Keogh, EJ; Pazzani, MJ			A simple dimensionality reduction technique for fast similarity search in large time series databases	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				We address the problem of similarity search in large time series databases. We introduce a novel-dimensionality reduction technique that supports an indexing algorithm that is more than an order of magnitude faster than the previous best known method. In addition to being much faster our approach has numerous other advantages. It is simple to understand and implement, allows more flexible distance measures including weighted Euclidean queries and the index can be built in linear time. We call our approach PCA-indexing (Piecewise Constant Approximation) and experimentally validate it on space telemetry, financial, astronomical, medical and synthetic data.	Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA	Keogh, EJ (reprint author), Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA.						Agrawal R., 1995, VLDB; Agrawal R., 1993, P 4 C FDN DAT ORG AL; CHAKRABARTI K, 1999, P IEEE INT C DAT ENG; CHAN KP, 1999, P 15 INT C DAT ENG; DAS G, 1998, P 3 INT C KNOWL DISC; FALOUTSOS C, 1994, P ACM SIGMOD C MINN; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163, DOI 10.1145/223784.223812; Guttman A., 1984, P ACM SIGMOD INT C M, P47; HELLERSTEIN JM, 1997, 16 ACM SIGACT S PRIN; Huang YW, 1999, P 5 INT C KNOWL DISC, P282, DOI 10.1145/312129.318357; Kanth K. V., 1998, P ACM SIGMOD INT C M, P166; Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; KEOGH E, 1999, P 22 ANN INT ACM SIG; KEOGH E, 1997, P 3 INT C KNOWL DISC; PARK S, 1999, 3 IEEE KNOWL DAT ENG; REFIEI D, 1997, P ACM SIGMOD C, P13; SCARGLE J, 1998, ASTROPHYSICAL J, V504; SHATKAY H, 1996, P 12 IEEE INT C DAT, P546; SHATKAY H, 1995, CS9537 BROWN U DEP C; STRUZIK Z, 1999, 3 EUR C PRINC PRACT; WETTSCHERECK D, 1997, AI REV, V11; YI BK, 1998, IEEE INT C DAT ENG, P201	22	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						122	133				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400011	
S	Lee, KC; Park, JS; Kim, YS; Byun, YT		Terano, T; Liu, H; Chen, ALP		Lee, KC; Park, JS; Kim, YS; Byun, YT			Missing value estimation based on dynamic attribute selection	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Raw Data used in data mining often contain missing information, which inevitably degrades the quality of the derived knowledge. In this paper, a new method of guessing missing attribute values is suggested. This method selects attributes one by one using attribute group mutual information calculated by flattening the already selected attributes. As each new attribute is added, its missing values are filled up by generating a decision tree, and the previously filled up missing values are naturally utilized. This ordered estimation of missing values is compared with some conventional methods including Lobo's ordered estimation which uses static ranking of attributes. Experimental results show that this method generates good recognition ratios in almost all domains with many missing values.	Hongik Univ, Dept Comp Sci, Seoul 121791, South Korea	Lee, KC (reprint author), Hongik Univ, Dept Comp Sci, Seoul 121791, South Korea.	lee@cs.hongik.ac.kr; jspark@cs.hongik.ac.kr; yskim@cs.hongik.ac.kr; byun@cs.hongik.ac.kr					CESTNIK B, 1987, PROGR MACHINE LEARNI; Kononenko I., 1984, EXPT AUTOMATIC LEARN; LEE KC, 1999, LECT NOTES ARTIF INT, V1574, P138; LOBO OO, 1999, LECT NOTES ARTIF INT, V1574, P499; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; QUINLAN JR, 1993, C4 5 PROGRAMS MACHIN, P27; *U CAL DEP INF COM, 1998, UCI MACH LEARN REP	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						134	137				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400012	
S	Yao, YY; Zhong, N		Terano, T; Liu, H; Chen, ALP		Yao, YY; Zhong, N			On association, similarity and dependency of attributes	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan					Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada; Yamaguchi Univ, Fac Engn, Dept Comp Sci & Syst Engn, Ube, Yamaguchi 755, Japan	Yao, YY (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.		Yao, Yiyu/B-2926-2008				Yao Y. Y., 1999, P PAC AS C KNOWL DIS, P479; Yao Y.Y., 1999, P 3 PAC AS C KNOWL D, P133; YAO YY, 1999, UNPUB GRANULAR COMPU	3	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						138	141				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400013	
S	Keung, CK; Lam, W		Terano, T; Liu, H; Chen, ALP		Keung, CK; Lam, W			Prototype generation based on instance filtering and averaging	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan			LEARNING ALGORITHMS	We propose a new algorithm, called Prototype Generation and Filtering (PGF), which combines the strength of instance-filtering and instance-averaging techniques. PGF is able to generate representative prototypes while eliminating noise and exceptions. We also introduce a distance measure incorporating the class label entropy information for the prototypes. Experiments have been conducted to compare our PGF algorithm with pure instance filtering, pure instance averaging, as well as state-of-the-art algorithms such as C4.5 and KNN. The results demonstrate that PGF can significantly reduce the size of the data while maintaining and even improving the classification performance.	Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Shatin, Hong Kong, Peoples R China	Keung, CK (reprint author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Shatin, Hong Kong, Peoples R China.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAREISS R, 1989, EXEMPLAR BASED KNOWL, V2; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; Bradshaw G., 1987, Proceedings of the Fourth International Workshop on Machine Learning; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DATTA P, 1995, P 12 INT C MACH LEAR, P158; Datta P., 1997, P 14 NAT C ART INT, P82; DATTA P, 1997, P 14 INT C MACH LEAR, P75; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KIBLER D, 1988, P 3 EUR WORK SESS LE, P63; Murphy P., 1994, UCI REPOSITORY MACHI; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; ULLMANN JR, 1974, IEEE T INFORMATION T, V20, P431; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, P323; WILSON DL, 1972, IEEE T SYST MAN CYB, V2, P431; Wilson D.R., 1997, P 14 INT C MACH LEAR, P403; Zhang J., 1992, P 9 INT MACH LEARN C, P470	23	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						142	152				11	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400014	
S	Huang, ZX; Lin, T		Terano, T; Liu, H; Chen, ALP		Huang, ZX; Lin, T			A visual method of cluster validation with Fastmap	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		data mining; clustering; cluster validation; cluster visualization	ALGORITHM	This paper presents a visual method of cluster validation using the Fastmap algorithm. Two problems are tackled with Fastmap in the interactive process of discovering interesting clusters from real world databases. That is, (1) to verify separations of clusters created by a clustering algorithm and (2) to determine the number of clusters to be produced. They are achieved through projecting objects and clusters by Fastmap to the 2D space and visually examining the results by humans. We use a real example to show how this method has been used in discovering interesting clusters from a real data set.	Univ Hong Kong, E Business Technol Inst, Pokfulam, Hong Kong, Peoples R China; CSIRO, Canberra, ACT 2601, Australia	Huang, ZX (reprint author), Univ Hong Kong, E Business Technol Inst, Pokfulam, Hong Kong, Peoples R China.						AGRAWAL R, 1998, P SIGMOD C; Ester M., 1996, P 2 INT C KNOWL DISC; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163, DOI 10.1145/223784.223812; Fukunaga K., 1990, INTRO STAT PATTERN R; GANTI V, 1999, ICDE 1999, P502; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain A.K., 1988, ALGORITHMS CLUSTERIN; NG RT, 1994, P VLDB; Theodoridis S., 1999, PATTERN RECOGNITION; Young F. W., 1987, MULTIDIMENSIONAL SCA; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328	11	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						153	164				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400015	
S	Tung, AKH; Hou, J; Han, JW		Terano, T; Liu, H; Chen, ALP		Tung, AKH; Hou, J; Han, JW			COE: clustering with obstacles entities - A preliminary study	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Clustering analysis has been a very active area of research in the data mining community. However, most algorithms have ignored the fact that physical obstacles exist in the real world and could thus affect the result of clustering dramatically. In this paper, we will look at the problem of clustering in the presence of obstacles. We called this problem the COE (Clustering with Obstacles Entities) problem and provide an outline of an algorithm called COE-CLARANS to solve it.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Tung, AKH (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.						Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; HAN J, 2000, IN PRESS DATA MINING; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Ng R, 1994, P 20 INT C VER LARG, P144; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	5	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						165	168				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400016	

PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
S	Zhou, SG; Zhou, AY; Cao, J; Wen, J; Fan, Y; Hu, YF		Terano, T; Liu, H; Chen, ALP		Zhou, SG; Zhou, AY; Cao, J; Wen, J; Fan, Y; Hu, YF			Combining sampling technique with DBSCAN algorithm for clustering large spatial databases	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				In this paper, we combine sampling technique with DBSCAN algorithm to cluster large spatial databases, two sampling-based DBSCAN (SDBSCAN) algorithms are developed. One algorithm introduces sampling technique inside DBSCAN; and the other uses sampling procedure outside DBSCAN. Experimental results demonstrate that our algorithms are effective and efficient in clustering large-scale spatial databases.	Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China	Zhou, SG (reprint author), Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China.						Ester M., 1996, P 2 INT C KNOWL DISC; ZHOU S, 1999, COMBINING SAMPLING T	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						169	172				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400017	
S	Inoue, H; Narihisa, H		Terano, T; Liu, H; Chen, ALP		Inoue, H; Narihisa, H			Improving generalization ability of self-generating neural networks through ensemble averaging	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		self-generating neural networks; self-generating neural tree; ensemble averaging; classification; competitive learning		We present an ensemble averaging effect for improving the generalization capability of self-generating neural networks applied to classification problems. The results of our computational experiments show that ensemble averaging effect is 1-7% improvements in accuracy comparing with single SGNN for three benchmark problems.	Okayama Univ Sci, Dept Informat & Comp Engn, Okayama 7000005, Japan	Inoue, H (reprint author), Okayama Univ Sci, Dept Informat & Comp Engn, 1-1 Ridai Cho, Okayama 7000005, Japan.						INOUE H, 1999, 5 INT C INF SYST AN, V5, P608; Kohonen Teuvo, 1995, SELF ORG MAPS; PREHELT L, 1994, 2194 U KARLSR; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; Thrun S. B., 1991, CMUCS91197; WEN WX, 1992, INT JOINT C NEUR NET, P751; WEN WX, 1996, NEURAL NETWORKS THEO, P210	7	11	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						177	180				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400019	
S	Lin, TY; Tremba, J		Terano, T; Liu, H; Chen, ALP		Lin, TY; Tremba, J			Attribute transformations on numerical databases - Applications to stock market and economic data	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		database; stock market data; rough set; extensional databases; predictive		The effects of attribute transformations on numerical data mining are investigated. Theoretical examples from classical mathematics are used to illustrate its critical-ness. The simplest kind of attribution transformations, linear transformations, is applied to stock market and economic data. Some useful "predictive" rules are generated. Here "predictive" is used in the sense that the logical patterns involve time elements.	San Jose State Univ, Dept Math & Comp Sci, San Jose, CA 95192 USA; Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley Initiat Soft Comp, Berkeley, CA 94720 USA	Lin, TY (reprint author), San Jose State Univ, Dept Math & Comp Sci, San Jose, CA 95192 USA.						Date C. J., 2000, INTRO DATABASE SYSTE; Date C.J., 1981, INTRO DATABASE SYSTE; LIN F, 1997, LIFE SCI RES, V1, P30; LIN TY, 1996, GUEST EDITORIAL INTE, V2, P94; MEYER D, 1988, THEORY RELATIONAL DA; Pawlak Z., 1991, ROUGH SETS THEORETIC; TREMBA J, 1997, APPL ROUGH SETS EC S; ZADEH LA, 1976, INT J MAN MACH STUD, V8, P249, DOI 10.1016/S0020-7373(76)80001-6; *RED LOBB, 1993, SOFTW DAT R DAT RPLU; *SEM EQ MAT INT, 1996, MARK STAT HIST BOOK; *SEM IND ASS, SEAS ADJ BOOK BILL R	11	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						181	192				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400020	
S	Okada, T		Terano, T; Liu, H; Chen, ALP		Okada, T			Efficient detection of local interactions in the cascade model	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		local interaction; cascade model; sum of squares; itemset lattice; pruning of lattice		Detection of interactions among data items constitutes an essential part of knowledge discovery. The cascade model is a rule induction methodology using levelwise expansion of a lattice. It can detect positive and negative interactions using the sum of squares criterion for categorical data. An attribute-value pair is expressed as an item, and the BSS (between-groups sum of squares) value along a link in the itemset lattice indicates the strength of interaction among item pairs. A link with a strong interaction is represented as a rule. Items on the node constitute the left-hand side (LHS) of a rule, and the right-hand side (RHS) displays veiled items with strong interactions with the added item. This implies that we do not need to generate an itemset containing the RHS items to get a rule. This property enables effective rule induction. That is, rule links can be dynamically detected during the generation of a lattice. Furthermore, the BSS value of the added attribute gives an upper bound to those of other attributes along the link. This property gives us an effective pruning method for the itemset lattice. The method was implemented as the software DISCAS. There, the items to appear in the LHS and RHS are easily controlled by input parameters. Its algorithms are depicted and an application is provided as an illustrative example.	Kwansei Gakuin Univ, Ctr Informat & Med Studies, Nishinomiya, Hyogo 6628501, Japan	Okada, T (reprint author), Kwansei Gakuin Univ, Ctr Informat & Med Studies, Uegahara 1-1-155, Nishinomiya, Hyogo 6628501, Japan.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Gini C., 1971, J AM STAT ASSOC, V66, P534; Liu B, 1998, P 4 INT C KNOWL DISC, P80; MERETAKIS D, 1999, P ACM SIGMOD WORKSH; Mertz C., 1996, UCI REPOSITORY MACHI; OKADA T, 1999, KWANSEI GAKUIN STUDI, V14, P1; Okada T, 1999, LECT NOTES ARTIF INT, V1704, P468; OKADA T, 2000, IN PRESS J JPN SOC A, V15; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134	13	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						193	203				11	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400021	
S	Suzuki, E; Tsumoto, S		Terano, T; Liu, H; Chen, ALP		Suzuki, E; Tsumoto, S			Evaluating hypothesis-driven exception-rule discovery with medical data sets	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				This paper presents a validation, with two common medical data sets, of exception-rule discovery based on a hypothesis-driven approach. The analysis confirmed the effectiveness of the approach in discovering valid, novel and surprising knowledge.	Yokohama Natl Univ, Fac Engn, Div Elect & Comp Engn, Yokohama, Kanagawa 240, Japan	Suzuki, E (reprint author), Yokohama Natl Univ, Fac Engn, Div Elect & Comp Engn, Yokohama, Kanagawa 240, Japan.						SUZUKI E, 1996, P 2 INT C KNOWL DISC, P275; Suzuki E, 1998, LECT NOTES ARTIF INT, V1510, P10; Suzuki E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Suzuki E, 1999, LECT NOTES ARTIF INT, V1721, P184; TSUMOTO S, 1999, ISM S DAT MIN KNOWL, P63	5	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						208	211				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400023	
S	Ishikawa, T; Numao, M; Terano, T		Terano, T; Liu, H; Chen, ALP		Ishikawa, T; Numao, M; Terano, T			Discovering protein functional models using inductive logic programming	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				The paper describes a method for machine discovery of protein functional models from protein databases using Inductive Logic Programming based on top-down search for relative least general generalization. The method discovers effectively protein function models that explain the relationship between functions of proteins and their amino acid sequences described in protein databases. The method succeeds in discovering protein functional models for forty membrane proteins, which coincide with conjectured models in literature of molecular biology.	Kisarazu Natl Coll Technol, Dept Informat & Comp Eng, Chiba 2920041, Japan; Tokyo Inst Technol, Dept Comp Sci, Fac Eng, Tokyo 1528552, Japan; Univ Tokyo, Grad Sch Syst Management, Tokyo 1120012, Japan	Ishikawa, T (reprint author), Kisarazu Natl Coll Technol, Dept Informat & Comp Eng, Chiba 2920041, Japan.						Attwood T. K., 1999, INTRO BIOINFORMATICS; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P217, DOI 10.1093/nar/25.1.217; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FUTAI M, 1991, BIOMEMBRANE ENG; Ishikawa T., 1999, Journal of Japanese Society for Artificial Intelligence, V14; ISHIKAWA T, 1995, P GEN INF WORKSH 199, P39; Muggleton S., 1990, P 1 C ALG LEARN THEO; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; MUGGLETON S, 1992, PROTEIN ENG, V5, P647, DOI 10.1093/protein/5.7.647; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						212	215				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400024	
S	Yun, CH; Chen, MS		Terano, T; Liu, H; Chen, ALP		Yun, CH; Chen, MS			Mining Web transaction patterns in an electronic commerce environment	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				In this paper, we explore a new data mining capability which involves mining Web transaction patterns for an electronic commerce (EC) environment. We propose an innovative mining model that takes both the traveling patterns and purchasing patterns of customers into consideration. First, we develop algorithm WR to extract meaningful Web transaction records from Web transactions so as to filter out the effect of irrelevant traversal sequences. Second, we devise algorithm WTM for determining the large transaction patterns from the Web transaction records obtained.	Natl Taiwan Univ, Dept Elect Engn, Taipei 10764, Taiwan	Yun, CH (reprint author), Natl Taiwan Univ, Dept Elect Engn, Taipei 10764, Taiwan.						Agrawal R., 1994, P 20 INT C VER LARG, P478; Buchner A.G., 1998, ACM SIGMOD RECORD, V27, P54, DOI 10.1145/306101.306124; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; Park JS, 1997, IEEE T KNOWL DATA EN, V9, P813	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						216	219				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400025	
S	Li, JY; Dong, GZ; Ramamohanarao, K		Terano, T; Liu, H; Chen, ALP		Li, JY; Dong, GZ; Ramamohanarao, K			Making use of the most expressive jumping emerging patterns for classification	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Classification aims to discover a model from training data that can be used to predict the class of test instances. In this paper, we propose the use of jumping emerging patterns (JEPs) as the basis for a new classifier called them JEP-Classifier. Each JEP can capture some crucial difference between a pair of datasets. Then, aggregating all JEPs of large supports can produce more potent classification power. Procedurally, the JEP-Classifier learns the pair-wise features (sets of JEPs) contained in the training data, and uses the collective impacts contributed by the most expressive pair-wise features to determine the class labels of the test data. Using only the most expressive JEPs in the JEP-Classifier strengthens its resistance to noise in the training data, and reduces its complexity (as there are usually a very large number of JEPs). We use two algorithms for constructing the JEP-Classifier which are both scalable and efficient. These algorithms make use of the border representation to efficiently store and manipulate JEPs. We also present experimental results which show that the JEP-Classifier achieves much higher testing accuracies than the association-based classifier of [8], which was reported to outperform C4.5 in general.	Univ Melbourne, Dept CSSE, Parkville, Vic 3052, Australia; Wright State Univ, Dept CSE, Dayton, OH 45435 USA	Li, JY (reprint author), Univ Melbourne, Dept CSSE, Parkville, Vic 3052, Australia.						Blake C, 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; DONG G, 1999, 2 INT C DISC SCI TOK; DONG G, 1999, P 9 INT DAT C IDC 99, P155; Han J., 1996, ADV KNOWLEDGE DISCOV, P399; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Liu B., 1998, P 4 INT C KNOWL DISC; Quinlan J.R., 1992, C4 5 PROGRAM MACHINE; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260	10	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						220	232				13	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400026	
S	Matsuzawa, H; Fukuda, T		Terano, T; Liu, H; Chen, ALP		Matsuzawa, H; Fukuda, T			Mining structured association patterns from databases	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				We consider the data-mining problem of discovering structured association patterns from large databases. A structured association pattern is a set of sets of items that can represent a two level structure in some specified set of target data. Although the structure is very simple, it cannot be extracted by conventional pattern discovery algorithms. We present an algorithm that discovers all frequent structured association patterns. We were motivated to consider the problem by a specific text mining application, but our method is applicable to a broad range of data mining applications. Experiments with synthetic and real data show that our algorithm efficiently discovers structured association patterns in a large volume of data.	IBM Tokyo Res Lab, Yamato, Kanagawa 2428502, Japan	Matsuzawa, H (reprint author), IBM Tokyo Res Lab, 1623-14 Shimotsuruma, Yamato, Kanagawa 2428502, Japan.						Abiteboul S., 1997, P 6 INT C DAT THEOR, P1; Agrawal R., 1995, P INT C DAT ENG; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; BRIN RS, 1997, P ACM SIGMOD C MAN D, P255; BUNEMAN P, 1997, P ACM SIGACT SIGMOD; Han J, 1995, P 21 INT C VER LARG, P420; Hopcroft J. E., 1973, SIAM Journal on Computing, V2, DOI 10.1137/0202019; MCCREIGHT EM, 1976, J ACM, V23, P262, DOI 10.1145/321941.321946; NAGAO M, 1988, MACHINE TRANSLATION, P141; NASUKAWA TS, 1999, RT0319 IBM TOK RES L; Nirenburg Sergei, 1987, MACHINE TRANSLATION; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; ROBERTO J, 1998, P ACM SIGMOD C MAN D; SRIKANT R, 1996, P INT C EXT DAT TECH; Srikant R., 1995, P 21 INT C VER LARG, P407; WANG K, 1997, P 3 INT C KNOWL DISC, P271	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						233	244				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400027	
S	Zhang, T		Terano, T; Liu, H; Chen, ALP		Zhang, T			Association rules	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				New association rules are presented for measure of association relationships between patterns. The new association rules are shown to not only measure three well-known association relationships correctly, but also satisfy other criteria for correct measure of association. Comparison with other measures is discussed both theoretically and experimentally. Applications in supervised mining of association rules and in pattern-driven multidimensional pattern analysis are presented.	Triada Ltd, Foster City, CA 94404 USA	Zhang, T (reprint author), Triada Ltd, 323B Vintage Pk Dr, Foster City, CA 94404 USA.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, P 2 INT C KNOWL DISC; Agrawal R., 1994, P 20 INT C VER LARG, P487; AGRAWAL R, 1996, FAST DISCOVERY ASS R, P307; BUGAJSKI JM, 1997, Patent No. 5592667; BUGAJSKI JM, 1993, Patent No. 5245337; BUGAJSKI JM, 1994, Patent No. 5293164; CHEUNG AW, 1996, P 4 INT C PAR DISTR; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Han J, 1995, P 21 INT C VER LARG, P420; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Lee SD, 1998, DATA MIN KNOWL DISC, V2, P233, DOI 10.1023/A:1009703019684; MANNILA H, 1994, P AAAI WORKSH KNOWL, P144; MANNILA H, 1998, 4 INT C KNOWL DISC D; Meo R, 1998, DATA MIN KNOWL DISC, V2, P195, DOI 10.1023/A:1009774406717; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Savasere A, 1995, P 21 INT C VER LARG, P432; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; Srikant R., 1995, P 21 INT C VER LARG, P407; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Wijsen J, 1998, DATA MIN KNOWL DISC, V2, P263, DOI 10.1023/A:1009755120593; ZHANG T, 1999, Patent No. 5983232; ZHANG T, 1999, Patent No. 5966709	25	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						245	256				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400028	
S	Cheung, DW; Wang, L; Yiu, SM; Zhou, B		Terano, T; Liu, H; Chen, ALP		Cheung, DW; Wang, L; Yiu, SM; Zhou, B			Density-based mining of quantitative association rules	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Many algorithms have been proposed for mining of boolean association rules. However, very little work has been done in mining quantitative association rules. Although we can transform quantitative attributes into boolean attributes, this approach is not effective and is difficult to scale up for high dimensional case and also may result in many imprecise association rules. Newly designed algorithms for quantitative association rules still are persecuted by nonscalable and noise problem. In this paper, an efficient algorithm, QAR-miner, is proposed. By using the notion of "density" to capture the characteristics of quantitative attributes and an efficient procedure to locate the "dense regions", QAR-miner not only can solve the problems of previous approaches, but also can scale up well for high dimensional case. Evaluations on QAR-miner have been performed using both synthetic and real databases. Preliminary results show that QAR-miner is effective and, can scale up quite linearly with the increasing number of attributes.	Univ Hong Kong, Dept Comp Sci & Informat Syst, Pokfulam, Hong Kong, Peoples R China	Cheung, DW (reprint author), Univ Hong Kong, Dept Comp Sci & Informat Syst, Pokfulam, Hong Kong, Peoples R China.						AGRAWAL R, 1992, P 18 C VLDB VANC CAN; Agrawal R., 1993, P 4 C FDN DAT ORG AL; AGRAWAL R, 1994, P 20 C VLDB SANT CHI; Cheung David, 1996, IEEE T KNOWLEDGE DAT, V8; CHEUNG DW, 1999, BUILDING DENSE REGIO; CHEUNG DW, 1998, P 2 PAKDD 98 C MELB; HAN J, 1995, P 21 C VLDB ZUR SWIT; LENT B, 1997, P ICDE97 BIRM UK APR; Park J.S., 1995, P ACM SIGMOD INT C M; SAVASERE A, 1995, P 21 C VLDB ZUR SWIT; Srikant R, 1996, P ACM SIGMOD C MAN D; TOIVONEN H, 1996, P 22 C VLDB MUMB IND; ZHOU B, 1999, P 3 PAKDD 99 C BEIJ	13	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						257	268				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400029	
S	Han, JC; Cercone, N		Terano, T; Liu, H; Chen, ALP		Han, JC; Cercone, N			AViz: A visualization system for discovering numeric association rules	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		KDD; data mining; data visualization; association rules		We introduce an interactive visualization system, AViz, for discovering numerical association rules from large data sets. The process of interactive visual discovery consists of six steps: preparing the raw data, visualizing the original data, cleaning the data, discretizing numerical attributes, and discovering and visualizing association rules. The basic framework of the AViz system is presented and three approaches to discretize numerical attributes, including equal-sized, bin-packing based equal-depth, and interaction-based approaches, are proposed and implemented. The algorithm for discovering and visualizing numerical association rules is discussed and analyzed. The AViz system has been experimented on a census data set. The experimental results demonstrate that the AViz system is useful and helpful for discovering and visualizing numerical association rules.	Univ Waterloo, Dept Comp Sci, Waterloo, ON N2L 3G1, Canada	Han, JC (reprint author), Univ Waterloo, Dept Comp Sci, Waterloo, ON N2L 3G1, Canada.						Agrawal R., 1994, P 20 INT C VER LARG, P487; Cai Y., 1991, Knowledge discovery in databases; DERTHICK M, 1997, INTERACTIVE VISUALIZ, P2; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; GROTH R, 1998, HANDS ON APPROACH BU; HAN J, 1999, P 3 PAC AS C KNOWL D, P390; KEIM D, 1997, P INT C VER LARG DAT; KEIM DA, 1996, VISUALIZATION TECHNI; KENNEDY JB, 1996, FRAMEWORK INFORMATIO, V25; Liu B, 1999, P 3 PAC AS C KNOWL D, P380; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311	13	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						269	280				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400030	
S	Fujino, R; Arimura, H; Arikawa, S		Terano, T; Liu, H; Chen, ALP		Fujino, R; Arimura, H; Arikawa, S			Discovering unordered and ordered phrase association patterns for text mining	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan			SUFFIX	This paper considers the problem of finding all frequent phrase association patterns in a large collection of unstructured texts, where a phrase association pattern is a set of consecutive sequences of arbitrary number of keywords which appear together in a document. For the ordered and the unordered versions of phrase association patterns, we present efficient algorithms, called Levelwise-Scan, based on the sequential counting technique of Apriori algorithm. To cope with the problem of the huge feature space of phrase association patterns, the algorithm uses the generalized suffix tree and the pattern matching automaton. By theoretical and empirical analyses, we show that the algorithms runs quickly on most random texts for a wide range of parameter values and scales up for large disk-resident text databases.	Nippon Steel Informat & Commun Syst Inc, Kitakyushu, Fukuoka 8040001, Japan; Kyushu Univ, Dept Informat, Fukuoka 8128581, Japan	Fujino, R (reprint author), Nippon Steel Informat & Commun Syst Inc, Kitakyushu, Fukuoka 8040001, Japan.						Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; AHO AV, 1998, CACM; ARIMURA H, 1998, P ALT 98 LNAI, P247; Croft W.B., 1991, P 14 ANN INT ACM SIG, P32, DOI DOI 10.1145/122860.122864; DEVROYE L, 1992, SIAM J COMPUT, V21, P48, DOI 10.1137/0221005; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FELDMAN R, 1995, P KDD 97, P167; KASAI T, 1999, P DAT MIN WORKSH, P24; KEARNS MJ, 1994, MACH LEARN, V17, P115; Lewis D.D., 1997, REUTERS 21578 TEXT C; LUI LCK, 1992, P 3 ANN S COMB PATT; MCCREIGHT EM, 1976, J ACM, V23, P262, DOI 10.1145/321941.321946; MORISHITA S, 1998, P DS 98 LNAI, V1532; Shimozono S, 2000, NEW GENERAT COMPUT, V18, P49; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; Ullman J. D., 1974, DESIGN ANAL COMPUTER; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863	18	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						281	293				13	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400031	
S	Candan, KS; Li, WS		Terano, T; Liu, H; Chen, ALP		Candan, KS; Li, WS			Using random walks for mining Web document associations	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				World Wide Web has emerged as a primary means for storing and structuring information. In this paper, we present a framework for mining implicit associations among Web documents. We focus on the following problem: "For a given set of seed URLs, find a list of Web pages which reflect the association among these seeds." In the proposed framework, associations of two documents are induced by the connectivity and linking path length. Based on this framework, we have developed a random walk-based Web mining technique and validated it by experiments on real Web data. In this paper, we also discuss the extension of the algorithm for considering document contents.	NEC USA Inc, C&C Res Labs, San Jose, CA 95134 USA; Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA	Candan, KS (reprint author), NEC USA Inc, C&C Res Labs, MS-SJ10, San Jose, CA 95134 USA.						Bharat K., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290972; BHARAT K, 1999, P 8 WORLD WID WEB C; Chakrabarti S., 1998, P 7 INT WORLD WID WE, P65; DEAN J, 1999, P 8 WORLD WID WEB C; Gibson D., 1998, P 9 ACM C HYP HYP, P225, DOI 10.1145/276627.276652; Hakimi S. L., 1971, Networks, V1, DOI 10.1002/net.3230010203; Hwang F., 1992, STEINER TREE PROBLEM, V53; Kleinberg J. M, 1998, P 9 ANN ACM SIAM S D, P668; Kumar R., 1999, P 8 WORLD WID WEB C; LI WS, 2000, IN PRESS ACM COMPUTI; PAGE L, 1998, P 7 WORLD WID WEB C; *NETSC COMM CORP, WHATS REL WEB PAG	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						294	305				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400032	
S	Muyeba, MK; Keane, JA		Terano, T; Liu, H; Chen, ALP		Muyeba, MK; Keane, JA			A concurrent approach to the key-preserving attribute-oriented induction method	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Attribute-Oriented Induction (AOI) reduces the search space of large, data to produce a minimal rule set. Classical AOI techniques only consider attributes that can be generalised but eliminates keys to relations. The Key-Preserving AOI (AOI-KP) preserves keys of the input relation and relate them to the rules for subsequent data queries. Previously, the sequential nature of AOI-KP affected performance on a single processor machine. More significantly, time was spent doing I/O to files linked to each generated rule. AOI-KP is O (np) and storage requirement O (n), where n and p represent the number of input and generalised tuples respectively. We. present two enhanced AOI-KP algorithms, concAOI-KP (concurrent AOI-KP) and onLineConcAOI-KP of orders O (np) and O (n) respectively. The two algorithms have storage requirement O (p) and O (q), q = p*r, O <r less than or equal to7 respectively. A prototype support tool exists and initial results indicate substantially increased utilisation of a single processor.	UMIST, Dept Computat, Manchester M60 1QD, Lancs, England	Muyeba, MK (reprint author), UMIST, Dept Computat, Manchester M60 1QD, Lancs, England.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Carter CL, 1998, IEEE T KNOWL DATA EN, V10, P193, DOI 10.1109/69.683752; Frawley W. J., 1991, Knowledge discovery in databases; FREITAS AA, 1996, MINING VERY LARGE DA; FU Y, 1996, THESIS S FRASER U; HAN J, 1991, ATTRIBUTE ORIENTED I, P213; MUYEBA KM, 1999, P 3 EUR C PRINC KNOW, P249; Zaki MJ, 1997, J PARALLEL DISTR COM, V43, P156, DOI 10.1006/jpdc.1997.1339	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						306	316				11	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400033	
S	Domingo, C; Watanabe, O		Terano, T; Liu, H; Chen, ALP		Domingo, C; Watanabe, O			Scaling up a boosting-based learner via adaptive sampling	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan			ALGORITHMS	In this paper we present a experimental evaluation of a boosting based learning system and show that can be run efficiently over a large dataset. The system uses as base learner decision stumps, single atribute decision trees with only two terminal nodes. To select the best decision stump at each iteration we use an adaptive sampling method. As a boosting algorithm, we use a modification of AdaBoost that is suitable to be combined with a base learner that does not use all the dataset. We provide experimental evidence that our method is as accurate as the equivalent algorithm that uses all the dataset but much faster.	Tokyo Inst Technol, Dept Math & Comp Sci, Meguro Ku, Tokyo 152, Japan	Domingo, C (reprint author), Tokyo Inst Technol, Dept Math & Comp Sci, Meguro Ku, Tokyo 152, Japan.						BAUER E, 1998, MACH LEARN, P1; DIETTERICH T, 1998, MACH LEARN, V32, P1; Domingo C, 1998, LECT NOTES ARTIF INT, V1532, P150; DOMINGO C, 1999, C139 TOK I TECHN DEP; Domingo C, 1999, LECT NOTES ARTIF INT, V1721, P172; DOMINGO C, 1999, C133 TOK I TECHN DEP; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J, 1995, P 12 INT C MACH LEAR; Fayad U.M., 1993, P 13 INT JOINT C ART, P1022; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; FREUND Y, 1997, P 13 INT C MACH LEAR, P148; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JOHN GH, 1996, P 2 INT C KNOWL DISC; KEOGH E, 1998, UCI REPOSITORY MACHI; LIPTON RJ, 1993, THEOR COMPUT SCI, V116, P195, DOI 10.1016/0304-3975(93)90224-H; LIPTON RJ, 1995, J COMPUT SYST SCI, V51, P18, DOI 10.1006/jcss.1995.1050; PROVOST F, 1999, P 5 INT C KNOWL DISC; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Wald A, 1947, SEQUENTIAL ANAL; WATANABE O, 1999, LECT NOTES COMPUTER, V1644, P134	23	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						317	328				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400034	
S	Lazarevic, A; Fiez, T; Obradovic, Z		Terano, T; Liu, H; Chen, ALP		Lazarevic, A; Fiez, T; Obradovic, Z			Adaptive boosting for spatial functions with unstable driving attributes	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		multi-strategy learning; boosting; attribute representation; spatial databases; fast k-NN classifier		Combining multiple global models (e.g. back-propagation based neural networks) is an effective technique for improving classification accuracy by reducing a variance through manipulating training data distributions. Standard combining methods do not improve local classifiers (e.g. k-nearest neighbors) due to their low sensitivity to data perturbation. Here, we propose an adaptive attribute boosting technique to coalesce multiple local classifiers each using different relevant attribute information. In addition, a modification of boosting method is developed for heterogeneous spatial databases with unstable driving attributes by drawing spatial blocks of data at each boosting round. To reduce the computational costs of k-nearest neighbor (k-NN) classifiers, a novel fast k-NN algorithm is designed. The adaptive attribute boosting applied to real life spatial data and artificial spatial data show observable improvements in prediction accuracy for both local and global classifiers when unstable driving attributes are present in the data. The "spatial" variant of boosting applied to the same data sets resulted in highly significant improvements for the k-NN classifier, making it competitive to boosted neural networks.	Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA; Washington State Univ, Dept Crop & Soil Sci, Pullman, WA 99164 USA	Lazarevic, A (reprint author), Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA.						Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Bishop CM, 1995, NEURAL NETWORKS PATT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Cherkauer K., 1996, AAAI WORKSH INT MULT, P15; Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238163; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; KONG EB, 1996, P 12 NAT C ART INT, P725; LIU L, 1998, FEATURE SELECTION KN; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; POKRAJAC D, IN PRESS SPATIAL DAT; RICCI F, 1998, P 10 EUR C MACH LEAR; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839; VUCETIC S, 1999, P IEEE INNS INT C NE	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						329	340				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400035	
S	Ratsch, G; Scholkopf, B; Smola, AJ; Mika, S; Onoda, T; Muller, KR		Terano, T; Liu, H; Chen, ALP		Ratsch, G; Scholkopf, B; Smola, AJ; Mika, S; Onoda, T; Muller, KR			Robust ensemble learning for data mining	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				We propose a new boosting algorithm which similarly to nu -Support-Vector Classification allows for the possibility of a pre-specified fraction nu of points to lie in the margin area or even on the wrong side of the decision boundary. It gives a nicely interpretable way of controlling the trade-off between minimizing training error and capacity. Furthermore, it can act as a filter for finding and selecting informative patterns from a database.	GMD FIRST, D-12489 Berlin, Germany; Microsoft Res, Cambridge, England; ANU, Dept Engn, Canberra, ACT 0200, Australia; CIRL CRIEPI, Komae, Tokyo 2018511, Japan	Ratsch, G (reprint author), GMD FIRST, Kekulestr 7, D-12489 Berlin, Germany.		Ratsch, Gunnar/B-8182-2009; Muller, Klaus/C-3196-2013; Scholkopf, Bernhard/A-7570-2013				BREIMAN L, 1997, 504 U CAL STAT DEP; Drucker H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000352; Grove A. J., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; LeCun Y., 1995, Neural Networks: The Statistical Mechanics Perspective. Proceedings of the CTP-PBSRI. Joint Workshop on Theoretical Physics; Merz C.J., 1998, UCI REPOSITORY MACHI; Quinlan J.R., 1996, LECT NOTES COMPUTER, V1160, P143; RATSCH G, 1999, ADV LARGE MARGIN CLA, P207; RATSCH G, 1998, IN PRESS MACHINE LEA; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scholkopf B., 2000, NEURAL COMPUT, V12, P1083; SCHWENK H, 1998, ADV NEURAL INF PROCE, V10	11	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						341	344				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400036	
S	Nguyen, TD; Ho, TB; Shimodaira, H		Terano, T; Liu, H; Chen, ALP		Nguyen, TD; Ho, TB; Shimodaira, H			Interactive visualization in mining large decision trees	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				This paper presents a tree visualizer that combines several techniques from the field of information visualization to handle efficiently large decision trees in an interactive mining system.	Japan Adv Inst Sci & Technol, Tatsunokuchi, Ishikawa 9231292, Japan	Nguyen, TD (reprint author), Japan Adv Inst Sci & Technol, Tatsunokuchi, Ishikawa 9231292, Japan.						ANKERST M., 1999, P 5 INT C KNOWL DISC, P392, DOI 10.1145/312129.312298; Brunk C., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; CARD SK, 1999, READINGS INFORMATION; NGUYEN DT, 1999, J JAPANESE SOC ARTIF, V14, P131; Rao J. S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						345	348				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400037	
S	Geva, S; Buckingham, L		Terano, T; Liu, H; Chen, ALP		Geva, S; Buckingham, L			VQTree: Vector quantization for decision tree induction	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				We describe a new oblique decision tree induction algorithm. The VQTree algorithm uses Learning Vector Quantization to form a nonparametric model of the training set, and from that obtains a set of hyperplanes which are used as oblique splits in the nodes of a decision tree. We use a set of public data sets to compare VQTree with two existing decision tree induction algorithms, C5.0 and OC1. Our experiments show that VQTree produces compact decision trees with higher accuracy than either C5.0 or OC1 on some datasets.	Queensland Univ Technol, Brisbane, Qld 4001, Australia	Geva, S (reprint author), Queensland Univ Technol, GPO Box 2434, Brisbane, Qld 4001, Australia.						Breiman L, 1984, CLASSIFICATION REGRE; Gersho A., 1992, VECTOR QUANTIZATION; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; Kohonen T., 1988, SELF ORG ASSOCIATIVE; Murphy P., 1994, UCI REPOSITORY MACHI; Murthy S, 1994, J ARTIFICIAL INTELLI, V2, P1; QUINLAN JR, 1992, C4 5 PROGRAMS MACH L; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; QUINLAN JR, 1994, COMPUTATIONAL LEARNI, V1, P445; Sanchez J. S., 1998, Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170), DOI 10.1109/ICPR.1998.711200; UTGOFF PE, 1991, 10 U MASS AMH	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						349	359				11	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400038	
S	Giannotti, F; Manco, G		Terano, T; Liu, H; Chen, ALP		Giannotti, F; Manco, G			Making knowledge extraction and reasoning closer	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				The paper shows how a logic-based database language can support the various steps of the KDD process by providing a high degree of expressiveness, and the separation of concerns between the specification level and the mapping to the underlying databases and data mining tools. In particular, the mechanism of user-defined aggregates provided in LDL++ allows to specify data mining tasks and to formalize the mining results in a uniform way. We show how the mechanism applies to the concept of Inductive Databases, proposed in [2,12]. We concentrate on bayesian classification and show how user defined aggregates allow to specify the mining evaluation functions and the returned patterns. The resulting formalism provides a flexible way to customize, tune and reason on both the evaluation functions and the extracted knowledge.	CNR, CNUCE, I-56125 Pisa, Italy	Giannotti, F (reprint author), CNR, CNUCE, Via S Maria 36, I-56125 Pisa, Italy.						AGRAWAL R, 1998, P ACM SIGMOD 98; Boulicaut JF, 1998, LECT NOTES ARTIF INT, V1510, P194; BOULICAUT JF, 1999, P ACM INT WORKSH DAT, P87, DOI 10.1145/319757.319796; Ceri S., 1996, P C VER LARG DAT, P122; ELKAN C, 1997, P INT C KNOWL DISC D; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; GIANNOTTI F, 2000, IN PRESS IEEE T KNOW; GIANNOTTI F, 1999, J LOGIC PROGRAMMING; Giannotti F, 1999, LECT NOTES ARTIF INT, V1704, P125; GIANNOTTI F, 1999, B4199902 CNUCE CNR I; GIANNOTTI F, 1999, P INT C PRACT APPL K; Han J, 1998, SIGMOD REC, V27, P97; MANNILA H, 1997, INT LOG PROGR S, P21; MITCHELL J, 1997, MACHINE LEARNING; RUGGIERI S, 2000, C45 U PIS DEP COMP S; SHEN K, 1996, ADV KNOWLEDGE DISCOV, P375; Taylor C.C., 1994, MACHINE LEARNING NEU; TSUR D, 1998, P ACM SIGMOD INT C M, P1, DOI 10.1145/276304.276306; WANG H, 1999, 7 INT WORKSH DAT PRO; ZANIOLO C, 1993, LECT NOTES COMPUTER, V760; ZANIOLO C, 1998, LOGIC BASED USER DEF	21	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						360	371				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400039	
S	Saito, K; Nakano, R		Terano, T; Liu, H; Chen, ALP		Saito, K; Nakano, R			Discovery of relevant weights by minimizing cross-validation error	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				In order to discover relevant weights of neural networks, this paper proposes a novel method to learn a distinct squared penalty factor for each weight as a minimization problem over the cross-validation error. Experiments showed that the proposed method works well in discovering a polynomial-type law even from data containing irrelevant variables and a small amount of noise.	NTT, Commun Sci Labs, Sora Ku, Kyoto 6190237, Japan; Nagoya Inst Technol, Showa Ku, Nagoya, Aichi 4668555, Japan	Saito, K (reprint author), NTT, Commun Sci Labs, Sora Ku, 2-4 Hikaridai, Kyoto 6190237, Japan.						Nakano R, 1999, LECT NOTES ARTIF INT, V1721, P287; SAITO K, 1997, P 15 INT JOINT C ART, P1078	2	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						372	375				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400040	
S	Torgo, L		Terano, T; Liu, H; Chen, ALP		Torgo, L			Efficient and comprehensible local regression	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				This paper describes an approach to multivariate regression that aims at improving the computational efficiency and comprehensibility of local regression techniques. Local regression modeling is known for its ability to accurately approximate quite diverse regression surfaces with high accuracy. However, theses methods are also known for being computationally demanding and for not providing any comprehensible model of the data. These two characteristics can be regarded as major drawbacks in the context of a typical data, mining scenario. The method we describe tackles these problems by integrating local regression within a partition-based induction method.	Univ Porto, FEP, LIACC, P-4150 Oporto, Portugal	Torgo, L (reprint author), Univ Porto, FEP, LIACC, R Campo Alegre 823, P-4150 Oporto, Portugal.						Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Breiman L, 1984, CLASSIFICATION REGRE; CLEVELAND WS, 1995, SMOOTHING LOCAL REGR; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; TORGO L, 1999, 992 LIACC; Torgo L., 1999, THESIS U PORTO; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383	7	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						376	379				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400041	
S	Skowron, A; Stepaniuk, J; Tsumoto, S		Terano, T; Liu, H; Chen, ALP		Skowron, A; Stepaniuk, J; Tsumoto, S			Information granules for spatial reasoning	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				The aim of the paper is to present an outline of granular computing framework for spatial reasoning. In our previous papers we have discussed basic notions related to granular computing, namely the information granule syntax and semantics as well as the inclusion and closeness (similarity) relations of granules. Different information sources (units, agents) are equipped with two kinds of operations on information granules: operations possessed by agents transforming tuples of information granules into new granules and approximation operations for computing, by agents information granule approximations delivered by other agents. More complex granules are constructed by means of these operations from some input information granules.	Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland; Bialystok Univ Technol, Inst Comp Sci, PL-15351 Bialystok, Poland; Shimane Med Univ, Dept Med Informat, Izumo, Shimane 6938501, Japan	Skowron, A (reprint author), Warsaw Univ, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.						Duntsch I., 1999, Fundamenta Informaticae, V39; Escrig M.T., 1998, QUALITATIVE SPATIAL; Pawlak Z., 1991, ROUGH SETS THEORETIC; POLKOWSKI L, 1999, FUNDAMENTA INFORMATI, V1, P201; RODDICK JF, NEWSLETTER SPECIAL I, V1, P34; Skowron A, 1999, LECT NOTES ARTIF INT, V1711, P357; Skowron A, 1999, LECT NOTES ARTIF INT, V1704, P542; SKOWRON A, 1999, B INT ROUGH SET SOC, V3, P147; SOGO T, 1999, ACQUISITION QUALITAT, P1054; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; Zadeh L. A., 1999, COMPUTING WORDS INFO, V1	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						380	383				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400042	
S	Merkl, D; Rauber, A		Terano, T; Liu, H; Chen, ALP		Merkl, D; Rauber, A			Uncovering the hierarchical structure of text archives by using an unsupervised neural network with adaptive architecture	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Discovering the inherent structure in data has become one of the major challenges in data mining applications. It requires the development of stable and adaptive models that are capable of handling the typically very high-dimensional feature spaces. In this paper we present the Growing Hierarchical Self-Organizing Map (GH-SOM), a neural network model based on the self-organizing map. The main feature of this extended model is its capability of growing both in terms of map size as well as in a three-dimensional tree-structure in order to represent the hierarchical structure present in a data collection. This capability, combined with the stability of the self-organizing map for high-dimensional feature space representation, makes it an ideal tool for data analysis and exploration. We demonstrate the potential of this method with an application from the information retrieval domain, which is prototypical of the high-dimensional feature spaces frequently encountered in today's applications.	Vienna Tech Univ, Inst Softwaretechn, A-1040 Vienna, Austria	Merkl, D (reprint author), Vienna Tech Univ, Inst Softwaretechn, Favoritenstr 9-11-188, A-1040 Vienna, Austria.						Blackmore J., 1993, P IEEE INT C NEUR NE; Fritzke B, 1995, NEURAL PROCESS LETT, V2, P1; KOHONEN T, 1998, P INT C ART NEUR NET; Kohonen Teuvo, 1995, SELF ORG MAPS; LIN X, 1991, P INT ACM SIGIR C R; Merkl D., 1997, P WORKSH SELF ORG MA; MERKL D, 1998, HDB NATURAL LANGUAGE; MERKL D, 1998, NEUROCOMPUTING, V21; MERKL D, 1999, P INT JOINT C ART IN; Miikkulainen R., 1990, Connection Science, V2; RAUBER A, 1999, P 10 INT C DAT EXP S; RAUBER A, 1999, P 4 PAC AS C KNOWL D; ROUSSINOV D, 1998, P ACM C DIG LIBR 98; Salton G., 1989, AUTOMATIC TEXT PROCE; ULTSCH A, 1993, INFORMATION CLASSIFI	15	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						384	395				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400043	
S	Pei, J; Han, JW; Mortazavi-asl, B; Zhu, H		Terano, T; Liu, H; Chen, ALP		Pei, J; Han, JW; Mortazavi-asl, B; Zhu, H			Mining access patterns efficiently from Web logs	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				With the explosive growth of data available on the World Wide Web, discovery and analysis of useful information from the World Wide Web becomes a practical necessity. Web access pattern, which is the sequence of accesses pursued by users frequently, is a kind of interesting and useful knowledge in practice. In this paper, we study the problem of mining access patterns from Web logs efficiently. A novel data structure, called Web access pattern tree, or WAP-tree in short, is developed for efficient mining of access patterns from pieces of logs. The Web access pattern tree stores highly compressed, critical information for access pattern mining and facilitates the development of novel algorithms for mining access patterns in large set of log pieces. Our algorithm can find access patterns from Web logs quite efficiently. The experimental and performance studies show that our method is in general an order of magnitude faster than conventional methods.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Pei, J (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	peijian@cs.sfu.ca; han@cs.sfu.ca; mortazav@cs.sfu.ca; hzhua@cs.sfu.ca					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bettini C, 1998, DATA ENG B, V21, P32; COOLEY R, 1999, J KNOWLEDGE INFORMAT, V1; GRAHAMCUMMING J, 1997, P 6 INT WORLD WID WE; Han JW, 1999, PROC INT CONF DATA, P106; Lu H., 1998, P 1998 SIGMOD WORKSH, P12; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; PERKOWITZ M, 1997, P 6 INT WORLD WID WE; SPILIOPOULOU M, 1998, P 6 INT C EXT DAT TE; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; SULLIVAN T, 1997, P 3 C HUM FACT WEB D; Tauscher L, 1997, INT J HUM-COMPUT ST, V47, P97, DOI 10.1006/ijhc.1997.0125; ZAIANE O, 1998, P ADV DIG LIB C ADL, P144	15	25	27	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						396	407				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400044	
S	Diao, YL; Lu, HJ; Wu, DK		Terano, T; Liu, H; Chen, ALP		Diao, YL; Lu, HJ; Wu, DK			A comparative study of classification based personal E-mail filtering	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				This paper addresses personal E-mail filtering by casting it in the framework of text classification. Modeled as semi-structured documents, Email messages consist of a set of fields with predefined semantics and a number of variable length free-text fields. While most work on classification either concentrates on structured data or free text, the work in this paper deals with both of them. To perform classification, a naive Bayesian classifier was designed and implemented, and a decision tree based classifier was implemented. The design considerations and implementation issues are discussed. Using a relatively large amount of real personal E-mail data, a comprehensive comparative study was conducted using the two classifiers. The importance of different features is reported. Results of other issues related to building an effective personal E-mail classifier are presented and discussed. It is shown that both classifiers can perform filtering with reasonable accuracy. While the decision tree based classifier outperforms the Bayesian classifier when features and training size are selected optimally for both, a carefully designed naive Bayesian classifier is more robust.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Diao, YL (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.						Cohen W. W., P 1996 AAAI SPRING S; COHEN WW, P SIGIR 1996; CRAVEN M, P 15 NAT C ART INT; KILANDER F, PROPERTIES ELECT TEX; LEWIS D, 1998, EUR C MACH LEARN; LEWIS DD, 3 ANN S DOC AN INF R, P81; Lewis DD, 1997, INFORM PROCESS MANAG, V33, P209, DOI 10.1016/S0306-4573(96)00063-5; MCCALLUM A, 1998 AAAI ICML WORKS; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SAHAMI M, 1998 WORKSH; SPERTUS E, 1997, P INN APPL ART INT	12	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						408	419				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400045	
S	Matsuda, T; Horiuchi, T; Motoda, H; Washio, T		Terano, T; Liu, H; Chen, ALP		Matsuda, T; Horiuchi, T; Motoda, H; Washio, T			Extension of Graph-Based Induction for general graph structured data	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				A machine learning technique called Graph-Based Induction (GBI) efficiently extracts typical patterns from directed graph data by stepwise pair expansion (pairwise chunking). In this paper, we expand the capability of the Graph-Based Induction to handle not only tree structured data but also multi-inputs/outputs nodes and loop structure (including a self-loop) which cannot be treated in the conventional way. The method is verified to work as expected using artificially generated data and we evaluated experimentally the computation time of the implemented program. We, further, show the effectiveness of our approach by applying it to two kinds of the real-world data: World Wide Web browsing data and DNA sequence data.	Osaka Univ, ISIR, Osaka 5670047, Japan	Matsuda, T (reprint author), Osaka Univ, ISIR, 8-1 Mihogaoka, Osaka 5670047, Japan.						AGRWAL R, 1994, P 20 VLDB C, P487; Blake C, 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; INOKUCHI A, 1999, P 3 PAC AS C KNOWL D, P420; MICHALSKI RS, 1990, MACHINE LEARNING ART, V3, P63; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; WALLACE C, 1996, P 13 INT C MACH LEAR, P516; Yoshida K., 1997, Journal of Japanese Society for Artificial Intelligence, V12; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A	12	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						420	431				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400046	
S	Ng, CY; Kao, B; Cheung, D		Terano, T; Liu, H; Chen, ALP		Ng, CY; Kao, B; Cheung, D			Text-source discovery and GLOSS update in a dynamic Web	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan		text-source discovery; GIOSS; search engines		"Text-source discovery" is the problem of identifying relevant document databases that potentially contain documents that match a user query. GlOSS [6] is a cost-effective technique for solving the text-source discovery problem. However, the GlOSS approach assumes that the document databases are fully cooperative in exporting statistical information about their collections. This paper discusses how the GlOSS technique can be applied to a dynamic and uncooperative Web environment in assisting users to locate relevant Web information sources.	Univ Hong Kong, Dept Comp Sci & Informat Syst, Pokfulam, Hong Kong, Peoples R China	Ng, CY (reprint author), Univ Hong Kong, Dept Comp Sci & Informat Syst, Pokfulam, Hong Kong, Peoples R China.						FELDMAN S, 1997, MAGAZINE DATABAS MAY; GRAVANO ATL, P 1994 ACM SIGMOD; GRAVANO ATL, 1995, P 1995 VLDB C MAY; GROSSAN B, SEARCH ENG WHAT THEY; Gudivada V. N., 1997, IEEE Internet Computing, V1, DOI 10.1109/4236.623969; MARON ME, 1985, COMMUN ACM, V28, P290; *FAQ, WEB ROB FAQ	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						432	441				10	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400047	
S	Hotta, S; Inoue, K; Urahama, K		Terano, T; Liu, H; Chen, ALP		Hotta, S; Inoue, K; Urahama, K			Extraction of fuzzy clusters from weighted graphs	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				A spectral graph method is presented for partitioning of nodes in a graph into fuzzy clusters on the basis of weighted adjacency matrices. Extraction of a fuzzy cluster from a node set is formulated by an eigenvalue problem and clusters are extracted sequentially from major one to minor ones. A clustering scheme is devised at first for undirected graphs and it is next extended to directed graphs and also to undirected bipartite ones. These clustering methods are applied to analysis of a link structure in Web networks and image retrieval queried by keywords or sample images. Extracted structure of clusters is visualized by a multivariate exploration method called the correspondence analysis.	Kyushu Inst Design, Fukuoka 8158540, Japan	Hotta, S (reprint author), Kyushu Inst Design, Fukuoka 8158540, Japan.						DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DONATH WE, 1973, IBM J RES DEV, V17, P420; Drineas P, 1999, PROCEEDINGS OF THE TENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P291; Florescu D., 1998, SIGMOD Record, V27; Gibson D., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Inoue K, 1999, PATTERN RECOGN LETT, V20, P699, DOI 10.1016/S0167-8655(99)00034-3; Jambu M, 1991, EXPLORATORY MULTIVAR; Kleinberg J. M, 1998, P 9 ANN ACM SIAM S D, P668; Sarkar S, 1998, COMPUT VIS IMAGE UND, V71, P110, DOI 10.1006/cviu.1997.0637; TAMASSIA R, 1998, GRAPH DRAWING ALGORI	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						442	453				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400048	
S	Chuang, WT; Yang, J		Terano, T; Liu, H; Chen, ALP		Chuang, WT; Yang, J			Text summarization by sentence segment extraction using machine learning algorithms	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				We present an approach to the design of an automatic text summarizer that generates a summary by extracting sentence segments. First, sentences are broken into segments by special cue markers. Each segment is represented by a set of predefined features (e.g. location of the segment, number of title words in the segment). Then supervised learning algorithms are used to train the summarizer to extract important sentence segments, based on the feature vector. Results of experiments indicate that the performance of the proposed approach compares quite favorably with other approaches (including MS Word summarizer).	Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; LLC, HRL Labs, Malibu, CA 90265 USA	Chuang, WT (reprint author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.						Edmundson HP, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P23; Kupiec J, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P55; Luhn HP, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P15; MANN William C., 1988, TEXT, P243, DOI 10.1515/text.1.1988.8.3.243; Marcu D., 1997, THESIS U TORONTO; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Yang J., 1999, INTELL DATA ANAL, V3, P55, DOI 10.1016/S1088-467X(99)00005-0	7	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						454	457				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400049	
S	Yugami, N; Ohta, Y; Okamoto, S		Terano, T; Liu, H; Chen, ALP		Yugami, N; Ohta, Y; Okamoto, S			Fast discovery of interesting rules	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				Extracting interesting rules from databases is an important field of knowledge discovery. Typically, enormous number of rules are embedded in a database and one of the essential abilities of discovery systems is to evaluate interestingness of rules to filter out less interesting rules. This paper proposes a new criterion of rule's interestingness based on its exceptionality. This criterion evaluates exceptionality of rules by comparing their accuracy with those of simpler and more general rules. We also propose a disovery algorithm, DIG, to extract interesting rules with respect to the criterion effectively.	Fujitsu Labs Ltd, Sawara Ku, Fukuoka 8148588, Japan	Yugami, N (reprint author), Fujitsu Labs Ltd, Sawara Ku, 2-2-1 Momochihama, Fukuoka 8148588, Japan.						Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Blake C., 1999, UCI REPOSITORY MACHI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P181; Kamber M., 1996, P 2 INT C KNOWL DISC, P263; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SILVERSCHATZ A, 1996, IEEE T KNOWL DATA EN, V8, P970; SMYTH P, 1991, KNOWLEDGE DISCOVERY, P160; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Suzuki E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	11	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						17	28				12	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400002	
S	Tani, AH; Soon, HSV		Terano, T; Liu, H; Chen, ALP		Tani, AH; Soon, HSV			Predictive adaptive resonance theory and knowledge discovery in databases	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				This paper investigates the scalability of predictive Adaptive Resonance Theory (ART) networks for knowledge discovery in very large databases. Although predictive ART performs fast and incremental learning, the number of recognition categories or rules that it creates during learning may become substantially large and cause the learning speed to slow down. To tackle this problem, we introduce an on-line algorithm for evaluating and pruning categories during learning. Benchmark experiments on a large scale data set show that on-line pruning has been effective in reducing the number of the recognition categories and the time for convergence. Interestingly, the pruned networks also produce better predictive performance.	Kent Ridge Digital Labs, Singapore 119613, Singapore; Ngee Ann Polytech, Singapore 599489, Singapore	Tani, AH (reprint author), Kent Ridge Digital Labs, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.						Carpenter G. A., 1995, Connection Science, V7, DOI 10.1080/09540099508915655; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; KOHAVI R, 1996, P KDD 96; Murphy PM, 1992, UCI REPOSITORY MACHI; TAN AH, 1995, NEURAL NETWORKS, V8, P437, DOI 10.1016/0893-6080(94)00092-Z	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						173	176				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400018	
S	Shirata, CY; Terano, T		Terano, T; Liu, H; Chen, ALP		Shirata, CY; Terano, T			Extracting predictors of corporate bankruptcy: Empirical study on data mining methods	KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS: CURRENT ISSUES AND NEW APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2000)	APR 18-20, 2000	KYOTO, JAPAN	Japanese Soc Artificial Intelligence, Inst Electr, Informat & Commun Engineers, SIG DE, SIG AI, Japan Soc Software Sci & Technol, SIG DB, Informat Processing Soc Japan, SIG ICS, ACM SIG MOD Japan				We presents some empirical results of a study regarding financial ratios as predictors of Japanese corporate bankruptcy based on a large sample of bankrupt and non-bankrupt firms' financial data. In this study, variable as predictors of bankruptcy had been selected by three Al-based data mining techniques and two conventional statistical methods, Logit analysis and Stepwise. After the selection of a set of variables for every method, discriminant power of each set was compared to verify the most suitable data mining technique to select financial variables. Finally, the study concludes that a set of variables selected by Logit analysis (with logit model) indicated the best discriminant power, more than 87% accuracy.	Tsukuba Coll Technol Japan, Tsukuba, Ibaraki 3050831, Japan; Univ Tsukuba, Bunkyo Ku, Tokyo 112, Japan	Shirata, CY (reprint author), Tsukuba Coll Technol Japan, 4-12 Kasuga, Tsukuba, Ibaraki 3050831, Japan.						ALTMAN E, 1977, J BANK FINANC, V1, P35; Breimann L, 1984, CLASSIFICATION REGRE; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; TERANO T, 1998, INTERACTIVE GENERIC, P393	4	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67382-2	LECT NOTES ARTIF INT			2000	1805						204	207				4	Computer Science, Artificial Intelligence	Computer Science	BS61A	WOS:000170556400022	
J	Imielinski, T; Virmani, A; Abdulghani, A				Imielinski, T; Virmani, A; Abdulghani, A			DMajor - Application programming interface for database mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						database mining; second generation; MSQL; API; association rules		In the process of rule generation from databases, the volume of generated rules often greatly exceeds the size of the underlying database. Typically only a small fraction of that large volume of rules is of any interest to the user. We believe that the main challenge facing database mining is what to do with the rules after having generated them. Rule post-processing involves selecting rules which are relevant or interesting, building applications which use the rules and finally, combining rules together to form a larger and more meaningful statements. In this paper we propose an application programming interface which enables faster development of applications which rely on rules. We also provide a rule query language which allows both selective rule generation as well as retrieval of selected categories of rules from the pre-generated rule collections.	Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08903 USA	Imielinski, T (reprint author), Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08903 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, VLDB, P487; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; HAN J, 1996, SIGMOD 96 WORKSH KDD; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; IMIELINSKI T, 1999, M SQL QUERY LANGUAGE; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Meo R, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P122; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Savasere A, 1995, P 21 INT C VER LARG, P432; SHEN W, 1996, ADV KNOWLEDGE DISCOV; TSUR D, 1997, P ACM SIGMOD C MAN D; VIRMANI A, 1998, THESIS RUTGERS U; WROBEL S, 1996, P 2 INT C KNOWL DISC; *INT ORG STAND AM, 1994, SQL3 ISO ANSI	15	5	5	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1999	3	4					347	372		10.1023/A:1009841028985		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	261MB	WOS:000084012000001	
J	Imielinski, T; Virmani, A				Imielinski, T; Virmani, A			MSQL: A query language for database mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						database mining; query language; MSQL; SQL; association rules		The tremendous number of rules generated in the mining process makes it necessary for any good data mining system to provide for powerful query primitives to post-process the generated rulebase, as well as for performing selective, query based generation. In this paper, we present the design and compilation of MSQL, the rule query language developed as part of the Discovery Board system.	Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08903 USA	Imielinski, T (reprint author), Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08903 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; HAN J, 1996, SIGMOD 96 WORKSH KDD; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Meo R, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P122; NG R, 1998, P ACM SIGMOD C MAN D; SARAWAGI S, 1998, P ACM SIGMOD C MAN D; SHEN W, 1996, ADV KNOWLEDGE DISCOV; TSUR D, 1997, P ACM SIGMOD C MAN D; VIRMANI A, 1998, THESIS RUTGERS U	9	92	95	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1999	3	4					373	408		10.1023/A:1009816913055		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	261MB	WOS:000084012000002	
J	Domingos, P				Domingos, P			The role of occam's razor in knowledge discovery	DATA MINING AND KNOWLEDGE DISCOVERY			English	Review						model selection; overfitting; multiple comparisons; comprehensible models; domain knowledge	LEARNING ALGORITHMS; BAYESIAN NETWORKS; BIAS; VARIANCE; RULES	Many KDD systems incorporate an implicit or explicit preference for simpler models, but this use of "Occam's razor" has been strongly criticized by several authors (e.g., Schaffer, 1993; Webb, 1996). This controversy arises partly because Occam's razor has been interpreted in two quite different ways. The first interpretation (simplicity is a goal in itself) is essentially correct, but is at heart a preference for more comprehensible models. The second interpretation (simplicity leads to greater accuracy) is much more problematic. A critical review of the theoretical arguments for and against it shows that it is unfounded as a universal principle, and demonstrably false. A review of empirical evidence shows that it also fails as a practical heuristic. This article argues that its continued use in KDD risks causing significant opportunities to be missed, and should therefore be restricted to the comparatively few applications where it is appropriate. The article proposes and reviews the use of domain constraints as an alternative for avoiding overfitting, and examines possible methods for handling the accuracy-comprehensibility trade-off.	Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Domingos, P (reprint author), Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.	pedrod@cs.washington.edu					Abu-Mostafa Y. S., 1990, Journal of Complexity, V6, DOI 10.1016/0885-064X(90)90006-Y; AKAIKE H, 1978, ANN I STAT MATH, V30, P9, DOI 10.1007/BF02480194; ANDREWS R, 1996, P NIPS 96 WORKSH RUL; Bernardo J, 1994, BAYESIAN THEORY; Bishop CM, 1995, NEURAL NETWORKS PATT; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; BREIMAN L, 1997, BORN AGAIN TREES; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Bruns J, 1997, Z ORTHOP GRENZGEB, V135, P138, DOI 10.1055/s-2008-1039570; CESTNIK B, 1988, P 8 EUR C ART INT MU, P348; CHEESEMAN P, 1990, MOR KAUF M, P73; Chickering DM, 1997, MACH LEARN, V29, P181; Clark P, 1993, P 10 INT MACH LEARN, P49; CLEARWATER S, 1990, P 2 IEEE INT C TOOLS, P34; Cohen W., 1995, P 12 INT C MACH LEAR, P115; COHEN WW, 1994, ARTIF INTELL, V68, P303, DOI 10.1016/0004-3702(94)90070-1; Cooper GF, 1997, DATA MIN KNOWL DISC, V1, P203, DOI 10.1023/A:1009787925236; Cover T. M., 1991, ELEMENTS INFORMATION; Craven M.W., 1996, THESIS U WISCONSIN M; DATTA P, 1995, P 12 INT C MACH LEAR, P158; Djoko Surnjani, 1995, P 1 INT C KNOWL DISC, P75; Domigos P., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; DOMINGOS P, 1999, P 16 INT JOINT C ART; DOMINGOS P, 1998, P NIPS 98 WORKSH INT; Domingos P., 1996, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V5, DOI 10.1142/S0218213096000080; Domingos P., 1998, P 15 INT C MACH LEAR, P127; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos P., 1997, P 14 INT C MACH LEAR, P98; Domingos P, 1996, MACH LEARN, V24, P141; DONOHO S, 1996, P 13 INT C MACH LEAR, P113; Drucker H., 1994, P 11 INT C MACH LEAR, P53; Edgington E. S., 1980, RANDOMIZATION TESTS; Elomaa T., 1994, P 11 INT C MACH LEAR, P62; FISHER DH, 1988, P 5 INT C MACH LEARN, P22; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GAMS M, 1989, P 4 EUR WORK SESS LE, P71; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Grove A. J., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Han J., 1996, P 2 INT C KNOWL DISC, P250; HASLING DW, 1984, DEV EXPERT SYSTEMS, P117; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; IMIELINSKI T, 1996, P 2 INT C KNOWL DISC, P256; JENSEN D, 1999, IN PRESS MACHINE LEA; Jensen D., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Jensen D., 1992, THESIS WASHINGTON U; Joachims T., 1998, P 10 EUR C MACH LEAR; Kamber M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Kohavi R., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Kohavi R., 1997, P 14 INT C MACH LEAR, P161; Kong E. B., 1995, P 12 INT C MACH LEAR, P313; Kononenko I., 1990, CURRENT TRENDS KNOWL; LANGLEY P, 1996, P 2 INT C KNOWL DISC, P327; Lawrence S., 1997, P 14 NAT C ART INT A, P540; Lee Y, 1998, MACH LEARN, V30, P217, DOI 10.1023/A:1007404308006; Liu B., 1997, P 3 INT C KNOWL DISC, P31; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Maclin R, 1996, MACH LEARN, V22, P251, DOI 10.1007/BF00114730; MACLIN R, 1997, P 14 NAT C ART INT P; Meo R, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P122; MILLER RG, 1981, SIMULTANEOUS STAT IN; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; MITCHELL TM, 1980, NEED BIASES LEARNING; Murphy M A, 1994, J Clin Neurosci, V1, P257, DOI 10.1016/0967-5868(94)90066-3; Nedellec C, 1996, ADV INDUCTIVE LOGIC, P82; Oates T., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; OURSTON D, 1994, ARTIF INTELL, V66, P273, DOI 10.1016/0004-3702(94)90028-0; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Pazzani M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PAZZANI MJ, 1991, J EXP PSYCHOL LEARN, V17, P416, DOI 10.1037/0278-7393.17.3.416; PEARL J, 1978, INT J GEN SYST, V4, P255, DOI 10.1080/03081077808960690; PIATETSKYSHAPIR.G, 1996, KDD NUGGETS, V96, P28; PROVOST F, 1998, KDD 98 TUTORIAL EVAL; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Quinlan J.R., 1995, P 14 INT JOINT C ART, P1019; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; Rao J. S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; RUSSELL SJ, 1986, P 5 NAT C ART INT PH, P447; SALZBERG S., 1995, P 14 INT JOINT C ART, P1025; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SCHAPIRE R, 1997, P 14 INT C MACH LEAR; SCHOLKOPF B, 1998, P 1 INT C KNOWL DISC; SCHUURMANS D, 1997, P 14 INT C MACH LEAR, P340; SCHUURMANS D, 1997, P 14 NAT C ART INT A, P552; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHAWETAYLOR J, 1996, NCTR96053 U LOND DEP; Shen W., 1996, ADV KNOWLEDGE DISCOV, P375; SMOLA A, 1998, P NIPS 98 WORKSH LAR; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Todorovski L., 1997, P 14 INT C MACH LEAR, P376; Tornay S. C., 1938, OCKHAM STUDIES SELEC; Vapnik V.N., 1995, NATURE STAT LEARNING; WALLACE CS, 1968, COMPUT J, V11, P185; Webb GI, 1996, J ARTIF INTELL RES, V4, P397; WEBB GI, 1997, P 15 INT JOINT C ART, P846; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341	102	99	103	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1999	3	4					409	425		10.1023/A:1009868929893		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	261MB	WOS:000084012000003	
J	Guo, Y; Grossman, R				Guo, Y; Grossman, R			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Univ London, Imperial Coll, Dept Comp, London WC1E 7HU, England; Univ Illinois, Natl Ctr Data Min, Chicago, IL USA; Magnify Inc, Chicago, IL USA	Guo, Y (reprint author), Univ London, Imperial Coll, Dept Comp, London WC1E 7HU, England.							0	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1999	3	3					235	236		10.1023/A:1009878008434		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	260RH	WOS:000083963300001	
J	Srivastava, A; Han, EH; Kumar, V; Singh, V				Srivastava, A; Han, EH; Kumar, V; Singh, V			Parallel formulations of decision-tree classification algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; parallel processing; classification; scalability; decision trees		Classification decision tree algorithms are used extensively for data mining in many domains such as retail target marketing, fraud detection, etc. Highly parallel algorithms for constructing classification decision trees are desirable for dealing with large data sets in reasonable amount of time. Algorithms for building classification decision trees have a natural concurrency, but are difficult to parallelize due to the inherent dynamic nature of the computation. In this paper, we present parallel formulations of classification decision tree learning algorithm based on induction. We describe two basic parallel formulations. One is based on Synchronous Tree Construction Approach and the other is based on Partitioned Tree Construction Approach. We discuss the advantages and disadvantages of using these methods and propose a hybrid method that employs the good features of these methods. We also provide the analysis of the cost of computation and communication of the proposed hybrid method. Moreover, experimental results on an IBM SP-2 demonstrate excellent speedups and scalability.	Univ Minnesota, Dept Comp Sci & Engn, Army HPC Res Ctr, Minneapolis, MN 55455 USA; Hitachi Amer Inc, Informat Technol Lab, Tarrytown, NY 10591 USA							AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; ALSABTI K, 1997, P 23 VLDB C; ALSABTI K, 1998, CLOUDS CLASSIFICATIO; ANURAG S, 1997, TR97010 U MINN DEP C; Breiman L, 1984, CLASSIFICATION REGRE; Catlett J., 1991, THESIS U SYDNEY; Chan P., 1993, P 2 INT C INF KNOWL, P314; Chan P. K., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); CHATTRATICHAT J, P 3 INT C KNOWL DISC; GEORGE D, 1994, EXP HEMATOL, V22, P379; GOIL S, 1996, P S PAR DISTR COMP S; GOLDBERG DE, 1989, GENETIC AOGORITHMS S; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; JOSHI MV, 1998, P INT PAR PROC S; KUFRIN R, 1997, PARALLEL PROCESSING, V3; Kumar V., 1994, INTRO PARALLEL COMPU; LIPPMANN RP, 1987, IEEE ASSP MAGAZINE, V4, P22; Mehta M., 1996, P 5 INT C EXT DAT TE; PEARSON RA, 1994, PARALLEL PROCESSING, V2, P207; QUINLAN JR, 1993, C4 5 PROGRMAS MACHIN; SHAFER JC, 1996, P 22 VLDB C; SHANKAR R, 1995, FRONTIERS 95; Spiegelhalter D.J., 1994, MACHINE LEARNING NEU; WIRTH J, 1988, 5 INT C MACH LEARN	24	37	39	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1999	3	3					237	261		10.1023/A:1009832825273		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	260RH	WOS:000083963300002	
J	Xu, XW; Jager, J; Kriegel, HP				Xu, XW; Jager, J; Kriegel, HP			A fast parallel clustering algorithm for large spatial databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clustering algorithms; parallel algorithms; distributed algorithms; scalable data mining; distributed index structures; spatial databases		The clustering algorithm DBSCAN relies on a density-based notion of clusters and is designed to discover clusters of arbitrary shape as well as to distinguish noise. In this paper, we present PDBSCAN, a parallel version of this algorithm. We use the 'shared-nothing' architecture with multiple computers interconnected through a network. A fundamental component of a shared-nothing system is its distributed data structure. We introduce the dR*-tree, a distributed spatial index structure in which the data is spread among multiple computers and the indexes of the data are replicated on every computer. We implemented our method using a number of workstations connected via Ethernet (10 Mbit). A performance evaluation shows that PDBSCAN offers nearly linear speedup and has excellent scaleup and sizeup behavior.	Siemens AG, D-81730 Munich, Germany; Univ Munich, Inst Comp Sci, D-80538 Munich, Germany	Xu, XW (reprint author), Siemens AG, Otto Hahn Ring 6, D-81730 Munich, Germany.	Xiaowei.Xu@mchp.siemens.de; jaeger@informatik.uni-muenchen.de; kriegel@informatik.uni-munchen.de					AGRAWAL R, 1996, PARALLEL MINING ASS; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; BIALLY T, 1969, IEEE T INFORM THEORY, V15, P658, DOI 10.1109/TIT.1969.1054385; CHEUNG DW, 1996, P INT C PAR DISTR IN; Ester M., 1995, P 1 INT C KNOWL DISC, P94; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Faloutsos C., 1989, Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, DOI 10.1145/73721.73746; GEIST A, 1996, PVM PARALLEL VIRTUAL; GUETING RH, 1994, VLDB J, V3, P357, DOI 10.1007/BF01231602; JAJA J, 1992, INTRO PARALLEL ALGOR, P61; Kamel I., 1993, P 2 INT C INF KNOWL; LI X, 1989, PARALLEL COMPUT, V11, P275, DOI 10.1016/0167-8191(89)90036-7; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; Mehta M., 1997, VLDB Journal, V6, DOI 10.1007/s007780050033; OLSON CF, 1995, PARALLEL COMPUT, V21, P1313, DOI 10.1016/0167-8191(95)00017-I; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; PFITZNER DW, 1998, DATA MIN KNOWL DISC, V2, P419; RICHARDS AJ, 1983, REMOTE SENSING DIGIT; SANDER J, 1998, DENSITY BASED CLUSTE, V2, P1; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; Stonebraker M, 1993, P ACM SIGMOD INT C M, P2, DOI 10.1145/170035.170038; Stonebraker M., 1986, DATABASE ENG, V9; RASMUSSEN EM, 1989, J DOC, V45, P1, DOI 10.1108/eb026836; XU X, 1999, EFFICIENT CLUSTERING; XU XW, 1998, 14 INT C DAT ENG ICD; ZHANG T, 1998, BIRCH NEW DATA CLUST, P1	27	35	41	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1999	3	3					263	290		10.1023/A:1009884809343		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	260RH	WOS:000083963300003	
J	Cheung, DW; Xiao, YQ				Cheung, DW; Xiao, YQ			Effect of data distribution in parallel mining of associations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association rules; data mining; data skewness; workload balance; parallel mining; parallel computing		Association rule mining is an important new problem in data mining. It has crucial applications in decision support and marketing strategy. We proposed an efficient parallel algorithm for mining association rules on a distributed share-nothing parallel system. Its efficiency is attributed to the incorporation of two powerful candidate set pruning techniques. The two techniques, distributed and global prunings, are sensitive to two data distribution characteristics: data skewness and workload balance. The prunings are very effective when both the skewness and balance are high. We have implemented FPM on an IBM SP2 parallel system. The performance studies show that FPM outperforms CD consistently, which is a parallel version of the representative Apriori algorithm (Agrawal and Srikant, 1994). Also, the results have validated our observation on the effectiveness of the two pruning techniques with respect to the data distribution characteristics. Furthermore, it shows that FPM has nice scalability and parallelism, which can be tuned for different business applications.	Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong	Cheung, DW (reprint author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong.						Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Cheung DW, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P31, DOI 10.1109/PDIS.1996.568665; CHEUNG DW, 1996, P 1996 IEEE INT C DA; Cover T. M., 1991, ELEMENTS INFORMATION; Fayyad U.M., 1995, ADV KNOWLEDGE DISCOV; HAN E, 1997, P 1997 ACM SIGMOD IN; Han J, 1995, P 21 INT C VER LARG, P420; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Message Passing Interface Forum, 1994, MPI MESS PASS INT ST; NG RT, 1998, P 1998 ACM SIGMOD IN; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; PARK JS, 1995, P 1995 INT C INF KNO; Savasere A, 1995, P 21 INT C VER LARG, P432; SHINTANI T, 1996, P 4 INT C PAR DISTR; SILBERSCHATZ A, 1995, NSF WORKSH FUT DAT S; SRIKANT R, 1996, P 1996 ACM SIGMOD IN; Srikant R., 1996, P 5 INT C EXT DAT TE; Srikant R., 1995, P 21 INT C VER LARG, P407; ZAKI MJ, 1996, SUP 96 PITTSB PA NOV; *INT BUS MACH, 1995, SCAL POWER PAR SYST	23	7	7	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1999	3	3					291	314		10.1023/A:1009836926181		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	260RH	WOS:000083963300004	
J	Xiang, Y; Chu, T				Xiang, Y; Chu, T			Parallel learning of belief networks in large and difficult domains	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						belief networks; parallel implementation of data mining		Learning belief networks from large domains can be expensive even with single-link lookahead search (SLLS). Since a SLLS cannot learn correctly in a class of problem domains, multi-link lookahead search (MLLS) is needed which further increases the computational complexity. In our experiment, learning in some difficult domains over more than a dozen variables took days. In this paper, we study how to use parallelism to speed up SLLS for learning in large domains and to tackle the increased complexity of MLLS for learning in difficult domains. We propose a natural decomposition of the learning task for parallel processing. We investigate two strategies for job allocation among processors to further improve load balancing and efficiency of the parallel system. For learning from very large datasets, we present a regrouping of the available processors such that slow data access through the file system can be replaced by fast memory access. Experimental results in a distributed memory MIMD computer demonstrate the effectiveness of the proposed algorithms.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada; Avant Corp, Sunnyvale, CA USA	Xiang, Y (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.						BEINLICH I, 1989, KSL8884 STANF U MED; Chickering D., 1995, P 5 C ART INT STAT F, P112; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; HERSKOVITS EH, 1990, P 6 C UNC ART INT CA, P54; HU J, 1997, THESIS U REGINA; Jensen F. V., 1996, INTRO BAYESIAN NETWO; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Lewis T. G., 1992, INTRO PARALLEL COMPU; Moldovan D I, 1993, PARALLEL PROCESSING; Pearl J., 1988, PROBABILISTIC REASON; SPIRO B, 1991, GEOMICROBIOL J, V9, P1; XIANG Y, 1997, P 10 INT S METH INT; Xiang Y., 1996, P 12 C UNC ART INT P, P564; Xiang Y, 1997, MACH LEARN, V26, P65, DOI 10.1023/A:1007324100110	16	13	14	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1999	3	3					315	339		10.1023/A:1009888910252		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	260RH	WOS:000083963300005	
J	Provost, F; Kolluri, V				Provost, F; Kolluri, V			A survey of methods for scaling up inductive algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Review						scaling up; inductive learning; decision trees; rule learning	LEARNING ALGORITHMS; REPRESENTATION; SELECTION; BIAS	One of the defining challenges for the KDD research community is to enable inductive learning algorithms to mine very large databases. This paper summarizes, categorizes, and compares existing work on scaling up inductive algorithms. We concentrate on algorithms that build decision trees and rule sets, in order to provide focus and specific details; the issues and techniques generalize to other types of data mining. We begin with a discussion of important issues related to scaling up. We highlight similarities among scaling techniques by categorizing them into three main approaches. For each approach, we then describe, compare, and contrast the different constituent techniques, drawing on specific examples from published papers. Finally, we use the preceding analysis to suggest how to proceed when dealing with a large problem, and where to focus future research.	Bell Atlantic Sci & Technol, White Plains, NY 10604 USA; Univ Pittsburgh, Dept Informat Sci, Pittsburgh, PA 15260 USA; Lycos Inc, Pittsburgh, PA 15213 USA	Provost, F (reprint author), Bell Atlantic Sci & Technol, 500 Westchester Ave, White Plains, NY 10604 USA.	provost@acm.org; venkat@sis.pitt.edu					AGRAWAL R, 1996, P 2 INT C KNOWL DISC, P287; AGRAWAL R, 1995, 1000589094 RJ IBM CO; AGRAWAL R, 1994, RJ9839 IBM CORP; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; ALMUALLIM H, 1995, P 12 INT C MACH LEAR; ANDERSEN W, 1994, MASSIVELY PARALLEL A; ARONIS J, 1997, P 3 INT C KNOWL DISC; ARONIS J, 1997, P FLOR ART INT RES S; Aronis J., 1996, P 2 INT C KNOWL DISC, P355; ARONIS J, 1994, AAAI 94 WORKSH KNOWL; AUER P, 1995, P 12 INT C MACH LEAR, P21; Blockeel H, 1999, DATA MIN KNOWL DISC, V3, P59, DOI 10.1023/A:1009867806624; Breiman L, 1984, CLASSIFICATION REGRE; BROCKHAUSEN P, 1996, P MLNET SPONS FAM WO; BUCHANAN BG, 1996, J AM CHEM SOC, V96, P6168; BUCHANAN BG, 1978, ARTIF INTELL, V11, P5, DOI 10.1016/0004-3702(78)90010-3; BUNTINE WL, 1991, THESIS U TECHNOLOGY; Catlett J., 1991, THESIS U TECHNOLOGY; Catlett J., 1991, P 8 INT WORKSH MACH, P596; Chan P., 1993, AAAI WORKSH KNOWL DI, V227-240; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008640732416; CHEN M, 1997, IEEE T KNOWLEDGE DAT; CHEN MS, 1995, USING MULTIATTRIBUTE; CLEARWATER S, 1989, P 6 INT WORKSH MACH, P366; CLEARWATER SH, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P24, DOI 10.1109/TAI.1990.130305; Cohen W., 1995, P 12 INT C MACH LEAR, P115; COHEN WW, 1993, 13TH P INT JOINT C A, P988; COOK D, 1990, P 2 INT IEEE C TOOLS, P366; CRAVEN MW, 1996, 1326 U WISC; DANYLUK A, 1993, MACH LEARN, P81; DESJARDINS M, 1995, MACHINE LEARNING, V20; Devijver PA, 1982, PATTERN RECOGNITION; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P., 1997, P 14 INT C MACH LEAR, P98; Domingos P., 1996, P 2 INT C KNOWL DISC, P96; Domingos P., 1996, P 2 INT C KNOWL DISC, P319; Duda R., 1973, PATTERN CLASSIFICATI; EVETT M, 1994, THESIS U MARYLAND CO; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Fayyad U, 1996, P 2 INT C KNOWL DISC, P367; FAYYAD U, 1996, P 2 INT C KNOWL DISC, P50; FAYYAD U, 1993, P 10 INT C MACH LEAR; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Fayyad UM, 1997, DATA MIN KNOWL DISC, V1, P5, DOI 10.1023/A:1009715820935; FOX EA, 1995, COMMUNICATIONS ACM, V38; Freitas A. A., 1996, Cybernetics and Systems '96. Proceedings of the Thirteenth European Meeting on Cybernetics and Systems Research; FREITAS AA, 1997, MINING VERY LARGE DA; FREY LJ, 1999, P 7 INT WORKSH ART I; FRIEDMAN J, 1997, P 29 S INT COMP SCI; FURNKRANZ J, 1994, P 11 INT MACH LEARN; Furnkranz J, 1998, J ARTIF INTELL RES, V8, P129; Gaines B.R., 1989, P 6 INT WORKSH MACH, P156; GALAL G, 1999, IN PRESS J AM SOC IN; GEHRKE J, 1998, P 24 INT C VER LARG; GRAEFE G, 1998, P 4 INT C KNOWL DISC; GROSSMAN R, 1998, 4 INT C KNOWL DISC D; GUO Y, 1998, KDD 97 WORKSH DISTR, P61; HAINES TL, 1998, COMMUNICATION; HALL LO, 1998, KDD 97 WORKSH DISTR, P10; Han J., 1996, P 2 INT C KNOWL DISC, P250; HARRISJONES C, 1997, AMSCATWP97118 CTR AD; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; Hayes P.J., 1979, FRAME CONCEPTIONS TE, P46; HOLSHEIMER M, 1996, ADV KNOWLEDGE DISCOV, P447; HOLTE R, 1993, MACH LEARN, V3, P63; Holte RC, 1989, P 11 INT JOINT C ART, P813; HUBR P, 1997, P 3 INT C KNOWL DISC, P304; Iba W., 1992, P 9 INT C MACH LEARN, P233; JENSEN D, 1999, MULTIPLE COMPARISONS; JENSEN D, 1998, COMMUNICATION; John G. H., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; KARGUPTA H, 1998, KDD 97 WORKSH DISTR, P70; KARGUPTA H, 1998, KDD 98 WORKSH DISTR; KARP PD, 1995, P 1995 INT JOINT C A, P751; KARP PD, 1994, P 3 INT C INF KNOWL; Kaufman K, 1996, P 2 INT C KNOWL DISC, P232; Kearns M., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167200; KOHAVI R, 1998, 15 INT C MACH LEARN; KOHAVI R, 1995, P 1 INT C KNOWL DISC; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KOHAVI R, 1996, THESIS STANFORD U PA; Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621; Kononenko Igor, 1994, P EUR C MACH LEARN; KUFRIN R, 1997, P 14 NAT C ART INT A, P565; KUMAR V, 1987, INT J PARALLEL PROG, V16, P501, DOI 10.1007/BF01389001; LATHROP R, 1990, AI MIT EXPANDING FRO; LI B, 1998, THESIS NEW YORK U; LIM TJ, 1999, IN PRESS MACHINE LEA; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Mehta M., 1996, P 5 INT C EXT DAT TE; Merz C., 1997, UCI REPOSITORY MACHI; Miller AJ, 1990, SUBSET SELECTION REG; Mitchell TM, 1980, CBMTR117 RUTG U; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Moore A, 1994, P 11 INT C MACH LEAR; Moore A, 1998, J ARTIF INTELL RES, V8, P67; MUGGLETON S., 1992, INDUCTIVE LOGIC PROG; MUSICK R, 1998, UCRLID129903 LAWR LI; MUSICK R, 1993, P 10 INT C MACH LEAR, P212; Oates T, 1997, P 14 INT C MACH LEAR, P254; Oates T., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PIATETSKYSHAPIR. G, 1996, P 2 INT C KNOWL DISC, P89; PRODROMIDIS AL, 1998, KDD 97 WORKSH DISTR, P22; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PROVOST F, 1999, IN PRESS ACM SLGKDD; PROVOST F, 1996, P 13 NAT C ART INT M; PROVOST F, 1997, ISL973 U PITTSB; PROVOST FJ, 1994, P 2 INT C INT SYST M; Provost FJ, 1996, MACH LEARN, V23, P33; PROVOST FJ, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P749; PROVOST FJ, 1992, THESIS U PITTSBURGH; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; QUINLAN J, 1983, MACHINE LEARNING AI; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RAO VN, 1987, INT J PARALLEL PROG, V16, P479, DOI 10.1007/BF01389000; RIBEIRO JS, 1995, P 1 INT C KNOWL DISC, P240; RIDDLE P, 1994, APPL ARTIF INTELL, V8, P125, DOI 10.1080/08839519408945435; RYMON R, 1993, P 10 INT C MACH LEAR; SARAWAGI S, 1998, P ACM SIGMOD INT C M; Savasere A, 1995, P 21 INT C VER LARG, P432; Schlimmer J.C., 1993, P 10 INT C MACH LEAR, P284; SEGAL R, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P619; Shafer J., 1996, P 22 INT C VER LARG; SHASHA D, 1998, PC4 5; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; SIMON H, 1973, KNOWLEDGE COGNITION, P105; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926; Srikant R, 1996, P ACM SIGMOD C MAN D; STOLFO S, 1997, P AAAI 97 WORKSH AI, P91; Stolfo S. J., 1997, P AAAI WORKSH AI APP, P83; TOIVONEN H, 1996, P 24 INT C VER LARG; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WEBB GI, 1995, J ARTIFICIAL INTELLI, V3, P383; WEISS SM, 1990, ARTIF INTELL, V45, P47, DOI 10.1016/0004-3702(90)90037-Z; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1997, ARTIF INTELL, V10, P1; WILLIAMS GJ, 1990, THESIS AUSTR NATL U; Wu XD, 1998, LECT NOTES ARTIF INT, V1531, P24; ZAKI M, 1998, THESIS U ROCHESTER R; Zaki M. J., 1997, P 7 INT WORKSH RES I; ZAKI MJ, 1999, P IEEE INT C DAT ENG	147	63	63	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1999	3	2					131	169		10.1023/A:1009876119989		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	227LZ	WOS:000082083000001	
J	Lawrence, RD; Almasi, GS; Rushmeier, HE				Lawrence, RD; Almasi, GS; Rushmeier, HE			A scalable parallel algorithm for self-organizing maps with applications to sparse data mining problems	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						parallel processing; parallel IO; scalable data mining; clustering; Kohonen self-organizing maps; data visualization	NEURAL NETWORKS; COMPUTERS	We describe a scalable parallel implementation of the self organizing map (SOM) suitable for data-mining applications involving clustering or segmentation against large data sets such as those encountered in the analysis of customer spending patterns. The parallel algorithm is based on the batch SOM formulation in which the neural weights are updated at the end of each pass over the training data. The underlying serial algorithm is enhanced to take advantage of the sparseness often encountered in these data sets. Analysis of a realistic test problem shows that the batch SOM algorithm captures key features observed using the conventional on-line algorithm, with comparable convergence rates. Performance measurements on an SP2 parallel computer are given for two retail data sets and a publicly available set of census data.These results demonstrate essentially linear speedup for the parallel batch SOM algorithm, using both a memory-contained sparse formulation as well as a separate implementation in which the mining data is accessed directly from a parallel file system. We also present visualizations of the census data to illustrate the value of the clustering information obtained via the parallel SOM method.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Heights, NY 10598 USA	Lawrence, RD (reprint author), IBM Corp, Thomas J Watson Res Ctr, POB 218, Yorktown Heights, NY 10598 USA.						BUHUSI CV, 1993, P 9 ROM S COMP SCI 9, P51; CECCARELLI M, 1993, CONCURRENCY-PRACT EX, V5, P449, DOI 10.1002/cpe.4330050602; Gropp W, 1994, USING MPI PORTABLE P; HONKELA T, 1998, WEBSOM SELFORGANIZIN; Ienne P, 1997, IEEE T NEURAL NETWOR, V8, P315, DOI 10.1109/72.557669; Kohonen T., 1993, P IEEE INT C NEUR NE, P1147; KOHONEN T, 1996, P ART NEUR NETW ICAN; KOHONEN T, 1988, COMPUTER, V21, P11, DOI 10.1109/2.28; Kohonen T., 1990, IEEE T NEURAL NETWOR, V1, P229; KOHONEN T, 1995, SOMPAK SELFORGANIZIN; KOHONEN T, 1995, SELFORGANIZING MAPS; Kohonen T, 1985, P IEEE, p[73, 1551]; KOIKKALAINEN T, 1994, P ECAI 94 11 EUR C A; LAGUS K, 1996, P 2 INT C KNOWL DISC, P238; Lu S., 1994, IJCNN INT JOINT C NE; Mann R., 1990, P INT JOINT C NEUR N, VII, P84; MULIER F, 1994, P 12 IAPR INT C PATT, V2, P224, DOI 10.1109/ICPR.1994.576908; MULIER F, 1995, NEURAL COMPUT, V7, P1141; MYKLEBUST G, 1995, P IEEE INT C NEUR NE; NATARAJAN R, 1997, 20749 RC IBM RES; OBERMAYER K, 1990, PARALLEL COMPUT, V14, P381, DOI 10.1016/0167-8191(90)90088-Q; Rushmeier H., 1997, Proceedings. Visualization '97 (Cat. No.97CB36155), DOI 10.1109/VISUAL.1997.663922; SIMOUDIS E, 1996, IEEE EXPERT INTELLIG, P26; WU CH, 1991, PARALLEL COMPUT, V17, P821, DOI 10.1016/S0167-8191(05)80069-9	24	23	23	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1999	3	2					171	195		10.1023/A:1009817804059		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	227LZ	WOS:000082083000002	
J	Coppersmith, D; Hong, SJ; Hosking, JRM				Coppersmith, D; Hong, SJ; Hosking, JRM			Partitioning nominal attributes in decision trees	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						binary decision tree; classification; data mining; entropy; Gini index; impurity; optimal splitting		To find the optimal branching of a nominal attribute at a node in an L-ary decision tree, one is often forced to search over all possible L-ary partitions for the one that yields the minimum impurity measure. For binary trees (L = 2) when there are just two classes a short-cut search is possible that is linear in n, the number of distinct values of the attribute. For the general case in which the number of classes, k, may be greater than two, Burshtein et al. have shown that the optimal partition satisfies a condition that involves the existence of (L\atop 2) hyperplanes in the class probability space. We derive a property of the optimal partition for concave impurity measures (including in particular the Gini and entropy impurity measures) in terms of the existence of L vectors in the dual of the class probability space, which implies the earlier condition. Unfortunately, these insights still do not offer a practical search method when n and k are large, even for binary trees. We therefore present a new heuristic search algorithm to find a good partition. It is based on ordering the attribute's values according to their principal component scores in the class probability space, and is linear in n. We demonstrate the effectiveness of the new method through Monte Carlo simulation experiments and compare its performance against other heuristic methods.	IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Heights, NY 10598 USA	Coppersmith, D (reprint author), IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Heights, NY 10598 USA.						Breiman L, 1984, CLASSIFICATION REGRE; BURSHTEIN D, 1989, 14754 RC IBM RES DIV; BURSHTEIN D, 1992, ANN STAT, V20, P1637, DOI 10.1214/aos/1176348789; CHOU PA, 1988, THESIS STANFORD U ST; CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; Mehta M., 1996, P 5 INT C EXT DAT TE; NADAS A, 1991, P ICASSP, P565, DOI 10.1109/ICASSP.1991.150402; Palmer W. C, 1965, 45 WEATH BUR; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; WILLEKE GE, 1995, 94NDS4 IWR US ARM CO; *NASA, 1992, GA23247502 NASA; *TEQN SERV INC, 1996, NAT EL DROUGHT ATL C	13	12	12	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1999	3	2					197	217		10.1023/A:1009869804967		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	227LZ	WOS:000082083000003	
J	Masand, B; Datta, P; Mani, DR; Li, B				Masand, B; Datta, P; Mani, DR; Li, B			CHAMP: A prototype for automated cellular churn prediction	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; knowledge discovery; churn prediction application; predictive modeling		We describe CHAMP (CHurn Analysis, Modeling, and Prediction), an automated system for modeling cellular customer behavior on a large scale. Using historical data from GTE's data warehouse for cellular phone customers, every month CHAMP identifies churn factors for several geographic regions and updates models to generate churn scores predicting who is likely to churn within the near future. CHAMP is capable of developing customized monthly models and churn scores for over one hundred GTE cellular phone markets totaling over 5 million customers.	GTE Labs Inc, Waltham, MA 02254 USA	Masand, B (reprint author), GTE Labs Inc, Waltham, MA 02254 USA.						BREIMAN I, 1984, CLASSIFICATION REGRE; Catlett J., 1991, P 8 INT WORKSH MACH, P596; FAHLMANN SE, 1988, ADV NEURAL INFORMATI, V2; Gordon D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00317.x; KOHAVI R, 1994, MLCPLUSPLUS MACHINE; Koza J, 1993, GENETIC PROGRAMMING; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; PUSKORIUS GV, 1991, P INT JOINT C NEUR N; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; Tukey J.W., 1977, EXPLORATORY DATA ANA	12	8	9	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1999	3	2					219	225		10.1023/A:1009873905876		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	227LZ	WOS:000082083000004	
J	Dzeroski, S; Lavrac, N				Dzeroski, S; Lavrac, N			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material							FIRST-ORDER; INDUCTION		Jozef Stefan Inst, Ljubljana, Slovenia	Dzeroski, S (reprint author), Jozef Stefan Inst, Jamova 39, Ljubljana, Slovenia.						Blockeel H, 1998, P 15 INT C MACH LEAR, P55; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; DERAEDT L, 1995, P 6 INT WORKSH ALG L, P80; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; DZEROSKI S, 1999, IN PRESS INDUCTIVE L; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P118; Dzeroski S, 1998, APPL ARTIF INTELL, V12, P363, DOI 10.1080/088395198117686; Karalic A, 1997, MACH LEARN, V26, P147, DOI 10.1023/A:1007365207130; KING RD, 1992, P NATL ACAD SCI USA, V89, P11322, DOI 10.1073/pnas.89.23.11322; Kirsten M, 1998, P 8 INT C IND LOG PR, P261; Kramer S, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P812; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Muggleton S., 1991, New Generation Computing, V8; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Srinivasan A, 1996, ARTIF INTELL, V85, P277, DOI 10.1016/0004-3702(95)00122-0; Srinivasan A, 1997, KLUWER INT SER ENG C, V414, P243	16	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	1999	3	1					5	6		10.1023/A:1009891420736		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	192WR	WOS:000080103100001	
J	Dehaspe, L; Toivonen, H				Dehaspe, L; Toivonen, H			Discovery of frequent DATALOG patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						frequent patterns; inductive logic programming; DATALOG queries; association rules; episodes; sequential patterns	KNOWLEDGE DISCOVERY; DECLARATIVE BIAS; CARCINOGENICITY; MUTAGENICITY; SEARCH; ILP	Discovery of frequent patterns has been studied in a variety of data mining settings. In its simplest form, known from association rule mining, the task is to discover all frequent itemsets, i.e., all combinations of items that are found in a sufficient number of examples. The fundamental task of association rule and frequent set discovery has been extended in various directions, allowing more useful patterns to be discovered with special purpose algorithms. We present WARMR, a general purpose inductive logic programming algorithm that addresses frequent query discovery: a very general DATALOG formulation of the frequent pattern discovery problem. The motivation for this novel approach is twofold. First, exploratory data mining isi well supported: WARMR offers the flexibility required to experiment with standard and in particular novel settings not supported by special purpose algorithms. Also, application prototypes based on WARMR can be used as benchmarks in the comparison and evaluation of new special purpose algorithms. Second, the unified representation gives insight to the blurred picture of the frequent pattern discovery domain. Within the DATALOG formulation a number of dimensions appear that relink diverged settings. We demonstrate the frequent query approach and its use on two applications, one in alarm analysis, and one in a chemical toxicology domain.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium; Univ Helsinki, Rolf Nevanlinna Inst, FIN-00014 Helsinki, Finland; Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland	Dehaspe, L (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Heverlee, Belgium.	luc.dehaspe@cs.kuleuven.ac.be; hannu.toivonen@rni.helsinki.fi	Toivonen, Hannu/A-3657-2012	Toivonen, Hannu/0000-0003-1339-8022			ADE H, 1995, MACH LEARN, V20, P119, DOI 10.1007/BF00993477; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; ASHBY J, 1991, MUTAT RES, V257, P229, DOI 10.1016/0165-1110(91)90003-E; Bettini C., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237680; Blockeel H, 1998, P 15 INT C MACH LEAR, P55; BLOCKEEL H, 1996, P 6 INT WORKSH IND L, V1314, P199; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; BRISTOL D, 1996, ENV HLTH PERSPECTI S, V3, P1001; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DEHASPE L, 1998, THESIS KU LEUVEN; DEHASPE L, 1996, LECT NOTES ARTIF INT, V1079, P613; Dehaspe L, 1997, LECT NOTES ARTIF INT, V1297, P125; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; DERAEDT L, 1998, IN PRESS LECT NOTES; DERAEDT L, 1996, P 3 INT WORKSH MULT, P29; DERAEDT L, 1995, LECT NOTES ARTIF INT, V997, P80; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Djoko Surnjani, 1995, P 1 INT C KNOWL DISC, P75; Dousson C., 1993, P INT JOINT C ART IN, P166; DZEROSKI S, 1998, P 15 INT C MACH LEAR; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P118; Fayyad U., 1996, P 2 INT C KNOWL DISC, P351; GOODMAN RM, 1991, INTEGRATED NETWORK M, V2, P541; Han J, 1995, P 21 INT C VER LARG, P420; Hatonen K, 1996, PROC INT CONF DATA, P115, DOI 10.1109/ICDE.1996.492095; Holsheimer M, 1995, P 1 INT C KNOWL DISC, P150; KIETZ JU, 1994, P 11 INT C MACH LEAR; Kietz J.-U., 1992, INDUCTIVE LOGIC PROG, P335; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; King RD, 1996, ENVIRON HEALTH PERSP, V104, P1031, DOI 10.2307/3433027; KLEMETTINEN M, 1998, J NETWORK SYSTEMS MA; Klosgen W., 1996, ADV KNOWLEDGE DISCOV; Kramer S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Langley P, 1996, ELEMENTS MACHINE LEA; LINDNER G, 1995, P MLNET FAM WORKSH S; Lu H., 1995, P 21 INT C VER LARG, P478; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MORRIS RA, 1995, 2 INT WORKSH TEMP RE; MUGGLETON S, 1995, NEW GEN COMPUTING, V13; Muggleton S., 1996, P 6 INT WORKSH IND L, P225; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; NEDELLEC C, 1996, FR ART INT, V32, P82; Oates T, 1996, P 13 INT C MACH LEAR, P346; Plotkin G.D., 1970, MACH INTELL, V5, P153; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sasisekharan R, 1996, IEEE EXPERT, V11, P37, DOI 10.1109/64.482956; Savasere A, 1995, P 21 INT C VER LARG, P432; Shen W., 1996, ADV KNOWLEDGE DISCOV, P375; Srikant R., 1996, Advances in Database Technology - EDBT '96. 5th International Conference on Extending Database Technology. Proceedings; Srikant R., 1995, P 21 INT C VER LARG, P407; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; SRINISAVAN A, 1997, P 15 INT JOINT C ART; Srinivasan A., 1997, LECT NOTES ARTIF INT, V1297, P273; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; Ullman J. D., 1988, PRINCIPLES DATABASE, VI; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; WANG K, 1997, P 3 INT C KNOWL DISC, P271; WANG X, 1997, P 3 INT C KNOWL DISC, P89; WEBER I, 1997, LECT NOTES ARTIF INT, V1297, P288; WEBER I, 1998, P FACHGR MASCH LERN; Wrobel S, 1997, LECT NOTES ARTIF INT, V1263, P78	67	97	108	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	1999	3	1					7	36		10.1023/A:1009863704807		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	192WR	WOS:000080103100002	
J	Srinivasan, A; King, RD				Srinivasan, A; King, RD			Feature construction with Inductive Logic Programming: A study of quantitative predictions of biological activity aided by structural attributes	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						constructive induction; indicator variables; ILP; QSAR; drug design; scientific discovery	DIHYDROFOLATE-REDUCTASE; NEURAL NETWORKS; NITRO-COMPOUNDS; FIRST-ORDER; MUTAGENICITY; REGRESSION	Recently, computer programs developed within the field of Inductive Logic Programming (ILP) have received some attention for their ability to construct restricted first-order logic solutions using problem-specifrc background knowledge. Prominent applications of such programs have been concerned with determining "structure-activity" relationships in the areas of molecular biology and chemistry. Typically the task here is to predict the "activity" of a compound (for example, toxicity), from its chemical structure. A summary of the research in the area is: (a) ILP programs have largely been restricted to qualitative predictions of activity ("high", "low" etc.); (b) When appropriate attributes are available, ILP programs have equivalent predictivity to standard quantitative analysis techniques like linear regression. However ILP programs usually perform better when such attributes are unavailable; and (c) By using structural information as background knowledge, an ILP program can provide comprehensible explanations for biological activity. This paper examines the use of ILP programs as a method of "discovering" new attributes. These attributes could then be used by methods like linear regression, thus allowing for quantitative predictions while retaining the ability to use structural information as background knowledge. Using structure-activity tasks as a test-bed, the utility of ILP programs in constructing new features was evaluated by examining the prediction of biological activity using linear regression, with and without the aid of ILP learnt logical attributes. In three out of the five data sets examined the addition of ILP attributes produced statistically better results. In addition six important structural features that have escaped the attention of the expert chemists were discovered. The method used here to construct new attributes is not specific to the problem of predicting biological activity, and the results obtained suggest a wider role for ILP programs in aiding the process of scientific discovery.	Univ Oxford, Comp Lab, Oxford OX1 3QD, England; Univ Wales, Dept Comp Sci, Aberystwyth, Dyfed, Wales	Srinivasan, A (reprint author), Univ Oxford, Comp Lab, Oxford OX1 3QD, England.						ANDREA TA, 1991, J MED CHEM, V34, P2824, DOI 10.1021/jm00113a022; BRATKO I, 1993, 3 INT WORKSH IND LOG, P279; Breiman L, 1984, CLASSIFICATION REGRE; COHEN WW, 1995, NEW GENERAT COMPUT, V13, P369; COLLINS JS, 1968, MACHINE INTELLIGENCE, V2; DAVIS AM, 1994, J MED CHEM, V37, P963, DOI 10.1021/jm00033a014; DEBNATH AK, 1991, J MED CHEM, V34, P786, DOI 10.1021/jm00106a046; DERAEDT L, 1992, MACH LEARN, V8, P107, DOI 10.1023/A:1022664419589; Dolsak B., 1992, INDUCTIVE LOGIC PROG, P453; DZEROSKI S, 1994, P 5 INT C DEV APPL C; DZEROSKI S, 1995, THESIS LJUBLJANA; Feng C, 1992, ILP, P473; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; HANSCH C, 1982, J MED CHEM, V25, P777, DOI 10.1021/jm00349a003; HANSCH C, 1962, NATURE, V194, P178, DOI 10.1038/194178b0; KARALIC A, 1994, IJSDP7001 J STEF I; Karalic A, 1997, MACH LEARN, V26, P147, DOI 10.1023/A:1007365207130; King RD, 1997, J COMPUT AID MOL DES, V11, P571, DOI 10.1023/A:1007967728701; KING RD, 1992, P NATL ACAD SCI USA, V89, P11322, DOI 10.1073/pnas.89.23.11322; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; KING RD, 1995, NEW GEN COMPUT, V13; Kramer S, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P812; KRAMER S, 1998, P 8 INT WORKSH IND L, P80; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Lloyd J. W., 1984, FDN LOGIC PROGRAMMIN; Michalski R. S., 1983, MACHINE LEARNING ART, P83; MICHALSKI RS, 1986, P AAAI AUG, V2, P1041; MUGGLETON S, 1990, P 1 C ALG LEARN THE; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muggleton S., 1991, New Generation Computing, V8; MUGGLETON S, 1992, PROTEIN ENG, V5, P647, DOI 10.1093/protein/5.7.647; Muggleton S. H, 1987, IJCAI 87, P287; NORUSIS MJ, 1994, SPSS BASE SYSTEM USE; Quinlan J. R., 1979, Expert Systems in the Micro-Electronic Age. Proceedings of the 1979 AISB Summer School; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; RENDELL L, 1989, P 6 INT WORKSH MACH, P461; RENDELL L, 1985, IJCAI 85, P650; Shapiro A.D., 1987, STRUCTURED INDUCTION; SILIPO C, 1976, J MED CHEM, V19, P6849; SILVERSTEIN G, 1989, P 6 INT WORKSH MACH; Srinivasan A., 1994, P 4 INT WORKSH IND L, P217; Srinivasan A, 1996, ARTIF INTELL, V85, P277, DOI 10.1016/0004-3702(95)00122-0; SRINIVASAN A, 1996, P 6 INT WORKSH IND L, P89; SRINIVASAN A, 1998, IN PRESS J LOGIC PRO; VILLEMIN D, 1993, J CHIM PHYS PCB, V90, P1505; Walpole RE, 1978, PROBABILITY STAT ENG; Wold H., 1985, ENCY STATISTICAL SCI, V6, P581; WOLD S, 1978, TECHNOMETRICS, V20, P397, DOI 10.2307/1267639; ZELLE JM, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P817	50	30	30	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	1999	3	1					37	57		10.1023/A:1009815821645		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	192WR	WOS:000080103100003	
J	Blockeel, H; de Raedt, L; Jacobs, N; Demoen, B				Blockeel, H; de Raedt, L; Jacobs, N; Demoen, B			Scaling up inductive logic programming by learning from interpretations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						inductive logic programming; knowledge discovery in databases; first order decision trees; learning from interpretations	DISCOVERY	When comparing inductive logic programming (ILP) and attribute-value learning techniques, there is a trade-off between expressive power and efficiency. Inductive logic programming techniques are typically more expressive but also less efficient. Therefore, the data sets handled by current inductive logic programming systems are small according to general standards within the data mining community. The main source of inefficiency lies in the assumption that several examples may be related to each other, so they cannot be handled independently. Within the learning from interpretations framework for inductive logic programming this assumption is unnecessary, which allows to scale up existing ILP algorithms. In this paper we explain this learning setting in the context of relational databases. We relate the setting to propositional data mining and to the classical ILP setting, and show that learning from interpretations corresponds to learning from multiple relations and thus extends the expressiveness of propositional learning, while maintaining its efficiency to a large extent (which is not the case in the classical ILP setting). As a case study, we present two alternative implementations of the ILP system TILDE (Top-down Induction of Logical DEcision trees): TILDEclassic, which loads all data in main memory, and TILDELDS, which loads the examples one by one. We experimentally compare the implementations, showing TILDELDS can handle large data sets (in the order of 100,000 examples or 100 MB) and indeed scales up linearly in the number of examples.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium	Blockeel, H (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Heverlee, Belgium.						Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Blockeel H., 1997, LECT NOTES ARTIF INT, V1297, P77; Blockeel H, 1998, P 15 INT C MACH LEAR, P55; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; Bongard M.M., 1970, PATTERN RECOGNITION; BRATKO I, 1990, PROLOG PROGRAMMING A; BRATKO I, 1995, COMMUN ACM, V38, P65, DOI 10.1145/219717.219771; Breiman L, 1984, CLASSIFICATION REGRE; COHEN WW, NEW GEN COMPUTING, V13, P95; Cohen W. W., 1995, Journal of Artificial Intelligence Research, V2; CUSSENS J, 1997, LECT NOTES ARTIF INT, V1297, P93; Dehaspe L, 1997, LECT NOTES ARTIF INT, V1297, P125; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; DERAEDT L, 1998, IN PRESS LECT NOTES; DERAEDT L, 1996, FRONTIERS ARTIFICIAL, V32; DERAEDT L, 1998, LECT NOTES ARTIF INT, V446, P1; DERAEDT L, 1995, LECT NOTES ARTIF INT, V997, P80; DeRaedt L, 1997, ARTIF INTELL, V95, P187, DOI 10.1016/S0004-3702(97)00041-6; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Dougherty J, 1995, P 12 INT C MACH LEAR; Dzeroski S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130399; Elmasri R., 1989, FUNDAMENTALS DATABAS; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FURNKRANZ J, 1997, P 15 INT JOINT C ART, P852; FURNKRANZ J, 1997, P IJCAI 97 WORKSH FR; JACOBS N, 1998, P 8 INT C IND LOG PR, P145; KITANO H, 1997, P 15 INT JOINT C ART, P24; KRAMER S, 1996, P 13 NAT C ART INT A; LAVRAC N, 1997, LECT NOTES ARTIFICIA, V1297; Mehta M., 1996, P 5 INT C EXT DAT TE; Morik K, 1997, MACH LEARN, V27, P287, DOI 10.1023/A:1007317925872; MUGGLETON S, 1995, NEW GEN COMPUTING, V13; MUGGLETON S, 1997, LECT NOTES ARTIFICIA, V1314; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; MUGGLETON S, 1993, P 4 C ALG LEARN THEO; PAGE D, 1998, LECT NOTES ARTIFICIA, V1446; Plotkin G.D., 1970, MACH INTELL, V5, P153; QUINLAN J, 1993, LECT NOTES ARTIFICIA; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SEBAG M, 1998, LECT NOTES ARTIF INT, V1446, P95; Shafer J., 1996, P 22 INT C VER LARG; SRINIVASAN A, 1996, ARTIF INTELL, P85; VANLAER W, 1997, LECT NOTES ARTIF INT, V1325, P277; WATANABE L, 1991, P 12 INT JOINT C ART, P770; WROBEL S, 1996, P 2 INT C KNOWL DISC	48	40	42	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	1999	3	1					59	93		10.1023/A:1009867806624		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	192WR	WOS:000080103100004	
J	Srinivasan, A				Srinivasan, A			A study of two sampling methods for analyzing large datasets with ILP	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						sampling methods; windowing; ILP; scaling-up	MUTAGENICITY	This paper is concerned with problems that arise when submitting large quantities of data to analysis by an Inductive Logic Programming (ILP) system. Complexity arguments usually make it prohibitive to analyse such datasets in their entirety. We examine two schemes that allow an ILP system to construct theories by sampling from this large pool of data. The first, "subsampling", is a single-sample design in which the utility of a potential rule is evaluated on a randomly selected sub-sample of the data. The second, "logical windowing", is multiple-sample design that tests and sequentially includes errors made by a partially correct theory. Both schemes are derived from techniques developed to enable propositional learning methods (like decision trees) to cope with large datasets. The ILP system CProgol, equipped with each of these methods, is used to construct theories for two datasets - one artificial (a chess endgame) and the other naturally occurring (a language tagging problem). In each case, we ask the following questions of CProgol equipped with sampling: (1) Is its theory comparable in predictive accuracy to that obtained if all the data were used (that is, no sampling was employed)?; and (2) Is its theory constructed in less time than the one obtained with all the data? For the problems considered, the answers to these questions is "yes". This suggests that an ILP program equipped with an appropriate sampling method could begin to address problems satisfactorily that have hitherto been inaccessible simply due to data extent.	Univ Oxford, Comp Lab, Oxford OX1 3QD, England	Srinivasan, A (reprint author), Univ Oxford, Comp Lab, Oxford OX1 3QD, England.						BAIN M, 1991, P 8 INT WORKSH MACH, P380; BARNETT V, 1992, SAMPLE SURVEY PRINCI; BRATKO I, 1993, 3 INT WORKSH IND LOG, P279; Breiman L, 1984, CLASSIFICATION REGRE; CUSSENS J, 1997, IN PRESS P 7 IND LOG; DERAEDT L, 1992, MACH LEARN, V8, P107, DOI 10.1023/A:1022664419589; Dolsak B., 1992, INDUCTIVE LOGIC PROG, P453; DZEROSKI S, 1994, COMPUTER TECHNIQUES, V5, P129; EHRENFEUCHT A, 1988, COLT 88, P110; Feng C, 1992, ILP, P473; FURNKRANZ J, 1997, P 14 NAT C ART INT A, P509; FURNKRANZ J, 1997, OEFAITR9707 AUSTR RE; GRIES D, 1983, SCI PROGRAMMING; HAREL D, 1989, ALGORITHMICS; KING MC, 1992, NAT GENET, V2, P89, DOI 10.1038/ng1092-89; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; LEWIS DD, 1994, P 11 INT MACH LEARN; Lloyd J. W., 1984, FDN LOGIC PROGRAMMIN; Michalski R. S., 1983, MACH LEARN, V1, P83; MORONEY MJ, 1953, FACTS FIGURES; Muggleton S., 1990, P 1 C ALG LEARN THEO; Muggleton S, 1994, SIGART B, V5, P5; MUGGLETON S, 1996, P 6 IND LOG PROGR WO; MUGGLETON S, 1993, LNAI, P37; MUGGLETON S, 1996, LNAI; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muggleton S., 1991, New Generation Computing, V8; MUGGLETON S, 1992, PROTEIN ENG, V5, P647, DOI 10.1093/protein/5.7.647; Muggleton S.H., 1989, P 6 INT WORKSH MACH; Nilsson N., 1980, PRINCIPLES ARTIFICIA; PLOTKIN G, 1971, AUTOMATIC METHODS IN; Quinlan J. R., 1979, Expert Systems in the Micro-Electronic Age. Proceedings of the 1979 AISB Summer School; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; SEBAG M, 1997, P 15 INT C ART INT I; Srinivasan A, 1996, ARTIF INTELL, V85, P277, DOI 10.1016/0004-3702(95)00122-0; Wald A, 1947, SEQUENTIAL ANAL; Walpole RE, 1978, PROBABILITY STAT ENG; WIRTH J, 1988, P 5 INT C MACH LEARN, P87; WROBEL S, 1996, ADV INDUCTIVE LOGIC; ZELLE JM, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P817	40	20	20	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	1999	3	1					95	123		10.1023/A:1009824123462		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	192WR	WOS:000080103100005	
J	Kleinberg, J; Papadimitriou, C; Raghavan, P				Kleinberg, J; Papadimitriou, C; Raghavan, P			A microeconomic view of data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						market segmentation; optimization; clustering		We present a rigorous framework, based on optimization, for evaluating data mining operations such as associations and clustering, in terms of their utility in decision-making. This framework leads quickly to some interesting computational problems related to sensitivity analysis, segmentation and the theory of games.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA; IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Kleinberg, J (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Aumann Robert J, 1992, HDB GAME THEORY, V1; Avriel M., 1976, NONLINEAR PROGRAMMIN; Berry M. R. J., 1997, DATA MINING TECHNIQU; BRIN S, 1997, P ACM SIGMOD INT C M; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Dantzig G., 1963, LINEAR PROGRAMMING E; Derman C., 1970, FINITE STATE MARKOV; Gunopulos D., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263684; KLEINBERG J, 1998, P ACM S THEOR COMP; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; MASAND BM, 1996, P INT C KNOWL DISC D; Papadimitriou C.H., 1997, COMBINATORIAL OPTIMI; Piatetsky-Shapiro G., 1994, P AAAI 94 WORKSH KNO, P25; Silberschatz A., 1996, IEEE T KNOWLEDGE DAT, V8; SMYTH P, 1991, P INT C KNOWL DISC D, P159; Srikant R., 1995, P INT C VER LARG DAT; TOIVONEN H, 1996, P INT C VER LARG DAT	20	69	72	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1998	2	4					311	324		10.1023/A:1009726428407		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	182WA	WOS:000079520100001	
J	Boley, D				Boley, D			Principal direction divisive partitioning	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article							RETRIEVAL	We propose a new algorithm capable of partitioning a set of documents or other samples based on an embedding in a high dimensional Euclidean space (i.e., in which every document is a vector of real numbers). The method is unusual in that it is divisive, as opposed to agglomerative, and operates by repeatedly splitting clusters into smaller clusters. The documents are assembled into a matrix which is very sparse, it is this sparsity that permits the algorithm to be very efficient. The performance of the method is illustrated with a set of text documents obtained from the World Wide Web. Some possible extensions are proposed for further investigation.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Boley, D (reprint author), Univ Minnesota, Dept Comp Sci & Engn, 200 Union St SE,Rm 4-192, Minneapolis, MN 55455 USA.						Anderberg M.R., 1973, CLUSTER ANAL APPL; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; Bishop CM, 1998, IEEE T PATTERN ANAL, V20, P281, DOI 10.1109/34.667885; BOLEY D, 1998, IN PRESS AI REV; BOLEY D, 1998, EXPT PDDP SOFTWARE; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; Cutting D, 1992, 15 ANN INT ACM SIGIR, P318; Duda R., 1973, PATTERN CLASSIFICATI; FRAKES WR, 1992, INFORMATION RETRIEVA; Golub G.H., 1996, MATRIX COMPUTATIONS; HAN S, 1998, P ACM AUT AG 98 C MI, P408; HULL D, 1996, ACM SIGIR 9L, P279; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Lewis D. D., 1997, REUTERS 21578; LU SY, 1978, IEEE T SYST MAN CYB, V8, P381, DOI 10.1109/TSMC.1978.4309979; Moore J., 1997, 7 WORKSH INF TECHN S; Nadler M, 1993, PATTERN RECOGNITION; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Schutze H., 1997, ACM SIGIR 97, P74; Singhal A., 1996, ACM SIGIR C R D INF, P21; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; ZAMIR O, 1997, KDD 97; 1998, NO LIGHT	23	124	130	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1998	2	4					325	344		10.1023/A:1009740529316		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	182WA	WOS:000079520100002	
J	Murthy, SK				Murthy, SK			Automatic construction of decision trees from data: A multi-disciplinary survey	DATA MINING AND KNOWLEDGE DISCOVERY			English	Review						classification; tree-structured classifiers; data compaction	HIERARCHICAL CLASSIFIER DESIGN; MACHINE LEARNING ALGORITHMS; DIGITIZED POSS-II; PATTERN-RECOGNITION; FEATURE-SELECTION; NONPARAMETRIC CLASSIFICATION; REGRESSION TREES; NEURAL NETWORKS; DISCRIMINANT-ANALYSIS; THEORETIC APPROACH	Decision trees have proved to be valuable tools for the description, classification and generalization of data. Work on constructing decision trees from data exists in multiple disciplines such as statistics, pattern recognition, decision theory, signal processing, machine learning and artificial neural networks. Researchers in these disciplines, sometimes working on quite different problems, identified similar issues and heuristics for decision tree construction. This paper surveys existing work on decision tree construction, attempting to identify the important issues involved, directions the work has taken and the current state of the art.	Siemens Corp Res, Princeton, NJ 08540 USA	Murthy, SK (reprint author), Siemens Corp Res, Princeton, NJ 08540 USA.	murthy@scr.siemens.com					ACZEL J, 1975, MEASURES INFORMATION; AHA DW, AI STATS 95, P1; Aldrich C, 1997, CONTROL ENG PRACT, V5, P263, DOI 10.1016/S0967-0661(97)00235-9; ALI KM, 1995, ICSTR9538 U CAL; ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; ARGENTIERO P, 1982, IEEE T PATTERN ANAL, V4, P51; ATLAS L, 1990, P IEEE, V78, P1614, DOI 10.1109/5.58347; AYTUG H, 1994, IEEE T ENG MANAGE, V41, P165, DOI 10.1109/17.293383; BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278; BAJCSY R, 1993, IJCAI 93 P 13 INT JO, V2; BAKER E, 1976, P 3 INT JOINT C PATT, P45; BAKER FA, 1993, PLANT DIS, V77, P136; BELSON WA, 1959, APPLIED STATISTICS, V8, P65, DOI 10.2307/2985543; BENBASSAT M, 1978, IEEE T COMPUT, V27, P170; Bennet K.-P., 1992, P 4 MIDW ART INT COG, P97; BENNETT K, 1994, OPTIMIZATION METHODS, V3, P29; Bennett K.P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bennett Kristin P., 1994, P INT 94 26 S INT RE; Blum A., 1988, P 1988 WORKSH COMP L, P9; BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1007/BF00993345; BOWSERCHAO D, 1993, PHYS REV D, V47, P1900, DOI 10.1103/PhysRevD.47.1900; Boyce D. E., 1974, OPTIMAL SUBSET SELEC; BRANDMAN Y, 1990, IEEE T COMPUT, V39, P282, DOI 10.1109/12.45216; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L., 1994, BAGGING PREDICTORS; BRENT RP, 1991, IEEE T NEURAL NETWOR, V2, P346, DOI 10.1109/72.97911; BRESLOW LA, 1996, AIC96014 NAV CTR APP; BRODLEY CE, 1994, THESIS U MASSACHUSET; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; BROWN DE, 1993, P INT C SYST MAN CYB, V3, P475; BUCY RS, 1993, RAIRO-MATH MODEL NUM, V27, P515; BULUSWAR SD, 1994, P SOC PHOTO-OPT INS, V2353, P529, DOI 10.1117/12.188926; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; BUNTINE W, 1996, IEEE T KNOWLEDGE DAT; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; BUNTINE WL, 1991, THESIS U TECHNOLOGY; BUNTINE WL, 1989, UNCERTAINTY ARTIFICI, V3; CALLAHAN JD, 1991, J OPER RES SOC, V42, P227, DOI 10.1057/jors.1991.44; CASEY RG, 1984, IEEE T INFORM THEORY, V30, P93, DOI 10.1109/TIT.1984.1056834; Catlett J., 1991, THESIS U SYDNEY AUST; CHAI BB, 1996, P 13 INT C PATT REC; CHANDRAS.B, 1974, IEEE T COMPUT, VC 23, P102, DOI 10.1109/T-C.1974.223789; CHANDRASEKARAN B, 1986, PATTERN RECOGN, V2, P547; CHAUDHURI P, 1995, STAT SINICA, V5, P641; CHOU PA, 1988, THESIS STANFORD U; CHOU PA, 1986, P IEEE S INF THEOR A, P69; CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569; CIOS KJ, 1992, IEEE T NEURAL NETWOR, V3, P280, DOI 10.1109/72.125869; CLEOTE I, 1991, S AFRICAN COMPUTER J, V4, P10; COCKETT JRB, 1990, J ACM, V37, P815, DOI 10.1145/96559.96576; COHEN WW, 1994, MACH LEARNING; COMER D, 1977, J ACM, V24, P428, DOI 10.1145/322017.322023; COVER TM, 1977, IEEE T SYSTEMS MAN C, V7; Cox L. A.  Jr., 1989, Annals of Operations Research, V21, DOI 10.1007/BF02022091; CRAVEN MW, 1996, CSTR961326 U WISC; CRAWFORD SL, 1989, INT J MAN MACH STUD, V31, P197, DOI 10.1016/0020-7373(89)90027-8; CURRAM SP, 1994, J OPER RES SOC, V45, P440, DOI 10.1057/jors.1994.62; DAGO KT, 1994, NEUROPSYCHOBIOLOGY, V29, P91, DOI 10.1159/000119068; d'Alché-Buc F, 1994, Int J Neural Syst, V5, P259, DOI 10.1142/S012906579400027X; DAS SK, 1994, PROD PLAN CONTROL, V5, P342, DOI 10.1080/09537289408919505; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DATTATREYA GR, 1981, IEEE T PATTERN ANAL, V3, P293; DATTATREYA GR, 1985, PROGR PATTERN RECOGN, V2, P189; DIETTERICH TG, 1983, MACHINE LEARNING ART, V1, P41; DIETZ V, 1995, STUD PHYSIOL, V3, P51; DOAK J, 1994, EVALUATION SEARCH AL; DOWE DL, 1994, AI APPLICATIONS, V8, P71; DRAPER BA, 1994, IEEE T PATTERN ANAL, V16, P888, DOI 10.1109/34.310684; Draper N., 1981, APPL REGRESSION ANAL; Duda R. O., 1973, PATTEN CLASSIFICATIO; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; ERCIL A, 1993, WELD J, V72, P59; EVANS B, 1994, IEEE EXPERT, V9, P60, DOI 10.1109/64.295130; Everitt B. S., 1993, CLUSTER ANAL; FALCONER JA, 1994, ARCH PHYS MED REHAB, V75, P619, DOI 10.1016/0003-9993(94)90182-1; FAMILI A, 1994, AI EDAM, V8, P63; FANO RM, 1961, TRANSMISSION INFORMA; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; FAYYAD UM, 1990, AAAI 90 P NAT C ART, V2, P749; FEIGENBAUM EA, 1981, STATE ART MACH INTEL; FILE PE, 1994, COMPUT BIOMED RES, V27, P383, DOI 10.1006/cbmr.1994.1029; FISHER D, 1987, MACH LEARNING, V2, P130; FLETCHER R, 1963, COMPUT J, V6, P163; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FOROUTAN I, 1985, THESIS U CALIFORNIA; FOROUTAN I, 1987, IEEE T SYST MAN CYB, V17, P187, DOI 10.1109/TSMC.1987.4309029; FORSYTH RS, 1994, J EXP THEOR ARTIF IN, V6, P289, DOI 10.1080/09528139408953790; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; FUKANAGA K, 1989, IEEE T PATTERN ANAL, V11, P873; Furnkranz J, 1997, APPL ARTIF INTELL, V11, P91, DOI 10.1080/088395197118262; Garey M. R., 1974, Acta Informatica, V3; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; GELFAND SB, 1993, IEEE T INFORM THEORY, V39, P1907, DOI 10.1109/18.265499; GELSEMA ES, 1994, MACH INTELLIGENCE PA, V16; GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5; Gersho A., 1991, VECTOR QUANTIZATION; GIBB WJ, 1993, IEEE T BIO-MED ENG, V40, P727, DOI 10.1109/10.238457; GILLO MW, 1972, BEHAV SCI, V17, P251; GIPLIN EA, 1990, COMP BIOMEDICAL RES, V23, P46; GLESER MA, 1972, COMPUT BIOMED RES, V5, P180, DOI 10.1016/0010-4809(72)90080-8; GOLEA M, 1990, EUROPHYS LETT, V12, P205, DOI 10.1209/0295-5075/12/3/003; GOODMAN RM, 1988, IEEE T INFORM THEORY, V34, P979, DOI 10.1109/18.21221; Goodman R. M., 1990, Knowledge Acquisition, V2, DOI 10.1016/S1042-8143(05)80020-2; GOODRICH MT, 1995, TR951 J HOPK U DEP C; GORDON L, 1978, ANN STAT, V6, P515, DOI 10.1214/aos/1176344197; GRAY NAB, 1990, IEEE EXPERT, V5, P41, DOI 10.1109/64.54672; GREWE L, 1995, COMPUT VIS IMAGE UND, V61, P387, DOI 10.1006/cviu.1995.1030; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; GUO Y, 1995, INT J PROD RES, V33, P497, DOI 10.1080/00207549508930162; GURALI O, 1993, IEEE T KNOWL DATA EN, V5, P979, DOI 10.1109/69.250081; HAMPSON SE, 1986, BIOL CYBERN, V53, P203, DOI 10.1007/BF00336991; Hand D. J., 1981, DISCRIMINATION CLASS; Hanisch W., 1990, Journal of New Generation Computer Systems, V3; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hart A., 1984, RES DEV EXPERT SYSTE; HARTMANN CRP, 1982, IEEE T INFORM THEORY, V28, P565, DOI 10.1109/TIT.1982.1056522; HASKELL RE, 1989, COMPUTING 90S, P118; HATZIARGYRIOU ND, 1994, IEEE T POWER SYST, V9, P1052, DOI 10.1109/59.317626; HEATH D, 1992, THESIS J HOPKINS U B; Heath D., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); HELMBOLD DR, 1997, MACH LEARNING, P51; HENRICHO.EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; HERMAN GT, 1992, IEEE T PATTERN ANAL, V14, P782, DOI 10.1109/34.142914; HOEFFGEN KU, 1995, J COMPUTER SYSTEMS S, V50, P114; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Hunt K. J., 1993, Intelligent Systems Engineering, V2; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; IBARAKI T, 1968, 284 U ILL DEP COMP S; ICHINO M, 1984, IEEE T SYST MAN CYB, V14, P737; IIKURA Y, 1991, INT J REMOTE SENS, V12, P55; IMAM IF, 1993, LNCS, V689, P395; IRANI KB, 1993, IEEE EXPERT, V8, P41, DOI 10.1109/64.193054; Israel P., 1993, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V2, DOI 10.1142/S0218213093000199; ITTNER A, 1996, INT C MACH LEARNING; Jordan M. I., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.175372; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; JUDMAIER G, 1993, AM J GASTROENTEROL, V88, P706; KALKANIS G, 1993, PATTERN RECOGN LETT, V14, P355, DOI 10.1016/0167-8655(93)90112-Q; KANAL L, 1971, PATTERN RECOGN, V3, P225, DOI 10.1016/0031-3203(71)90013-6; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P193; KANAL LN, 1988, IEEE T INFORMATION T, V20, P697; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Kearns M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1337; Kearns M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237994; KENNEDY DM, 1993, PRODUCTS FINISHING, V57, P66; KENNEFICK JD, 1995, ASTRON J, V110, P78, DOI 10.1086/117498; KIM BY, 1991, IEEE T GEOSCI REMOTE, V29, P518, DOI 10.1109/36.135813; KIM H, 1994, EUR J OPER RES, V77, P82, DOI 10.1016/0377-2217(94)90030-2; KIM SH, 1994, COMMUN STAT THEORY, V23, P1227, DOI 10.1080/03610929408831315; KODRATOFF Y, 1994, APPL ARTIF INTELL, V8, P1, DOI 10.1080/08839519408945431; KODRATOFF Y, 1987, INT J MAN MACH STUD, V27, P181, DOI 10.1016/S0020-7373(87)80051-2; KOHAVI R, 1995, EUR C MACH LEARN; KOHAVI R, 1995, CSTR951560 STANF U; Kokol Peter, 1994, Journal of Medical Systems, V18, P201, DOI 10.1007/BF00996704; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; KORS JA, 1990, METHOD INFORM MED, V29, P330; KOVALEVSKY VA, 1968, CHARACTER READERS PA; Koza J. R., 1991, Parallel Problem Solving from Nature. 1st Workshop, PPSN 1 Proceedings; KRISHNAIAH PR, 1987, HDB STAT, V2; KRISHNAMOORTHY S, 1995, IEEE T SOFTWARE ENG, V21, P126; Kroger M, 1996, COMPUT PHYS COMMUN, V99, P81, DOI 10.1016/S0010-4655(96)00123-3; KUBAT M, 1994, BIOL CYBERN, V70, P443, DOI 10.1007/BF00203237; KULKARNI AV, 1978, IEEE T COMPUT, V27, P771; KURTZ SK, 1988, MATER LETT, V6, P317, DOI 10.1016/0167-577X(88)90114-0; KURZYNSKI MW, 1989, PATTERN RECOGN LETT, V10, P39, DOI 10.1016/0167-8655(89)90016-0; KURZYNSKI MW, 1988, PATTERN RECOGN, V21, P355, DOI 10.1016/0031-3203(88)90049-0; KURZYNSKI MW, 1983, PATTERN RECOGN, V16, P81, DOI 10.1016/0031-3203(83)90011-0; Kwok S. W., 1990, UNCERTAINTY ARTIFICI, V4, P327; Lagacherie P, 1997, INT J GEOGR INF SCI, V11, P183, DOI 10.1080/136588197242455; LANDEWEERD GH, 1983, PATTERN RECOGN, V16, P571, DOI 10.1016/0031-3203(83)90073-0; LANGLEY P, 1997, COMPUTATIONAL LEARNI, V4; LEE SW, 1992, P SOC PHOTO-OPT INS, V1661, P127, DOI 10.1117/12.130281; LEHNERT W, 1995, J EXP THEOR ARTIF IN, V7, P49, DOI 10.1080/09528139508953800; LEWIS PM, 1962, IRE T INFORM THEOR, V8, P171, DOI 10.1109/TIT.1962.1057691; LI XB, 1986, PATTERN RECOGN, V19, P229, DOI 10.1016/0031-3203(86)90013-0; LIN JH, 1994, INFORM PROCESS MANAG, V30, P851, DOI 10.1016/0306-4573(94)90012-4; LIN JH, 1992, INFORM PROCESS MANAG, V28, P723, DOI 10.1016/0306-4573(92)90064-7; Lin J.-H., 1992, DCC 92 DAT COMPR C L, P22; LIN WC, 1983, PATTERN RECOGN, V16, P1, DOI 10.1016/0031-3203(83)90002-X; LIU WZ, 1994, MACH LEARN, V15, P25, DOI 10.1007/BF01000407; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; LONG WJ, 1993, COMPUT BIOMED RES, V26, P74, DOI 10.1006/cbmr.1993.1005; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; LOVELAND DW, 1985, ACTA INFORM, V22, P101, DOI 10.1007/BF00290148; LUBINSKY D, 1994, APPL INTELL, V4, P283, DOI 10.1007/BF00872094; LUBINSKY DJ, 1994, THESIS RUTGERS U NEW; LUO RC, 1987, J ROBOTIC SYST, VC, P423; MAGERMAN DM, 1994, CSTR941502 STANF U; MANGASARIAN OL, 1990, SIAM WORKSH OPT; MANGASARIAN OL, 1994, UNPUB MISCLASSIFICAT; Mangasarian O. L., 1993, ORSA Journal on Computing, V5; Martin JK, 1997, MACH LEARN, V28, P257, DOI 10.1023/A:1007367629006; MARTIN JK, 1995, ICSTR9527 U CAL; MCKENZIE D, 1992, COMPUT HUM BEHAV, V8, P155, DOI 10.1016/0747-5632(92)90001-U; MCKENZIE DP, 1993, METHOD INFORM MED, V32, P161; MCQUEEN RJ, 1995, COMPUT ELECTRON AGR, V12, P275, DOI 10.1016/0168-1699(95)98601-9; MEGIDDO N, 1988, DISCRETE COMPUT GEOM, V3, P325, DOI 10.1007/BF02187916; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MELLISH C, 1995, IJCAI 95 P 14 INT JO; MEZRICH JJ, 1994, FINANCIAL ANAL J NOV, P75; MICHEIE S, 1994, MACH LEARNING NEURAL; MICHIE D, 1986, P ROY SOC LOND A MAT, V405, P185, DOI 10.1098/rspa.1986.0049; Miller AJ, 1990, SUBSET SELECTION REG; MINGERS J, 1987, J OPER RES SOC, V38, P39, DOI 10.2307/2582520; Mingers J., 1989, Machine Learning, V3, DOI 10.1007/BF00116837; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; Minsky M., 1969, PERCEPTRONS; MITCHELL T, 1994, COMMUNICATIONS A JUL; MIYAKAWA M, 1985, ACTA INFORM, V22, P475; MIYAZAKI N, 1989, INT J PRES VES PIP, V38, P1, DOI 10.1016/0308-0161(89)90127-0; MOGRE A, 1994, IEEE T SYST MAN CYB, V24, P470, DOI 10.1109/21.278995; Moret B. M. E., 1980, ACM Transactions on Programming Languages and Systems, V2, DOI 10.1145/357114.357120; MORET BME, 1982, COMPUT SURV, V14, P593; Morgan J.N., 1973, THAID SEQUENTIAL SEA; MUCCIARD.AN, 1971, IEEE T COMPUT, VC 20, P1023, DOI 10.1109/T-C.1971.223398; Muller W., 1994, Annals of Operations Research, V52, DOI 10.1007/BF02032305; Murphy M A, 1994, J Clin Neurosci, V1, P257, DOI 10.1016/0967-5868(94)90066-3; MURPHY OJ, 1991, IEEE T COMPUT, V40, P315, DOI 10.1109/12.76408; MURPHY PM, 1994, UCI REPOSITORY MACH; MURPHY PM, 1994, UNPUB MACH LEARNING; Murthy S, 1994, J ARTIFICIAL INTELLI, V2, P1; MURTHY SK, 1995, P 1 INT C KNOWL DISC; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; NAU DS, 1983, J ACM, V30, P687, DOI 10.1145/2157.322400; Naumov G. E., 1991, Soviet Physics - Doklady, V36; NIBLETT T, 1986, PROGR MACH LEARNING; NILSSON NJ, 1990, LEARNING MACH; Nilsson T, 1996, ARTIF INTELL MED, V8, P515, DOI 10.1016/S0933-3657(96)00350-8; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Oates T, 1997, P 14 INT C MACH LEAR, P254; OMUIRCHEARTAIGH CA, 1977, ANAL SURVEY DATA, V1; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PAGE CD, 1995, P C APPL DEC TECHN, V1, P325; Pal NR, 1997, INFORM SCIENCES, V96, P271, DOI 10.1016/S0020-0255(96)00162-4; PALVIA SC, 1992, COMMUN ACM, V35, P104, DOI 10.1145/135239.135246; PARK Y, 1989, J CLASSIF, V6, P195, DOI 10.1007/BF01908599; PARK Y, 1990, PATTERN RECOGN, V23, P1393, DOI 10.1016/0031-3203(90)90086-Z; PARK YT, 1994, PATTERN RECOGN, V27, P1493, DOI 10.1016/0031-3203(94)90127-9; PATTIPATI KR, 1990, IEEE T SYST MAN CYB, V20, P872, DOI 10.1109/21.105086; PAYNE RW, 1980, J ROY STAT SOC A STA, V143, P253, DOI 10.2307/2982129; Pearson R. A., 1990, International Journal of High Speed Computing, V2; PERNER P, 1996, LECT NOTES COMPUTER, V1121, P208; PIPITONE F, 1991, TESTING DIAGNOSIS AN; PIRAMUTHU S, 1994, IEEE T ENG MANAGE, V41, P172, DOI 10.1109/17.293384; BROWN DE, 1993, PATTERN RECOGN, V26, P953, DOI 10.1016/0031-3203(93)90060-A; PIZZI NJ, 1990, P SPIE INT SOC OPTIC, V1293, P671; Qing-Yun S., 1983, Pattern Recognition, V16, DOI 10.1016/0031-3203(83)90076-6; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; QUINLAN JR, 1993, COMPUTATIONAL LEARNI; QUINLAN JR, 1986, MACH LEARNING ARTIFI, V2; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; QUINLAN JR, 1990, MACH LEARNING ARTIFI, V3; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; QUINLAN JR, 1988, 5TH P INT C MACH LEA, P135; Renyi A., 1970, PROBABILITY THEORY; RIDDLE P, 1994, APPL ARTIF INTELL, V8, P125, DOI 10.1080/08839519408945435; RISANNEN J, 1989, STOCHASTIC COMPLEXIT; RISKIN EA, 1991, P IEEE ICASSP, V4, P2289; ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1; ROVNYAK S, 1994, IEEE T POWER SYST, V9, P1417, DOI 10.1109/59.336122; Rymon R., 1994, Telematics and Informatics, V11, DOI 10.1016/0736-5853(94)90022-1; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; SALZBERG S, 1995, PUBLICATIONS ASTRONO, V107, P1; Salzberg S, 1995, J Comput Biol, V2, P473, DOI 10.1089/cmb.1995.2.473; SANKAR A, 1993, IEEE T COMPUT, V42, P291; SAUL L, 1994, NEURAL COMPUT, V6, P1174, DOI 10.1162/neco.1994.6.6.1174; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SCHAFFER C, 1995, CONSERVATION GEN CAS; SCHLIMMER J, 1995, MACH LEARNING; SCHMIDL TM, 1993, 27 AS C SIGN SYST CO, V2, P1519; SCHUERMANN J, 1984, PATTERN RECOGN, V17, P359, DOI 10.1016/0031-3203(84)90087-6; SCHWARTZ S, 1993, AI FRONTIERS STAT, V3, P264; SETHI IK, 1977, PATTERN RECOGN, V9, P197, DOI 10.1016/0031-3203(77)90004-8; SETHI IK, 1990, P IEEE, V78; SETHI IK, 1982, IEEE T PATTERN ANAL, V4, P441; SETHI IK, 1994, PATTERN RECOGN, V27, P939, DOI 10.1016/0031-3203(94)90159-7; SHANG N, 1996, P INT C NEUR INF PRO, P133; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; Shimozono S., 1994, Transactions of the Information Processing Society of Japan, V35; SHLIEN S, 1992, PATTERN RECOGN LETT, V13, P83, DOI 10.1016/0167-8655(92)90037-Z; SHLIEN S, 1990, PATTERN RECOGN, V23, P757, DOI 10.1016/0031-3203(90)90098-6; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; Sirat JA, 1990, NETWORK-COMP NEURAL, V1, P423, DOI 10.1088/0954-898X/1/4/003; SKLANSKY J, 1980, IEEE T PATTERN ANAL, V2, P101; Sklansky J., 1981, PATTERN CLASSIFIERS; SMYTH P, 1995, P 12 INT C MACH LEAR, P506; Sonquist J, 1971, SEARCHING STRUCTURE; SRIDHARAN NS, 1989, IJCAI 89 P 11 INT JO; SUEN CY, 1984, PATTERN RECOGN, V17, P211, DOI 10.1016/0031-3203(84)90060-8; WANG QR, 1987, IEEE T PATTERN ANAL, V9, P91; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142; TALMON JL, 1992, INT J BIOMED COMPUT, V31, P45, DOI 10.1016/0020-7101(92)90053-U; TALMON JL, 1986, PATTERN RECOGN LETT, V4, P31, DOI 10.1016/0167-8655(86)90070-X; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; TAYLOR PC, 1993, STAT COMPUT, V3, P147, DOI 10.1007/BF00141771; Thrun S. B., 1991, CMUCS91197; TODESCHINI R, 1992, CHEMOMETR INTELL LAB, V16, P25, DOI 10.1016/0169-7439(92)80075-F; Tu P.-L., 1992, Proceedings. Fourth International Conference on Tools with Artificial Intelligence, TAI '92 (Cat. No. 92CH3203-7), DOI 10.1109/TAI.1992.246431; TURKSEN IB, 1993, IEEE T SYST MAN CYB, V23, P907, DOI 10.1109/21.256565; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Utgoff P. E., 1989, Connection Science, V1, DOI 10.1080/09540098908915648; Utgoff PE, 1997, MACH LEARN, V29, P5, DOI 10.1023/A:1007413323501; Utgoff P.E., 1990, P 7 INT C MACH LEARN, P58; UTGOFF PE, 1993, MACH LEARNING; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; Van Campenhout J. M., 1978, THESIS STANFORD U; VANCAMPENHOUT JM, 1987, HDB STAT, V2, P793; VANDEVELDE W, 1990, P 7 INT C MACH LEARN, P66; VARSHNEY PK, 1982, IEEE T COMPUT, V31, P164; WALLACE CS, 1968, COMPUT J, V11, P185; WALLACE CS, 1993, MACH LEARN, V11, P7, DOI 10.1023/A:1022646101185; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406; WANG ZG, 1993, ACTA AUTOMATICA SINI, V5, P267; WASSEL GN, 1972, IEEE T SYST MAN CYB, VSMC2, P533, DOI 10.1109/TSMC.1972.4309163; WATANABE L, 1991, IJCAI, V2, P770; WATANABE S, 1981, PATTERN RECOGN, V13, P381, DOI 10.1016/0031-3203(81)90094-7; WEIR N, 1995, ASTRON J, V110, P1, DOI 10.1086/117493; WEIR N, 1995, ASTRON J, V109, P2401, DOI 10.1086/117459; WHITE AP, 1994, MACH LEARN, V15, P321, DOI 10.1023/A:1022694010754; WILKS PAD, 1994, MED ENG PHYS, V16, P19, DOI 10.1016/1350-4533(94)90005-1; WIRTH J, 1988, 5TH P INT C MACH LEA, P87; Wolpert D. H., 1992, Complex Systems, V6; WOLPERT DH, 1992, 92035001 SFI TR; Woods K. S., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000698; YOU KC, 1976, P 3 S MACH PROC REM; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z; ZHOU XJ, 1991, IEEE T PATTERN ANAL, V13, P834, DOI 10.1109/34.85676; ZIMMERMAN S, 1959, AM MATH MONTHLY, V66, P690, DOI 10.2307/2309344; *EAD STAPL, 1981, J ALGORITHMS, V2, P369; *SOC AI STAT, 1993, AI STATS 93 4 INT WO; *SOC AI STAT, 1995, AI STATS 95 5 INT WO; 1993, AAAI 93 P 11 NAT C A; 1992, AAAI 92 P 10 NAT C A; 1994, AAAI 94 P 12 NAT C A	341	222	231	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1998	2	4					345	389		10.1023/A:1009744630224		45	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	182WA	WOS:000079520100003	
J	Hamuro, Y; Katoh, N; Matsuda, Y; Yada, K				Hamuro, Y; Katoh, N; Matsuda, Y; Yada, K			Mining pharmacy data helps to make profits	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; knowledge discovery; pharmacy; point of sales		Pharma, a drugstore chain in Japan, has been remarkably successful in the effective use of data mining. From over one tera bytes of sales data accumulated in databases, it has derived much interesting and useful knowledge that in turn has been applied to produce profits. Tn this paper, we shall explain several interesting cases of knowledge discovery at Pharma. We then discuss the innovative features of the data mining system developed in Pharma that led to meaningful knowledge discovery.	Osaka Ind Univ, Dept Business Adm, Osaka, Japan; Kyoto Univ, Grad Sch Engn, Sakyo Ku, Kyoto 606, Japan; G&G Pharma Inc, Osaka, Japan	Hamuro, Y (reprint author), Osaka Ind Univ, Dept Business Adm, 3-1-1 Nakagaito, Osaka, Japan.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Apte C., 1993, Proceedings. The Ninth Conference on Artificial Intelligence for Applications (Cat. No.93CH3254-0), DOI 10.1109/CAIA.1993.366608; CARTER C, 1987, IEEE EXPERT      FAL, P71; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; Hoschka P., 1991, Knowledge discovery in databases; Manago M., 1991, Knowledge discovery in databases; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; PIATESKYSHAPIRO G, 1991, KNOWLEDGE DISCOVERY; SCHMITZ J, 1990, DSS T I MAN SCI PROV; Uthurusamy R., 1991, Knowledge discovery in databases; YADA K, 1996, SEIRYODAI RONSHU, V28, P49	11	15	15	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1998	2	4					391	398		10.1023/A:1009748731133		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	182WA	WOS:000079520100004	
J	Lee, SD; Cheung, DW; Kao, B				Lee, SD; Cheung, DW; Kao, B			Is sampling useful in data mining? A case in the maintenance of discovered association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						sampling; data mining; knowledge discovery; association rules; update; maintenance; confidence interval		By nature, sampling is an appealing technique for data mining, because approximate solutions in most cases may already be of great satisfaction to the need of the users. We attempt to use sampling techniques to address the problem of maintaining discovered association rules. Some studies have been done on the problem of maintaining the discovered association rules when updates are made to the database. All proposed methods must examine not only the changed part but also the unchanged part in the original database, which is very large, and hence take much time. Worse yet, if the updates on the rules are performed frequently on the database but the underlying rule set has not changed much, then the effort could be mostly wasted. in this paper, we devise an algorithm which employs sampling techniques to estimate the difference between the association rules in a database before and after the database is updated. The estimated difference can be used to determine whether we should update the mined association rules or not. If the estimated difference is small, then the rules in the original database is still a good approximation to those in the updated database. Hence, we do not have to spend the resources to update the rules. We can accumulate more updates before actually updating the rules, thereby avoiding the overheads of updating the rules too frequently. Experimental results show that our algorithm is very efficient and highly accurate.	Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong	Lee, SD (reprint author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong.		Cheung, David/C-1825-2009; Kao, Chi Ming/C-1830-2009				Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; CHEUNG D, 1996, P 4 INT C PAR DISTR; CHEUNG D, 1996, P 12 INT C DAT ENG N; Cheung DW, 1997, P 5 INT C DAT SYST A, P185; Han J, 1995, P 21 INT C VER LARG, P420; HOLSHEIMER M, 1995, 1 INT C KNOWL DISC D, P150; KIVINEN J, 1994, P ACM SIGACT SIGMOD, V13, P77; Klemettinen M., 1994, 3 INT C INF KNOWL MA, P401; Mannila H., 1994, KNOWLEDGE DISCOVERY, P181; Mannila H., 1996, Cybernetics and Systems '96. Proceedings of the Thirteenth European Meeting on Cybernetics and Systems Research; PARK JS, 1995, P 1995 INT C INF KNO; Park J.S., 1995, P ACM SIGMOD INT C M; Srikant R., 1996, P ACM SIGMOD INT C M; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Trivedi KS, 1988, PROBABILITY STAT REL	16	23	23	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1998	2	3					233	262		10.1023/A:1009703019684		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	155ZE	WOS:000077976300002	
J	Wijsen, J; Meersman, R				Wijsen, J; Meersman, R			On the complexity of mining quantitative association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						quantitative association rules; computational complexity	DATABASES	The discovery of quantitative association rules in large databases is considered an interesting and important research problem. Recently, different aspects of the problem have been studied, and several algorithms have been presented in the literature, among others in (Srikant and Agrawal, 1996; Fukuda et al., 1996a; Fukuda et al., 1996b; Yoda et al., 1997; Miller and Yang, 1997). An aspect of the problem that has so far been ignored, is its computational complexity. In this paper, we study the computational complexity of mining quantitative association rules.	Free Univ Brussels, Dept Informat, B-1050 Brussels, Belgium	Wijsen, J (reprint author), Free Univ Brussels, Dept Informat, B-1050 Brussels, Belgium.						AGRAWAL A, 1994, P 20 INT C VER LARG, P487; Agrawal A, 1996, ADV KNOWLEDGE DISCOV, P307; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; CHEUNG D.W., 1996, IEEE INT C DAT ENG, P106; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163, DOI 10.1145/223784.223812; Fukuda T., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237708; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; Hu X H, 1996, INT C DAT ENG NEW OR, P96; KABANZA F, 1995, J COMPUT SYST SCI, V51, P3, DOI 10.1006/jcss.1995.1049; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Savasere A, 1995, P 21 INT C VER LARG, P432; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; WIJSEN J, 1997, 1997 ACM SIGMOD INT, P77; YEN SJ, 1996, J INTELL INF SYST, V7, P235, DOI 10.1007/BF00125369; Yoda K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	17	20	20	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1998	2	3					263	281		10.1023/A:1009755120593		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	155ZE	WOS:000077976300003	
J	Huang, ZX				Huang, ZX			Extensions to the k-means algorithm for clustering large data sets with categorical values	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; cluster analysis; clustering algorithms; categorical data		The k-means algorithm is well known for its efficiency in clustering large data sets. However, working only on numeric values prohibits it from being used to cluster real world data containing categorical values. In this paper we present two algorithms which extend the k-means algorithm to categorical domains and domains with mixed numeric and categorical values. The k-modes algorithm uses a simple matching dissimilarity measure to deal with categorical objects, replaces the means of clusters with modes, and uses a frequency-based method to update modes in the clustering process to minimise the clustering cost function. With these extensions the k-modes algorithm enables the clustering of categorical data in a fashion similar to k-means. The k-prototypes algorithm, through the definition of a combined dissimilarity measure, further integrates the k-means and k-modes algorithms to allow for clustering objects described by mixed numeric and categorical attributes. We use the well known soybean disease and credit approval data sets to demonstrate the clustering performance of the two algorithms. Our experiments on two real world data sets with half a million objects each show that the two algorithms are efficient when clustering large data sets, which is critical to data mining applications.	CSIRO, ACsys CRC, Canberra, ACT 2601, Australia	Huang, ZX (reprint author), CSIRO, ACsys CRC, GPO Box 664, Canberra, ACT 2601, Australia.						Anderberg M.R., 1973, CLUSTER ANAL APPL; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bezdek J., 1981, PATTERN RECOGNITION; BOBROWSKI L, 1991, IEEE T SYST MAN CYB, V21, P545, DOI 10.1109/21.97475; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; DUBES R, 1979, PATTERN RECOGN, V11, P235, DOI 10.1016/0031-3203(79)90034-7; DUBES RC, 1987, PATTERN RECOGN, V20, P645, DOI 10.1016/0031-3203(87)90034-3; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Everitt B., 1974, CLUSTER ANAL; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; Huang Z., 1997, P SIGMOD WORKSH RES, P1; Huang Z., 1997, P 1 PAC AS KNOWL DIS, P21; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kaufman L., 1990, FINDING GROUPS DATA; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, p573{592; KODRATOFF Y, 1988, IEEE T PATTERN ANAL, V10, P697; Lebowitz M., 1987, Machine Learning, V2, DOI 10.1007/BF00114264; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; MICHALSKI RS, 1983, IEEE T PATTERN ANAL, V5, P396; MILLIGAN GW, 1981, PSYCHOMETRIKA, V46, P187, DOI 10.1007/BF02293899; MILLIGAN GW, 1980, PATTERN RECOGN, V12, P41, DOI 10.1016/0031-3203(80)90001-1; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P123, DOI 10.1007/BF02294153; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Ng R, 1994, P 20 INT C VER LARG, P144; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RALAMBONDRAINY H, 1995, PATTERN RECOGN LETT, V16, P1147, DOI 10.1016/0167-8655(95)00075-R; RUSPINI EH, 1973, INFORM SCIENCES, V6, P273, DOI 10.1016/0020-0255(73)90043-1; Ruspini E. R., 1969, INFORM CONTR, V15, P22; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; WILLIAMS GJ, 1996, P PAC RIM KNOWL ACQ, P117; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324; *IBM, 1996, DAT MAN SOL	34	325	392	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1998	2	3					283	304		10.1023/A:1009769707641		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	155ZE	WOS:000077976300004	
J	Ng, R; Han, JW; Lakshmanan, L				Ng, R; Han, JW; Lakshmanan, L			Special issue on SIGMOD-97 Data Mining Workshop	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material																	0	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1998	2	3					231	232		10.1023/A:1009746502846		2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	155ZE	WOS:000077976300001	
J	Fayad, U				Fayad, U			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Microsoft Res, Redmond, WA 98052 USA	Fayad, U (reprint author), Microsoft Res, Redmond, WA 98052 USA.							0	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1998	2	2					115	119				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	123NZ	WOS:000076132400001	
J	Burges, CJC				Burges, CJC			A tutorial on Support Vector Machines for pattern recognition	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Support Vector Machines; statistical learning theory; VC dimension; pattern recognition	NETWORKS	The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.	Lucent Technol, Bell Labs, Murray Hill, NJ 07974 USA	Burges, CJC (reprint author), Lucent Technol, Bell Labs, Murray Hill, NJ 07974 USA.	burges@lucent.com					Aizerman M., 1964, AUTOMAT REM CONTR, V25, P821; ANTHONY M, 1995, HDB BRAIN THEORY NEU, P694; Bennett K.P., 1998, GEOMETRY WORK; Bishop CM, 1995, NEURAL NETWORKS PATT; BLANZ V, 1996, SPRINGER LECT NOTES, V1112, P251; BOSER B, 1992, 5 ANN WORKSH COMP LE; BUNCH JR, 1977, MATH COMPUT, V31, P163, DOI 10.2307/2005787; BUNCH JR, 1980, LINEAR ALGEBRA APPL, V34, P341, DOI 10.1016/0024-3795(80)90172-X; BURGES C, 1998, IN PRESS ADV KERNEL; Burges C. J. C., 1996, P 13 INT C MACH LEAR, P71; Burges CJC, 1997, ADV NEUR IN, V9, P375; BURGES CJC, 1996, SUPPORT VECTOR WEB P; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COURANT R, 1953, METHODS MATH PHYSICS; Devroye L., 1996, APPL MATH; Drucker H, 1997, ADV NEUR IN, V9, P155; Fletcher R, 1987, PRACTICAL METHODS OP; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GIROSI F, 1998, 1606 CBCL AI MIT; GUYON I, 1992, ADV NEUR IN, V4, P471; Halmos P.R., 1967, HILBERT SPACE PROBLE; Horn R. A., 1985, MATRIX ANAL; Joachims T., 1997, 23 U DORTM; KAUFMAN L, 1998, IN PRESS ADV KERNEL; Kolmogorov AN, 1970, INTRO REAL ANAL; MANGARASIAN OL, 1969, NONLINEAR PROGRAMMIN; MCCORMICK GP, 1983, NON LINEAR PROGRAMMI; Montgomery D.C., 1992, INTRO LINEAR REGRESS; More J. J., 1991, SIAM J OPTIMIZ, V1, P93; Mukherjee S., 1997, P IEEE WORKSH NEUR N, V7, P511; Muller K., 1997, P INT C ART NEUR NET, P999; OSUNA E, 1997, IEEE C COMP VIS PATT, P130; OSUNA E, 1998, UNPUB INT C PATT REC; OSUNA E, 1997, P IEEE WORKSH NEUR N, P276; Press WH, 1992, NUMERICAL RECIPES C; SCHMIDT M, 1996, INTERFACE 96 P SYDN; Scholkopf B., 1997, SUPPORT VECTOR LEARN; SCHOLKOPF B, 1998, IN PRESS 9 AUSTR C N; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; SCHOLKOPF B, 1996, SPRINGER LECT NOTES, V1112, P47; SCHOLKOPF B, 1998, IN PRESS NEURAL COMP; SCHOLKOPF B, 1998, IN PRESS ADV NEURAL, V10; Scholkopf B., 1995, P 1 INT C KNOWL DISC; Shawe-Taylor J., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238070; SHAWETAYLOR J, 1996, NCTR96053 NEUROCOLT; SMOLA A, 1998, IN PRESS 9 AUSTR C N; SMOLA AJ, 1998, IN PRESS NEURAL NETW; SMOLA AJ, 1998, IN PRESS ALGORITHMIC; STITSON MO, 1997, CSDTR9722 ROYAL HOLL; Strang G., 1986, INTRO APPL MATH; VANDERBEI RJ, 1994, PROGRAM STAT OPERATI; Vanderbei R. J., 1994, ORSA Journal on Computing, V6; VANPNIK V, STAT LEARNING THEORY; Vapnik V, 1997, ADV NEUR IN, V9, P281; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V.N., 1995, NATURE STAT LEARNING; WAHBA G, 1998, IN PRESS ADV KERNEL; Weston J., 1997, CSDTR9723 ROYAL HOLL; *MOR WRIGHT, 1993, OPT GUID	59	3510	3875	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1998	2	2					121	167		10.1023/A:1009715923555		47	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	123NZ	WOS:000076132400002	
J	Sander, J; Ester, M; Kriegel, HP; Xu, XW				Sander, J; Ester, M; Kriegel, HP; Xu, XW			Density-based clustering in spatial databases: The algorithm GDBSCAN and its applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clustering algorithms; spatial databases; efficiency; applications	SKY	The clustering algorithm DBSCAN relies on a density-based notion of clusters and is designed to discover clusters of arbitrary shape as well as to distinguish noise. In this paper, we generalize this algorithm in two important directions. The generalized algorithm-called GDBSCAN-can cluster point objects as well as spatially extended objects according to both, their spatial and their nonspatial attributes. In addition, four applications using 2D points (astronomy), 3D points (biology), 5D points (earth science) and 2D polygons (geography) are presented, demonstrating the applicability of GDBSCAN to real-world problems.	Univ Munich, Inst Comp Sci, D-80538 Munich, Germany	Sander, J (reprint author), Univ Munich, Inst Comp Sci, Oettingenstr 67, D-80538 Munich, Germany.	sander@informatik.uni-muenchen.de; ester@informatik.uni-muenchen.de; krigel@informatik.uni-muenchen.de; xwxu@informatik.uni-muenchen.de	Xu, Xiaowei/A-7884-2012				BECKER RH, 1995, ASTROPHYS J, V450, P559, DOI 10.1086/176166; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; BRINKHOFF T, 1994, P ACM SIGMOD INT C M, P197, DOI 10.1145/191839.191880; CONNOLLY ML, 1986, J MOL GRAPHICS, V4, P3; Ester M., 1995, P 1 INT C KNOWL DISC, P94; Ester M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Ester M, 1996, P 2 INT C KNOWL DISC, P226; GUETING RH, 1994, VLDB J, V3, P357, DOI 10.1007/BF01231602; HATTORI K, 1993, PATTERN RECOGN, V26, P741, DOI 10.1016/0031-3203(93)90127-I; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kaufman L., 1990, FINDING GROUPS DATA; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; MURTAGH F, 1983, COMPUT J, V26, P354; Ng R, 1994, P 20 INT C VER LARG, P144; Niemann H., 1990, PATTERN ANAL UNDERST; REID IN, 1991, PUBL ASTRON SOC PAC, V103, P661, DOI 10.1086/132866; RICHARDS AJ, 1983, REMOTE SENSING DIGIT; SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; Stonebraker M, 1993, P ACM SIGMOD INT C M, P2, DOI 10.1145/170035.170038; VINOD HD, 1969, J AM STAT ASSOC, V64, P506, DOI 10.2307/2283635; WEIR N, 1995, ASTRON J, V109, P2401, DOI 10.1086/117459; ZEPKA AF, 1994, ASTROPHYS J, P427; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328; *PROT DAT BANK, 1994, 70 BROOKH NAT LAB	27	201	232	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1998	2	2					169	194		10.1023/A:1009745219419		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	123NZ	WOS:000076132400003	
J	Meo, R; Psaila, G; Ceri, S				Meo, R; Psaila, G; Ceri, S			An extension to SQL for mining association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association rules; data mining and relational databases		Data mining evolved as a collection of applicative problems and efficient solution algorithms relative to rather peculiar problems, all focused on the discovery of relevant information hidden in databases of huge dimensions. In particular, one of the most investigated topics is the discovery of association rules. This work proposes a unifying model that enables a uniform description of the problem of discovering association rules. The model provides a SQL-like operator, named MINE RULE, which is capable of expressing all the problems presented so far in the literature concerning the mining of association rules. We demonstrate the expressive power of the new operator by means of several examples, some of which are classical, while some others are fully original and correspond to novel and unusual applications. We also present the operational semantics of the operator by means of an extended relational algebra.	Politecn Torino, Dipartimento Automat & Informat, I-10129 Turin, Italy; Politecn Milan, Dip Elettron & Informaz, I-20133 Milan, Italy	Meo, R (reprint author), Politecn Torino, Dipartimento Automat & Informat, Cso Duca degli Abruzzi 24, I-10129 Turin, Italy.	rosimeo@polito.it; psaila@elet.polimi.it; ceri@elet.polimi.it	Meo, Rosa/E-9345-2012				AGRAWAL R, 1995, KNOWLEDGE DISCOVERY, V2; Agrawal R, 1995, INT C DAT ENG TAIP T; Agrawal R., 1992, 18 INT C VER LARG DA, P560; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 1995, P 21 VLDB C ZUR SWIT; Agrawal R., 1994, P 20 VLDB C SANT CHI; AGRAWAL R, 1993, 4 INT C FDN DAT ORG; Atzeni P., 1993, RELATIONAL DATABASE; FALOUTSOS C, 1994, P ACM SIGMOD C MAN D; GRAY J, 1996, ICDE96 12 INT C DAT, P560; HAN J, 1995, P 21 VLDB C ZUR SWIT; HOUTSMA MAW, 1995, 11 INT C DAT ENG TAI; HOUTSMA MAW, 1996, IN PRESS DATA KNOWLE; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; MEO R, 1998, P IEEE INT C DAT ENG; Park J.S., 1995, P ACM SIGMOD INT C M; Srikant R, 1995, 9963 RJ IBM ALM RES; Srikant R., 1995, P 21 VLDB C ZUR SWIT; ULLMAN JD, 1988, PRINCIPLES COMPUTER, V1	20	62	62	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1998	2	2					195	224		10.1023/A:1009774406717		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	123NZ	WOS:000076132400004	
B	Weigend, AS		Ebecken, NFF		Weigend, AS			Learning from data: Building, evaluating and understanding models	DATA MINING			English	Meeting Abstract	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State					NYU, Stern Sch Business, New York, NY USA								0	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							3	4				2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800001	
B	Freitas, AA		Ebecken, NFF		Freitas, AA			A multi-criterial approach for the evaluation of rule interestingness	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				This paper studies several criteria for evaluating rule interestingness. It first reviews some rule interestingness principles with respect to the widely-used criteria of coverage, completeness and confidence factor of a rule. It then considers several additional factors (or criteria) influencing rule interestingness that have been somewhat neglected in the literature on rule interestingness. As a result, this paper argues that rule interestingness measures should be extended to take into account the additional rule-quality factors of disjunct size, imbalance of the class distribution, attribute interestingness, misclassification costs and the asymmetry of classification rules. The paper also presents a case study on how a popular rule interestingness measure can be extended to take into account the proposed additional rule-quality factors.	DAINF, CEFET, PR, BR-80230901 Curitiba, Parana, Brazil	Freitas, AA (reprint author), DAINF, CEFET, PR, Av Sete Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.		Freitas, Alex/H-1249-2011				Breiman L, 1984, CLASSIFICATION REGRE; Danyluk A. P., 1993, P 10 INT C MACH LEAR, P81; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Gebhardt F., 1991, Knowledge Acquisition, V3, DOI 10.1016/S1042-8143(05)80025-1; Glymour C, 1997, DATA MIN KNOWL DISC, V1, P11, DOI 10.1023/A:1009773905005; HOLTE RC, P INT JOINT C AI IJC, P813; Kamber M., 1996, P 2 INT C KNOWL DISC, P263; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Liu B., 1997, P 3 INT C KNOWL DISC, P31; MAJOR JA, J INTELLIGENT INFORM, V4, P39; MAJOR JA, P AAAI 93 WORKSH KNO, P28; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; QUINLAN JR, 1991, MACH LEARN, V6, P93, DOI 10.1007/BF00153762; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; ROBERTS H, 1995, P INT DAT AN C IDA 9; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; Taylor C.C., 1994, MACHINE LEARNING NEU; Ting K., 1994, P 10 CAN C ART INT, P91; TURNEY PD, J ARTIFICIAL INTELLI, V2, P369	22	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							7	20				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800002	
B	Pereira, CMNA; Schirru, R; Martinez, AS		Ebecken, NFF		Pereira, CMNA; Schirru, R; Martinez, AS			Learning an optimized classification system from a data base of time series patterns using genetic algorithms	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			DIAGNOSTICS	This work presents a novel methodology for pattern recognition that uses genetic learning to get an optimized classification system. Each class is represented by several time series in a data base. The idea is to find dusters in the set of the training patterns of each class so that their centroids can distinguish the classes with a minimum of misclassifications. Due to the high level of difficulty found in this optimization problem and the poor prior knowledge about the patterns domain, a model based on genetic algorithm is proposed to extract this knowledge, searching for the minimum number of subclasses that leads to a maximum correctness in the classification. The goal of this model is to find how many and which are the clusters to consider. To validate the methodology, reference problems, where the best solution is well-known, are proposed. Extending the scope of the application, the methodology is applied to a real problem, in which it is required to distinguish three nuclear accidents that may occur in a nuclear power plant. The misclassification rate was 5% in a total of 180 trials. To ratify the results an artificial neural network was designed and trained to solve the same problem. The results and comparisons are shown and commented.	Univ Fed Rio de Janeiro, COPPE, Programa Engn Nucl, BR-68509 Rio De Janeiro, Brazil	Pereira, CMNA (reprint author), Univ Fed Rio de Janeiro, COPPE, Programa Engn Nucl, Caixa Postal 68509, BR-68509 Rio De Janeiro, Brazil.						Alvarenga MAB, 1997, NUCL TECHNOL, V120, P188; BARTAL Y, 1995, NUCL TECHNOL, V110, P436; BARTLETT EB, 1992, NUCL TECHNOL, V97, P272; Darwin C, 1859, ORIGIN SPECIES MEANS; Davis L., 1991, HDB GENETIC ALGORITH; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Gray P., 1997, SURVEY GLOBAL OPTIMI; GREFENSTETTE J. J., 1990, USERS GUIDE GENESIS; HOLLAND JH, 1975, ADAPTATION NATURAL A; KIM YS, 1994, FUZZY SET SYST, V65, P297, DOI 10.1016/0165-0114(94)90026-4; Kosko B., 1992, NEURAL NETWORKS FUZZ; RENDERS JM, 1992, 14851 EUR EN JOINT R; STEVEN K, 1991, INTRO BIOL ARTIFICIA	13	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							21	34				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800003	
B	Chen, F; Figlewski, S; Weigend, AS		Ebecken, NFF		Chen, F; Figlewski, S; Weigend, AS			Modeling financial data using clustering and tree-based approaches	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				This paper compares tree-based approaches to clustering. We model a set of 3-million transactional T-bond futures data using these two techniques and compare their predictive performance on trade profit. We illustrate their respective strengths and weaknesses.	NYU, Leonard N Stern Sch Business, New York, NY 10012 USA	Chen, F (reprint author), NYU, Leonard N Stern Sch Business, 44 W 4th St, New York, NY 10012 USA.						BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Breiman L, 1984, CLASSIFICATION REGRE; CHEESEMAN P, 1995, KNOWLEDGE DISCOVERY, V2, P153; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1	4	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							35	51				17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800004	
B	Meneses, CJ; Grinstein, GG		Ebecken, NFF		Meneses, CJ; Grinstein, GG			Categorization and evaluation of data mining techniques	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				A fundamental issue in the application of data mining algorithms to solve problems of real life is to know ahead of the time the usability of the algorithm for the class of problems being considered. In other words, we would like to know, before starting the KDD process for a particular problem P, with its features belonging to a type C-j of problems or tasks, how well a specific data mining algorithm A(i) would perform in solving P. In this paper, we survey the main approaches to categorize and evaluate data mining techniques. This will help to clarify the relationship that can exist between a particular data mining algorithm and the type of tasks or problems for which it is best suited. Perhaps the most important conclusion we show is that no single technique provides the best performance for all types of tasks, and that a multi-strategy approach is needed to deal with real complex problems. Categorizing data mining techniques will guide the user, prior the start of the KDD process or during the data mining phase, in the selection of the best subset of techniques to resolve a problem or data mining task.	Univ Massachusetts, Inst Visualizat & Percept Res, Dept Comp Sci, Lowell, MA 01854 USA	Meneses, CJ (reprint author), Univ Massachusetts, Inst Visualizat & Percept Res, Dept Comp Sci, 1 Univ Ave, Lowell, MA 01854 USA.						Adriaans P, 1996, DATA MINING; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; ANDERSEN P, 1993, MANAGE SCI, V39, P1261, DOI 10.1287/mnsc.39.10.1261; ANKERST M, 1996, IEEE VIS 96 C, P4; BESHERS C, 1990, COMPUTER GRAPHICS, V24, P37; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Cleveland W. S., 1993, VISUALIZING DATA; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FAYYAD UM, 1997, 3 INT C KNOWL DISC D; GOLDBERG DE, 1994, COMMUN ACM, V37, P113, DOI 10.1145/175247.175259; Han J., 1996, ADV KNOWLEDGE DISCOV, P399; Heckerman D., 1996, ADV KNOWLEDGE DISCOV, P273; Hertz J, 1991, INTRO THEORY NEURAL; Hoffman P., 1997, Proceedings. Visualization '97 (Cat. No.97CB36155), DOI 10.1109/VISUAL.1997.663916; INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402; Keim D. A., 1995, Proceedings. Visualization '95 (Cat. No.95CB35835), DOI 10.1109/VISUAL.1995.485140; KIVINEN J, 1993, LEARNING RULES LOCAL; LEBLANC J, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P230, DOI 10.1109/VISUAL.1990.146386; LENAT DB, 1983, ARTIF INTELL, V21, P61, DOI 10.1016/S0004-3702(83)80005-8; MENESES C, 1998, CATEGORIZATION EVALU; Minsky M., 1975, PSYCHOL COMPUTER VIS, P211; Mitchell T. M, 1997, MACHINE LEARNING; Moustakis V, 1996, INT J HUM-COMPUT INT, V8, P221; PIATETSKYSHAPIR.G, 1998, SIFTW TOOLS DAT MIN; Pickett R. M., 1988, Proceedings of the 1988 IEEE International Conference on Systems, Man, and Cybernetics (IEEE Cat. No.88CH2556-9); Quinlan J. R., 1987, P 10 INT JOINT C ART, P304; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1991, P 12 INT JOINT C ART, P746; REKIMOTO J, 1993, P 3 ANN WORKSH INF T, P125; Ringland GA, 1988, APPROACHES KNOWLEDGE; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; Robertson G., 1991, P ACM C HUM FACT COM, P189, DOI 10.1145/108844.108883; Russell S., 1995, ARTIFICIAL INTELLIGE; Nakhaeizadeh G., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Schneiderman B., 1992, ACM Transactions on Graphics, V11; Taylor C.C., 1994, MACHINE LEARNING NEU; Ward M. O., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), DOI 10.1109/VISUAL.1994.346302; Weiss S. M., 1998, PREDICTIVE DATA MINI; [Anonymous], 1993, C4 5 PROGRAMS MACHIN	43	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							53	80				28	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800005	
B	Rezende, SO; Oliveira, RBT; Felix, LCM; Rocha, CAJ		Ebecken, NFF		Rezende, SO; Oliveira, RBT; Felix, LCM; Rocha, CAJ			Visualization for knowledge discovery in database	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				The ever larger interest of the companies in accompanying new processing technologies and storage of data, as well as using the information as a large patrimony, has motivated several researches for the study of the process of transformation of this data into knowledge, which provides an intelligent aid to decision-making, In this context, the process of Knowledge Discovery in Databases (KDD) arises as a technology which can help with the knowledge search in the data. This search can be accomplished with the aid of visualization techniques, which can facilitate the understanding, on the part of human Analysts, of the knowledge extracted from data. This can be accomplished by identifying structures, characteristics, tendencies, anomalies and relationships among the data. These techniques frequently offer mechanisms that facilitate the search of patterns/models from data bases.	Univ Sao Paulo, Inst Math & Comp Sci, Dept Comp Sci & Stat, BR-13560970 Sao Carlos, SP, Brazil	Rezende, SO (reprint author), Univ Sao Paulo, Inst Math & Comp Sci, Dept Comp Sci & Stat, Av Dr Carlos Botelho 1465,CP 668, BR-13560970 Sao Carlos, SP, Brazil.						Clark P., 1991, P 5 EUR WORK SESS LE, P151; DECKER KM, 1995, TECHNOLOGY OVERVIEW; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Fayyad UM, 1996, IEEE EXPERT, V11, P20; FELIX LCM, 1998, 72 ICMCUSP; Inmon WH, 1996, COMMUN ACM, V39, P49, DOI 10.1145/240455.240470; KERBER R, 1995, INTELLIGENT HYBRID S, P121; KOHAVI R, 1996, DATA MINING USING ML; LI B, 1996, DATA MINING NOW; MANNILA H, 1997, DATA MINING MACHINE; OLIVEIRA RBT, 1998, 71 ICMCUSP; Pressman Roger S., 1994, SOFTWARE ENG PRACTIT; Quilan J. R., 1993, C4 5 PROGRAMS MACHIN	13	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							81	95				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800006	
B	Garcia, ACB; Lopes, AA		Ebecken, NFF		Garcia, ACB; Lopes, AA			ADDKnowledge - A tool of semiautomatic acquisition of knowledge for the construction of specialist systems	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Knowledge-based systems have successfully been used to assist users to accomplish tasks in various domains from credit evaluation to aircraft design. The strength of these systems lays on the quality of the acquired and modeled domain knowledge. Knowledge acquisition has been the bottleneck of knowledge based system's development. Many studies have focused on methodological, ontological and automation issues related to knowledge acquisition. However, they present a myopic view of the problem looking at the knowledge base creation separately from the system's interface conception. This paper presents a knowledge acquisition model, ADDKnowledge, that integrates knowledge base and system's interface constructions. Our model focused on engineering design task using a parametric dependency network to represent domain(both engineering and interface domains) knowledge and a rational decision making procedure to represent the inference mechanism. In addition to presenting a model, a prototype system illustrates the feasibility of the model. The ADDKNOWLEDGE project is in its early stages. We have spent a great deal of effort building a tool to assist users to develop their knowledge base integrating three major skills: textual explanation, case examples and case experimentation. Our current effort is on maturing our knowledge acquisition model and on including interface construction assistance.	Univ Fed Fluminense, Dept Ciencia Computacao, Niteroi, RJ, Brazil	Garcia, ACB (reprint author), Univ Fed Fluminense, Dept Ciencia Computacao, Praca Valonguinho S-N, Niteroi, RJ, Brazil.						BOOSE J, 1987, INT J MAN MACHINE ST, V26; BRANCHMAN JR, 1985, READINGS KNOWLEDGE R; Carroll J. M., 1985, HUMAN COMPUTER INTER, V1, P283, DOI 10.1207/s15327051hci0103_3; DEELUCAS D, 1988, MEMORY COGNITION, P16469; ESHELMAN L, 1986, P 5 NAT C ART INT PH; GARCIA ACB, 1992, THESIS; Gruber T. R., 1992, ONTOLINGUA MECH SUPP; KAHN G, 1987, INTELLIGENT MIXED IN; KIM O, 1992, LARGE SCALE MULTIPLE; Kolodner J. L., 1993, CASE BASED REASONING; Marcus S., 1988, AUTOMATING KNOWLEDGE; NEWELL A, 1980, PHYSICAL SYMBOL SYST; QUILLIAN MR, 1968, SEMANTIC INFORMATION; SCHMALHOFER F, 1988, 10 ANN C COGN SCI SO, P724; Wielinga B. J., 1992, Knowledge Acquisition, V4, DOI 10.1016/1042-8143(92)90013-Q	15	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							97	110				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800007	
B	Arguello, JR		Ebecken, NFF		Arguello, JR			The determination measure	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			DECISION	In this paper, a new criteria to select roots for decision tree induction is presented, analized and compared with entropy based mechanisms. The new criteria is linked to confidence and support for rule evaluation and its properties are evaluated. Algorithms for tree extraction in large databases are used and results using the new criteria for more than 100K cases are shown. The criteria shows useful for dealing with real databases where the irrelevant attributes and number of values per attribute is previously unknown.	Univ Costa Rica, Dept Comp & Informat Sci, San Jose, Costa Rica	Arguello, JR (reprint author), Univ Costa Rica, Dept Comp & Informat Sci, San Jose, Costa Rica.						ARGUELLO J, 1996, THESIS U FLORIDA; ARGUELLO J, 1996, SIGMOD WORKSH RES IS, P1; ARGUELLO J, 1997, REV INGENIERIA, V6, P9; ARGUELLO JR, 1986, THESIS U DENVER; BENEDICT P, 1990, DATA GEN PROGRAM 2 V; GOODMAN RM, 1990, KNOWLEDGE ACQUISITIO, V1, P1; GOODMAN RM, 1988, IEEE T INFORM THEORY, V34, P979, DOI 10.1109/18.21221; HAMMING R, 1980, CODING INFORMATION T, P101; Michalski R. S., 1983, MACHINE LEARNING ART, V1; Quinlan J., 1983, MACHINE LEARNING ART, V1, P463; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHANNON CE, 1949, MATH THEORY COMMUNIC, P7; SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926	15	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							111	142				32	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800008	
B	Costa, JFP		Ebecken, NFF		Costa, JFP			Mining binary attributes	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			PROTEINS	In this work, we consider the case where we have categorical attributes with a huge number of values in a prediction context. In particular, the methodology introduced here concerns the use of these attributes in binary decision trees; nevertheless, it is applicable to other prediction methods. The main idea consists in extracting ("mining") the most predictive binary attributes, from the set of initial attributes ("mine"). In order to do this, we consider three different operations: hierarchical clustering, multiplication, and factorization. The first operation, hierarchical clustering, serves for reducing the number of values of a categorical attribute. In fact, by applying the hierarchical clustering method AVL [6, 7] to the set of values of a categorical attribute, we can group these values into clusters. Then, we can define a new categorical attribute whose values correspond to these clusters. By doing so, we get a new synthetic attribute with a much smaller number of values. The second operation, multiplication, consists in transforming ("multiplying") a set of categorical attributes v(1), v(2),..., v(p) into a single categorical attribute v. If L-i is the number of values of v(i) then, the number of values of v is L(1)xL(2)x...xL(p),. The interest of this operation is that v contains more information than the p attributes taken separately. The third operation, factorization, is the inverse of the "multiplication" operation. It consists in splitting a categorical attribute v with L values into, for instance, a pair of simpler attributes, (v(1), v(2)). The interest of this operation is that the attributes v(1) and v(2) have each a much smaller number of values (about root L). Our method, ARCADE, can be applied in situations where one has a large number of categorical attributes or categorical attributes with a large number of values. For instance, we have applied it to the protein secondary structure prediction problem. The descriptive attributes used by us were categorical with a huge number of values (160000 (sick).	Univ Porto, Dept Matemat Aplicada, P-4150 Porto, Portugal	Costa, JFP (reprint author), Univ Porto, Dept Matemat Aplicada, Rua Campo Alegre 823, P-4150 Porto, Portugal.		Da Costa, Joaquim/B-6720-2011	Da Costa, Joaquim/0000-0002-3991-2715			ALMUALLIM H, 1995, P INT C MACH LEARN I; Breiman L, 1984, CLASSIFICATION REGRE; COLLOCH N, 1993, PROTEIN ENG, V6, P377, DOI 10.1093/protein/6.4.377; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; DACOSTA JFP, 1996, THESIS U RENNES 1 FR; LERMAN IC, 1983, NATO ASI SERIES, V1, P179; LERMAN IC, 1997, 3312 INRIA; LERMAN IC, 1991, SYMBOLIC-NUMERIC DATA ANALYSIS AND LEARNING, P27; LERMAN IC, 1993, BIOCHIMIE, V75, P379, DOI 10.1016/0300-9084(93)90172-O; LERMAN IC, 1997, 1138 IRISA; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; ROST B, 1993, J MOL BIOL; SOLOVYEV VV, 1994, COMPUT APPL BIOSCI, V10, P661; ZHANG X, 1992, J MOL BIOL, V225, P1049, DOI 10.1016/0022-2836(92)90104-R	15	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							143	157				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800009	
B	Baranauskas, JA; Monard, MC		Ebecken, NFF		Baranauskas, JA; Monard, MC			Experimental feature selection using the wrapper approach	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			MACHINE LEARNING LIBRARY; MLC++; C++	Machine learning methods provide algorithms for mining databases in order to help analyze the information, find patterns, and improve prediction accuracy. In practice, the user of a data mining tool is interested in accuracy, efficiency, and comprehensibility for a specific domain which may be reached through feature selection. In this work we use the wrapper approach for Feature Subset Selection. The FSS algorithm from MLC++ library was used to run experiments with datasets containing many features. Accuracies for five inducers using all features, features found by FSS as well as the union of all those selected features are presented. Results confirm the superiority of FSS wrapper approach but in some cases the computational cost is excessive.	Univ Sao Paulo, Inst Math & Comp Sci, Dept Comp Sci & Stat, BR-05508 Sao Paulo, Brazil	Baranauskas, JA (reprint author), Univ Sao Paulo, Inst Math & Comp Sci, Dept Comp Sci & Stat, BR-05508 Sao Paulo, Brazil.		Baranauskas, Jose Augusto/B-3573-2011; Monard, Maria/F-4835-2011				Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; DIETTERICH TG, 1997, MACHINE LEARNING RES; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Fayyad UM, 1996, AI MAG, V17, P51; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; KOHAVI R, 1996, TOOLS ARTIFICIAL INT, P234; KOHAVI R, 1995, P 1 INT C KNOWL DISC; Merz C.J., 1998, UCI REPOSITORY MACHI	8	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							161	170				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800010	
B	Gottgtroy, MPB; Rodrigues, MJN; de Sousa, MTG		Ebecken, NFF		Gottgtroy, MPB; Rodrigues, MJN; de Sousa, MTG			Data mining agents	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				From when the study of Machine Learning began and up to the present time, almost all the paradigms have been based on the idea of learning by repetition. In this case, one of the great problem faced is to have databases with good quality data, and principally, with a sufficient amount of data to base the work of learning algorithms upon. Today, the amount of data is not the problem anymore; in contrast, many organizations now have a wide range and quantity of information stored in large databases. They are so large and without consistent modeling that gives support to that dimensionality, the first stage of the Machine Learning process is now a specific step. This step is the "search" into the databases, of relationships between the data and concepts stored to guide the whole process, and it is now discussed and used throughout the world and known as data-mining. Despite the problems inherited by the learning algorithms used and the existing databases, the necessity of storing and treating the unstructured information and sharing information - by distributed processing or accessing the global network - have brought new problems to be addressed, principally in the areas of Data Bases and Artificial Intelligence, to make possible the execution of data-mining task. The Multi-Agent System view, like a development paradigm of new generation computational systems, emerges as a promising technology to solve many of these problems.	Univ Fed Rio Grande Norte, Dept Informat & Matemat Aplicada, Lab Logica & Inteligencia Computac, BR-59072970 Natal, RN, Brazil	Gottgtroy, MPB (reprint author), Univ Fed Rio Grande Norte, Dept Informat & Matemat Aplicada, Lab Logica & Inteligencia Computac, BR-59072970 Natal, RN, Brazil.						Berndt D. J., 1996, FINDING PATTERNS TIM; Bigus J. P., 1996, DATA MINING NEURAL N; BOY G, SOFTWARE AGENTS COOP; BRADSHAW JM, SOFTWARE AGENTS; BUNTINE W, 1996, ADV KNOWLEDGE DISCOV; CHEESEMAN, 1996, ADV KNOWLEDGE DISCOV; Dennet D., 1987, INT STANCE; DUPUY JP, 1995, NAS BASES CIENCIAS C; EBERHART R, COMPUTATIONAL INTELL; ELDER JF, 1996, ADV KNOWLEDGE DISCOV; Faltings B., 1992, RECENT ADV QUALITATI; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; GAINES, 1996, TRANSFORMING RULES T; GOTTGTROY MPB, 1998, SISTEMAS MULTIAGENTS; GOTTGTROY MPB, 1998, P 3 IFAC CIGR WORKSH; HERMANS B, INTELLIGENT SOFTWARE; Holsheimer M., 1994, DATA MINING SEARCH K; HOLSHEIMER M, 1996, DATA SURVEYOR SEARCH; Kasabov N.K., 1996, FDN NEURAL NETWORKS; Langley P, 1996, ELEMENTS MACHINE LEA; MULLER J, AUTONOMOUS AGENTS 98; MULLER J, AUTONOMOUS AGENTS 97; MULLER JP, 1997, DESIGN INTELLIGENT A; NEWELL A, 1976, COMPUTER SCI EMPIRIC; Russell S., 1995, ARTIFICIAL INTELLIGE; *AP PROFF, 1996, PC TOOLS	26	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							171	182				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800011	
B	Wang, XR; Rong, G		Ebecken, NFF		Wang, XR; Rong, G			A compound test with high confidence level for gross error detection	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			MAXIMUM-POWER; CONSTRAINTS	Measured process data are inherently inaccurate and violate process constraints because of their underlying stochastic properties and possible gross errors caused by process disturbances, malfunctioning or miscalibrated instrumentation and even process leaks, etc. Therefore, the theory of gross error detection (GED) and data reconciliation has been developed to solve the contradictions between the measurements and their constraints. A number of gross error detection techniques are widely applied in different chemical processes. However, their performances have not always been so satisfactory: if the probability of type I error is low then that of type II error is always quite high. Here a compound test with high confidence level (HCL test) is presented in this paper, which has a low percentage of both two types of errors. Moreover, a practical example based on real process data is provided and a comparison with other tests proves that the new method is quite effective.	Zhejiang Univ, Inst Ind Control Technol, State Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China	Wang, XR (reprint author), Zhejiang Univ, Inst Ind Control Technol, State Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China.						CROWE CM, 1989, AICHE J, V35, P869, DOI 10.1002/aic.690350521; CROWE CM, 1992, CAN J CHEM ENG, V70, P1030; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888; KIM IW, 1996, 96 KOR CHIN JOINT WO, P39; PERSON K, 1901, PHILOS MAGAZINE, V6, P559; TONG HW, 1995, AICHE J, V41; WANG XR, 1997, THESIS ZHEIJIANG U; TRACY ND, 1992, J QUAL TECHNOL, V24, P88	9	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							183	191				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800012	
B	von der Luhe, M		Ebecken, NFF		von der Luhe, M			How to get more donors: Unicef database marketing and data mining for non-commercial organizations	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Data base supported target group communication is no longer used by commercial enterprises only - today non-commercial organizations look for innovative approaches regarding the implementation of new methods. And a data warehouse is not necessarily required for creating direct marketing activities that are based on client information - Unicef is a good example. This article gives an overview of a data mining application used to improve target group segmentation within a social organisation.	Ogilvy & Mather Dataconsult, D-60599 Frankfurt, Germany	von der Luhe, M (reprint author), Ogilvy & Mather Dataconsult, Geleitstr 14, D-60599 Frankfurt, Germany.							0	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							205	210				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800014	
B	Shen, L; Shen, H; Pritchard, P; Topor, R		Ebecken, NFF		Shen, L; Shen, H; Pritchard, P; Topor, R			Finding the N largest itemsets	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				The largest itemset in a given collection of transactions D is the itemset that occurs most frequently in D. This paper studies the problem of finding the N largest itemsets, whose solution can be used to generate an appropriate number of interesting itemsets for mining association rules. We present an efficient algorithm for finding the N largest itemsets. The algorithm is implemented and compared with the naive solution using the Apriori approach. We present experimental results as well as theoretical analysis showing that our algorithm has a much better performance than the naive solution. We also analyze the cost of our algorithm and observe that it has a polynomial time complexity in most cases of practical applications.	Griffith Univ, Sch Comp & Informat Technol, Nathan, Qld 4111, Australia	Shen, L (reprint author), Griffith Univ, Sch Comp & Informat Technol, Nathan, Qld 4111, Australia.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; CHEN MS, 1996 IEEE P 16 ICDCS; Cormen T.H., 1989, INTRO ALGORITHMS; HAN J, 1995, P 21 VLDB INT C ZUR; Mannila H., 1994, AAAI WORKSH KNOWL DI, P181; MANNILA H, 1997, C19978 U HELS DEP CO; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Savasere A, 1995, P 21 INT C VER LARG, P432; SRIKANT R, 1996, P 5 EDBT INT C AV FR; Srikant R., 1996, P ACM SIGMOD INT C M; Srikant R., 1995, P 21 INT C VER LARG, P407	12	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							211	222				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800015	
B	Branco, ACS; Camargo, H; Evsukoff, A; de Aragon, DF; Pereira, LF		Ebecken, NFF		Branco, ACS; Camargo, H; Evsukoff, A; de Aragon, DF; Pereira, LF			A knowledge acquisition method for fuzzy expert systems - An improvement via mountain-clustering	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				This work presents a knowledge acquisition method for fuzzy systems applied to pattern recognition problems. An improvement to an earlier version of this method (Evsukoff[3]) is proposed through the use of a clustering technique to generate the fuzzy partitions of the input space. An adaptation of the Mountain-Clustering method (Yager[12]) was applied and two different approaches of clustering for generate the input fuzzy partitions have been developed. These clustering approaches were used with the supervised learning algorithm and were tested upon some classification problems found in the literature.	ILTC, Intituto Logica Filosofia & Teoria Ciencia, BR-24030080 Niteroi, RJ, Brazil	Branco, ACS (reprint author), ILTC, Intituto Logica Filosofia & Teoria Ciencia, Rua Almirante Teffe 637, BR-24030080 Niteroi, RJ, Brazil.						BLEKAS K, P 9 IEEE INT C TOOLS; BRANCO ACS, 1994, 2 WORLD C EXP SYST L; EVSUKOFF A, 1998, EUR WORKSH FUZZ DEC; EVSUKOFF A, 1997, 6 IEEE INT C FUZZ SY; Ishibuchi H., 1996, Proceedings of the Fifth IEEE International Conference on Fuzzy Systems. FUZZ-IEEE '96 (Cat. No.96CH35998), DOI 10.1109/FUZZY.1996.551810; Jang J.S.R., 1995, P IEEE, V83; JOSHI A, 1997, IEEE T NEURAL NETWOR, V8; NAUCK D, 1996, P EUFIT 96; Prechelt L., 1994, 2194 U KARLSR; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Ripley B., 1996, PATTERN RECOGNITION; Yager R., 1994, ESSENTIALS FUZZY MOD; Zimmermann HJ, 1996, FUZZY SET THEORY ITS	13	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							223	233				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800016	
B	Marsala, C; Bigolin, NM		Ebecken, NFF		Marsala, C; Bigolin, NM			Spatial data mining with fuzzy decision trees	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			ASSOCIATION RULES; DATABASES; DISCOVERY	In this paper, an approach is presented to search for useful patterns and discover hidden information in Spatial Object-Oriented Databases (SOODB). Although many approaches of knowledge discovery for relational spatial databases exist, there is a growing interest in mining SOODB. Indeed, object-oriented databases are well-suited to represent complex spatial information. Moreover, a very large number of existing spatial databases are ready to be mined. We propose an algorithm to mine a SOODB. After a spatial object query and a mathematical and fuzzy preprocessing, we apply decision tree based techniques and fuzzy set theory to discover knowledge. An experiment on a region of France to discover classification rules related to houses and urban area is conducted with this algorithm to validate the interest of the approach.	Univ Paris 06, LIP6, F-75252 Paris 05, France	Marsala, C (reprint author), Univ Paris 06, LIP6, 4 Pl Jussieu, F-75252 Paris 05, France.	Christophe.Marsala@lip6.fr; Nara.Martini-Bigolin@lip6.fr					ADIBA M, 1993, OBJETS BASES DONNEES; AGRAWAL R, 1995, P 21 INT C VER LARG, P487; Agrawal R., 1994, P 20 INT C VER LARG, P487; BANCILHON F, 1992, BUILDING OBJECT ORIE; BOUCHONMEUNIER B, 1997, FUZZY INFORMATION EN, P139; ESTER M, 1997, P 5 S SPAT DAT BERL; Fayyad U, 1996, AI MAG, V17, P37; FOTHERINGHAM A, 1993, SPATIAL ANAL GIS APP; HAN J, 1994, KNOWLEDGE BUILDING K, P221; HAN JW, 1992, PROC INT CONF VERY L, P547; HAN J, 1997, P 1997 ACM SIGMOD IN; Kamber M., 1997, Proceedings. Seventh International Workshop on Research Issues in Data Engineering. High Performance Database Management for Large-Scale Applications (Cat. No.97TB100122), DOI 10.1109/RIDE.1997.583715; Koperski K, 1995, LECT NOTES COMPUT SC, V951, P47; KOPERSKI K, 1998, IN PRESS COMMUNICATI; MARSALA C, 1998, 014 LIP6; MARSALA C, 1996, P 5 IEEE INT C FUZZ, V2, P1512, DOI 10.1109/FUZZY.1996.552399; MEHTA M, 1996, LECT NOTES COMPUTER, V1057; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; Thompson D., 1992, FUNDAMENTALS SPATIAL; XU X, 1998, 14 INT C DAT ENG; YOON S, 1996, WORKSH RES ISSUES DA; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	22	2	4	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							235	248				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800017	
B	Santos, MS; Ludermir, TB; Santos, FL; de Melo, CP; Gomes, JE		Ebecken, NFF		Santos, MS; Ludermir, TB; Santos, FL; de Melo, CP; Gomes, JE			Artificial nose and data analysis using multi layer perceptron	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			CONDUCTING POLYMER TECHNOLOGY	An Artificial Nose is being made to detect the smell of some substances and the results of prototype phase 0 and phase 1 are displayed. In phase 0 and phase 1 we utilize conducting polymer sensors. A pattern recognition technique based on Multi Layer Perception (MLP) model of Artificial neural network (ANN) is adopted. In this gaper we present a study that was done with the recognition of the whisky, wine, ethanol, carbon thetracloride and methanol. The NeuroSoluction software is used in this study.	Univ Fed Pernambuco, Dept Informat Phys & Chem, Recife, PE, Brazil	Santos, MS (reprint author), Univ Fed Pernambuco, Dept Informat Phys & Chem, Recife, PE, Brazil.		Ludermir, Teresa/F-6766-2012	Ludermir, Teresa/0000-0002-8980-6742			BARTLETT PN, 1990, SENSORS ACTUATORS, P3911; DEMELO CP, 1998, INT C SYNTH MET ICMS; FUNAZAKI N, 1995, SENSOR ACTUAT B-CHEM, V24, P797; Gardner JW, 1995, SENSOR ACTUAT A-PHYS, V51, P57, DOI 10.1016/0924-4247(96)80053-7; GARDNER JW, 1994, SENSOR ACTUAT B-CHEM, V18, P211; HOLGATE SA, 1998, NEW SCI         0131; KELLER PE, 1995, MED MEETS VIRTUAL RE, V3; KELLER PE, 1994, IEEE EL 94 INT C BOS; KLUGER J, 1998, TIME             MAR, P23; SANTOS MS, 1997, 3 C BRAS RED NEUR SA; SANTOS MS, 1997, 4 S BRAS RED NEUR GO; TALAIE A, 1996, SYNTHETIC METALS, P8321; Talaie A, 1996, SYNTHETIC MET, V82, P231, DOI 10.1016/S0379-6779(96)03797-6; Van der Pauw L.J., 1961, Philips Research Reports, V16	14	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							251	263				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800018	
B	Siegler, W; Steurer, E		Ebecken, NFF		Siegler, W; Steurer, E			Forecasting of the German stock index DAX with neural networks: Using daily data for experiments with input variable reduction and a modified error function	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Using neural networks for the prediction of economic time series still involves many problems. Examples for using neural networks in financial market applications are de Groot (1993), Baun (1997) and Burgess (1996). In these studies neural networks were successfully applied. Intensive work has been done regarding data transformation and the selection of an appropriate topology for neural networks. By using daily data of the German stock index DAX this study shows that: 1) Principal Component Analysis is not an appropriate technique for input variable reduction. 2) The Usage of a modified mean squared error as error function leads to significantly better results.	HYPO BANK AG, Res Dept, D-80278 Munich, Germany	Siegler, W (reprint author), HYPO BANK AG, Res Dept, D-80278 Munich, Germany.						BATES JM, 1969, OPER RES QUART, V20, P451, DOI 10.2307/3008764; BAUN S, 1997, VERTEILUNGSPROGNOSE; BURGESS AN, 1996, P UN SEM INT SYST FI; CLEMEN RT, 1989, INT J FORECASTING, V5, P559, DOI 10.1016/0169-2070(89)90012-5; DEDEGROOT C, 1993, 10038 ETH; DICKINSO.JP, 1973, OPER RES QUART, V24, P253, DOI 10.2307/3007853; DIEBOLD FX, 1988, J BUS ECON STAT, V6, P105, DOI 10.2307/1391423; REFENES AN, 1992, NEURAL NETWORK APPL; THOMASON MR, 1996, NEUROVEST J, V4, P30; THOMASON MR, 1996, NEUROVEST J, V4, P29; UTANS J, 1997, P 4 INT C NEUR NETW; *SNNS, 1995, STUTTG NEUR NETW SIM	12	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							265	273				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800019	
B	Lopes, TAP; de Andrade, OP; Vianna, AL		Ebecken, NFF		Lopes, TAP; de Andrade, OP; Vianna, AL			Neural networks on the dynamic models updating	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				The correlation.: between theoretical and experimental models, which takes into account the eigenfrequencies and eigenmodes obtaneid from an eigenvalue problem and experimental modal analysis, permits to match the theorectical and experimental results. Updating aims to modify the structural theoretical model matrices, such as mass and stiffness, to reproduce closely as possible the measured response from the data. A new methodology for updating, based on neural networks, is proposed. The neural network will represent the inverse of the parameters sensitivity matrix. The input data for the neural network (changes on natural frequencies and modes) will correspond to the pertubation of measured parameters and the output neurons will represent changes on discrete masses or physical boundary conditions, associated to the pertubation paramenter. A spatial frame is used for evaluation of the neural network approach.	Univ Fed Rio de Janeiro, COPPE, BR-21945970 Rio De Janeiro, Brazil	Lopes, TAP (reprint author), Univ Fed Rio de Janeiro, COPPE, Caixa Postal 68508, BR-21945970 Rio De Janeiro, Brazil.						DASCOTTE E, 1990, 8 INT MOD AN C, P1032; HEMEZ FM, 1993, THESIS U COLORADO US; JANTER T, 1989, P 14 INT SEM MOD AN; Kosko B., 1990, NEURAL NETWORKS FUZZ; LOPES TAP, 1995, THESIS COPPE UFRJ; MOTTERSHEAD JE, 1993, J SOUND VIB, V167, P347, DOI 10.1006/jsvi.1993.1340; Natke HG, 1988, PROBALISTIC ENG MECH, V3, P28, DOI 10.1016/0266-8920(88)90005-7; *ANS, 1992, ANSYS US MAN, V1; *ANS, 1992, ANSYS US MAN, V3; *ANS, 1992, ANSYS US MAN, V2; *ANS, 1992, ANSYS US MAN, V4	11	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							275	287				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800020	
B	Hruschka, ER; Ebecken, NFF		Ebecken, NFF		Hruschka, ER; Ebecken, NFF			Rule extraction from neural networks in data mining applications	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			KNOWLEDGE	This work deals with the efficient discovery of valuable and nonobvious information from large collections of data, using Computacional Intelligence tools. For this purpose, a study about knowledge acquirement from supervised neural networks employed for classification problems is presented. An algorithm for rule extraction from neural networks, based on the work by Lu et al. [1] in 1996, is developed. This algorithm, named Modified RX, is experimentally evaluated in three different domains. The results are compared to those obtained by classification trees. In respect of the efficacy, one observes that the successful application of the algorithm mainly depends on the knowledge representation acquired by the conecctionist model, while the eficciency only depends on the neural network training time.	R Nossa Senhora Aparecida, Dept Comp Sci, Positivo Fac, BR-80440000 Curitiba, Parana, Brazil	Hruschka, ER (reprint author), R Nossa Senhora Aparecida, Dept Comp Sci, Positivo Fac, Senhora Aparecida 174, BR-80440000 Curitiba, Parana, Brazil.		Hruschka, Eduardo/E-6593-2011				BARON R, 1994, 9417 EC NORM SUP LY; CRAVEN MW, 1997, IN PRESS FUTURE GENE; CRAVEN MW, 1996, ADV NEURAL INFORMATI, V8; CRAVEN MW, 1994, MACH LEARN P 11 INT; Fu L, 1994, NEURAL NETWORKS COMP; FU LM, 1994, IEEE T SYST MAN CYB, V24, P1114; FU LM, 1993, IEEE T SYST MAN CYB, V23, P173, DOI 10.1109/21.214775; GAINES BR, 1996, ADV KNOWLEDGE DISCOV, P205; GALLANT SI, 1988, COMMUN ACM, V31, P152, DOI 10.1145/42372.42377; HARP SA, 1996, HDB GENETIC ALGORITH, P202; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HENERY RJ, 1994, E HORWOOD SERIES ART; KANE R, 1994, FINANCIAL FORECASTIN, P3190; MICHIE D, 1994, MACHINE LEARNING NEU, P157; Narazaki H, 1996, IEEE T SYST MAN CY B, V26, P107, DOI 10.1109/3477.484442; NARAZAKI H, 1995, METHOD EXTRACTING AP; OLIVEIRA JP, 1997, 3 C BRAS RED NEUR FL, P173; Lu HJ, 1996, IEEE T KNOWL DATA EN, V8, P957; Smith M, 1996, NEURAL NETWORKS STAT; THRUN S, 1993, IAI935 U BONN; TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1007/BF00993103; Yildiz N, 1997, NEURAL COMPUT APPL, V5, P14, DOI 10.1007/BF01414099; *IBM, 1996, IBM INT MIN AIX US G; *NEUR INC TECHN PU, 1995, NEUR PRED; ATTAR SOFTWARE XPERT	25	2	2	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							289	301				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800021	
B	Ludermir, TB; Braga, AP; Nobre, CN; Carvalho, APL		Ebecken, NFF		Ludermir, TB; Braga, AP; Nobre, CN; Carvalho, APL			Extracting rules from neural networks: A data mining approach	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				This paper discusses how rule extraction from Artificial Neural Networks (ANNs) can help in the design of expert systems and in the application of RNAs as a data mining technique. Examples of methods of rule extraction from RNAs are given in the paper.	Univ Fed Pernambuco, Dept Informat, BR-50732970 Recife, PE, Brazil	Ludermir, TB (reprint author), Univ Fed Pernambuco, Dept Informat, Cx Postal 7851, BR-50732970 Recife, PE, Brazil.		Ludermir, Teresa/F-6766-2012; Braga, Antonio/A-2912-2008	Ludermir, Teresa/0000-0002-8980-6742; Braga, Antonio/0000-0002-9007-0920			ANDREWS R, 1995, P 5 AUSTR C NEUR NET; BLASIG R, 1994, ADV NEURAL INFORMATI, V6; Breiman L, 1984, CLASSIFICATION REGRE; Craven M.W., 1993, P 10 INT C MACH LEAR, P73; CRAVEN MW, 1994, P 11 INT C MACH LEAR, P152; CRAVEN MW, 1996, THESIS; FU LM, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P590; GALLAGHER RB, 1988, EUR RESPIR J, V1, P153; Goonatilake S, 1995, INTELLIGENT HYBRID S; KERBER R, 1991, P 1991 AAAI WORKSH K; MCMILLAN C, 1992, ADV NEURAL INFORMATI, V4; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SETIONO R, 1995, P 14 INT JOINT C ART; Thrun S. B., 1991, CMUCS91197; Towell G., 1993, MACH LEARN, P71	15	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							303	314				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800022	
B	Zhu, TS; Gao, W		Ebecken, NFF		Zhu, TS; Gao, W			Using data mining to learn the patterns of pitch variation in Chinese speech	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Pitch model is very important in speech synthesis, and it mainly describes the variation of pitch. In order to synthesize speech with high intelligibility and naturalness, a system should be with an appropriate Ditch model. We try to find the pitch model from actual speech samples by data mining. A prototype system called SpeechDM has been implemented to extract patterns from two-word phrase of Chinese. Dataset is used for data management, and multi-thread training tasks are controlled by training manager. This paper gives the process firstly, then each step is introduced in detail, Some results and conclusions are given at last.	Acad Sinica, Inst Comp Technol, Beijing 100080, Peoples R China	Zhu, TS (reprint author), Acad Sinica, Inst Comp Technol, Beijing 100080, Peoples R China.						CHU M, 1995, THESIS ACAD SINICA; FAMILI, 1995, P IDA 95 S BAD BAD G, P54; FAYYAD UM, 1996, ADV KNOWLEDGE DICOVE; HAN J, 1994, P 1994 ACM SIGMOD IN; John G. H., 1997, THESIS STANFORD U; KERO B, 1995, KDD WORKSH 4 INT C D; LIN T, 1994, ACOUSTICS COURSE STU; Wang Wei, 1995, PRINCIPLE ARTIFICIAL; YANG XJ, 1990, SPEECH SIGNAL DIGITI	9	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							315	322				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800023	
B	do Amaral, JAAA; Botelho, PL; Ebecken, NFF; Xavier, AE; Caloba, LP		Ebecken, NFF		do Amaral, JAAA; Botelho, PL; Ebecken, NFF; Xavier, AE; Caloba, LP			Ship's classification by its magnetic signature: a neuro-genetic approach	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				The ship's classification by its magnetic signatures is of great importance in the development of magnetic sea mines. This work concerns the use of neural network classification system combined with the relevant features method to solve this problem. Alternatively we use genetic algorithm techniques to the train neural network. We compare both approaches in order to find the best characteristics of each one.								AMARAL JAA, 1998, THESIS COPPE UFRJ BR; CALOBA LP, 1994, IDENTIFYING RELEVANT; SOUZA H, 1993, MAGNETISM REPORTS IP	3	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							323	332				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800024	
B	Lopes, MCS; Costa, MCA; Ebecken, NFF		Ebecken, NFF		Lopes, MCS; Costa, MCA; Ebecken, NFF			A comparison of methods for Customer Classification	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				This work presents a comparison of current methods used for classification problems. The solution of two typical applications related to Customer Classification for Business Applications are considered: the first proposed in the Second International Competition of Data Analysis by Intelligent Techniques [6] and a higher dimensionality case.	Univ Fed Rio de Janeiro, COPPE, BR-21945970 Rio De Janeiro, Brazil	Lopes, MCS (reprint author), Univ Fed Rio de Janeiro, COPPE, Caixa Postal 68506, BR-21945970 Rio De Janeiro, Brazil.						Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; ARBIB MA, 1995, HDB BRAIN THEORY NEU, P30; Kennedy R. L., 1997, SOLVING DATA MINING; MASTERS T, 1995, ADV ALGORITHMS NEURA, P234; MASTERS T, 1994, SIGNAL IMAGE PROCESS, P61; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Taylor C.C., 1994, MACHINE LEARNING NEU; 1998, ERUDIT 98 2 INT COMP	8	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							333	347				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800025	
B	Pinheiro, CAR		Ebecken, NFF		Pinheiro, CAR			Events specification in active database management system	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Active Databases Management System have been objective of countless researches in the last years. Its active functionalities, as well as the concept of active objects or events are used in several application areas, not only in technology of databases. However, there is not a clearly defined notion distinguishing systems considered "actives" of the "non actives". However, certain essential characteristics are requested for the elaboration of these active functionalities, as ECA rules definition, events specification, production rules, and others. The present paper goals to give a generic view of one of those mentioned characteristics that I consider to be one of the most fundamental topics for the elaboration of active systems, that is the events specification. Starting from a solid and concise specification of the concerning events to a certain application, the elaboration of a efficient rules execution model for an active database management system is possible. This way, it will be given a general vision of the ECA rules, the event concept, its relationships, its types and classifications, and the pertinent operators to the events algebra. The establishment's necessity of the conditions that leads the events specification will be exposed, the definition of the executed actions when of the occurrence of events and the conditions validation, approached inside of the concept of the production rules.	Univ Fed Fluminense, Inst Matemat, Dept Ciencia Computacao, Pos Graduacao Ciencia Computacao, BR-24210130 Niteroi, RJ, Brazil	Pinheiro, CAR (reprint author), Univ Fed Fluminense, Inst Matemat, Dept Ciencia Computacao, Pos Graduacao Ciencia Computacao, Praca do Valonguinho S-N,4 Andar, BR-24210130 Niteroi, RJ, Brazil.						BUCHMANN AP, BUILDING INTEGRATED; CHAKRAVARTHY S, 1993, UFCISTR93002 COMP IN; CHAKRAVARTHY S, 1995, UFCISTR95028 COMP IN; CHAKRAVARTHY S, 1993, UFCISTR93007 COMP IN; CHAKRAVARTHY S, 1992, UFCISTR92041 COMP IN; DITTRICH KR, 1993, INT WORKSH INFR GOES; DITTRICH KR, 1995, LECT NOTICES COMPUTE; FRITSCHI H, 1997, 9704 U ZUR I INF; GATZIU S, 1993, 1 INT WORKSH RUL DAT; GEPPERT A, 1993, 9513 U ZUR I INF; GHANDEHARIZADEH S, IMPLEMENTING LANGUAG; HANSON EN, 1994, TR94017 U FLOR COMP; HANSON EN, 1992, UFCISTR92031 COMP IN; HULL R, LANGUAGE CONSTRUCTS; KIM SK, 1995, UFCISTR95032 COMP IN; Rich E., 1991, ARTIFICIAL INTELLIGE; Russell S., 1995, ARTIFICIAL INTELLIGE; Stefik M., 1995, INTRO KNOWLEDGE SYST; *ORACLE, 1995, OR SERV APPL DEV GUI; *ORACLE, 1995, OR SERV CONC REL 7 3	20	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							351	366				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800026	
B	da Silva, EB; Xexeo, GB		Ebecken, NFF		da Silva, EB; Xexeo, GB			Constructing data mining functionalities in a DBMS	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State			DISCOVERY	One of the main obstacles in applying data mining techniques to large, real-world databases is the lack of integration between applications and the database management system where the collection of target data is stored. In these applications, data are obtained by applying an SQL query to that database and then stored in flat files for further processing. As a result, these applications cannot benefit from previously implemented functionalities of the accessed database management system. In this paper, we present an architecture for rule extraction applications development. This architecture is constructed by adding the functionalities required in order to accomplish the extraction of rules from a database. Moreover, this architecture enables the standard and efficient construction of data mining applications for rule extraction.	UFRJ, COPPE, Programa Engn Sistemas & Computacao, BR-21945970 Rio De Janeiro, Brazil	da Silva, EB (reprint author), UFRJ, COPPE, Programa Engn Sistemas & Computacao, POB 68511, BR-21945970 Rio De Janeiro, Brazil.						Cattell R. G., 1994, OBJECT DATA MANAGEME; FREITAS SH, 1995, CSM242 U ESS; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; HAN JW, 1996, P SIGMOD 96 WORKSH R, P547; HOLSHEIMER M, 1994, ARCHITECTURAL SUPPOR; HOLSHEIMER M, 1995, PERSPECTIVE DATABASE, P10; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; MAURO RC, 1997, P 13 BRAZ S DAT FORT, P272; Ramakrishnan S., 1994, 20 INT C VER LARG DA, P487	9	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							367	381				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800027	
B	Baiao, F; Mattoso, M; Zaverucha, G		Ebecken, NFF		Baiao, F; Mattoso, M; Zaverucha, G			A knowledge-based perspective of the Distributed Design of Object Oriented Databases	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				The performance of applications on Object Oriented Database Management Systems (OODBMSs) is strongly affected by Distributed Design, which reduces irrelevant data accessed by applications and data exchange among sites. In an OO environment, the Distributed Design is a very complex task, and an open research problem. In this work we propose a knowledge based approach to the fragmentation phase of the distributed design of object oriented databases. in this approach, we will show a rule-based implementation of an analysis algorithm from our previous work and propose some ideas towards the use of Inductive Logic Programming (ILP) to perform a knowledge discovery/revision process using our set of rules as background knowledge. The objective of the work is to uncover some previously unknown issues to be considered in the distributed design process. Our main objective here is to show the viability of performing a revision process in order to obtain better and better fragmentation algorithms. We do not intend to propose the best fragmentation algorithm ever possible. We concentrate here on the process of revising a DDOODB algorithm through Knowledge Discovery techniques, rather than only obtaining a final optimal algorithm.	UFRJ, COPPE, Dept Comp Sci, BR-21945970 Rio De Janeiro, Brazil	Baiao, F (reprint author), UFRJ, COPPE, Dept Comp Sci, POB 68511, BR-21945970 Rio De Janeiro, Brazil.						BAIAO F, 1998, IN PRESS P 9 INT C C; Baiao F, 1997, PROCEEDINGS OF SECOND INTERNATIONAL WORKSHOP ON CSCW IN DESIGN, P42; BELLATRECHE L, 1996, 7 INT WORKSH DAT EXP; BLOCKEEL H, 1996, P INT S METH INT SYS; CAREY M, 1993, P 1993 ACM SIGM INT, V22, P12; CHAKRAVARTHY S, 1997, 2 IFCIS INT C COOP I; Chen YH, 1996, DISTRIB PARALLEL DAT, V4, P107; CLUET S, 1992, P 1992 ACM SIGMOD SA, V21, P383; Elmasri R., 1989, FUNDAMENTALS DATABAS; EZEIFE C, 1994, 9403 U MAN DEP COMP; EZEIFE CI, 1995, DISTRIB PARALLEL DAT, V3, P247, DOI 10.1007/BF01418059; GARCEZ A, 1997, P IEEE INT C NEUR NE, V1, P121; KARLAPALEM K, 1994, DISTRIBUTED OBJECT M; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Lima F, 1996, PARALLEL AND DISTRIBUTED COMPUTING SYSTEMS - PROCEEDINGS OF THE ISCA 9TH INTERNATIONAL CONFERENCE, VOLS I AND II, P720; MAIER D, 1994, DISTRIBUTED OBJECT M; MALINOWSKI E, 1996, THESIS U FLORIDA; Mitchell T. M, 1997, MACHINE LEARNING; NAVATHE S, 1995, J COMPUTER SOFTWARE, V3; Ozsu M. T., 1991, PRINCIPLES DISTRIBUT; PROVOST F, 1996, P 13 NAT C ART INT; Savonnet M, 1996, PARALLEL AND DISTRIBUTED COMPUTING SYSTEMS - PROCEEDINGS OF THE ISCA 9TH INTERNATIONAL CONFERENCE, VOLS I AND II, P732; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8	23	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							383	399				17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800028	
B	Sulaiman, A; Souza, J		Ebecken, NFF		Sulaiman, A; Souza, J			A Decision Support System that reverse engineers abstract database transactions the conceptual model	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Traditional methods of database integration don't solve applications integration issues. These methods work on database schema. Beyond the complexity of integrating names and meanings between data and metadata of heterogeneous databases, is the understanding of the business that originated applications. Database transactions should have been projected to reflect the business activities. In general, differences between abstractions levels don't let database transactions mirror business activities. Business process consists of separate activities. Sometimes database transactions solve part of a defined activity. Otherwise more than one activity can be embedded in a database transaction. Database log records all occurrences of database transactions; it has their complete histories. Database log is an endogenous datawarehouse: In this datawarehouse one can mine rules, which will help understanding the nature of the business task and the adequacy of the related database logical model. This paper describes a conceptual model for a Decision Support System that will help database administrators on reverse engineering legacy system applications from its database logs, generating rules about transactions, to retrieve business process. That approach will complement Conceptual Schema Integration.	UFRJ, COPPE, Coordenacao Programas Posgraduacao Engn, Ctr Tecnol, BR-68513 Rio De Janeiro, Brazil	Sulaiman, A (reprint author), UFRJ, COPPE, Coordenacao Programas Posgraduacao Engn, Ctr Tecnol, Cidade Univ,Bloco H,Sala 319, BR-68513 Rio De Janeiro, Brazil.						Agrawal R., 1993, P ACM SIGMOD; Agrawal R., 1998, MINING PROCESS MODEL; Elmasri R., 1994, FUNDAMENTALS DATABAS; Gray J., 1993, T PROCESSING CONCEPT; IMMON W, 1997, DATA STORES DATA WAR; IMMON WH, 1992, BUILDING DATA WAREHO; MARTIN J, 1982, STRAT DAT PLANN METH; PASSOS E, 1995, LECT NOTES ARTIFICIA, V991; Rumbaugh J, 1991, OBJECT ORIENTED MODE; SULAIMAN A, 1992, THESIS ENG MIL I; SULAIMAN A, 1995, 2 UNC DAT WORKSH UFF; SULAIMAN A, DEV MAGAZINE     MAI; Zachman J.A., 1987, IBM SYSTEMS J, V26; *IBM, 1978, BUS SYST PLANN INF S	14	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							401	411				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800029	
B	Sousa, MS; Mattoso, MLQ; Ebecken, NFF		Ebecken, NFF		Sousa, MS; Mattoso, MLQ; Ebecken, NFF			Data mining: a database perspective.	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Data mining on large databases has been a major concern in research community, due to the difficulty of analyzing huge volumes of data using only traditional OLAP tools. This sort of process implies a lot of computational power, memory and disk I/O, which can only be provided by parallel computers. We present a discussion of how database technology can be integrated to data mining techniques. Finally, we also point out several advantages of addressing data consuming activities through a tight integration of a parallel database server and data mining techniques.	Univ Fed Rio de Janeiro, COPPE, BR-21945970 Rio De Janeiro, Brazil	Sousa, MS (reprint author), Univ Fed Rio de Janeiro, COPPE, POB 68511, BR-21945970 Rio De Janeiro, Brazil.	mauros@cos.ufrj.br; marta@cos.ufrj.br; nelson@ntt.ufrj.br; nelson@ntt.ufrj.br					Agrawal R., 1996, P 2 INT C KNOWL DISC; Agrawal R., 1998, P ACM SIGMOD INT C M; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 1994, P 20 VLDB INT C SANT; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; BIGUS JP, 1996, DATA MINING NEURALNE; Breiman L, 1984, CLASSIFICATION REGRE; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P471; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FREITAS A, 1997, THESIS; Freitas A. A, 1998, MINING VERY LARGE DA; Hallmark G, 1997, PROC INT CONF DATA, P314, DOI 10.1109/ICDE.1997.581820; HAN J, 1996, P INT C KDD PORTL OR; HAN J, 1995, CANADIAN AI MAGAZINE; HOLSHEIMER M, 1996, ADV KNOWLEDGE DISCOV, P447; KUFRIN R, 1995, P IJCAI WORKSH PAR P, P87; METHA M, 1996, P 5 INT C EXT DAT TE; METHA M, 1997, VLDB J; Mitchell T. M, 1997, MACHINE LEARNING; NAVATHE SB, 1989, SIGMOD REC, V18, P440, DOI 10.1145/67544.66966; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SHAFER J, 1996, P 22 INT C VLDB MUMB; SOUSA MS, 1998, P INT C DEXA WORKSH; SOUSA MS, 1998, P INT C PDPTA SPEC S; Srikant R., 1996, P 5 INT C EXT DAT TE; *OR CORP, OR PAR SERV CONC ADM	27	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							413	431				19	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800030	
B	Shi, XM; Chan, MC; Li, DY		Ebecken, NFF		Shi, XM; Chan, MC; Li, DY			Knowledge explorer: A prototype for mining knowledge from databases	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Knowledge discovery in databases (KDD) was defined as the non-trivial process of identifying valid, potentially useful and ultimately understandable patterns in data [1]. Knowledge discovery is considered as the overall process of discovering while data mining refers to the applications of algorithms for extracting patterns from data. In this paper, a prototype of a KDD system, refer to as the Knowledge Explorer (KE), has been developed. KE is an interactive and task-driven knowledge discovery system. It has a friendly human-oriented interface and some powerful mining tools. The basic process of discovering acid the logical scheme of KE are introduced. Five components of KE, including the database, the domain knowledge hierarchies, the discovery task editor, data mining tools and the reporter of discovered knowledge, are discussed. Examples are given to illustrate how KE deals with a specific discovery task.	Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong	Shi, XM (reprint author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong.						chen Ming-Syan, 1996, IEEE T KNOWLEDGE DAT, V8; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; LI DY, 1995, RES DEV COMPUTERS, V42, P32; LI DY, 1998, IN PRESS J KNOWLEDGE; LI DY, 1998, LOGIC PROGRAMMING SO; LI DY, 1993, J COMPUTER SCI, V20, P44; SHI XM, 1994, P 1 INT S YOUNG INV	7	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							433	449				17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800031	
J	Fayyad, U				Fayyad, U			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Microsoft Corp, Redmond, WA 98052 USA	Fayyad, U (reprint author), Microsoft Corp, Redmond, WA 98052 USA.						Brachman R., 1996, ADV KNOWLEDGE DISCOV; FRIEDMAN J, 1997, P 29 S INT COMP SCI; Huber P. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; HUBER PJ, 1997, P C STAT SCI HON BIC; TUKEY J, 1962, ANN STAT, V33	5	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	1998	2	1					5	7		10.1023/A:1009712318968		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZZ733	WOS:000074761700001	
J	Hernandez, MA; Stolfo, SJ				Hernandez, MA; Stolfo, SJ			Real-world data is dirty: Data cleansing and the merge/purge problem	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data cleaning; data cleansing; duplicate elimination; semantic integration		The problem of merging multiple databases of information about common entities is frequently encountered in KDD and decision support applications in large commercial and government organizations. The problem we study is often called the Merge/Purge problem and is difficult to solve both in scale and accuracy. Large repositories of data typically have numerous duplicate information entries about the same entities that are difficult to cull together without an intelligent "equational theory" that identifies equivalent items by a complex, domain-dependent matching process. We have developed a system for accomplishing this Data Cleansing task and demonstrate its use for cleansing lists of names of potential customers in a direct marketing-type application. Our results for statistically generated data are shown to be accurate and effective when processing the data multiple times using different keys for sorting on each successive pass. Combing results of individual passes using transitive closure over the independent results, produces far more accurate results at lower cost. The system provides a rule programming module that is easy to program and quire good at finding duplicates especially in an environment with massive amounts of data. This paper details improvements in our system, and reports on the successful implementation for a real-world database that conclusively validates our results previously achieved for statistically generated data.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Hernandez, MA (reprint author), Univ Illinois, Springfield, IL 62794 USA.						Agrawal R., 1988, Proceedings. International Symposium on Databases in Parallel and Distributed Systems (IEEE Cat. No.88CH2665-8), DOI 10.1109/DPDS.1988.675002; BATINI C, 1986, COMPUT SURV, V18, P323; BITTON D, 1983, ACM T DATABASE SYST, V8, P255, DOI 10.1145/319983.319987; BUCKLES BP, 1982, FUZZY SET SYST, V7, P213, DOI 10.1016/0165-0114(82)90052-5; BUCKLEY JP, 1995, P IEEE INT C SYST MA, P3573; Church K.W., 1991, STAT COMPUT, V1, P93, DOI 10.1007/BF01889984; CLARK TK, 1995, KDD NUGGETS, V95, P7; DIETTERICH TG, 1983, MACHINE LEARNING ART, V1, P41; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; FAYYAD U, 1996, AI MAGAZINE, V17; FELLEGI I, 1969, AM STAT ASS J    DEC, P1183; FORGY CL, 1981, CMUCS81135 CARN MELL; George R, 1996, INT J INTELL SYST, V11, P649, DOI 10.1002/(SICI)1098-111X(199609)11:9<649::AID-INT4>3.3.CO;2-J; GHANDEHARIZADEH S, 1990, THESIS U WISCONSIN M; HERNANDEZ M, 1995, P 1995 ACM SIGMOD C; KUKICH K, 1992, COMPUT SURV, V24, P377; Lebowitz M., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Monge A.E., 1997, P SIGMOD WORKSH RES, P23; NYBERG C, 1994, P ACM SIGMOD INT C M, P233, DOI 10.1145/191839.191884; POLLOCK JJ, 1987, ACM COMPUT SURV, V27, P358; SENATOR T, 1995, P 7 C INN APPL AI AU; WANG YR, 1989, P 6 INT C DAT ENG FE; *ACM, 1991, SIGMOD REC	23	141	157	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	1998	2	1					9	37		10.1023/A:1009761603038		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZZ733	WOS:000074761700002	
J	Silverstein, C; Brin, S; Motwani, R				Silverstein, C; Brin, S; Motwani, R			Beyond market baskets: Generalizing association rules to dependence rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; market basket; association rules; dependence rules; closure properties; text mining		One of the more well-studied problems in data mining is the search for association rules in market basket data. Association rules are intended to identify patterns of the type: "A customer purchasing item A often also purchases item B." Motivated partly by the goal of generalizing beyond market basket data and partly by the goal of ironing out some problems in the definition of association rules, we develop the notion of dependence rules that identify statistical dependence in both the presence and absence of items in itemsets. We propose measuring significance of dependence via the chi-squared test for independence from classical statistics. This leads to a measure that is upward-closed in the itemset lattice, enabling us to reduce the mining problem to the search for a border between dependent and independent itemsets in the lattice. We develop pruning strategies based on the closure property and thereby devise an efficient algorithm for discovering dependence rules. We demonstrate our algorithm's effectiveness by testing it on census data, text data (wherein we seek term dependence), and synthetic data.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Silverstein, C (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	csilvers@cs.stanford.edu; brin@cs.stanford.edu; motwani@cs.stanford.edu					Agrawal R., 1996, P 2 INT C KNOWL DISC; AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 1996, P ADV KNOWL DISC DAT, P307; Agresti A., 1992, STAT SCI, V7, P131, DOI DOI 10.1214/SS/1177011454; DELAPLACE PS, 1878, OEUVRES COMPLETES LA; DEMOIAVRE A, 1933, MISCELLANEA ANAL S; DIETZFELBINGER M, 1988, P 29 IEEE S FDN COMP, P524, DOI 10.1109/SFCS.1988.21968; EWALD R, 1994, 3 INT C INF KNOWL MA; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FREDMAN ML, 1984, J ACM, V31, P538, DOI 10.1145/828.1884; FUKUDA T, 1996, P 15 ACM S PRINC DAT; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; GUNOPULOS D, 1997, INPRESS P 6 INT C DA; Han J, 1995, P 21 INT C VER LARG, P420; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Lancaster H. O, 1969, CHISQUARED DISTRIBUT; MANNILA H, 1994, P AAAI WORKSH KNOWL, P144; Moore D. S., 1986, GOODNESS FIT TECHNIQ, P63; MOSTELLER F, 1964, INFERENCE DISPUTED A; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897; Piatetsky G., 1991, KNOWLEDGE DISCOVERY; Savasere A, 1995, P 21 INT C VER LARG, P432; Srikant R., 1995, P 21 INT C VER LARG, P407; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134	27	124	127	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	1998	2	1					39	68		10.1023/A:1009713703947		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZZ733	WOS:000074761700003	
J	Hsu, CN; Knoblock, CA				Hsu, CN; Knoblock, CA			Discovering robust knowledge from databases that change	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						robustness; database transactions and changes; rule consistency; knowledge discovery	SEMANTIC QUERY OPTIMIZATION	Many applications of knowledge discovery and data mining such as rule discovery for semantic query optimization, database integration and decision support, require the knowledge to be consistent with the data. However, databases usually change over time and make machine-discovered knowledge inconsistent. Useful knowledge should be robust against database changes so that it is unlikely to become inconsistent after database updates. This paper defines this notion of robustness in the context of relational databases and describes how robustness of first-order Hem-clause rules can be estimated. Experimental results show that our estimation approach can accurately identify robust rules. We also present a rule antecedent pruning algorithm that improves the robustness and applicability of machine discovered rules to demonstrate the usefulness of robustness estimation.	Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA; Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA; Univ So Calif, Dept Comp Sci, Marina Del Rey, CA 90292 USA	Hsu, CN (reprint author), Arizona State Univ, Dept Comp Sci & Engn, POB 875406, Tempe, AZ 85287 USA.	chunnan@asu.edu; knoblock@isi.edu					AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AMBITE JL, 1995, AAAI SPR S INF GATH; Arens Y., 1996, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V6, DOI 10.1007/BF00122124; Arens Y., 1993, International Journal of Intelligent & Cooperative Information Systems, V2, DOI 10.1142/S0218215793000071; BACCHUS F, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P222; Bacchus F., 1992, P NAT C ART INT AAAI, P602; BELL S, 1995, P 1 INT C KNOWL DISC; CESTNIK B, 1991, LECT NOTES ARTIF INT, V482, P138; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COHEN WW, 1993, P 13 INT JOINT C ART; Cussens J., 1993, Machine Learning: ECML-93. European Conference on Machine Learning Proceedings; DAO S, 1995, P 1 INT C KNOWL DISC; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, pCH5; FURNKRANZ J, 1994, MACHINE LEARNING; HELMBOLD DP, 1994, MACH LEARN, V14, P27, DOI 10.1007/BF00993161; HOWSON C, 1988, SCI REASONING BAYESI; HSU CN, 1994, MACHINE LEARNING; HSU CN, 1993, P 2 INT C INF KNOWL; HSU CN, 1996, THESIS U SO CALIFORN; HSU CN, 1996, ADV KNOWLEDGE DISCOV, pCH17; HSU CN, 1996, P 13 NAT C ART INT A; KING JJ, 1981, THESIS STANFORD U; KNOBLOCK CA, 1994, P 2 INT C INT COOP I; LAVRAC N, 1994, INDUCTIV LOGIC PROGR; LLOYD J. W., 1987, FDN LOGIC PROGRAMMIN; MANNILA H, 1994, DATA KNOWL ENG, V12, P83, DOI 10.1016/0169-023X(94)90023-X; MINTON S, 1988, THESIS CARNEGIE MELL; Pawlak Z., 1991, ROUGH SETS THEORETIC; PIATETSKYSHAPIR.G, 1984, THESIS NEW YORK U; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; RAEDT LD, 1993, P 13 INT JOINT C ART; Ramsay Allan, 1988, FORMAL METHODS ARTIF; SHEKHAR S, 1993, IEEE T KNOWL DATA EN, V5, P950, DOI 10.1109/69.250077; Siegel M., 1991, Knowledge discovery in databases; SUN W, 1994, IEEE T KNOWL DATA EN, V6, P136; Ullman J. D., 1988, PRINCIPLES DATABASE, VI; ULLMAN JD, 1988, PRINCIPLES DATABASE, V2; WIDMER G, 1993, MACHINE LEARNING	38	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	1998	2	1					69	95		10.1023/A:1009717820785		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZZ733	WOS:000074761700004	
J	Bansal, K; Vadhavkar, S; Gupta, A				Bansal, K; Vadhavkar, S; Gupta, A			Neural networks based forecasting techniques for inventory control applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						neural networks; applications of neural networks; inventory management system; statistical reasoning; data mining and knowledge discovery		An increasing number of organizations are involved in the development of information systems for effective linkages with their suppliers, customers, and other channel partners involved in transportation, distribution, warehousing and maintenance activities. We use neural network based data mining and knowledge discovery techniques to solve the problems of inventory in a large medical distribution company. The paper describes the use of traditional statistical techniques to evaluate the best neural network type. Based on the neural network model described in this paper, a prototype was conceived with data from a large decentralized organization. The prototype was successful in reducing the total level of inventory by 50% in the organization, while maintaining the same level of probability that a particular customer's demand will be satisfied.	Gupta Consultancy Inc, Newtonville, MA 02160 USA; MIT, Alfred P Sloan Sch Management, Cambridge, MA 02139 USA	Bansal, K (reprint author), 422 Poplar St, Wilmette, IL 60091 USA.						BECKER S, 1988, P 1988 CONN MOD SUMM, P29; BRACHMAN RJ, 1996, COMMUN ACM, V39, P11; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Hamilton JD, 1994, TIME SERIES ANAL; Hebb D. O., 1949, ORG BEHAV; Hush D.R, 1993, IEEE SIGNAL PROC JAN, P8; MOZER MC, 1993, NEURAL NET ARCHITECT; MURATA, 1991, ARTIFICIAL NEURAL NE, V1, P9; SOULIE F, 1991, ARTIFICIAL NEURAL NE, V1, P605	9	11	11	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	1998	2	1					97	102		10.1023/A:1009769804855		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZZ733	WOS:000074761700005	
B	Rodrigues, MD; Ramos, C; Henriques, PR		Ebecken, NFF		Rodrigues, MD; Ramos, C; Henriques, PR			Knowledge discovery with retail basket analysis	DATA MINING			English	Proceedings Paper	International Conference on Data Mining	SEP 02-04, 1998	RIO JANEIRO, BRAZIL	Fed Univ Rio Janeiro, Fed Agcy Studies & Projects Management, Brazilian Natl Res Council, Res Fdn Rio Janeiro State				Minute by minute the amount of data in the world databases is increasing inexorably. To support this growth of data the concept of data warehouse (DW) was created. DW when combined with On-Line Analytical Processing (OLAP) Codd[2] and Executive Information Systems (EIS) Buytendijk[1] tools, enable data access and visualization in a very flexible way. Features include very quick data exploration, vertical navigation (drill up/drill down), aggregation and graphical facilities. However, the amount and the complexity of data in data warehouses is so big that it becomes difficult to the business analysts to recognise trends and relations in data even with multidimensional decision support systems. A new generation of tools and techniques for automated intelligent database analysis is needed. These tools and techniques are the subject of the rapidly emerging field of Knowledge Discovery in Data Bases (KDD). In this paper, we propose an integrated system - DECADIS - DEscoberta de Conhecimento em Armazens de Dados de DIStribuicao (Knowledge Discovery in Retail Data Warehouses), designed for understanding customer behaviour and consumption patterns in a Portuguese company in the retail industry.	Polytechn Inst Porto, Sch Engn, P-4200 Porto, Portugal	Rodrigues, MD (reprint author), Polytechn Inst Porto, Sch Engn, Rua Sao Tome, P-4200 Porto, Portugal.						BUYTENDIJK FA, 1995, OLAP PLAYING KEEPS; GORDON LM, 1997, DATA MINING TECHNIQU; IMIELINSKI T, 1993, P ACM SIGMOD C MAN D; SALLEY CT, 1993, PROVIDING OLAP ON LI; SMITH PJ, 1996, ADV KNOWLEDGE DISCOV, P1; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311	6	0	0	WIT PRESS/COMPUTATIONAL MECHANICS PUBLICATIONS	SOUTHAMPTON	ASHURST LODGE, ASHURST, SOUTHAMPTON SO40 7AA, ENGLAND		1-85312-677-2				1998							193	204				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BM59J	WOS:000079195800013	
J	Stolorz, P; Musick, R				Stolorz, P; Musick, R			Special issue: Scalable high performance computing for KDD	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Jet Prop Lab, Pasadena, CA 91109 USA; Univ Calif Lawrence Livermore Natl Lab, Livermore, CA USA	Stolorz, P (reprint author), Jet Prop Lab, 4800 Oak Grove Dr, Pasadena, CA 91109 USA.						Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Fayyad U, 1996, COMMUN ACM, V39, P51, DOI 10.1145/240455.240471; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843	4	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1997	1	4					339	341		10.1023/A:1009799201038		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA833	WOS:000072406600001	
J	Zaki, MJ; Parthasarathy, S; Ogihara, M; Li, W				Zaki, MJ; Parthasarathy, S; Ogihara, M; Li, W			Parallel algorithms for discovery of association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						parallel data mining; association rules; maximal hypergraph cliques; lattice traversal		Discovery of association rules is an important data mining task. Several parallel and sequential algorithms have been proposed in the literature to solve this problem. Almost all of these algorithms make repeated passes over the database to determine the set of frequent itemsets (a subset of database items), thus incurring high I/O overhead. In the parallel case, most algorithms perform a sum-reduction at the end of each pass to construct the global counts, also incurring high synchronization cost. In this paper we describe new parallel association mining algorithms. The algorithms use novel itemset clustering techniques to approximate the set of potentially maximal frequent itemsets. Once this set has been identified, the algorithms make use of efficient traversal techniques to generate the frequent itemsets contained in each cluster. We propose two clustering schemes based on equivalence classes and maximal hypergraph cliques, and study two lattice traversal techniques based on bottom-up and hybrid search. We use a vertical database layout to cluster related transactions together. The database is also selectively replicated so that the portion of the database needed for the computation of associations is local to each processor. After the initial set-up phase, the algorithms do not need any further communication or synchronization. The algorithms minimize I/O overheads by scanning the local database portion only twice. Once in the set-up phase, and once when processing the itemset clusters, Unlike previous parallel approaches, the algorithms use simple intersection operations to compute frequent itemsets and do not have to maintain or search complex hash structures. Our experimental testbed is a 32-processor DEC Alpha cluster inter-connected by the Memory Channel network. We present results on the performance of our algorithms on various databases, and compare it against a well known parallel algorithm. The best new algorithm outperforms it by an order of magnitude.	Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA; Oracle Corp, Java Prod Grp, Redwood Shores, CA 94065 USA	Zaki, MJ (reprint author), Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.						Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R., 1993, ACM SIGMOD INT C MAN; Agrawal R., 1996, ADV KNOWLEDGE DISCOV; AGRAWAL R, 1994, 20 VLDB C; Berge C., 1989, HYPERGRAPHS COMBINAT; CHEUNG D, 1996, 4 INT C PAR DISTR IN; Cheung DW, 1996, IEEE T KNOWL DATA EN, V8, P911, DOI 10.1109/69.553158; FAYYAD U, 1996, COMMUNICATIONS ACM D; Garey M. R., 1979, COMPUTERS INTRACTABI; GILLETT R, 1996, IEEE MICRO, V16; HAN EHK, 1997, ACM SIGMOD C MAN DAT; HOLSHEIMER M, 1995, 1 INT C KNOWL DISC D; HOUTSMA M, 1995, 11 INT C DAT ENG; MANNILA H, 1994, AAAI WKSHP KNOWL DIS; Park J.S., 1995, ACM INT C INF KNOWL; PARK JS, 1995, ACM SIGMOD INT C MAN; PARTHASARATHY S, 1997, 653 URCS TR; SAVASERE A, 1995, 21 VLDB C; TOIVONEN H, 1996, 22 VLDB C; Zaki M. J., 1997, 3 INT C KNOWL DISC D; ZAKI MJ, 1997, 651 URCS TR; ZAKI MJ, 1997, 7 INT WKSHP RES ISS; ZAKI MJ, 1996, SUPERCOMPUTING 96; ZAKI MJ, 1997, 9 ACM S PAR ALG ARCH	24	63	66	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1997	1	4					343	373		10.1023/A:1009773317876		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA833	WOS:000072406600002	
J	Schweitzer, H				Schweitzer, H			A distributed algorithm for content based indexing of images by projections on Ritz primary images	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						image-and-video-indexing; primary-images; image-data-mining	RECOGNITION	Large collections of images can be indexed by their projections on a few "primary" images. The optimal primary images are the eigenvectors of a large covariance matrix. We address the problem of computing primary images when access to the images is expensive. This is the case when the images cannot be kept locally, but must be accessed through slow communication such as the Internet, or stored in a compressed form. A distributed algorithm that computes optimal approximations to the eigenvectors (known as Ritz vectors) in one pass through the image set is proposed. When iterated, the algorithm can recover the er,act eigenvectors. The widely used SVD technique for computing the primary images of a small image set is a special case of the proposed algorithm. In applications to image libraries and learning, it is necessary to compute different primary images for several sub-categories of the image set. The proposed algorithm can compute these additional primary images "offline", without the image data. Similar computation by other algorithms is impractical even when access to the images is inexpensive.	Univ Texas Dallas, Richardson, TX 75083 USA	Schweitzer, H (reprint author), Univ Texas Dallas, POB 830688, Richardson, TX 75083 USA.						ABDI H, 1995, PERCEPTION, V24, P539, DOI 10.1068/p240539; BERRY MW, 1992, INT J SUPERCOMPUT AP, V6, P13; Burl M. C., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), DOI 10.1109/CVPR.1994.323844; CHAMPAGNE B, 1994, IEEE T SIGNAL PROCES, V42, P2758, DOI 10.1109/78.324741; Devijver PA, 1982, PATTERN RECOGNITION; Fukunaga K., 1990, INTRO STAT PATTERN R; Golub G.H., 1996, MATRIX COMPUTATIONS; Hertz J, 1991, INTRO THEORY NEURAL; Jolliffe I., 1986, PRINCIPAL COMPONENT; Leonardis A, 1996, PROC CVPR IEEE, P453, DOI 10.1109/CVPR.1996.517111; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511; MURASE H, 1994, IEEE T PATTERN ANAL, V16, P1219, DOI 10.1109/34.387485; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; MURASE H, 1995, IEEE T IMAGE PROCESS, V4, P620; Patel NV, 1997, HANDBOOK OF MULTIMEDIA INFORMATION MANAGEMENT, P139; PENTLAND A, 1994, SPIE STORAGE RETRIEV, V2, P34; Rosenfeld A, 1982, DIGITAL PICTURE PROC; SANGER TD, 1989, ADV NEURAL INFORMATI, P11; SCHWEITZER H, 1998, IN PRESS P 6 INT C C; SCHWEITZER HS, 1995, IEEE T PATTERN ANAL, V17, P1033, DOI 10.1109/34.473229; STEWART GW, 1969, NUMER MATH, V13, P362, DOI 10.1007/BF02165413; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; YANG XP, 1989, IEEE T ACOUST SPEECH, V37, P1550, DOI 10.1109/29.35393	24	3	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1997	1	4					375	390		10.1023/A:1009725401947		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA833	WOS:000072406600003	
J	Goil, S; Choudhary, A				Goil, S; Choudhary, A			High performance OLAP and data mining on parallel computers	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Data Cube; parallel computing; high performance; data mining; Attribute Focusing		On-Line Analytical Processing (OLAP) techniques are increasingly being used in decision support systems to provide analysis of data. Queries posed on such systems are quire complex and require different views of data. Analytical models need to capture the multidimensionality of the underlying data, a task for which multidimensional databases are well suited. Multidimensional OLAP systems store data in multidimensional arrays on which analytical operations are performed. Knowledge discovery and data mining requires complex operations on the underlying data which can be very expensive in terms of computation time.. High performance parallel systems can reduce this analysis rime. Precomputed aggregate calculations in a Data Cube can provide efficient query processing for OLAP applications. In this article, we present algorithms for construction of data cubes on distributed-memory parallel computers. Data is loaded from a relational database into a multidimensional array. We present two methods, sort-based and hash-based for loading the base cube and compare their performances. Data cubes are used to perform consolidation queries used in roil-up operations using dimension hierarchies. Finally, we show how data cubes are used for data mining using Attribute Focusing techniques. We present results fbr these on the IBM-SP2 parallel machine. Results show that our algorithms and techniques for OLAP and data mining on parallel systems are scalable to a large number of processors, providing a high performance platform for such applications.	Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60201 USA; Northwestern Univ, Ctr Parallel & Distributed Comp, Evanston, IL 60201 USA	Goil, S (reprint author), Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60201 USA.		Choudhary, Alok/C-5486-2009				BHANDARI I, 1993, IEEE T SOFTWARE ENG, V19, P1157, DOI 10.1109/32.249661; BHANDARI I, 1996, 20443 RC IBM TJ WATS; BHANDARI I, 20136 RC IBM TJ WATS; CODD E, 1993, PROVIDING OLAP USER; FAYYAD UM, DATA MINING KNOWLEDG, P1; GOIL S, IN PRESS 4 INT C HIG; GRAY J, 1996, P INT C DAT ENG; GUTING A, 1994, VLDB J, V3, P357; HARINARAYAN V, P SIGMOD 96; Kumar V., 1994, INTRO PARALLEL COMPU; SARAWAGI S, 1996, 10026 IBM ALM RES CT; SARAWAGI S, 1994, P 11 INT C DAT ENG H; ZHAO Y, 1996, PERFORMANCE ARRAY BA; *OLAP COUNC, OLAP COUNC BENCHM	14	11	11	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1997	1	4					391	417		10.1023/A:1009777418785		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA833	WOS:000072406600004	
J	Pfitzner, DW; Salmon, JK; Sterling, T				Pfitzner, DW; Salmon, JK; Sterling, T			Halo world: Tools for parallel cluster finding in astrophysical N-body simulations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clustering density estimation; parallel computation; astrophysics; N-body simulation	COLD DARK-MATTER; LARGE-SCALE STRUCTURE; VELOCITY BIAS	Cosmological N-body simulations on parallel computers produce large datasets - gigabytes at each instant of simulated cosmological time, and hundreds of gigabytes over the course of a simulation. These large datasets require further analysis before they can be compared to astronomical observations, The "Halo World" tools include two methods for performing halo finding: identifying all of the gravitationally stable clusters in a point-sampled density field. One of these methods is a parallel implementation of the friends of friends (FOF) algorithm, widely used in the field of N-body cosmology. The new IsoDen method based on isodensity surfaces has been developed to overcome some of the shortcomings of FOF. Parallel processing is the only viable way of obtaining the necessary performance and storage capacity to carry out these analysis tasks. Ultimately we must also plan to use disk storage as the only economically viable alternative for storing and manipulating such large data sets. Both IsoDen and friends of friends have been implemented on a variety of computer systems, with parallelism up to 512 processors, and successfully used to extract halos from simulations with up to 16.8 million particles.	Australian Natl Univ, Mt Stromlo & Siding Spring Observ, Weston, ACT 2611, Australia; Ctr Adv Comp Res, Pasadena, CA 91125 USA	Pfitzner, DW (reprint author), Australian Natl Univ, Mt Stromlo & Siding Spring Observ, PB Weston Creek, Weston, ACT 2611, Australia.						BARNES J, 1986, NATURE, V324, P446, DOI 10.1038/324446a0; BECKER DJ, 1995, P 1995 INT C PAR PRO, V1; Bertschinger E., 1991, Computers in Physics, V5; CARLBERG RG, 1994, ASTROPHYS J, V433, P468, DOI 10.1086/174659; DAVIS M, 1985, ASTROPHYS J, V292, P371, DOI 10.1086/163168; GELB JM, 1994, ASTROPHYS J, V436, P467, DOI 10.1086/174922; PEEBLES PJE, 1993, PRINCIPLES PHYSICAL; PFITZNER DW, 1996, 2 STROML S NAT ELL G, P109; SALMON JK, 1997, 8 SIAM C PAR PROC SC; Scott D.W., 1992, MULTIVARIATE DENSITY; Silverman B. W., 1986, DENSITY ESTIMATION S; SUMMERS FJ, 1995, ASTROPHYS J, V454, P1, DOI 10.1086/176459; WARREN MS, 1995, COMPUT PHYS COMMUN, V87, P266, DOI 10.1016/0010-4655(94)00177-4; WARREN MS, 1997, IN PRESS SUPERCOMPUT; ZUREK WH, 1994, ASTROPHYS J, V431, P559, DOI 10.1086/174507	15	5	5	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1997	1	4					419	438		10.1023/A:1009729602855		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA833	WOS:000072406600005	
J	Fayyad, U				Fayyad, U			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Microsoft Res, Redmond, WA 98052 USA	Fayyad, U (reprint author), Microsoft Res, Redmond, WA 98052 USA.							0	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	1997	1	3					237	239		10.1023/A:1009792101442		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA829	WOS:000072406200001	
J	Mannila, H; Toivonen, H				Mannila, H; Toivonen, H			Levelwise search and borders of theories in knowledge discovery	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						theory of knowledge discovery; association rules; episodes; integrity constraints; hypergraph transversals	INFERRING FUNCTIONAL-DEPENDENCIES; COMPLEXITY	One of the basic problems in knowledge discovery in databases (KDD) is the following: given a data set r, a class L of sentences for defining subgroups of r, and a selection predicate, find all sentences of L: deemed interesting by the selection predicate. We analyze the simple levelwise algorithm for finding all such descriptions. We give bounds for the number of database accesses that the algorithm makes. For this, we introduce the concept of the border of a theory, a notion that turns out to be surprisingly powerful in analyzing the algorithm. We also consider the verification problem of a KDD process: given r and a set of sentences S subset of or equal to L, determine whether S is exactly the set of interesting statements about r. We show strong connections between the verification problem and the hypergraph transversal problem. The verification problem arises in a natural way when using sampling to speed up the pattern discovery step in KDD.	Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland	Mannila, H (reprint author), Univ Helsinki, Dept Comp Sci, POB 26, FIN-00014 Helsinki, Finland.		Toivonen, Hannu/A-3657-2012	Toivonen, Hannu/0000-0003-1339-8022			Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; BELL S, 1995, P 1 INT C KNOWL DISC, P27; Berge C, 1973, HYPERGRAPHS COMBINAT; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Chang C.C., 1990, MODEL THEORY; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DERAEDT L, 1993, P 13 INT JOINT C ART, P1058; EITER T, 1995, SIAM J COMPUT, V24, P1278, DOI 10.1137/S0097539793250299; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Fredman ML, 1996, J ALGORITHM, V21, P618, DOI 10.1006/jagm.1996.0062; Fukuda T., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237708; Gunopulos D., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263684; GURVICH V, 1995, LCSRTR251 RUTG U; Han J, 1995, P 21 INT C VER LARG, P420; Holsheimer M, 1995, P 1 INT C KNOWL DISC, P150; Houtsma M., 1993, 9567 RJ IBM ALM RES; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; KANTOLA M, 1992, INT J INTELL SYST, V7, P591, DOI 10.1002/int.4550070703; Kietz J.-U., 1992, INDUCTIVE LOGIC PROG, P335; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; KLOESGEN W, 1995, J INTELL INF SYST, V4, P53; KNOBBE AJ, 1996, CYBERNET SYST, V2, P961; Langley P, 1996, ELEMENTS MACHINE LEA; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; MANNILA H, 1986, J COMPUT SYST SCI, V33, P126, DOI 10.1016/0022-0000(86)90015-2; MANNILA H, 1992, DISCRETE APPL MATH, V40, P237, DOI 10.1016/0166-218X(92)90031-5; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Mannila H., 1992, DESIGN RELATIONAL DA; MANNILA H, 1994, DATA KNOWL ENG, V12, P83, DOI 10.1016/0169-023X(94)90023-X; MISHRA N, 1995, UNPUB BOUNDED DEGREE; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; PFAHRINGER B, 1995, P 1 INT C KNOWL DISC, P234; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Savasere A, 1995, P 21 INT C VER LARG, P432; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Srikant R., 1995, P 21 INT C VER LARG, P407; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134	40	251	258	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	1997	1	3					241	258		10.1023/A:1009796218281		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA829	WOS:000072406200002	
J	Mannila, H; Toivonen, H; Verkamo, AI				Mannila, H; Toivonen, H; Verkamo, AI			Discovery of frequent episodes in event sequences	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						event sequences; frequent episodes; sequence analysis	PATTERNS	Sequences of events describing the behavior and actions of users or systems can be collected in several domains. An episode is a collection of events that occur relatively close to each other in a given partial order. We consider the problem of discovering frequently occurring episodes in a sequence. Once such episodes are known, one can produce rules for describing or predicting the behavior of the sequence. We give efficient algorithms for the discovery of all frequent episodes from a given class of episodes, and present detailed experimental results. The methods are in use in telecommunication alarm management.	Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland	Mannila, H (reprint author), Univ Helsinki, Dept Comp Sci, POB 26, FIN-00014 Helsinki, Finland.	heikki.mannila@cs.helsinki.fi; hannu.toivonen@cs.helsinki.fi; inkeri.verkamo@cs.helsinki.fi	Toivonen, Hannu/A-3657-2012	Toivonen, Hannu/0000-0003-1339-8022			AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; BAIROCH A, 1995, NUCLEIC ACIDS RES, V24, P189; Bettini C., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237680; DENNING PJ, 1968, COMMUN ACM, V11, P323, DOI 10.1145/363095.363141; Dousson C., 1993, P INT JOINT C ART IN, P166; Fayyad U., 1996, P 2 INT C KNOWL DISC, P351; Fleischer R, 1997, P 8 ANN S COMB PATT, P12; FORGY CL, 1982, ARTIF INTELL, V19, P17, DOI 10.1016/0004-3702(82)90020-0; GEHANI NH, 1992, PROC INT CONF VERY L, P327; GOODMAN RM, 1995, INTEGRATED NETWORK M, V4, P316; GROSSI R, 1989, INFORM PROCESS LETT, V33, P113, DOI 10.1016/0020-0190(89)90188-9; Han J, 1995, P 21 INT C VER LARG, P420; HATONEN K, 1996, 12 INT C DAT ENG ICD, P115; HATONEN K, 1996, 1996 IEEE NETW OP MA, P520; Holsheimer M, 1995, P 1 INT C KNOWL DISC, P150; HOWE AE, 1995, 5 INT WORKSH ART INT, P271; Jakobson G., 1993, IEEE Network, V7, DOI 10.1109/65.244794; JONASSEN I, 1995, PROTEIN SCI, V4, P1587; Kalbfleisch JD, 1980, STAT ANAL FAILURE TI; Laird P., 1993, LECT NOTES ARTIF INT, V744, P1; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Milne R., 1994, Intelligent Systems Engineering, V3; MORRIS RA, 1994, P INT WORKSH TEMP RE, P29; MUGGLETON S., 1992, INDUCTIVE LOGIC PROG; Oates T, 1996, P 13 INT C MACH LEAR, P346; Seshadri P, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P99; Srikant R., 1996, Advances in Database Technology - EDBT '96. 5th International Conference on Extending Database Technology. Proceedings; Srikant R., 1995, P 21 INT C VER LARG, P407; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; *GEN U HOSP U GEN, EXPASY MOL BIOL SERV	34	406	427	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	1997	1	3					259	289		10.1023/A:1009748302351		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA829	WOS:000072406200003	
J	Fawcett, T; Provost, F				Fawcett, T; Provost, F			Adaptive fraud detection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						mud detection; rule learning; profiling; constructive induction; intrusion detection; applications		One method for detecting fraud is to check for suspicious changes in user behavior. This paper describes the automatic design of user profiling methods for the purpose of fraud detection, using a series of data mining techniques. Specifically, we use a rule-learning program to uncover indicators of fraudulent behavior from a large database of customer transactions. Then the indicators are used to create a set of monitors, which profile legitimate customer behavior and indicate anomalies. Finally, the outputs of the monitors are used as features in a system that learns to combine evidence to generate high-confidence alarms. The system has been applied to the problem of detecting cellular cloning fraud based on a database of call records. Experiments indicate that this automatic approach performs better than hand-crafted methods for detecting fraud. Furthermore, this approach can adapt to the changing conditions typical of fraud detection environments.	NYNEX Sci & Technol, White Plains, NY 10604 USA	Fawcett, T (reprint author), NYNEX Sci & Technol, 400 Westchester Ave, White Plains, NY 10604 USA.	fawcett@nynexst.com; foster@nynexst.com					Aronis J. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Aronis J., 1996, P 2 INT C KNOWL DISC, P355; BUCHANAN BG, 1978, PATTERN DIRECTED INF, P297; Chatfield C., 1984, ANAL TIME SERIES INT; CLEARWATER SH, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P24, DOI 10.1109/TAI.1990.130305; DAVIS A, 1993, 13 INT C ART INT EXP, V2, P155; DEMARIA R, 1996, CELLULAR BUSINESS, P24; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P117; EZAWA K, 1995, P 1 INT C KNOWL DISC, P100; EZAWA K, 1996, IEEE EXPERT, P45; Farnum N.R., 1989, QUANTITATIVE FORECAS; FAWCETT T., 1996, P 2 INT C KNOWL DISC, P8; FRANK J, 1994, NAT COMP SEC C, V1, P22; HERZOG J, 1995, BEWARE HURRICANE CLO; Kittler J., 1986, HDB PATTERN RECOGNIT, P59; Kumar S., 1995, THESIS PURDUE U; Nilsson Nils J., 1965, LEARNING MACHINES; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost FJ, 1996, MACH LEARN, V23, P33; Quinlan J. R., 1987, P 10 INT JOINT C ART, P304; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; REDDEN M, 1996, CELLULAR BUSINESS, P84; SEGAL R, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P619; SMYTH P, 1994, PATTERN RECOGN, V27, P149, DOI 10.1016/0031-3203(94)90024-8; STEWARD S, 1997, CELLULAR BUSINESS, V23; Stolfo S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; SUNDARAM A, 1996, ACM CROSSROADS, V2; WALTERS D, 1994, MOBILE PHONE NEWS, P4; WEBB GI, 1995, J ARTIFICIAL INTELLI, V3, P383; Young P. C., 1984, RECURSIVE ESTIMATION; YUHAS BP, 1995, LEARNING STRUCTURE T; YUHAS BP, 1993, NEURAL NETW INNS, P239	33	217	222	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	1997	1	3					291	316		10.1023/A:1009700419189		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA829	WOS:000072406200004	
J	Salzberg, SL				Salzberg, SL			On comparing classifiers: Pitfalls to avoid and a recommended approach	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						classification; comparative studies; statistical methods		An important component of many data mining projects is finding a good classification algorithm, a process that requires very careful thought about experimental design. If not done very carefully comparative studies of classification and other types of algorithms can easily result in statistically invalid conclusions. This is especially true when one is using data mining techniques to analyze very large databases. which inevitably contain some statistically unlikely data. This paper describes several phenomena that can. if ignored, invalidate an experimental comparison. These phenomena and the conclusions that follow apply nor only to classification but to computational experiments in almost any aspect of data mining. The paper also discusses why comparative analysis is more important in evaluating some types of algorithms than for others. and provides some suggestions about how to avoid the pitfalls suffered by many experimental studies.	Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	Salzberg, SL (reprint author), Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.		Salzberg, Steven/F-6162-2011				AHA D. W., 1992, P 9 INT C MACH LEARN, P1; Cochran W, 1957, EXPT DESIGNS; COHEN PR, 1997, 6 INT WORKSH ART INT, P115; DENTON FT, 1985, REV ECON STAT, V67, P124, DOI 10.2307/1928442; DIETTERICH T, 1996, STAT TESTS COMP SUPE; Everitt B. S., 1977, ANAL CONTINGENCY TAB; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FEELDERS A, 1995, 5 INT WORKSH ART INT, P219; Flexer A., 1996, Cybernetics and Systems '96. Proceedings of the Thirteenth European Meeting on Cybernetics and Systems Research; Gascuel O., 1992, P 10 EUR C ART INT E, P435; Hildebrand D. K., 1986, STAT THINKING BEHAV; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JENSEN D, 1991, P 1991 KNOWL DISC DA, P148; JENSEN D, 1995, LABELING SPACE TOOL; Kibler D., 1988, P 3 EUR WORK SESS LE, P81; Kohavi R., 1995, P 14 INT JOINT C ART, P1071; L. Prechelt, 1996, NEURAL NETWORKS, V9; Marsden Peter V., 1995, SOCIOL METHODOL, P111; Murphy P. M., 1995, UCI REPOSITORY MACHI; QIAN N, 1988, J MOL BIOL, V202, P65; Sejnowski T. J., 1987, Complex Systems, V1; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wolpert D. H., 1992, Complex Systems, V6	24	222	223	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	1997	1	3					317	328		10.1023/A:1009752403260		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA829	WOS:000072406200005	
J	Fayyad, UM				Fayyad, UM			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Microsoft Res, Redmond, WA 98052 USA	Fayyad, UM (reprint author), Microsoft Res, Redmond, WA 98052 USA.						BRACHMAN R, 1996, COMMUNICATIONS A NOV; FAYYAD U, 1995, P AAAI 94 WORKSH KNO; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FAYYAD UM, 1995, P 1 INT C KNOWL DISC; KETTENRING J, 1996, STAT MASSIVE DATA SE; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Simoudis E., 1996, P 2 INT C KNOWL DISC	7	15	16	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					5	10		10.1023/A:1009715820935		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900001	
J	Glymour, C; Madigan, D; Pregibon, D; Smyth, P				Glymour, C; Madigan, D; Pregibon, D; Smyth, P			Statistical themes and lessons for data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						statistics; uncertainty; modeling; bias; variance	MODEL UNCERTAINTY	Data mining is on the interface of Computer Science and Statistics, utilizing advances in both disciplines to make progress in extracting information from large databases. It is an emerging field that has attracted much attention in a very short period of time. This article highlights some statistical themes and lessons that are directly relevant to data mining and attempts to identify opportunities where close cooperation between the statistical and computational communities might reasonably provide synergy for further progress in data analysis.	Carnegie Mellon Univ, Dept Cognit Psychol, Pittsburgh, PA 15213 USA; Univ Washington, Dept Stat, Seattle, WA 98195 USA; AT&T Bell Labs, Stat Res, Murray Hill, NJ 07974 USA; Univ Calif Irvine, Irvine, CA 92717 USA	Glymour, C (reprint author), Carnegie Mellon Univ, Dept Cognit Psychol, Pittsburgh, PA 15213 USA.	cg09@andrew.cmu.edu; madigan@stat.washington.edu; daryl@research.att.com; smyth@ics.uci.edu					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BERGER JO, 1987, J AM STAT ASSOC, V82, P112, DOI 10.2307/2289131; BREIMAN L, 1996, IN PRESS MACHINE LEA; CHASNOFF IJ, 1989, JAMA-J AM MED ASSOC, V261, P1741, DOI 10.1001/jama.261.12.1741; CHATFIELD C, 1995, J ROY STAT SOC A STA, V158, P419, DOI 10.2307/2983440; DALAL SR, 1989, J AM STAT ASSOC, V84, P945, DOI 10.2307/2290069; DIGGLE P, 1994, APPL STAT-J ROY ST C, V43, P49, DOI 10.2307/2986113; DRAPER D, 1995, J ROY STAT SOC B MET, V57, P45; DRAPER D, 1993, COMBINGING INFORMATI; Efron B., 1993, INTRO BOOSTRAP; Fisher R. A., 1958, STAT METHODS RES WOR; FREEDMAN DA, 1983, AM STAT, V37, P152, DOI 10.2307/2685877; GEIGER D, 1996, P 12 ANN C UNC ART I; Gilks W., 1996, MARKOV CHAIN MONTE C; HAND DJ, 1994, J ROY STAT SOC A STA, V157, P317, DOI 10.2307/2983526; Hastie T.J., 1990, GEN ADDITIVE MODELS; HOERL RW, 1993, AM STAT, V47, P280, DOI 10.2307/2685288; Huber P.J., 1981, ROBUST STAT; JEFFREYS H, 1980, BAYESIAN ANAL ECONOM, P451; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; KIIVERI H, 1982, SOCIOL METHODOL, P209; KOOPERBERG C, 1996, IN PRESS J AM STAT A; Lauritzen SL, 1996, GRAPHICAL MODELS; Leamer E.E., 1978, SPECIFICATION SEARCH; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; Madigan D., 1994, J AM STAT ASSOC, V89, P1335; MATHESON JE, 1976, MANAGE SCI, V22, P1087, DOI 10.1287/mnsc.22.10.1087; McCullagh P, 1989, GEN LINEAR MODELS; MICHELANGELI PA, 1995, J ATMOS SCI, V52, P1237, DOI 10.1175/1520-0469(1995)052<1237:WRRAQS>2.0.CO;2; MILLER RG, 1981, SIMULTANEOUS STAT IN; Neyman J, 1933, PHILOS T R SOC LOND, V231, P289, DOI 10.1098/rsta.1933.0009; PEARL J, 1990, R155 UCLA COMP SCI D; PEARL J, 1991, P 2 INT C; Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.1093/biomet/82.4.669; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SCHEINES R, 1995, CMUPHIL66 DE PHIL; Scheines Richard, 1994, TETRAD 2 USERS MANUA; Schervish M. J., 1995, THEORY STAT; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SELVIN HC, 1966, AM STAT, V20, P20, DOI 10.2307/2681493; SIMPSON EH, 1951, J ROY STAT SOC B, V13, P238; SMITH AFM, 1993, J ROY STAT SOC B MET, V55, P3; Spirtes P., 1993, SPRINGER LECT NOTES; Spirtes P, 1995, P 11 C UNC ART INT U, P499; Spirtes P, 1995, P 1 INT C KNOWL DISC, P294; SPIRTES P, 1997, IN PRESS P C AI STAT; Stigler Stephen M., 1986, HIST STAT MEASUREMEN; WEN SW, 1995, JAMA-J AM MED ASSOC, V274, P1687, DOI 10.1001/jama.274.21.1687; Wright S., 1921, J AGR RES, V20, P557; *EN MOD FOR, 1982, 6 EMF STANF U EN MOD	51	71	77	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					11	28		10.1023/A:1009773905005		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900002	
J	Gray, J; Chaudhuri, S; Bosworth, A; Layman, A; Reichart, D; Venkatrao, M; Pellow, F; Pirahesh, H				Gray, J; Chaudhuri, S; Bosworth, A; Layman, A; Reichart, D; Venkatrao, M; Pellow, F; Pirahesh, H			Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data cube; data mining; aggregation; summarization; database; analysis; query		Data analysis applications typically aggregate data across many dimensions looking for anomalies or unusual patterns. The SQL aggregate functions and the GROUP BY operator produce zero-dimensional or one-dimensional aggregates. Applications need the N-dimensional generalization of these operators. This paper defines that operator, called the data cube or simply cube. The cube operator generalizes the histogram, cross-tabulation, roll-up, drill-down, and sub-total constructs found in most report writers. The novelty is that cubes are relations. Consequently, the cube operator can be imbedded in more complex non-procedural data analysis programs. The cube operator treats each of the N aggregation attributes as a dimension of N-space. The aggregate of a particular set of attribute values is a point in this space. The set of points forms an N-dimensional cube. Super-aggregates are computed by aggregating the N-cube to lower dimensional spaces. This paper (1) explains the cube and roll-up operators, (2) shows how they fit in SQL, (3) explains how users can define new aggregate functions for cubes, and (4) discusses efficient techniques to compute the cube. Many of these features are being added to the SQL Standard.	Microsoft Corp, Adv Technol Div, Microsoft Res, Redmond, WA 98052 USA; IBM Res Corp, San Jose, CA 95120 USA	Gray, J (reprint author), Microsoft Corp, Adv Technol Div, Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.						AGRAWAL R, 1996, P 21 VLDB BOMB; CHAMBERLIN D, 1996, USING NEW DB2 IBMS O; Date C.J., 1995, INTRO DATABASE SYSTE; DATE CJ, 1996, DATABASE PROGRAMMING, V9, P17; EARLE RJ, 1994, Patent No. [5359724, 05359724]; GRAEFE G, 1993, COMPUT SURV, V25, P73; GRAY J, 1991, BENCHMARK HDB; GRAY J, 1996, P INT C DAT ENG NEW; Gray J., 1993, BENCHMARK HDB DATABA; Harinarayan V., 1996, P ACM SIGMOD INT C M, P205, DOI 10.1145/233269.233333; MELTON J, 1996, MCI006 ISO IEC DBL 4; MELTON J, 1992, 9077 ISO IEC; Melton J, 1993, UNDERSTANDING NEW SQ; SHUKLA A, 1996, P 21 VLDB BOMB; *INF SOFTW, 1996, DAT DEV KIT US GUID; *MICR, 1994, MICR ACC REL DAT MAN; *MICR, 1995, MICR EXC US GUID; *MICR CORP, 1996, 63900 MICR CORP; *RED BRICK SYST, 1994, RISQL REF GUID RED B	19	275	298	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					29	53		10.1023/A:1009726021843		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900003	
J	Friedman, JH				Friedman, JH			On bias, variance, 0/1 - Loss, and the curse-of-dimensionality	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						classification; bias; variance; curse-of-dimensionality; bagging; naive Bayes; nearest-neighbors		The classification problem is considered in which an output variable y assumes discrete values with respective probabilities that depend upon the simultaneous values of a set of input variables x = {x(1),..., x(n)}. At issue is how error in the estimates of these probabilities affects classification error when the estimates are used in a classification rule. These effects are seen to be somewhat counter intuitive in both their strength and nature. In particular the bias and variance components of the estimation error combine to influence classification in a very different way than with squared error on the probabilities themselves. Certain types of (very high) bias can be canceled by low variance to produce accurate classification. This can dramatically mitigate the effect of the bias associated with some simple estimators like "naive" Bayes, and the bias induced by the curse-of-dimensionality on nearest-neighbor procedures. This helps explain why such simple methods are often competitive with and sometimes superior to more sophisticated ones for classification, and why "bagging/aggregating" classifiers can often improve accuracy. These results also suggest simple modifications to these procedures that can (sometimes dramatically) further improve their classification performance.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Univ, Stanford Linear Accelerator Ctr, Stanford, CA 94305 USA	Friedman, JH (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.						Bellman R., 1961, ADAPTIVE CONTROL PRO; Breiman L., 1996, BIAS VARIANCE ARCING; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 1995, BAGGING PREDICTORS; CHOW WS, 1992, PATTERN RECOGN, V25, P423; Dietterich TG, 1995, MACHINE LEARNING BIA; Efron B., 1995, CROSS VALIDATION BOO; FIX E, 1951, 4 US AIRF SCH AV MED; FRIEDMAN JH, 1985, LCS012 STANF U DEP S; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Good I. J., 1965, ESTIMATION PROBABILI; Hand D. J., 1982, KERNEL DISCRIMINANT; Heckerman David, 1994, P 10 C UNC ART INT, P293; Henley WE, 1996, STATISTICIAN, V45, P77, DOI 10.2307/2348414; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1996, BIAS PLUS VARIANCE D; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Langley P, 1992, P 10 NAT C ART INT, P223; LIPPMANN RP, 1989, IEEE COMMUNICATION M, V11, P47; McLachlan G., 1992, DISCRIMINANT ANAL ST; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; ROSEN DB, 1995, WORKSH MACH LEARN NE; Tibshirani Robert, 1996, BIAS VARIANCE PREDIC; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918	24	222	225	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					55	77		10.1023/A:1009778005914		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900004	
J	Heckerman, D				Heckerman, D			Bayesian networks for data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Review						Bayesian networks; Bayesian statistics; learning; missing data; classification; regression; clustering; causal discovery	BELIEF NETWORKS; PROBABILISTIC INFERENCE; GRAPHICAL MODELS; INFLUENCE DIAGRAMS; EXPERT-SYSTEMS; INFORMATION; PROPAGATION; UNCERTAINTY; LIKELIHOOD; COMPLEXITY	A Bayesian network is a graphical model that encodes probabilistic relationships among variables of interest. When used in conjunction with statistical techniques, the graphical model has several advantages for data modeling. One, because the model encodes dependencies among all variables, it readily handles situations where some data entries are missing. Two, a Bayesian network can be used to learn causal relationships, and hence can be used to gain understanding about a problem domain and to predict the consequences of intervention. Three, because the model has both a causal and probabilistic semantics, it is an ideal representation for combining prior knowledge (which often comes in causal form) and data. Four, Bayesian statistical methods in conjunction with Bayesian networks offer an efficient and principled approach for avoiding the overfitting of data. In this paper, we discuss methods for constructing Bayesian networks from prior knowledge and summarize Bayesian statistical methods for using data to improve these models. With regard to the latter task, we describe methods for learning both the parameters and structure of a Bayesian network, including techniques for learning with incomplete data. In addition, we relate Bayesian-network methods for learning to techniques for supervised and unsupervised learning. We illustrate the graphical-modeling approach using a real-world case study.	Microsoft Corp, Res, Redmond, WA 98052 USA	Heckerman, D (reprint author), Microsoft Corp, Res, 9S, Redmond, WA 98052 USA.						ALIFERIS C, 1994, P 10 C UNC ART INT S, P8; BADSBERG J, 1992, COMPUTATION STAT, P251; BECKER S, 1989, P 1988 CONN MOD SUMM, P29; Bernardo J, 1994, BAYESIAN THEORY; BERNARDO JM, 1979, ANN STAT, V7, P686, DOI 10.1214/aos/1176344689; Braithwaite R.B., 1931, FDN MATH OTHER LOGIC; BUNTINE W, 1993, ARTIFICIAL INTELLIGE, V3; Buntine W., 1991, P 7 C UNC ART INT, p[52, 524]; Buntine W., 1994, J ARTIFICIAL INTELLI, V2, P159; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; CHALONER KM, 1983, STATISTICIAN, V32, P174, DOI 10.2307/2987609; Cheeseman P., 1995, ADV KNOWLEDGE DISCOV; Chib S, 1995, J AM STAT ASSOC, V90, P1313, DOI 10.2307/2291521; CHICKERING D, 1996, P 12 C UNC ART INT P; Chickering D. M., 1995, P 11 C UNC ART INT, p[87, 515]; CHICKERING DM, 1996, MSRTR9608; COOPER G, 1991, SMI911 STANF U SECT; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; COX RT, 1946, AM J PHYS, V14, P1, DOI 10.1119/1.1990764; DAGUM P, 1993, ARTIF INTELL, V60, P141, DOI 10.1016/0004-3702(93)90036-B; DAMBROSIO B, 1991, P 7 C UNC ART INT LO, P95; DARWICHE A, 1995, P 12 C UNC ART INT P, P203; Dawid A. P., 1992, Statistics and Computing, V2, DOI 10.1007/BF01890546; DAWID AP, 1984, J ROYAL STATISTICA A, V147, P178; de Finetti B., 1970, THEORY PROBABILITY; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DICICCIO T, 1995, 630 CARN MELL U DEP; FRIEDMAN J, 1996, DATA MINING KNOWLEDG, V1; FRIEDMAN J, 1995, INTRO COMPUTATIONAL; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; FRYDENBERG M, 1990, SCAND J STAT, V17, P333; GEIGER D, 1995, MSRTR9416; GEIGER D, 1996, P 12 C UNC ART INT P; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Gilks W. R., 1995, MARKOV CHAIN MONTE C; Good I. J., 1950, PROBABILITY WEIGHING; Heckerman D., 1995, P 11 C UNC ART INT, P285; HECKERMAN D, 1996, MSRTR95454; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Heckerman D., 1989, P 5 WORKSH UNC ART I, P174; Heckerman D, 1995, J ARTIF INTELL RES, V3, P405; HECKMAN D, 1995, COMMUNICATIONS ACM, V38; HENRION M, 1990, UNCERTAINTY ARTIFICI, V5, P163; HOJSGAARD S, 1994, USERS GUIDE BIOFROST; HOWARD R, 1983, PRINCIPLES APPL DECI; HOWARD RA, 1970, PR INST ELECTR ELECT, V58, P632, DOI 10.1109/PROC.1970.7719; Howard R.A., 1981, READINGS PRINCIPLES, V2, P721; Humphreys P, 1996, BRIT J PHILOS SCI, V47, P113, DOI 10.1093/bjps/47.1.113; JAAKKOLA T, 1996, P 12 C UNC ART INT P, P240; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Jensen F. V., 1990, COMPUTATIONAL STATIS, V4, P269; Kass R., 1988, BAYESIAN STATISTICS, P261; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; Koopman BO, 1936, T AM MATH SOC, V39, P399, DOI 10.2307/1989758; LAURITZEN S, 1994, LECT NOTES STAT, V89, P143; Lauritzen S.L., 1982, LECT CONTINGENCY TAB; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LAURITZEN SL, 1992, J AM STAT ASSOC, V87, P1098, DOI 10.2307/2290647; MACKAY D, 1996, CHOICE BASIS LAPLACE; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MADIGAN D, 1995, COMMUN STAT THEORY, V24, P2271, DOI 10.1080/03610929508831616; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; MADIGAN D, 1996, P AAAI WORKSH INT MU; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; Martin J., 1995, DISCRETE FACTOR ANAL; MENG XL, 1991, J AM STAT ASSOC, V86, P899, DOI 10.2307/2290503; Neal R. M., 1993, CRGTR931 U TOR DEP C; OLMSTED SM, 1983, THESIS STANFORD U; Pearl J., 1991, KNOWLEDGE REPRESENTA, P441; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.1093/biomet/82.4.669; Pitman EJG, 1936, P CAMB PHILOS SOC, V32, P567; RAFTERY A, 1996, IN PRESS PRACTICAL M; Raftery A.E., 1995, SOCIOLOGICAL METHODO; RAMAMURTHI K, 1988, COMPUTERS ENG, P333; RISSANEN J, 1987, J ROY STAT SOC B MET, V49, P223; RISSANEN J, 1987, J ROYAL STAT SOC B, V49, P253; ROBINS J, 1986, MATH MODELLING, V7, P1393, DOI 10.1016/0270-0255(86)90088-6; RUBIN DB, 1978, ANN STAT, V6, P34, DOI 10.1214/aos/1176344064; Russell S., 1995, P 14 INT JOINT C ART, P1146; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; Savage L.J., 1954, FDN STAT; Scheines R., 1993, CAUSATION PREDICTION; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SEWELL WH, 1968, AM J SOCIOL, V73, P559, DOI 10.1086/224530; SHACHTER R, 1990, P 6 C UNC ART INT BO, P237; SHACHTER RD, 1988, OPER RES, V36, P589, DOI 10.1287/opre.36.4.589; SHACHTER RD, 1989, MANAGE SCI, V35, P527, DOI 10.1287/mnsc.35.5.527; Silverman B. W., 1986, DENSITY ESTIMATION S; SINGH M, 1995, MSCIS9536 U PENNS CO; SPETZLER CS, 1975, MANAGE SCI, V22, P340, DOI 10.1287/mnsc.22.3.340; SPIEGELHALTER DJ, 1993, STAT SCI, V8, P219, DOI 10.1214/ss/1177010888; SPIEGELHALTER DJ, 1990, NETWORKS, V20, P579, DOI 10.1002/net.3230200507; Spirtes P, 1995, P 1 INT C KNOWL DISC; Suermondt H. J., 1991, International Journal of Approximate Reasoning, V5, DOI 10.1016/0888-613X(91)90028-K; Thiesson B., 1995, P 1 INT C KNOWL DISC, P306; THIESSON B, 1995, SCORE INFORMATION RE; Thomas A., 1992, BAYESIAN STATISTICS, V4, P837; Tukey J.W., 1977, EXPLORATORY DATA ANA; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; Verma T. S., 1990, P 6 C UNC ART INT, P220; WINKLER RL, 1967, J AM STAT ASSOC, V62, P776, DOI 10.2307/2283671; WITTAKER J, 1990, GRAPHICAL MODELS APP	105	162	202	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					79	119		10.1023/A:1009730122752		41	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900005	
J	Bhandari, I; Colet, E; Parker, J; Pines, Z; Pratap, R; Ramanujam, K				Bhandari, I; Colet, E; Parker, J; Pines, Z; Pratap, R; Ramanujam, K			Advanced scout: Data mining and knowledge discovery in NBA data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; knowledge discovery; attribute focusing; basketball; NBA		Advanced Scout is a PC-based data mining application used by National Basketball Association (NBA) coaching staffs to discover interesting patterns in basketball game data. We describe Advanced Scout software from the perspective of data mining and knowledge discovery. This paper highlights the pre-processing of raw data that the program performs, describes the data mining aspects of the software and how the interpretation of patterns supports the process of knowledge discovery. The underlying technique of attribute focusing as the basis of the algorithm is also described. The process of pattern interpretation is facilitated by allowing the user to relate patterns to video tape.	IBM Corp, TJ Watson Res Ctr, Armonk, NY 10504 USA	Bhandari, I (reprint author), IBM Corp, TJ Watson Res Ctr, Armonk, NY 10504 USA.						BHANDARI I, 1993, IEEE T SOFTWARE ENG, V19, P1157, DOI 10.1109/32.249661; BHANDARI IS, 1995, 20136 RC IBM TJ WATS; CELKO J, 1995, DATAMATION, V41, P42; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; MCMURRAY S, 1995, US NEWS WORLD R 1211, P79; Redman T.C., 1992, DATA QUALITY MANAGEM; STERBA J, 1996, WALL STREET J   0322, P7	7	23	24	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					121	125		10.1023/A:1009782106822		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900006	
J	Fayyad, U				Fayyad, U			Untitled	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material									Microsoft Res, Redmond, WA 98052 USA	Fayyad, U (reprint author), Microsoft Res, Redmond, WA 98052 USA.							0	1	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	2					137	139		10.1023/A:1009771407489		3	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA828	WOS:000072406100001	
J	Zhang, T; Ramakrishnan, R; Livny, M				Zhang, T; Ramakrishnan, R; Livny, M			BIRCH: A new data clustering algorithm and its applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						very large databases; data clustering; incremental algorithm; data classification and compression	MODELS	Data clustering is an important technique for exploratory data analysis, and has been studied for several years. It has been shown to be useful in many practical domains such as data classification and image processing. Recently, there has been a growing emphasis on exploratory analysis of very large datasets to discover useful patterns and/or correlations among attributes. This is called data mining, and data clustering is regarded as a particular branch. However existing data clustering methods do not adequately address the problem of processing large datasets with a limited amount of resources (e.g., memory and cpu cycles). So as the dataset size increases, they do not scale up well in terms of memory requirement, running time, and result quality. In this paper, an efficient and scalable data clustering method is proposed, based on a new in-memory data structure called CF-tree, which serves as an in-memory summary of the data distribution. We have implemented it in a system called BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and studied its performance extensively in terms of memory requirements, running time, clustering quality, stability and scalability; we also compare it with other available methods. Finally, BIRCH is applied to solve two real-life problems: one is building an iterative and interactive pixel classification tool, and the other is generating the initial codebook for image compression.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	Zhang, T (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.	zhang@cs.wisc.edu; raghu@cs.wisc.edu; miron@cs.wisc.edu					BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; CHEESEMAN P, 1988, P 5 INT C MACH LEARN; CHENG M, 1995, P IS T SPIE C VIS DA; DUBES R, 1980, ADV COMPUTERS, V19; Duda R., 1973, PATTERN CLASSIFICATI; ESTER M, 1995, P 4 INT S LARG SPAT; FEIGENBAUM EA, 1984, COGNITIVE SCI, V8, P305, DOI 10.1207/s15516709cog0804_1; FISHER D, 1987, MACHINE LEARNING, V2; FISHER DH, 1995, CS9501 VAND U DEP CO; GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5; Gersho A., 1992, VECTOR QUANTIZATION; Guttman A., 1984, P ACM SIGMOD INT C M, P47; Hartigan J. A., 1979, APPL STAT, V28; HUANG C, 1992, IEEE T IMAGE PROCESS, V1; Kaufman L., 1990, WILEY SERIES PROBABI; Kou W., 1995, DIGITAL IMAGE COMPRE; KUCHARIK CJ, 1996, UNPUB J GEOPHYSICAL; KUCHARIK CJ, 1996, P 22 C AGR FOR MET A; LEBOWITZ M, 1987, EXPT INCREMENTAL CON; Lee RCT, 1981, ADV INFORMATION SYST, V8, P169; Linde Y., 1980, IEEE T COMMUNICATION, V28; MURTAGH F, 1983, COMPUTER J; NG RT, 1994, P VLDB; Olson C.F., 1993, PARALLEL ALGORITHMS; Rabbani M., 1991, DIGITAL IMAGE COMPRE; Xu X., 1995, P 1 INT C KNOWL DISC; ZHANG T, 1996, THESIS U WISCONSIN M; ZHANG T, 1995, BIRCH EFFICIENT DATA	28	124	130	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	2					141	182		10.1023/A:1009783824328		42	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA828	WOS:000072406100002	
J	Mangasarian, OL				Mangasarian, OL			Mathematical programming in data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						mathematical programming; feature selection; clustering; robust representation	POLYNOMIAL-TIME ALGORITHM	Mathematical programming approaches to three fundamental problems will be described: feature selection, clustering and robust representation. The feature selection problem considered is that of discriminating between two sets while recognizing irrelevant and redundant features and suppressing them. This creates a lean model that often generalizes better to new unseen data. Computational results on real data confirm improved generalization of leaner models. Clustering is exemplified by the unsupervised learning of patterns and clusters that may exist in a given database and is a useful tool for knowledge discovery in databases (KDD). A mathematical programming formulation of this problem is proposed that is theoretically justifiable and computationally implementable in a finite number of steps. A resulting k-Median Algorithm is utilized to discover very useful survival curves for breast cancer patients from a medical database. Robust representation is concerned with minimizing trained model degradation when applied to new problems. A novel approach is proposed that purposely tolerates a small error in the training process in order to avoid overfitting data that may contain errors. Examples of applications of these concepts are given.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	Mangasarian, OL (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.						ALSULTAN KS, 1995, PATTERN RECOGN, V28, P1443, DOI 10.1016/0031-3203(95)00022-R; Bennet K.P., 1992, ADV OPTIMIZATION PAR, P56; BENNETT KP, 1997, IN PRESS GEOMETRY WO; Bennett K. P., 1993, Computational Optimization and Applications, V2, DOI 10.1007/BF01299449; Bennett K.P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bertsekas D. P, 1989, PARALLEL DISTRIBUTED; Bertsekas D.P., 1995, NONLINEAR PROGRAMMIN; BIXBY RE, 1992, OPER RES, V40, P885, DOI 10.1287/opre.40.5.885; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Bradley PS, 1997, ADV NEUR IN, V9, P368; BRADLEY PS, 1995, UNPUB INFORMS J COMP; BREDENSTEINER EJ, 1995, 218 RENSS POL I DEP; CORDELLIER F, 1978, MATH PROGRAM, V14, P295, DOI 10.1007/BF01588972; Dantzig G., 1963, LINEAR PROGRAMMING E; DELEONE R, 1993, CONCURRENCY-PRACT EX, V5, P623, DOI 10.1002/cpe.4330050802; DELEONE R, 1988, LECTURE NOTES EC MAT, V304, P103; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Ferris MC, 1994, SIAM J OPTIMIZ, V4, P815, DOI 10.1137/0804047; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Floudas C., 1995, NONLINEAR MIXED INTE; Fukunaga K., 1990, STAT PATTERN RECOGNI; GAIVORONSKI AA, 1994, OPTIMIZATION METHODS, V4; Garfinkel R. S., 1972, INTEGER PROGRAMMING; GLOVER F, 1990, DECISION SCI, V21, P771, DOI 10.1111/j.1540-5915.1990.tb01249.x; GRINOLD RC, 1972, MANAGE SCI, V19, P272, DOI 10.1287/mnsc.19.3.272; Hassoun M. H., 1995, FUNDAMENTALS ARTIFIC; Hertz J, 1991, INTRO THEORY NEURAL; Hillier F., 1995, INTRO OPERATIONS RES; Huber P.J., 1981, ROBUST STAT; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Jain A.K., 1988, ALGORITHMS CLUSTERIN; John G. H., 1994, P 11 INT C MACH LEAR; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; KARLIN S, 1992, MATH METHODS THEORY, V2; KARLIN S, 1992, MATH METHODS THEORY, V1; KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150; Klarbring A, 1993, COMPUTATIONAL METHOD, P233; Kleinbaum DG, 1996, SURVIVAL ANAL; Le Cun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Lustig I. J., 1994, ORSA Journal on Computing, V6; MANGASARIAN O. L., 1996, APPL MATH PARALLEL C, P175; Mangasarian O. L., 1994, OPTIMIZATION METHODS, V4, P103, DOI 10.1080/10556789408805581; Mangasarian O. L., 1969, NONLINEAR PROGRAMMIN; MANGASARIAN OL, 1979, SIAM J CONTROL OPTIM, V17, P745, DOI 10.1137/0317052; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Mangasarian O. L., 1993, ORSA Journal on Computing, V5; Mangasarian OL, 1996, NONLINEAR OPTIMIZATION AND APPLICATIONS, P283; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; MLADENIC D, 1993, P 10 INT C MACH LEAR, P205; Murphy PM, 1992, UCI REPOSITORY MACHI; Murty K. G, 1983, LINEAR PROGRAMMING; Murty K. G., 1992, NETWORK PROGRAMMING; MURTY KG, 1995, OPERATIONS RES; Nemhauser G.L., 1988, INTEGER COMBINATORIA; OVERTON ML, 1983, MATH PROGRAM, V27, P34, DOI 10.1007/BF02591963; Panagiotopoulos P. D., 1985, INEQUALITY PROBLEMS; RAO MR, 1971, J AM STAT ASSOC, V66, P622, DOI 10.2307/2283542; Rockafellar R., 1984, NETWORK FLOWS MONOTR; Rockafellar R. T., 1970, CONVEX ANAL; ROY A, 1993, NEURAL NETWORKS, V6, P535, DOI 10.1016/S0893-6080(05)80057-7; Rumelhart D, 1986, PARALLEL DISTRIBUTED; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; Shavlik J. W., 1990, READINGS MACHINE LEA; SMITH FW, 1968, IEEE T COMPUT, VC 17, P367, DOI 10.1109/TC.1968.229395; STREET WN, 1998, IN PRESS J OPTIMIZAT, V96; TSYPKIN Y., 1973, FDN THEORY LEARNING; Vanderbei R. J., 1997, LINEAR PROGRAMMING F; Vapnik V.N., 1995, NATURE STAT LEARNING; von Neumann John, 1944, THEORY GAMES EC BEHA; WOLBERG WH, 1995, WPBC WISCONSIN PROGN; Wolpert D. H., 1995, MATH GEN; *CPLEX OPT INC, 1992, US CPLEX IM LIN OPT	73	58	60	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	2					183	201		10.1023/A:1009735908398		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA828	WOS:000072406100003	
J	Cooper, GF				Cooper, GF			A simple constraint-based algorithm for efficiently mining observational databases for causal relationships	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						causal discovery; data mining; observational data	BAYESIAN NETWORKS	This paper presents a simple, efficient computer-based method for discovering causal relationships from databases that contain observational data. Observational data is passively observed, as contrasted with experimental data. Most of the databases available for data mining are observational. There is great potential for mining such databases to discover causal relationships. We illustrate how observational data can constrain the causal relationships among measured variables, sometimes to the point that we can conclude that one variable is causing another variable. The presentation here is based on a constraint-based approach to causal discovery. A primary purpose of this paper is to present the constraint-based causal discovery method in the simplest possible fashion in order to (1) readily convey the basic ideas that underlie more complex constraint-based causal discovery techniques, and (2) permit interested readers to rapidly program and apply the method to their own databases, as a start toward using more elaborate causal discovery algorithms.	Univ Pittsburgh, Ctr Biomed Informat, Pittsburgh, PA 15213 USA	Cooper, GF (reprint author), Univ Pittsburgh, Ctr Biomed Informat, Suite 8084,Forbes Tower, Pittsburgh, PA 15213 USA.						ALIFERIS C, 1994, P 10 C UNC ART INT S, P8; ALMOND RG, 1997, WEB PAGE SOFTWARE LE; Bishop Y.M.M., 1975, DISCRETE MULTIVARIAT; BOUCKAERT RR, 1995, THESIS U UTRECHT UTR; Castillo E., 1997, EXPERT SYSTEMS PROBA; CHICKERING DM, 1996, P 12 C UNC ART INT S, P158; COOPER G, 1995, P 5 INT WORKSH ART I, P140; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; GEIGER D, 1990, NETWORKS, V20, P507, DOI 10.1002/net.3230200504; Heckerman D., 1996, MSRTR9506; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Herskovits E., 1991, THESIS STANFORD U; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Little RJA, 1987, STAT ANAL MISSING DA; Meek C., 1995, P 11 C UNC ART INT, P411; Pearl J., 1988, PROBABILISTIC REASON; PEARL J, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P441; PEARL J, 1994, R218L U CAL LOS ANG; PEARL J, 1996, P 12 C UNC ART INT, P420; Richardson T, 1996, P 12 C UNC ART INT, P454; Scheines R., 1993, CAUSATION PREDICTION; SCHEINES R, 1995, TETRAD, V2; Spirtes P, 1995, P 11 C UNC ART INT U, P499	23	48	51	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	2					203	224		10.1023/A:1009787925236		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA828	WOS:000072406100004	
J	Cox, KC; Eick, SG; Wills, GJ; Brachman, RJ				Cox, KC; Eick, SG; Wills, GJ; Brachman, RJ			Visual data mining: Recognizing telephone calling fraud	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						visualization; fraud; information discovery; interaction; telecommunications data mining		Human pattern recognition skills me remarkable and in many situations far exceed the ability of automated mining algorithms. By building domain-specific interfaces that present information visually, we can combine human detection with machines' far greater computational capacity. We illustrate our ideas by describing a suite of visual interfaces we built for telephone fraud detection.	AT&T Bell Labs, Lucent Technol, Naperville, IL 60566 USA	Cox, KC (reprint author), AT&T Bell Labs, Lucent Technol, Room 1G-351,1000 E Warrenville Rd, Naperville, IL 60566 USA.						ANTIS JM, 1996, IEEE SOFTWARE, P72; Ball T, 1996, COMPUTER, V29, P33, DOI 10.1109/2.488299; BECKER RA, 1995, IEEE T VIS COMPUT GR, V1, P16, DOI 10.1109/2945.468391; DIBATTISTA G, 1994, COMP GEOM-THEOR APPL, V4, P235; Eick SG, 1996, AT&T TECH J, V75, P74; EICK SG, 1993, VISUALIZATION 93, PROCEEDINGS, P204	6	31	31	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	2					225	231		10.1023/A:1009740009307		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA828	WOS:000072406100005	
